{"meta":{"title":"ZDK's blog","subtitle":null,"description":null,"author":"ZDK","url":"https://github.com/zdkswd"},"pages":[{"title":"categories","date":"2018-05-16T08:57:06.000Z","updated":"2018-05-16T08:58:10.000Z","comments":false,"path":"categories/index.html","permalink":"https://github.com/zdkswd/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-05-16T07:23:52.000Z","updated":"2018-05-16T08:58:32.000Z","comments":false,"path":"tags/index.html","permalink":"https://github.com/zdkswd/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"鸟哥 Linux账号管理","slug":"鸟哥 Linux账号管理","date":"2019-02-04T11:25:32.000Z","updated":"2019-02-04T11:27:05.000Z","comments":true,"path":"2019/02/04/鸟哥 Linux账号管理/","link":"","permalink":"https://github.com/zdkswd/2019/02/04/鸟哥 Linux账号管理/","excerpt":"","text":"鸟哥 Linux账号管理Linux的账号与群组使用者识别码：UID与GID当登录Linux主机时，输入的是账号，Linux 主机并不会直接认识你的帐号，他仅认识 ID，帐号只是为了让人们容易记忆而已，ID 与帐号的 对应就在 / etc /passwd 当中。 每个登陆的使用者至少都会取得两个 ID ，一个是使用者 ID (User ID ，简称 UID)、一个是群组 ID (Group ID ，简称 GID)。 文件是利用UID与GID来判别拥有者与群组。每一个文件都会有所谓的拥有者ID与拥有群组ID，当要显示文件属性时，系统会依据 / etc / passwd 与 / etc /group 的内容， 找到 UID / GID 对应的帐号与群组名称再显示出来。 使用者账号Linux 系统上面的使用者需要登陆主机以取得 shell工作环境，通过网络要使用ssh。输入账号密码后，系统做了工作： 先找寻 / etc / passwd里面是否有你输入的帐号，如果没有则跳出，如果有的话则将该帐号对应的 UID 与 GID (在 / etc / group 中) 读出来，另外，该帐号的主文件夹与 shell 设置也一并读出。 来则是核对密码表啦!这时Linux会进入 / etc / shadow里面找出对应的帐号与UID，然后核对一下你刚刚输入的密码与里头的密码是否相符。 一切都OK的话，就进入Shell控管的阶段 。 / etc / passwd 文件结构这个文件的构造是这样的:每一行都代表一个帐号，有几行就代表有几个帐号在你的系统中! 不过需要特别留意的是，里头很多帐号本来就是系统正常运行所必须要的，我们可以简称他为系统帐号， 例如 bin, daemon, adm, nobody 等等，这些帐号请不要随意的杀掉。 shadow中存储的密码单向运算。 遗忘密码 一般用户的密码忘记了:这个最容易解决，请系统管理员帮忙， 他会重新设置好你的密码而不需要知道你的旧密码!利用 root 的身份使用 passwd 指令来处理即可。 root密码忘记了，就比较麻烦了，但是可以使用各种可行的方法开机进入Linux再去修改。 关于群组：有效与初始群组，groups，newgrp/ etc / group文件结构这个文件就是在记录GID与群组名称的对应。 有效群组（effective group）与初始群组（initial group）每个使用者在他的passwd第四栏有所谓的GID，就是所谓的初始群组（initial group），也就是当使用者一登陆系统，立刻就拥有这个群组的相关权限。 groups有效与支持群组的观察知道所有的支持群组： 在这个输出的讯息中，可知道 dmtsai 这个用户同时属于 dmtsai, wheel 及 users 这三个群组，而且，第一个输出的群组即为有效群组 (effective group) 。 通常有效群组的作用在新建文件，确定新建文件所在的群组。 newgrp：有效群组的切换newgrp 是有限制的，那就是你想要 切换的群组必须是你已经有支持的群组。举例来说， dmtsai 可以在 dmtsai / wheel / users 这三 个群组间切换有效群组，但是 dmtsai 无法切换有效群组成为 sshd 。 加入一个群组有两个方式，一是通过系统管理员 (root) 利用 usermod 帮你加入，如果 root 太忙了而且你的系统有设置群组管理员，那么还可以通过群组管理员以 gpasswd 加入他所管理的群组中 。 / etc / gshadow以系统管理员的角度来说，这个 gshadow 最大的功能就是创建群组管理员。root 可能平时太忙碌，所以当有使 用者想要加入某些群组时， root 或许会没有空管理。此时如果能够创建群组管理员的话，那 么该群组管理员就能够将那个帐号加入自己管理的群组中! 可以免去 root 的忙碌啦!不过， 由于目前有类似 sudo 之类的工具， 所以这个群组管理员的功能已经很少使用了。 账号管理新增与移除使用者：useradd，相关配置文件，passwd，usermod，userdel创建一个可用的账号需要账号与密码两个数据，账号可以用useradd来新建使用者，密码则使用passwd。 系统会进行的操作： 在 / etc / passwd 里面创建一行与帐号相关的数据，包括创建 UID / GID / 主文件夹等 。 在 / etc / shadow 里面将此帐号的密码相关参数填入，但是尚未有密码。 在 / etc / group 里面加入一个与帐号名称一模一样的群组名称。 在 / home 下面创建一个与帐号同名的目录作为使用者主文件夹，且权限为 700。 由于在 / etc / shadow内仅会有密码参数而不会有加密过的密码数据，因此我们在创建使用者帐 号时， 还需要使用“ passwd 帐号 ”来给 密码才算是完成了使用者创建的流程。 以上是root来设置用户的权限。用户还可以自己来更改自己的密码。 使用chage来进行更详细的密码参数显示功能。 usermod在使用useradd后，可以利用usermod来对某些地方进行细部修改。 userdel 删除使用者的相关数据。 使用者功能一般身份使用者使用的指令。 idid 这个指令则可以查询某人或自己的相关 UID / GID 等等的信息 。 chsh就是change shell的简写。 新增与移除群组groupadd groupmod跟 usermod 类似的，这个指令仅是在进行 group 相关参数的修改而已。 groupdel gpasswd群组管理员功能 主机的细部权限规划：ACL的使用什么是ACL与如何支持启动ACLACL即Access Control List，传统的 Linux 权限只能针对一个用户、一个群组及非此群组的其他人设置权限而已，无法针对单一用户或个人来设计权限。而 ACL 就是为了要改变这个问题 。 ACL的设置技巧：getfacl，setfacl使用者身份切换susu 是最简单的身份切换指令了，可以进行任何身份的切换。 sudosu 需要了解新切换的使用者密码 (常常是需要 root 的密码)， sudo 的执行则仅需要 自己的密码即可! 甚至可以设置不需要密码即可执行 sudo 。由于 sudo可以让你以其他用 户的身份执行指令 (通常是使用 root 的身份来执行指令)，因此并非所有人都能够执行 sudo ， 而是仅有规范到 _etc_sudoers 内的用户才能够执行 sudo 这个指令。 一般用户能够具有 sudo 的使用权，就是管理员事先审核通过后，才开放sudo 的使用权的!因此，除非是信任用户，否则一般用户默认是不能操作 sudo的。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"廖雪峰SQL","slug":"廖雪峰SQL","date":"2019-02-03T05:22:32.000Z","updated":"2019-02-03T05:25:44.000Z","comments":true,"path":"2019/02/03/廖雪峰SQL/","link":"","permalink":"https://github.com/zdkswd/2019/02/03/廖雪峰SQL/","excerpt":"","text":"概述NoSQL数据库，也就是非SQL的数据库，包括MongoDB、Cassandra、Dynamo等等，它们都不是关系数据库。有很多人鼓吹现代Web程序已经无需关系数据库了，只需要使用NoSQL就可以。但事实上，SQL数据库从始至终从未被取代过。今天，SQL数据库仍然承担了各种应用程序的核心数据存储，而NoSQL数据库作为SQL数据库的补充，两者不再是二选一的问题，而是主从关系。所以，无论使用哪种编程语言，无论是Web开发、游戏开发还是手机开发，掌握SQL，是所有软件开发人员所必须的。 数据库作为一种专门管理数据的软件就出现了。应用程序不需要自己管理数据，而是通过数据库软件提供的接口来读写数据。至于数据本身如何存储到文件，那是数据库软件的事情，应用程序自己并不关心。 数据库按照数据结构来组织，存储和管理数据，数据库一共有三种模型。层次模型，网状模型，关系模型。关系模型把数据看作是一个二维表格，任何数据都可以通过行号+列号来唯一确定，它的数据模型看起来就是一个Excel表。 随着时间的推移和市场竞争，最终，基于关系模型的关系数据库获得了绝对市场份额。因为相比层次模型和网状模型，关系模型理解和使用起来最简单。 通过给定一个班级名称，可以查到一条班级记录，根据班级ID，又可以查到多条学生记录，这样，二维表之间就通过ID映射建立了“一对多”关系。 数据类型 表中列举了最常用的数据类型。很多数据类型还有别名，例如，REAL又可以写成FLOAT(24)。还有一些不常用的数据类型，例如，TINYINT（范围在0~255）。各数据库厂商还会支持特定的数据类型，例如JSON。 选择数据类型的时候，要根据业务规则选择合适的类型。通常来说，BIGINT能满足整数存储的需求，VARCHAR(N)能满足字符串存储的需求，这两种类型是使用最广泛的。 主流关系数据库目前主流关系数据库分为： 商用数据库，例如：Oracle，SQL Server，DB2等； 开源数据库，例如：MySQL，PostgreSQL等； 桌面数据库，以微软Access为代表，适合桌面应用程序使用； 嵌入式数据库，以Sqlite为代表，适合手机应用和桌面程序。 SQLSQL已经被ANSI组织定义为标准，不幸地是，各个不同的数据库对标准的SQL支持不太一致。并且，大部分数据库都在标准的SQL上做了扩展。也就是说，如果只使用标准SQL，理论上所有数据库都可以支持，但如果使用某个特定数据库的扩展SQL，换一个数据库就不能执行了。例如，Oracle把自己扩展的SQL称为PL/SQL，Microsoft把自己扩展的SQL称为T-SQL。 SQL语言关键字不区分大小写！！！但是，针对不同的数据库，对于表名和列名，有的数据库区分大小写，有的数据库不区分大小写。同一个数据库，有的在Linux上区分大小写，有的在Windows上不区分大小写。本文做出约定：SQL关键字总是大写，以示突出，表名和列名均使用小写。 MySQLMySQL是目前应用最广泛的开源关系数据库。MySQL经过几次收购就变成了Oracle旗下的产品。和其他关系数据库有所不同的是，MySQL本身实际上只是一个SQL接口，它的内部还包含了多种数据引擎，常用的包括： InnoDB：由Innobase Oy公司开发的一款支持事务的数据库引擎，2006年被Oracle收购； MyISAM：MySQL早期集成的默认数据库引擎，不支持事务。 MySQL接口和数据库引擎的关系就好比某某浏览器和浏览器引擎（IE引擎或Webkit引擎）的关系。对用户而言，切换浏览器引擎不影响浏览器界面，切换MySQL引擎不影响自己写的应用程序使用MySQL的接口。 使用MySQL时，不同的表还可以使用不同的数据库引擎。如果你不知道应该采用哪种引擎，记住总是选择InnoDB就好了。 由于MySQL是开源的，所以还有其衍生版本。 关系模型关系数据库是建立在关系模型上的。而关系模型本质上就是若干个存储数据的二维表，可以把它们看作很多Excel表。 表的每一行称为记录（Record），记录是一个逻辑意义上的数据。表的每一列称为字段（Column），同一个表的每一行记录都拥有相同的若干字段。 字段定义了数据类型（整型、浮点型、字符串、日期等），以及是否允许为NULL。注意NULL表示字段数据不存在。一个整型字段如果为NULL不表示它的值为0，同样的，一个字符串型字段为NULL也不表示它的值为空串’’。 通常情况下，字段应该避免允许为NULL。不允许为NULL可以简化查询条件，加快查询速度，也利于应用程序读取数据后无需判断是否为NULL。 和Excel表有所不同的是，关系数据库的表和表之间需要建立“一对多”，“多对一”和“一对一”的关系，这样才能够按照应用程序的逻辑来组织和存储数据。 在关系数据库中，关系是通过主键和外键来维护的。 主键对于关系表，有个很重要的约束，就是任意两条记录不能重复。不能重复不是指两条记录不完全相同，而是指能够通过某个字段唯一区分出不同的记录，这个字段被称为主键。 由于主键的作用十分重要，如何选取主键会对业务开发产生重要影响。如果我们以学生的身份证号作为主键，似乎能唯一定位记录。然而，身份证号也是一种业务场景，如果身份证号升位了，或者需要变更，作为主键，不得不修改的时候，就会对业务产生严重影响。 所以，选取主键的一个基本原则是：不使用任何业务相关的字段作为主键。 因此，身份证号、手机号、邮箱地址这些看上去可以唯一的字段，均不可用作主键。作为主键最好是完全业务无关的字段，我们一般把这个字段命名为id。常见的可作为id字段的类型有： 自增整数类型：数据库会在插入数据时自动为每一条记录分配一个自增整数，这样我们就完全不用担心主键重复，也不用自己预先生成主键； 全局唯一GUID类型：使用一种全局唯一的字符串作为主键，类似8f55d96b-8acc-4636-8cb8-76bf8abc2f57。GUID算法通过网卡MAC地址、时间戳和随机数保证任意计算机在任意时间生成的字符串都是不同的，大部分编程语言都内置了GUID算法，可以自己预算出主键。 对于大部分应用来说，通常自增类型的主键就能满足需求。我们在students表中定义的主键也是BIGINT NOT NULL AUTO_INCREMENT类型。如果使用INT自增类型，那么当一张表的记录数超过2147483647（约21亿）时，会达到上限而出错。使用BIGINT自增类型则可以最多约922亿亿条记录。 联合主键关系数据库实际上还允许通过多个字段唯一标识记录，即两个或更多的字段都设置为主键，这种主键被称为联合主键。对于联合主键，允许一列有重复，只要不是所有主键列都重复即可： id_num和id_type这两列作为联合主键。没有必要的情况下，我们尽量不使用联合主键，因为它给关系表带来了复杂度的上升。 外键在students表中，通过class_id的字段，可以把数据与另一张表关联起来，这种列称为外键。students表： classes表： 为了表达这种一对多的关系，我们需要在students表中加入一列class_id，让它的值与classes表的某条记录相对应。 在students表中，通过class_id的字段，可以把数据与另一张表关联起来，这种列称为外键。外键并不是通过列名实现的，而是通过定义外键约束实现的： 其中，外键约束的名称fk_class_id可以任意，FOREIGN KEY (class_id)指定了class_id作为外键，REFERENCES classes (id)指定了这个外键将关联到classes表的id列（即classes表的主键）。 通过定义外键约束，关系数据库可以保证无法插入无效的数据。即如果classes表不存在id=99的记录，students表就无法插入class_id=99的记录。 由于外键约束会降低数据库的性能，大部分互联网应用程序为了追求速度，并不设置外键约束，而是仅靠应用程序自身来保证逻辑的正确性。这种情况下，class_id仅仅是一个普通的列，只是它起到了外键的作用而已。 要删除一个外键约束，也是通过ALTER TABLE实现的： 注意：删除外键约束并没有删除外键这一列。删除列是通过DROP COLUMN …实现的。 多对多通过一个表的外键关联到另一个表，我们可以定义出一对多关系。有些时候，还需要定义“多对多”关系。多对多关系实际上是通过两个一对多关系实现的，即通过一个中间表，关联两个一对多关系，就形成了多对多关系。 多对多关系实际上是通过两个一对多关系实现的，即通过一个中间表，关联两个一对多关系，就形成了多对多关系：teacher表： classes表： 中间表teacher_class关联两个一对多关系： 通过中间表，我们就定义了一个“多对多”关系。 一对一一对一关系是指，一个表的记录对应到另一个表的唯一一个记录。 例如，students表的每个学生可以有自己的联系方式，如果把联系方式存入另一个表contacts，我们就可以得到一个“一对一”关系：这里一对一的前提是student_id不重复。 既然是一对一关系，那为啥不给students表增加一个mobile列，来合二为一。 如果业务允许，完全可以把两个表合为一个表。一对一关系准确地说，是contacts表一对一对应students表。 还有一些应用会把一个大表拆成两个一对一的表，目的是把经常读取和不经常读取的字段分开，以获得更高的性能。例如，把一个大的用户表分拆为用户基本信息表user_info和用户详细信息表user_profiles，大部分时候，只需要查询user_info表，并不需要查询user_profiles表，这样就提高了查询速度。 索引在关系数据库中，如果有上万甚至上亿条记录，在查找记录的时候，想要获得非常快的速度，就需要使用索引。 索引是关系数据库中对某一列或多个列的值进行预排序的数据结构。通过使用索引，可以让数据库系统不必扫描整个表，而是直接定位到符合条件的记录，这样就大大加快了查询速度。 例如，对于students表： 如果要经常根据score列进行查询，就可以对score列创建索引： 使用ADD INDEX idx_score (score)就创建了一个名称为idx_score，使用列score的索引。索引名称是任意的，索引如果有多列，可以在括号里依次写上，例如： 索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。反过来，如果记录的列存在大量相同的值，例如gender列，大约一半的记录值是M，另一半是F，因此，对该列创建索引就没有意义。 可以对一张表创建多个索引。索引的优点是提高了查询效率，缺点是在插入、更新和删除记录时，需要同时修改索引，因此，索引越多，插入、更新和删除记录的速度就越慢。 对于主键，关系数据库会自动对其创建主键索引。使用主键索引的效率是最高的，因为主键会保证绝对唯一。 唯一索引 通过UNIQUE关键字我们就添加了一个唯一索引。也可以只对某一列添加一个唯一约束而不创建唯一索引。 这种情况下，name列没有索引，但仍然具有唯一性保证。 无论是否创建索引，对于用户和应用程序来说，使用关系数据库不会有任何区别。这里的意思是说，当我们在数据库中查询时，如果有相应的索引可用，数据库系统就会自动使用索引来提高查询效率，如果没有索引，查询也能正常执行，只是速度会变慢。因此，索引可以在使用数据库的过程中逐步优化。 查询数据基本查询假设表名是students，要查询students表的所有行，我们用如下SQL语句： SELECT * FROM students; 使用SELECT FROM students时，SELECT是关键字，表示将要执行一个查询， 表示“所有列”，FROM表示将要从哪个表查询，本例中是students表。该SQL将查询出students表的所有数据。注意：查询结果也是一个二维表，它包含列名和每一行的数据。 不带FROM子句的SELECT语句有一个有用的用途，就是用来判断当前到数据库的连接是否有效。许多检测工具会执行一条SELECT 1;来测试数据库连接。 条件查询 SELECT * FROM &lt;表名&gt; WHERE &lt;条件表达式&gt; 条件表达式可以用&lt;条件1&gt; AND &lt;条件2&gt;表达满足条件1并且满足条件2。例如，符合条件“分数在80分或以上”，并且还符合条件“男生”，把这两个条件写出来： 根据score列的数据判断：score &gt;= 80 根据gender列的数据判断：gender = ‘M’，注意gender列存储的是字符串，需要用单引号括起来。 除了AND以外，还有NOT以及OR。如果不加括号，条件运算按照NOT、AND、OR的优先级进行，即NOT优先级最高，其次是AND，最后是OR。加上括号可以改变优先级。 常用的条件表达式 %表示0个到多个，_ 表示1个。 投影查询如果我们只希望返回某些列的数据，而不是所有列的数据，我们可以用SELECT 列1, 列2, 列3 FROM …，让结果集仅包含指定列。这种操作称为投影查询。例如，从students表中返回id、score和name这三列。 这样返回的结果集就只包含了我们指定的列，并且，结果集的列的顺序和原表可以不一样。 使用SELECT 列1, 列2, 列3 FROM …时，还可以给每一列起个别名，这样，结果集的列名就可以与原表的列名不同。它的语法是SELECT 列1 别名1, 列2 别名2, 列3 别名3 FROM …。 例如，以下SELECT语句将列名score重命名为points，而id和name列名保持不变： 投影查询同样可以接WHERE条件，实现复杂的查询。 排序我们使用SELECT查询时，细心的读者可能注意到，查询结果集通常是按照id排序的，也就是根据主键排序。这也是大部分数据库的做法。如果我们要根据其他条件排序怎么办？可以加上ORDER BY子句。例如按照成绩从低到高进行排序： 如果要反过来，按照成绩从高到底排序，我们可以加上DESC表示“倒序”： 默认的排序规则是ASC：“升序”，即从小到大。ASC可以省略，即ORDER BY score ASC和ORDER BY score效果一样。 如果有WHERE子句，那么ORDER BY子句要放到WHERE子句后面。例如，查询一班的学生成绩，并按照倒序排序： 分页查询使用SELECT查询时，如果结果集数据量很大，比如几万行数据，放在一个页面显示的话数据量太大，不如分页显示，每次显示100条。 要实现分页功能，实际上就是从结果集中显示第1~100条记录作为第1页，显示第101~200条记录作为第2页，以此类推。 因此，分页实际上就是从结果集中“截取”出第M~N条记录。这个查询可以通过LIMIT OFFSET 子句实现。我们先把所有学生按照成绩从高到低进行排序，把结果集分页，每页3条记录。要获取第1页的记录，可以使用LIMIT 3 OFFSET 0： 上述查询LIMIT 3 OFFSET 0表示，对结果集从0号记录开始，最多取3条。注意SQL记录集的索引从0开始。如果要查询第2页，那么我们只需要“跳过”头3条记录，也就是对结果集从3号记录开始查询，把OFFSET设定为3：类似的，查询第3页的时候，OFFSET应该设定为6:由于第4页只有1条记录，因此最终结果集按实际数量1显示。LIMIT 3表示的意思是“最多3条记录”。 OFFSET超过了查询的最大数量并不会报错，而是得到一个空的结果集。OFFSET是可选的，如果只写LIMIT 15，那么相当于LIMIT 15 OFFSET 0。 在MySQL中，LIMIT 15 OFFSET 30还可以简写成LIMIT 30, 15。使用LIMIT OFFSET 分页时，随着N越来越大，查询效率也会越来越低。 聚合查询对于统计总数、平均数这类计算，SQL提供了专门的聚合函数，使用聚合函数进行查询，就是聚合查询，它可以快速获得结果。仍然以查询students表一共有多少条记录为例，我们可以使用SQL内置的COUNT()函数查询。 COUNT( )表示查询所有列的行数，要注意聚合的计算结果虽然是一个数字，但查询的结果仍然是一个二维表，只是这个二维表只有一行一列，并且列名是COUNT( )。 通常，使用聚合查询时，我们应该给列名设置一个别名，便于处理结果。 COUNT(*)和COUNT(id)实际上是一样的效果。另外注意，聚合查询同样可以使用WHERE条件，因此我们可以方便地统计出有多少男生、多少女生、多少80分以上的学生等： 除了COUNT()函数外，SQL还提供了如下聚合函数： 注意，MAX()和MIN()函数并不限于数值类型。如果是字符类型，MAX()和MIN()会返回排序最后和排序最前的字符。 要统计男生的平均成绩，我们用下面的聚合查询： 要特别注意：如果聚合查询的WHERE条件没有匹配到任何行，COUNT()会返回0，而MAX()、MIN()、MAX()和MIN()会返回NULL。 分组对于聚合查询，SQL还提供了“分组聚合”的功能。我们观察下面的聚合查询： 执行这个查询，COUNT()的结果不再是一个，而是3个，这是因为，GROUP BY子句指定了按class_id分组，因此，执行该SELECT语句时，会把class_id相同的列先分组，再分别计算，因此，得到了3行结果。 但是这3行结果分别是哪三个班级的，不好看出来，所以我们可以把class_id列也放入结果集中： 聚合查询的列中，只能放入分组的列。 多表查询SELECT查询不但可以从一张表查询数据，还可以从多张表同时查询数据。查询多张表的语法是：SELECT * FROM &lt;表1&gt; &lt;表2&gt;。 同时从students表和classes表的“乘积”，即查询数据，可以这么写： 这种一次查询两个表的数据，查询的结果也是一个二维表，它是students表和classes表的“乘积”，即students表的每一行与classes表的每一行都两两拼在一起返回。结果集的列数是students表和classes表的列数之和，行数是students表和classes表的行数之积。 这种多表查询又称笛卡尔查询，使用笛卡尔查询时要非常小心，由于结果集是目标表的行数乘积，对两个各自有100行记录的表进行笛卡尔查询将返回1万条记录，对两个各自有1万行记录的表进行笛卡尔查询将返回1亿条记录。使用多表查询可以获取M x N行记录；多表查询的结果集可能非常巨大，要小心使用。 查询的结果集有两列id和两列name，两列id是因为其中一列是students表的id，而另一列是classes表的id，但是在结果集中，不好区分。两列name同理 要解决这个问题，我们仍然可以利用投影查询的“设置列的别名”来给两个表各自的id和name列起别名： 注意，多表查询时，要使用表名.列名这样的方式来引用列和设置别名，这样就避免了结果集的列名重复问题。但是，用表名.列名这种方式列举两个表的所有列实在是很麻烦，所以SQL还允许给表设置一个别名，让我们在投影查询中引用起来稍微简洁一点： 注意到FROM子句给表设置别名的语法是FROM &lt;表名1&gt; &lt;别名1&gt;, &lt;表名2&gt; &lt;别名2&gt;。这样我们用别名s和c分别表示students表和classes表。 多表查询也是可以添加WHERE条件的。 连接查询连接查询是另一种类型的多表查询。连接查询对多个表进行JOIN运算，简单地说，就是先确定一个主表作为结果集，然后，把其他表的行有选择性地“连接”在主表结果集上。 例如，我们想要选出students表的所有学生信息，可以用一条简单的SELECT语句完成，假设我们希望结果集同时包含所在班级的名称，上面的结果集只有class_id列，缺少对应班级的name列。存放班级名称的name列存储在classes表中，只有根据students表的class_id，找到classes表对应的行，再取出name列，就可以获得班级名称。 连接查询就派上了用场。我们先使用最常用的一种内连接——INNER JOIN来实现。 INNER JOIN查询的写法是： 先确定主表，仍然使用FROM &lt;表1&gt;的语法； 再确定需要连接的表，使用INNER JOIN &lt;表2&gt;的语法； 然后确定连接条件，使用ON &lt;条件…&gt;，这里的条件是s.class_id = c.id，表示students表的class_id列与classes表的id列相同的行需要连接； 可选：加上WHERE子句、ORDER BY等子句。 使用别名不是必须的，但可以更好地简化查询语句。有内连接（INNER JOIN）就有外连接（OUTER JOIN）。 有RIGHT OUTER JOIN，就有LEFT OUTER JOIN，以及FULL OUTER JOIN。它们的区别是： INNER JOIN只返回同时存在于两张表的行数据，由于students表的class_id包含1，2，3，classes表的id包含1，2，3，4，所以，INNER JOIN根据条件s.class_id = c.id返回的结果集仅包含1，2，3。 RIGHT OUTER JOIN返回右表都存在的行。如果某一行仅在右表存在，那么结果集就会以NULL填充剩下的字段。 LEFT OUTER JOIN则返回左表都存在的行。如果我们给students表增加一列，并添加class_id=5，由于classes表并不存在id=5的列，所以，LEFT OUTER JOIN的结果会增加一列，对应的class_name是NULL。 inner join left outer join right outer join full outer join 修改数据INSERT插入数据基本语法： 如果一个字段有默认值，那么在INSERT语句中也可以不出现。 要注意，字段顺序不必和数据库表的字段顺序一致，但值的顺序必须和字段顺序一致。也就是说，可以写INSERT INTO students (score, gender, name, class_id) …，但是对应的VALUES就得变成(80, ‘M’, ‘大牛’, 2)。 还可以一次性添加多条记录，只需要在VALUES子句中指定多个记录值，每个记录是由(…)包含的一组值： UPDATE更新数据库表中的记录，我们就必须使用UPDATE语句。 例如，我们想更新students表id=1的记录的name和score这两个字段，先写出UPDATE students SET name=’大牛’, score=66，然后在WHERE子句中写出需要更新的行的筛选条件id=1： UPDATE语句的WHERE条件和SELECT语句的WHERE条件其实是一样的，因此完全可以一次更新多条记录： 在UPDATE语句中，更新字段时可以使用表达式。例如，把所有80分以下的同学的成绩加10分： 如果WHERE条件没有匹配到任何记录，UPDATE语句不会报错，也不会有任何记录被更新。要特别小心的是，UPDATE语句可以没有WHERE条件，这时，整个表的所有记录都会被更新。 所以，在执行UPDATE语句时要非常小心，最好先用SELECT语句来测试WHERE条件是否筛选出了期望的记录集，然后再用UPDATE更新。 在使用MySQL这类真正的关系数据库时，UPDATE语句会返回更新的行数以及WHERE条件匹配的行数。 DELETE删除数据库表中的记录，我们可以使用DELETE语句。基本语法是： DELETE语句的WHERE条件也是用来筛选需要删除的行，因此和UPDATE类似，DELETE语句也可以一次删除多条记录： 如果WHERE条件没有匹配到任何记录，DELETE语句不会报错，也不会有任何记录被删除。要特别小心的是，和UPDATE类似，不带WHERE条件的DELETE语句会删除整个表的数据。 整个表的所有记录都会被删除。所以，在执行DELETE语句时也要非常小心，最好先用SELECT语句来测试WHERE条件是否筛选出了期望的记录集，然后再用DELETE删除。 在使用MySQL这类真正的关系数据库时，DELETE语句也会返回删除的行数以及WHERE条件匹配的行数。 实用SQL语句插入或替换如果我们希望插入一条新记录（INSERT），但如果记录已经存在，就先删除原记录，再插入新记录。此时，可以使用REPLACE语句，这样就不必先查询，再决定是否先删除再插入。 若id=1的记录不存在，REPLACE语句将插入新记录，否则，当前id=1的记录将被删除，然后再插入新记录。 插入或更新如果我们希望插入一条新记录（INSERT），但如果记录已经存在，就更新该记录，此时，可以使用INSERT INTO … ON DUPLICATE KEY UPDATE …语句： 若id=1的记录不存在，INSERT语句将插入新记录，否则，当前id=1的记录将被更新，更新的字段由UPDATE指定。 插入或忽略如果我们希望插入一条新记录（INSERT），但如果记录已经存在，就啥事也不干直接忽略，此时，可以使用INSERT IGNORE INTO …语句。 若id=1的记录不存在，INSERT语句将插入新记录，否则，不执行任何操作。 快照如果想要对一个表进行快照，即复制一份当前表的数据到一个新表，可以结合CREATE TABLE和SELECT。 新创建的表结构和SELECT使用的表结构完全一致。 写入查询结果集如果查询结果集需要写入到表中，可以结合INSERT和SELECT，将SELECT语句的结果集直接插入到指定表中。 例如，创建一个统计成绩的表statistics，记录各班的平均成绩： 可以用一条语句写入各班的平均成绩： 确保INSERT语句的列和SELECT语句的列能一一对应，就可以在statistics表中直接保存查询的结果： 事务在执行SQL语句的时候，某些业务要求，一系列操作必须全部执行，而不能仅执行一部分。例如，一个转账操作： 这两条SQL语句必须全部执行，或者，由于某些原因，如果第一条语句成功，第二条语句失败，就必须全部撤销。 这种把多条语句作为一个整体进行操作的功能，被称为数据库事务。数据库事务可以确保该事务范围内的所有操作都可以全部成功或者全部失败。如果事务失败，那么效果就和没有执行这些SQL一样，不会对数据库数据有任何改动。 数据库事务有ACID这4个特性。 A：Atomic，原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行； C：Consistent，一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100； I：Isolation，隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离； D：Duration，持久性，即事务完成后，对数据库数据的修改被持久化存储。 对于单条SQL语句，数据库系统自动将其作为一个事务执行，这种事务被称为隐式事务。 要手动把多条SQL语句作为一个事务执行，使用BEGIN开启一个事务，使用COMMIT提交一个事务，这种事务被称为显式事务，例如，把上述的转账操作作为一个显式事务： 很显然多条SQL语句要想作为一个事务执行，就必须使用显式事务。 COMMIT是指提交事务，即试图把事务内的所有SQL所做的修改永久保存。如果COMMIT语句执行失败了，整个事务也会失败。 有些时候，我们希望主动让事务失败，这时，可以用ROLLBACK回滚事务，整个事务会失败： 数据库事务是由数据库系统保证的，我们只需要根据业务逻辑使用它就可以。 隔离级别对于两个并发执行的事务，如果涉及到操作同一条记录的时候，可能会发生问题。因为并发操作会带来数据的不一致性，包括脏读、不可重复读、幻读等。数据库系统提供了隔离级别来让我们有针对性地选择事务的隔离级别，避免数据不一致的问题。 SQL标准定义了4种隔离级别，分别对应可能出现的数据不一致的情况： Read UncommittedRead Uncommitted是隔离级别最低的一种事务级别。在这种隔离级别下，一个事务会读到另一个事务更新后但未提交的数据，如果另一个事务回滚，那么当前事务读到的数据就是脏数据，这就是脏读（Dirty Read）。 事务B两次读到的数据不一致。 Read Committed在Read Committed隔离级别下，一个事务可能会遇到不可重复读（Non Repeatable Read）的问题。 不可重复读是指，在一个事务内，多次读同一数据，在这个事务还没有结束时，如果另一个事务恰好修改了这个数据，那么，在第一个事务中，两次读取的数据就可能不一致。 表中数据现在为Alice。 Repeatable Read在Repeatable Read隔离级别下，一个事务可能会遇到幻读（Phantom Read）的问题。 幻读是指，在一个事务中，第一次查询某条记录，发现没有，但是，当试图更新这条不存在的记录时，竟然能成功，并且，再次读取同一条记录，它就神奇地出现了。幻读就是没有读到的记录，以为不存在，但其实是可以更新成功的，并且，更新成功后，再次读取，就出现了。 事务B在第3步第一次读取id=99的记录时，读到的记录为空，说明不存在id=99的记录。随后，事务A在第4步插入了一条id=99的记录并提交。事务B在第6步再次读取id=99的记录时，读到的记录仍然为空，但是，事务B在第7步试图更新这条不存在的记录时，竟然成功了，并且，事务B在第8步再次读取id=99的记录时，记录出现了。 Repeatable Read下在同一个事务内的查询都是与事务开始时刻一致，所以在B事务过程中是不会读到期间A中insert的值的。 SerializableSerializable是最严格的隔离级别。在Serializable隔离级别下，所有事务按照次序依次执行，因此，脏读、不可重复读、幻读都不会出现。 虽然Serializable隔离级别下的事务具有最高的安全性，但是，由于事务是串行执行，所以效率会大大下降，应用程序的性能会急剧降低。如果没有特别重要的情景，一般都不会使用Serializable隔离级别。 默认隔离级别如果没有指定隔离级别，数据库就会使用默认的隔离级别。在MySQL中，如果使用InnoDB，默认的隔离级别是Repeatable Read。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://github.com/zdkswd/tags/SQL/"}]},{"title":"Shell Scripts","slug":"Shell Scripts","date":"2019-01-30T10:06:32.000Z","updated":"2019-01-30T10:06:47.000Z","comments":true,"path":"2019/01/30/Shell Scripts/","link":"","permalink":"https://github.com/zdkswd/2019/01/30/Shell Scripts/","excerpt":"","text":"Shell Scripts什么是Shell scriptsshell script是利用shell的功能所写的一个程序，这个程序使用纯文本文件，将一些shell的语法与指令（含外部指令）写在里面，搭配正则表达式，管线命令与数据流重导向等功能，以达到我们所想要的处理目的。 干嘛学习shell scripts自动化管理的重要依据追踪与管理系统的重要工作系统服务启动接口所在的目录下所有文件都是scripts，包括开机（booting）过程也都是利用shell script来帮忙搜寻系统的相关设置数据，然后再代入各个服务的设置参数。 简单入侵侦测功能连续指令单一化简易的数据处理跨平台支持与学习历程较短第一支script的撰写与执行shell script其实就是纯文本文件，可以编辑这个文件，然后让这个文件一次执行多个指令。 指令的执行是从上而下、从左而右的分析与执行。 指令、选项与参数间的多个空白都会被忽略掉。 空白行也将被忽略掉，并且[tab]按键所推开的空白同样视为空白键。 如果读取到一个Enter符号 (CR) ，就尝试开始执行该行 (或该串) 命令。 至于如果一行的内容太多，则可以使用“ [Enter]”来延伸至下一行。 可做为注解!任何加在 # 后面的数据将全部被视为注解文字而被忽略! 假设编写好的文件名为shell.sh。执行方法有。 直接指令下达：shell.sh文件必须具备可读与可执行（rx）的权限。无论如何到达shell.sh的目录，然后直接输入shell.sh就能执行。 以bash程序来执行，通过bash shell.sh或sh shell.sh来执行。 撰写第一支script 第一行# ! / bin / bash在宣告这个script使用的shell名称:因为我们使用的是bash，所以，必须要以“ # ! / bin / bash”来宣告这个文件内的语法使用bash的语法!那么当这个程序被执行时，他就能够载入bash的相关环境配置文件(一般来说就是non-login shell的~/.bashrc)，并且执行bash来使我们下面的指令能够执行!这很重要的! (在很多状况中，如果没有设置好这一行，那么该程序很可能会无法执行，因为系统可能无法判断该程序需要使用什么shell 来执行啊! ) 程序内容的说明: 整个script当中，除了第一行的“ # !”是用来宣告shell的之外，其他的 # 都是“注解”用途! 所以上面的程序当中，第二行以下就是用来说明整个程序的基本数据。一般来说，建议你一定要养成说明该script的:1.内容与功能;2.版本信息; 3.作者与联络方式;4.创建日期;5.历史纪录等等。这将有助于未来程序的改写与debug。 执行成果告知(定义回传值)，可以利用exit这个指令来让程序中断，并且回传一个数值给系统。利用exit n（n是数字）的功能，可以自订错误讯息，让程序变得更加smart。 撰写shell script的良好习惯创建在每个script的文件开始处记录好： script的功能 script的版本信息 script的作者与联络方式 script的版权宣告方式 script的历史记录 script内教特殊的指令，使用绝对路径的方式来下达 script运行时需要的环境变量预先宣告与设置","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"认识与学习BASH","slug":"认识与学习BASH","date":"2019-01-28T12:55:32.000Z","updated":"2019-01-28T13:04:20.000Z","comments":true,"path":"2019/01/28/认识与学习BASH/","link":"","permalink":"https://github.com/zdkswd/2019/01/28/认识与学习BASH/","excerpt":"","text":"认识与学习BASH认识BASH这个Shell硬件，核心与Shell必须通过shell将我们输入指令与内核沟通，好让内核可以控制硬件来正确无误的工作。操作系统其实是一组软件，这组软件在控制整个硬件与管理系统的活动监测，操作系统管理的就是整个硬件功能。使用者通过应用程序来指挥内核让内核达成我们所需要的硬件任务。壳程序的功能知识提供使用者操作系统的一个接口，因此需要可以调用其他软件，就是很多其他的指令，我们可以通过壳程序（就是命令行界面）来操作这些应用程序，让这些应用程序调用核心来运行所需的工作。只要能够操作应用程序的接口都能称为壳程序，狭义的壳程序指的是命令行包括bash，广义的壳程序包括图形接口软件。 为何要学命令行shell命令行shell：大家都一样几乎各家distribution使用的bash都是一样的。 远端管理：命令行就是比较快Linux的管理常常需要通过远端连线，而连线时命令行的传速度一定比较快，而且不容易出现断线或者是信息外流的问题。 Linux的任督二脉：shell系统的合法shell与/etc/shells功能shell有众多版本，Linux的叫bash，也是基于GNU架构下发展出来的。shell还包括sh，csh。在/ etc / shells这个文件中至少就有几个可以用的shells。 我们系统合法的shell要写入/ etc / shells这个文件，系统某些服务在运行过程中，会去检查使用者能够使用的shells，检查的文件就是 / etc / shells这个文件。 Bash shell的功能bash是Linux distributions的标准shell。bash主要相容于sh。bash的主要优点： 命令编修能力（history）bash可以使用上下键找到前后一个输入的指令，在很多distribution中，默认的指令记忆功能可以达到1000个，指令记录放在主文件夹内的.bash_history中，不过~/ .bash_history记录的是前一次登录以前所执行的指令，这一次登录的指令都被暂存在内存中，当成功登出系统后，指令记忆才会记录到.bash_history中。 命令与文件补全功能（【tab】键的好处）命令别名设置功能：（alias）在命令行输入alias就可以知道目前的命令别名有哪些了。 就可以用alias来替代ls -al命令了。 工作控制，前景背景控制（job control,foreground,background）程序化脚本（shell scripts）将管理系统需要下达的连续指令写成一个文件，该文件可以通过对谈互动式的方式来进行主机的侦测工作，也可以借由shell提供的环境变量及相关指令来进行设计。 万用字符（wildcard）bash还支持许多的万用字符来帮助使用者查询与指令下达，比如想知道有多少以X为开头的文件，就可使用 X * 来查看。 查询指令是否是Bash shell的内置命令：type通过type指令来知道指令是来自于外部指令（其他非bash所提供的指令）或是内置在bash当中的指令。 指令的下达与快速编辑按钮使用反斜杠加回车键，可以进行多行的输入。 Shell的变量功能什么是变量变量的可变性与方便性 小写的mail是指令，大写的MAIL是变量名称。 影响bash环境操作的变量系统通过PATH这个变量里面的内容记录的路径顺序来搜寻指令。环境变量如PATH，HOME，MAIL，SHELL等等，都是很重要的，为了区别与自订变量的不同，环境变量通常以大写字符表示。 脚本程序设计（shell script）的好帮手 变量的取用与设置：echo，变量设置规则，unset变量的取用：echo变量前面要加上$符号才行。 设置和修改变量内容，用等号连接变量与他的内容就好了。 当一个变量名称尚未被设置时，默认的内容是空，变量在设置时也要符合一些规则，否则设置失败。 子程序就是在目前这个shell的情况下，去启用另一个新的shell，新的shell就是子程序，在一般状态下，父程序的自订变量是无法在子程序中使用的，但是通过export将变量变成环境变量后，就能够在子程序下面应用了。 环境变量的功能用env观察环境变量与常见环境变量说明 MAIL当我们使用mail这个指令收信时，系统会去读取的邮件信箱文件（mailbox）。 用set观察所有变量（含环境变量与自订变量） 影响显示结果的语系变量（locale）利用locale指令查询Linux支持了多少语系。 变量键盘读取，数组与声明：read，array，declareread要读取来自键盘输入的变量，就是用read这个指令。 declare，typesetdeclare与typeset是一样都是声明变量的类型。 变量的默认类型是字符串，所以若是不指定变量类型，则1+2为一个字符串而不是计算式，bash环境中的数值计算默认最多能达到整数形态，所以1 / 3结果是0。 array变量类型 与文件系统及程序的限制关系：ulimit由于Linux主机是多用户多任务操作系统，防止资源超过限制，bash可以限制使用者的某些系统资源，包括可以打开的文件数量，可以使用的CPU时间，可以使用的内存总量。用ulimit来实现。 一般身份使用者如果以ulimit设置了-f的文件大小，那么只能继续减小文件的大小，不能增加文件的大小。 变量内容的删除，取代与替换（optional）变量内容的删除与取代 变量的测试与内容替换 命令别名与历史命令命令别名设置：alias，unalias 历史命令：history 当以bash登陆Linux主机之后，系统会主动由主文件夹的~ / .bash_history读取以前曾经下过的指令，记录的条数与bash的HISTFILESIZE这个变量设置值有关。 Bash Shell的操作环境路径与指令搜寻顺序指令运行的顺序： 以相对/ 绝对路径执行指令，例如/ bin / ls 或 . / ls。 由alias找到该指令来执行。 由bash内置的（builtin）指令来执行。 通过$PATH这个变量的顺序搜寻到的第一个指令来执行。 bash的进站与欢迎讯息：/ etc / issue,/ etc / motd登陆时的提示字串。 登陆后取得一些讯息，可以将讯息加入到/ etc / motd中，一定要root的身份才能修改。 bash的环境配置文件login与non-login shell区别在于取得bash用不用登陆（login）。这两个取得bash的情况中，读取的配置文件数据并不一致。login shell会读取下列文件： / etc / profile:这是系统整体的设置，最好不要修改这个文件。 ~ / .bash_profile 或 ~ / .bash_login 或 ~ / .profile :属于使用者个人设置，要改自己的数据，就写入这里。 non-login shell仅会读取：~ / .bashrc 而已。 终端机的环境设置：stty，set bash默认组合键。 万用字符与特殊符号万用字符： 特殊符号： 数据流重导向数据流重导向就是将某个指令执行后应该要出现在屏幕上的数据，给它传输到其他的地方，例如文件或者是设备，在Linux文字模式下很重要，尤其是如果想要将某些数据存储下来。 什么是数据流重导向 命令执行的判断依据：；，&amp;&amp;，‖管线命令（pipe）管线命令使用的是“|”界定符号，管线命令与连续下达命令式不一样的。管线命令“|”仅能处理经由前面一个指令传来的正确信息，也就是standard output信息，对于stdandard error并没有直接处理的能力。 管线命令仅会处理standard output，对于standard error output会予以忽略 管线命令必须能够接受来自前一个指令的数据成为standard input继续处理才行。 选取命令：cut，grepcut cut主要用途是在于将同一行里面的数据进行分解。 grepgrep是分析一行讯息，若当中有我们所需要的信息，就将该行拿出来。 排序命令：sort，wc，uniqsort uniq想要将重复的数据仅列出一个显示。 wcwc指令可以帮我们计算输出讯息的整体数据。 双向重导向：tee字符转换命令：tr，col，join，paste，expandtrtr可以用来删除一段讯息中文字，或者是进行文字讯息的替换。 col col键可以用来简单的处理将tab按键取代为空格键。 join paste相对于join要对比两个文件的数据相关性，paste就是直接将两行粘在一起，中间以tab隔开。 expand分区命令：split如果有文件太大，找split就对了，可以将一个大文件依据文件大小或行数来分区，就可以将大文件分区为小文件了。 参数代换：xargs关于减号-的用途","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"Vim","slug":"vim程序编辑器","date":"2019-01-27T02:19:32.000Z","updated":"2019-01-27T02:20:46.000Z","comments":true,"path":"2019/01/27/vim程序编辑器/","link":"","permalink":"https://github.com/zdkswd/2019/01/27/vim程序编辑器/","excerpt":"","text":"vim程序编辑器在所有的Linux distributions上都会有一套文书编辑器，即vi，vim是进阶版的vi，vim可以用不同颜色显示文字内容，还可以进行shell script，C program等程序编辑功能，可以将vim视为一种程序编辑器。 vi与vim在Linux的世界中，绝大部分的配置文件都是以ASCII的纯文本形态存在的，因此利用简单的文字编辑软件就能够修改设置了。 为何要学vim 所有的Unⅸ Like系统都会内置ⅵ文书编辑器，其他的文书编辑器则不一定会存在。 很多个别软件的编辑借口都会主动调用vi vim具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 因为程序简单，编辑速度相当快速。 重点是第二点，因为有太多的Linux上面的指令都默认使用vi作为数据编辑的接口，所以必须一定要学会vi，否则很多指令根本无法操作。 简单来说vi是老式的文本处理器，不过功能已经很齐全了，但是还是有可以进步的地方，vim则可以说是程序开发者的一项很好用的工具。 vi的使用一般指令模式（command mode）以ⅵ打开一个文件就直接进入一般指令模式了(这是默认的模式，也简称为一般模式)。在这个模式中，可以使用“上下左右”按键来移动光标，可以使用“删除字符”或”删除整列”来处理文件内容,也可以使用“复制,粘贴”来处理你的文件数据。 编辑模式（insert mode）在一般指令模式中可以进行删除丶复制丶贴上等等的动作’但是却无法编辑文件内容的!要等到你按下i,l,o,O,a,A,r,R等任何一个字母之后才会进入编辑模式。注意了!通常在Linux中按下这些按键时,在画面的左下方会出现” INSERT或REPLACE”的字样,此时才可以进行编辑。而如釆要回到一般指令模式时，则必须要按下”Esc”这个按键即可退岀编辑模式。 命令行命令模式（command-line mode）在一般模式中，输入：/?三个中的任何一个按钮，就可以将光标移动到最下面的那一列。在这个模式中可以提供你搜寻数据的动作，而读取、存盘、大量取代字符、离开vi、显示行号等等则是在此模式中达成的。 简易执行范例使用vi filename进入一般指令模式按下i进入编辑模式，开始编辑文字按下esc按钮回到一般指令模式进入命令行界面，文件存储并离开vi环境存盘（write）并离开（quit）的指令很简单，输入：wq（冒号要输入）即可存盘离开。（注意，按下后该光标就会移动到最后面一列）。如果文件权限不对，可能无法写入，此时可以使用强制写入，使用：wq！（冒号要输入）多加一个惊叹号。 按键说明编辑模式与命令行界面之间并不能切换。 一般指令模式可用的按钮说明，光标移动，复制贴上，搜寻取代 一般指令模式切换到编辑模式的可用的按钮说明 一般指令切换到命令行界面可用按钮说明 vim的暂存盘，救援恢复与打开时的警告讯息vim是通过暂存盘来进行救援恢复的。当使用vim编辑时，vim会在同一目录下再创建一个名为.filename.swap的文件。对文件做的动作会被记录到swp当中，如果系统由于某些原因断掉，编辑的文件还没有储存，swp就能发挥救援作用。 vim的额外功能目前大部分的distribution都以vim取代vi了。vim还可以直接进行debug。123debug和release的区别Debug：调试版本，包含调试信息，所以容量比Release大很多，并且不进行任何优化（优化会使调试复杂化，因为源代码和生成的指令间关系会更复杂），便于程序员调试。Release：发布版本，不对源代码进行调试，编译时对应用程序的速度进行优化，使得程序在代码大小和运行速度上都是最优的。 区块选择（Visual Block） 多文件编辑可以使用vim后面同时接好几个文件同时打开。 利用多文件编辑的功能’可以让你很快速的就将需要的数据复制到正确的文件内。当然这个功能也可以利用窗口接口来达到，那就是多窗口功能。 多窗口功能vim也可以实现分区窗口的功能。在命令行界面输入:sp {filename}即可，filename可有可无，如果想要在新窗口启动另一个文件，就加入文件名，否则仅输入:sp，出现的是同一个文件在两个窗口间。 vim的补全功能程序编辑器都可以进行语法检验以及根据输入来挑字进行补全。 先输入前者再输入后者。 vim环境设置与记录： ~/.vimrc，~/.viminfo以vim软件来搜寻一个文件内部的字串时，字串会被反白。再次vim编辑这个文件时，泛白的情况还是存在的。当重复编辑同一个文件第二次进入该文件时，光标还在上次离开的那一列上头。这是因为vim会主动的将做过的行为记录下来，记录的文件就是：~/.viminfo，该文件是自动生成的，不必自行创建，在vim里所做过的动作都可以在这个文件内部查询到。vim的环境参数有很多，如果想要知道目前的设置值，可以在一般指令模式时输入：set all来查阅。 每次使用vim都要重新设置一次各个参数值貌似不太合理，所以可以通过配置文件直接规定习惯的vim操作环境。整体的vim设置一般放在/ etc / vimrc 这个文件，不过不建议修改，可以修改 ~ / .vimrc这个文件（默认不存在，要手动创建）。 vim常用指令示意图 vim使用注意事项中文编码问题DOS与Linux的断行字符语系编码转换","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"鸟哥Linux Linux文件、目录与磁盘格式","slug":"鸟哥Linux Linux文件、目录与磁盘格式","date":"2019-01-25T08:27:32.000Z","updated":"2019-01-25T08:31:12.000Z","comments":true,"path":"2019/01/25/鸟哥Linux Linux文件、目录与磁盘格式/","link":"","permalink":"https://github.com/zdkswd/2019/01/25/鸟哥Linux Linux文件、目录与磁盘格式/","excerpt":"","text":"第五章 Linux文件权限与目录配置Linux最优秀的地方之一就在于他的多用户多任务环境。而为了让各个使用者具有较保密的文件数据，因此文件的权限管理就变的很重要了。Linux一般将文件可存取的身份分为三个类别，分别是owner\\/ group \\/ others，且三种身份各有read \\/ write \\/execute等权限。 使用者与群组文件拥有者Linux是个多用户多任务的系统，因此可能常常会有多人同时使用这部主机来进行工作。考虑到每个人的隐私权与喜好的工作环境，文件拥有者就相当重要。可以设置适当的权限，让一些隐私的文件只有自己才能访问。 群组概念经由简易的文件权限设置，就能限制非自己团队（亦即群组）的其他人不能够阅览内容，也可以让自己团队成员可以修改我所创建的文件。同时自己还有私人隐密文件，仍然可以设置让自己团队成员也看不到自己的文件数据。 其他人的概念就是不属于群组的其他人喽。 root想访问谁就访问谁。 Linux使用者身份与群组记录的文件在我们Linux系统当中，默认的情况下，所有的系统上的帐号与一般身份使用者，还有那个root的相关信息，都是记录在\\/ etc\\/ passwd这个文件内的。至于个人的密码则是记录在\\/ etc \\/ shadow这个文件下。此外，Linux所有的群组名称都纪录在\\/ etc \\/ group内!这三个文件可以说是Linux系统里面帐号、密码、群组信息的集中地。 Linux文件权限概念Linux文件属性先登录系统，使用su - 切换身份成为root，下达ls -al。 ls是list的意思，重点在显示文件的文件名与相关属性。选项“-al”则表示列出所有的文件详细的权限与属性（包含隐藏文件，就是第一个字符为“.”的文件）。不建议直接使用root登录系统，建议使用su - 来切换身份，离开su - 则使用exit回到登录时的身份即可。运行结果如下： 档案类型 i-node每个文件都会将他的权限与属性记录到文件系统的i-node中，我们使用的目录树是使用文件名来记录，因此每个文件名就会链接到一个i-node，这个属性记录的，就是有多少不同的文件名连接到同一个i-node号码。 容量大小默认单位为Bytes。 如何改变文件属性与权限改变所属群组，chgrp要被改变的群组名称必须要在\\/ etc \\/group文件中存在才行，否则就会显示错误。 改变文件拥有者，chown使用者必须是已经存在系统中的账号，也就是在\\/ etc \\/ passwd这个文件中有记录的使用者名称才能改变。chown还可以顺便直接修改群组的名称，如果要连目录下的所有次目录或文件同时更改文件拥有者的话，直接加上-R选项即可。 由于复制行为（cp）会复制执行者的属性和权限，把自己的文件复制给使用者，那他仍然无法修改。所以就有必要将这个文件的拥有者与群组修改一下。 改变权限，chmod 等我们设置权限变更时，该文件的权限数字就是770啦，变更权限的指令chmod的语法： 也可以使用符号类型改变文件权限。user（u）具有可读、可写、可执行的权限。group与others（g/o）具有可读与执行的权限。a代表上面三个身份 目录与文件之权限意义文件是实际含有数据的地方，包括一般文本文件、数据库内容档、二进制可执行文件(binary program)等等。因此，权限对于文件来说，他的意义是这样的: r(read):可读取此一文件的实际内容，如读取文本文件的文字内容。 w(write):可以编辑、新增或者是修改该文件的内容（但不含删除该文件); x(eXecute):该文件具有可以被系统执行的权限。 可执行x，在Windows下是借由扩展名来判断的，例如.exe,.bat,.com等等，但是在Linux下，我们的文件是否能被执行，则是由是否具有x这个权限来决定的，跟文件名没有绝对的关系。对一个文件具有w权限时，可以具有写入、编辑、新增、修改文件的内容的权限，但并不具备删除该文件本身的权限。 Linux文件种类与扩展名正规文件（regular file）第一个字符为【-】。又大略分为： 纯文本文件（ASCII） 二进制档（binary） 数据格式文件（data）目录(directory)第一个属性为[d]。链接文件（link）就是类似Windows系统下的捷径，第一个属性为[l]。设备与设备文件与系统周边及存储相关的一些文件，通常都集中在/dev这个目录下。 区块（block）设备文件：就是一些储存数据，以提供系统随机存取的周边设备，比如硬盘,可查看/ dev / sda，会发现第一个属性为[b]。 字符(character)设备文件:即一些序列的周边设备，如键盘鼠标，特点是一次性读取不能够截断输出。如不可能让鼠标调到另一个画面，而是连续滑到另一个地方，第一个属性为[c]。 数据接口文件(sockets):这类文件通常被用在网络上的数据承接，我们可以启动一个程序来监听用户端的要求，而用户端就可以通过这个socket来进行数据的沟通了。第一个属性为【s】，最常在\\/ run或\\/ tmp这些目录中看到这种文件类型。 数据输送档(FIFO,pipe):FIFO也是一种特殊的文件类型，主要目的在解决多个程序同时存取一个文件所造成的错误问题。FIFO是first-in-first-out的缩写。第一个属性为[p]。 Linux链接文件就可以简单的视为文件或目录的快捷方式。x只是代表这个文件具有可以执行的权限，并不一定能执行成功，还得看文件的内容。Linux系统的文件名只是了解该文件可能的用途而已，真正的执行与否仍需权限的规范才行。 Linux文件长度的限制。单一文件或目录最大容许文件名为255Bytes，以一个ASCII英文占用一个Bytes来说，则可达255个字符长度，若是以每个中文字2Bytes来说，最大文件名就是在128个中文字符。Linux文件是相当长的文件名，我们希望Linux文件名称可以一看就知道该文件在干嘛，所以文件名通常是很长很长。文件名最好可以避免一些特殊字符。 Linux目录配置Linux目录配置的依据—FHSLinux目录配置的标准Filesystem Hierachy Standard(FHS)。 根据FHS[2]的标准文件指出，他们的主要目的是希望让使用者可以了解到已安装软件通常放置于那个目录下，所以他们希望独立的软件开发商、操作系统制作者 、以及想要维护 系统的使用者，都能够遵循FHS的标准。也就是说，FHS的重点在于规范每个特定的目录下应该要放置什么样子的数据而已。这样做好处非常多，因为Linux操作系统就能够在既有的面貌下(目录架构不变)发展出开发者想要的独特风格。 上表右移。 FHS针对目录树架构仅定义了三层目录。 \\/ (root,根目录)：与开机系统有关。 \\/ usr (unix software resource):与软件安装/ 执行有关。 /var(variable):与系统运行过程有关。根目录（/）的意义与内容根目录是整个系统最重要的一个目录，因为不但所有的目录都是由根目录衍生出来的，同时根目录也与开机/ 还原 / 系统修复等动作有关。由于系统开机时需要特定的开机软件、核心文件、开机所需程序、函数库等等文件数据，若系统出现错误时，根目录也必须要包含有能够修复文件系统的程序才行。因为根目录是这么的重要，所以在FHS的要求方面，他希望根目录不要放在非常大的分区内，因为越大的分区你会放入越多的数据，如此一来根目录所在分区就可能会有较多发生错误的机会。因此FHS标准建议:根目录所在分区应该越小越好，且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小越好。如此不但性能较佳，根目录所在的文件系统也较不容易发生问题。 usr的意义与内容 var的意义与内容如果_usr是安装时会占用较大硬盘容量的目录，那么_var就是在系统运行后才会渐渐占用硬盘容量的目录。因为Ivar目录主要针对常态性变动的文件，包括高速缓存 (cache)、登录文件(log file)以及某些软件运行所产生的文件，包括程序文件(lock file, run file)，或者例如MySQL数据库的文件等等。常见的次目录有: 目录树 绝对路径与相对路径 Linux文件与目录管理目录与路径目录的相关操作 cd（change directory,变换目录） pwd（显示目前所在的目录） pwd是Print Working Directory的缩写，也就是显示目前所在目录的指令。mkdir(创建新目录) rmdir（删除“空”的目录） 如果想要删除旧有的目录时，就使用rmdir，例如将刚刚创建的test杀掉，使用“rmdir test”即可。目录需要一层一层的删除才行，而且被删除的目录里面必定不能存在其他的目录或文件!这也是所谓的空的目录(empty directory)的意思。如果要将所有目录下的东西都杀掉，这个时候就必须使用“rm -r test”。不过，还是使用rmdir比较不危险，你也可以尝试以-p的选项加入，来删除上层的目录。关于可执行文件路径的变量：$PATH当我们在执行一个指令的时候，如”Is”，系统会依照PATH的设置去每个PATH定义的目录下搜寻文件名为Is的可可执行文件，如果在PATH定义的目 录中含有多个文件名为ls的可可执行文件，那么先搜寻到的同名指令先被执行。 echo有显示、印出的意思，而PATH前面的$表示后面接的是变量。 PATH(一定是大写)这个变量的内容是由一堆目录所组成的，每个目录中由冒号来隔开，每个目录是有顺序之分的。 不同身份使用者默认的PATH不同，默认能够随意执行的指令也不同（如root与dmtsai）； PATH是可以修改的； 使用绝对路径或是相对路径直接指定某个指令的文件名来执行会比搜寻PATH来的正确； 指令应该放置到正确的目录下执行才会比较方便； 本目录（.）最好不要放到PATH中。 文件与目录管理文件与目录的检视 ls 复制，删除与移动：cp,rm,mvcp（复制文件或目录） 复制（cp）这个指令是非常重要的，不同身份者执行这个指令会有不同的结果产生，尤其是-a-p选项对于不同身份差别非常大。 在默认中，cp的来源文件与目的文件的权限是不同的，目的文件的拥有者通常会是指令操作者本身。由于这个特性，我们在进行备份时，某些需要特别注意的特殊权限文件，例如密码档以及配置文件就不能直接以cp复制，而必须加-a或者是-p等等可以完整复制文件权限的选项才行。如果想要复制文件给其他的使用者，也必须要注意到文件的权限（包含读写执行以及文件拥有者等等）否则其他人还是无法针对你给予的文件进行修订动作。 -l -s都会创建所谓的链接文件（link file）,但是这两种链接文件却有不一样的情况， -s是符号链接， -l是实体链接。 在复制时，需要清楚的了解到 是否完整的保留来源文件信息 来源文件是否为链接文件 来源文件是否为特殊文件，例如FIFO，socket 来源文件是否为目录 rm（移除文件或目录） 这是移除的指令(remove) ， 要注意的是，通常在Linux系统下，为了怕文件被root误杀，所以很多distributions都已经默认加入i这个选项了!而如果要连目录下的东西都一起杀掉的话，例如子目录里面还有子目录时，那就要使用一这个选项了!不过，使用”rm-r”这个指令之前，请千万注意了，因为该目录或文件“肯定”会被root杀掉!因为系统不会再次询问你是否要砍掉呦!所以那是个超级严重的指令下达呦!得特别注意!不过，如果你确定该目录不要了，那么使用rm-r来循环杀掉是不错的方式! mv（移动文件与目录，或更名） 这是搬运（move）的意思，当要移动文件或目录时这个指令就很重要了，还有一个用途就是更改文件名，这是Linux才有的指令，还有个rename指令可以用来更改大量文件的文件名。 取得路径的文件名称与目录名称 basename与dirname的用途。 文件内容查阅 cat由第一行开始显示文件内容 tac从最后一行开始显示，可以看出tac是cat的倒着写 nl显示的时候，顺便输出行号 more一页一页的显示文件内容 less与more类似，但是比more更好的是可以往前翻页 head只看头几行 tail只看尾巴几行 od以二进制的方式读取文件内容 直接检视文件内容cat（concatenate） 数据选择head（取出前面几行） tail（取出后面几行） 非纯文本文件od 修改文件时间或创建新文件：touch modification time(mtime):当该文件的内容数据变更时，就会更新这个时间，内容数据指的是文件的内容，而不是文件的属性或权限。 status time（ctime）：当该文件的状态改变时就会更新这个时间，比如权限与属性被改变了，就会更新这个时间。 access time（atime）：当该文件的内容被取用时就会更新这个读取时间。如使用cat去读取，就会更新该文件的atime。 文件与目录的默认权限与隐藏权限文件默认权限：umaskumask就是指定目前使用者在创建文件或目录时候的权限默认值。 文件隐藏属性chattr（设置文件隐藏属性） 这些指令是很重要的，尤其是在系统数据安全上面。 lsattr（显示文件隐藏属性） 使用chattr设置后，可以使用lsattr来查阅隐藏的属性。 文件特殊权限：SUID，SGID，SBITSet UID当s这个标志出现在文件拥有者的x权限上时，如- rwsr - xr - x就称为Set UID，简称为SUID。SUID的限制与功能： SUID权限仅对二进制程序有效 执行者对于该程序需要有x的可执行权限 本权限仅在执行该程序的过程中有效 执行者将具有该程序拥有者的权限。 SUID仅可以用在binary program上，不能用在shell script上，这是因为shell script知识将很多binary可执行文件加进来执行而已。所以SUID的权限部分，还是得看shell script调用进来的程序设置，SUID对于目录也是无效的。 Set GID与SUID不同的是，SGID可以针对文件或目录来设置。对于文件，SGID有如下的功能： SGID对二进制程序有用 程序执行着对于该程序来说，需具备x的权限 执行者在执行的过程中将会获得该程序群组的支持! Sticky BitSBIT目前只针对目录有效，对于文件已经没有效果了。SBIT对于目录的作用是： 当使用者对于此目录具有w,x权限，亦即具有写入的权限时。 当使用者在该目录下创建文件或目录时，仅有自己与root才有权力删除该文件。 观察文件类型：file 指令与文件的搜寻指令文件名的搜寻which（寻找可执行文件） 这个指令是根据”PAT}这个环境变量所规范的路径’去搜寻“可执行文件”的文件名。 文件文件名的搜寻whereis（由一些特定的目录中寻找文件文件名） find是很强大的搜寻指令，但时间花费很大，因为find是直接搜寻硬盘。whereis只招几个特定的目录，并没有全系统去查询。whereis主要针对的是/ bin / sbin下面的可执行文件，以及/ usr / share / man下面的man page文件跟几个比较特定的目录来处理。 locate、updatedb 使用locate 来寻找数据的时候特别的快，这是因为locate寻找的数据是由“已创建的数据库/ var / lib / mlocate / “里面的数据所搜寻到的，所以不用直接在去硬盘当中存取数据，当然是很快速的。但是有限制条件，他是由数据库来搜寻的，而数据库每天执行一次，若在数据库更新之前搜寻文件则搜寻不到。 updatedb根据 / etc / updatedb.conf的设置去搜寻系统硬盘内的文件名，并更新/ rar / lib / mlocate内的数据库文件。 locate依据 / var / lib / mlocate内的数据库记载,找出使用者输入的关键字文件名。 find Linux磁盘与文件系统管理认识Linux文件系统磁盘组成与分区文件系统特性每种操作系统能够使用的文件系统并不相同。举例来说，windows 98以前的微软操作系统主要利用的文件系统是FAT (或FAT16) ， windows 2000以后的版本有所谓的NTFS文件系统，至于Linux的正统文件系统则为Ext2 (Linux second extended file system, ext2fs)这一个。此外，在默认的情况下,windows 操作系统是不会认识Linux的Ext2的。 文件系统是如何运行与操作系统的文件数据有关。较新的操作系统的文件数据除了文件实际内容外，通常含有非常多的属性，例如Linux操作系统的文件权限(rwx)与文件属性(拥有者、群组、时间参数等)。文件系统通常会将这两部份的数据分别存放在不同的区块，权限与属性放置到inode中，至于实际数据则放置到data block区块中。另外，还有一个超级区块 (superblock)会记录整个文件系统的整体信息 ，包括inode与block的总量、使用量、剩余量等。 每个inode与block都有编号，至于这三个数据的意义可以简略说明如下: superblock :记录此filesystem的整体信息，包括inode/block的总量、使用量、剩余量，以及文件系统的格式与相关信息等; inode:记录文件的属性，一个文件占用一个inode，同时记录此文件的数据所在的block号码; block :实际记录文件的内容，若文件太大时，会占用多个block。 由于每个 inode与 block都有编号而每个文件都会占用一个 inode, inode内有文件数据置的 block号码。因此我们可以知道的是,如果能够找到文件的 inode的话那么自然会知道这个文件所放置数据的 block号码,当然也就能够读出该文件的实际数据了。这是个比较有效率的作法，因此我们的磁盘就能够在短时间内读取出全部的数据,读写的性能比较好。文件系统先格式化出inode与block的区块。inode中记录了4个区块的位置，此乃索引式文件系统。 还有一种文件系统比如FAT格式，就是我们惯用的U盘，这种格式是没有inode存在的所以是顺序读取的。 Linux的EXT2文件系统（inode）inode的内容在记录文件的权展与相关属性,至于bock区块则是在记录文件的实际内容。而且文件系统一开始就将 inode与 block规划好了,除非重新格式化(或者利用 resize2is等指令变更文件系统大小),否则 inode与 block固定后就不再变动但是如果仔细考虑一下,如果我的文件系统高达数百GB时,那么将所有的 inode与 block通通放置在一起将是很不智的决定,因为 inode与 block的数量太庞大,不容易管理。 为此Ext2文件系统在格式化的时候基本上是区分为多个区块群组，每个区块群组都有独立的inode，block，superblock系统。 在整体的规划当中，文件系统最前面有一个开机扇区 ( boot sector)，这个开机扇区可以安装开机管理程序，这是个非常重要的设计，因为如此一来我们就能够将不同的开机管理程序安装到个别的文件系统最前端，而不用覆盖整颗磁盘唯一的MBR，这样也才能够制作出多重开机的环境啊。 data block(数据区块)由于block大小的差异，会导致该文件系统能够支持的最大磁盘容量与最大但以文件大小并不相同。 block基本限制如下： 原则上，block的大小与数量在格式化完就不能再改变了（除非重新格式化） 每个block内最多只能够放置一个文件的数据; 承上，如果文件大于block的大小，则一个文件会占用多个block数量; 承上，若文件小于block ，则该block的剩余容量就不能够再被使用了(磁盘空间会浪费) block大小选择所造成的不同问题。选在大的block在存取大量小文件时可能造成浪费。选小的block在存取大文件时索引的数量更多，可能导致文件系统不良的读写性能。事实上，现在的磁盘容量都太大了，所以大家都只会选在4K的block大小。 inode table（inode表格）inode记录的文件数据至少有下面这些： 该文件的存取模式(read / write / excute) 该文件的拥有者与群组(owner / group) 该文件的容量。 该文件创建或状态改变的时间( ctime) 最近一次的读取时间( atime) 最近修改的时间( mtime) 定义文件特性的旗标(fag),如 SetUID 该文件真正内容的指向（pointer） inode的数量与大小也是在格式化时就已经固定了。 每个 inode大小均固定为128 Bytes(新的ext4与xfs可设置到256 Bytes）； 每个文件都仅会占用一个 inode而已; 承上,因此文件系统能够创建的文件数量与 inode的数量有关; 系统读取文件时需要先找到 inode,并分析 inode所记录的权限与使用者是否符合,若符合才能够开始实际读取 block的内容。 inode要记录的数据非常多，偏偏又只有128Bytes，而inode记录一个block要花掉4Byte，所以有一个巧妙的办法。将inode记录block号码的区域定义为12个直接1个间接一个双间接一个三间接记录区。直接就是直接可以通过号码来取得block，间接就是再拿一个block来当作记录block号码的记录区，如果文件太大，就会使用间接的block来记录号码。 superblock（超级区块）superblock是记录整个filesystem相关信息的地方，没有superblock就没有filesystem了。记录的信息有： block与inode的总量 未使用与已使用的inode，block数量 block与inode的大小 filesystem的挂载时间，最近一次写入数据的时间，最近一次检验磁盘的时间等文件系统的相关信息。 一个valid bit数值，若此文件系统已被挂载，则valid bit为0，若未被挂载，则valid bit为1。 superblock是非常重要的，因为文件系统的基本信息都在，如果superblock死掉了，文件系统要花费很多时间去挽救。一般来说，superblock的大小为1024Bytes，一个文件系统应该仅有一个superblock，除了第一个block group内会含有superblock后续的block group不一定含有superblock。若含有superblock也是为第一个block group内的superblock做备份。 Filesystem Description(文件系统描述说明)这个区段可以描述每个block group的开始与结束的block号码，以及说明每个区段(superblock, bitmap, inodemap, data block) 分别介于哪一个block号码之间。 block bitmap（区块对照表）记录使用与未使用block的号码。 inode bitmap（inode对照表）inode bitmap则是记录使用与未使用的inode号码。 dumpe2fs与目录树的关系目录在Linux下的文件系统创建一个目录，文件系统会分配一个inode与至少一块block给该目录。其中inode与至少一块block给该目录。其中inode记录该目录的相关权限与属性，并可记录分配到的那块block号码。而block则是记录在这个目录下的文件名与该文件名占用的inode号码数据。也就是说目录所占用的block内容在记录如下的信息。 在目录下面的文件数如果太多而导致一个block无法容纳的下所有的文件名与inode对照表，Linux会给予该目录多一个block来继续记录相关的数据。 文件目录树读取inode本身并不记录文件名，文件名的记录是在目录的block当中。当我们要读取某个文件时，就务必会经过目录的inode与block然后才能找到那个待读取文件的inode号码，最终才会督导正确的文件的block内的数据。 由于目录树是由根目录开始读起，因此系统通过挂载的信息可以找到挂载点的inode号码，挂载点实际上就是linux中的磁盘文件系统的入口目录。此时就能够得到根目录的inode内容，并依据该inode读取根目录的block内的文件名数据，再一层一层的往下读到正确的文件名。比如读取/ etc / passwd这个文件时的过程。 / 的inode :通过挂载点的信息找到inode号码为128的根目录inode，且inode规范的权限让我们可以读取该block的内容(有r与x)。 / 的block: 经过上个步骤取得block的号码，并找到该内容有etc/ 目录的inode号码( 33595521)。 etc/ 的inode :读取33595521号inode得知dmtsai具有r与x的权限，因此可以读取etc/ 的block内容; etc/ 的block :经过上个步骤取得block号码，并找到该内容有passwd文件的inode号码 ( 36628004) passwd的inode : 读取36628004号inode得知dmtsai具有r的权限，因此可以读取passwd的block内容; passwd的block :最后将该block内容的数据读出来。 EXT2/ EXT3/ EXT4文件的存取与日志式文件系统的功能若是想要新增一个文件，文件系统的行为是。 先确定使用者对于欲新增文件的目录是否具有w与x的权限，若有的话才能新增; 根据inode bitmap找到没有使用的inode号码，并将新文件的权限/ 属性写入。 根据block bitmap找到没有使用中的block号码，并将实际的数据写入block中，且更新inode的block指向数据; 将刚刚写入的inode与block数据同步更新inode bitmap与block bitmap，并更新superblock的内容。 一般来说，我们将inode table与data block称为数据存放区域，至于其他例如superblock、block bitmap与inode bitmap等区段就被称为metadata (中介数据)，因为superblock,inode bitmap及block bitmap的数据是经常变动的，每次新增、移除、编辑时都可能会影响到这三个部分的数据，因此才被称为中介数据的啦。 数据的不一致（inconsistent）状态由于不知名的原因可能导致metadata的内容与实际数据存放区产生不一致（inconsistent）的情况。传统的解决方法会在开机时皆有superblock当中记录的valid bit与filesystem state等状态来判断是否强制进行数据一致性的检查。这样的检查是很费时的。非常麻烦，造成了后来日志式文件系统的兴起。 日志式文件系统（Journaling filesystem）为了避免文件系统不一致的发生，在filesystem中规划一个区块，该区块专门记录写入或修订文件的步骤，就可以简化一致性检查的步骤。 预备：当系统要写入一个文件时，会先在日志记录区块中纪录某个文件准备要写入的信息; 实际写入：开始写入文件的权限与数据，开始更新metadata的数据。 结束：完成数据与metadata的更新后，在日志记录块当中完成该文件的记录。 万一数据的纪录过程当中发生了问题，那么我们的系统只要去检查日志记录区块，就可以知道哪个文件发生了问题，针对该问题来做一致性的检查即可，而不必针对整块filesystem去检查，这样就可以达到快速修复filesystem的能力。 Linux文件系统的运行编辑一个好大的文件，在编辑的过程中又频繁的要系统来写入到磁盘中，由于磁盘写入的速度要比内存慢很多， 因此你会常常耗在等待磁盘的写入/读取上，很没效率。为解决效率问题，Linux使用的方式是通过一个非同步处理（asynchronously）的方式。 当系统载入一个文件到内存后，如果该文件没有被更动过，则在内存区段的文件数据会被设置为干净(clean) 的。但如果内存中的文件数据被更改过了(例如你用nano去编辑过这个文件)，此时该内存中的数据会被设置为脏的 (Dirty) 。此时所有的动作都还在内存中执行，并没有写入到磁盘中!系统会不定时的将内存中设置为”Dirty”的数据写回磁盘，以保持磁盘与内存数据的一致性。 内存的速度要比磁盘快的多,因此如果能够将常用的文件放置到内存当中，就会增加系统性能。因此我们Linux系统上面文件系统与内存有非常大的关系。 系统会将常用的文件数据放置到内存的缓冲区，以加速文件系统的读/ 写; 承上，因此Linux的实体内存最后都会被用光!这是正常的情况!可加速系统性能; 可以手动使用sync来强迫内存中设置为Dirty的文件回写到磁盘中; 若正常关机时，关机指令会主动调用sync来将内存的数据回写入磁盘内; 但若不正常关机(如跳电、死机或其他不明原因)，由于数据尚未回写到磁盘内, 因此重新开机后可能会花很多时间在进行磁盘检验，甚至可能导致文件系统的损毁(非磁盘损毁)。 挂载点的意义（mount point）将文件系统与目录树结合的动作我们称为挂载。重点是挂载点一定是目录，该目录为进入该文件系统的入口，因此并不是有任何文件系统都能使用的，必须挂载到目录树的某个目录后，才能够使用该文件系统。 其他Linux支持的文件系统与VFSLinux的标准文件系统是ext2，且还有增加了日志功能的ext3/ext4，事实上，Linux还有支持很多文件系统格式的，尤其是最近这几年推出了好几种速度很快的日志式文件系统，包括SGI的XFS文件系统， 可以适用更小型文件的Reiserfs 文件系统，以及Windows的FAT文件系统等等，都能够被Linux所支持。 Linux VFS（Virtual Filesystem Switch）Linux的系统都是通过一个名为Virtual Filesystem Switch 的核心功能去读取filesystem的。也就是说， 整个Linux 认识的filesystem 其实都是VFS在进行管理，我们使用者并不需要知道每个partition上头的filesystem是什么。VFS会主动的帮我们做好读取的动作。 XFS文件系统简介EXT家族当前较伤脑筋的地方：支持度最广，但格式化超慢。基本上xfs就是一个日志式文件系统。xfs文件系统在数据的分布上主要规划为三个部分，一个是数据区，一个文件系统活动登录区，以及一个实时运行区。 文件系统的简单操作磁盘与目录的容量df:列出文件系统的整体磁盘使用量 Filesystem：代表该文件系统是在哪个partition，所以列出设备名称。 1k-blocks :说明下面的数字单位是1KB，可利用-h或-m来改变容量。 Used:顾名思义，就是使用掉的磁盘空间。 Available :也就是剩下的磁盘空间大小。 Use% :就是磁盘的使用率。 Mounted on：就是磁盘挂载的目录所在（挂载点）。 由于df主要读取的数据几乎都是针对一整个文件系统，因此读取的范围主要是在Superblock内的信息，所以这个指令显示结果的速度非常的快速。 du 与df不一样的是，du这个指令其实会到文件系统去搜寻所有的文件数据，所以上述指令运行会执行一小段时间。 实体链接与符号链接：lnHard Link（实体链接，硬式链接或实际链接） hard link只是在某个目录下新增一笔文件名链接到某inode号码的关联记录而已。 hard link的限制： 不能跨Filesystem。 不能link目录。链接到目录时，链接的数据需要连同被链接目录下面的所有数据都创建链接。 Sysbolic Link（符号链接，亦是捷径） Sysbolic link就是在创建一个独立的文件，而这个文件会让数据的读取指向他link的那个文件的文件名。 hard link比较安全。但hard link的限制太多了，包括无法做目录的link，用途上还是比较受限的，反而是Symbolic Link的使用较广。 删除动作，如删除/ etc / crontab文件，删除动作只是将 / etc目录下关于crontab的关连数据拿掉而已，crontab所在的inode与block其实都没有被变动。 磁盘的分区，格式化，检验与挂载若是想在系统中新增一个磁盘，需要： 对磁盘进行分区，以创建可用的partition。 对该partition进行格式化 (format)， 以创建系统可用的filesystem 若想要仔细一点，则可对刚刚创建好的filesystem进行检验。 在Linux系统上，需要创建挂载点 (亦即是目录) ，并将他挂载上来。 观察磁盘分区状态lsblk列出系统上所有磁盘列表Isblk可以看成” list block device”的缩写， 就是列出所有储存设备的意思。 blikid列出设备的UUID等参数UUID是全域单一识别码（universally unique identifier），Linux会将系统内所有设备都给予一个独一无二的识别码。这个识别码就可以拿来作为挂载或是使用这个设备、文件系统之用了。 parted列出磁盘的分区表类型与分区信息 磁盘分区：gdisk/ fdisk用gdisk新增分区partprobe更新Linux核心的分区表信息用gdisk删除一个分区fdisk文件系统检验文件系统挂载与卸载磁盘、文件系统参数修订mknodxfs-admin修改XFS文件系统的UUID与Label name设置开机挂载开机挂载/etc/fstab及/etc/mtab特殊设备loop挂载内存交换空间（swap）之创建如果硬件的配备资源足够的话’那么swap应该不会被我们的系统所使用到swaρ会被利用到的时刻通常就是实体内存不足的情况。目前在个人使用上内存已经足够大，不用设置swap也不会有太大的问题，但是服务器就不一定了，由于不知道何时会有大量来自网络的请求，因此最好还是能够预留一些swap来缓冲一下系统的内存用量。有备无患。 使用实体分区创建swap 分区:先使用gdik在你的磁盘中分区出一个分区给系统作为swap。由于Linux的gdisk默认会将分区的ID设置为 Linux的文件系统，所以你可能还得要设置一下system ID就是了。 格式化∶利用创建swap格式的” mkswap设备文件名”就能够格式化该分区成为swap格式。 使用:最后将该swap设备启动,方法为:” swapon设备文件名”。 观察:最终通过free与 swapon-s这个指令来观察一下内存的用量。 使用文件创建swap文件与文件系统的压缩，打包与备份压缩文件的用途与技术Linux系统常见的压缩指令虽然Linux文件的属性基本上是与文件名没有绝对关系的，为了帮助人类，适当的扩展名还是必要的。 bzip2，bzcat,bzmore,bzless,bzgrepgzip是为了取代 compress并提供更好的压缩比而成立的,那么bzip2则是为了取代gzip并提供更佳的压缩比而来的。 xz,xzcat,xzmore,xzless,xzgrepxz的压缩比好很多，但是xz最大的问题就是时间花太久了。运算时间要比gzip久很多。 打包指令：tartar","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"鸟哥Linux基础   Linux的规划与安装","slug":"鸟哥Linux基础   Linux的规划与安装","date":"2019-01-20T12:25:32.000Z","updated":"2019-01-21T10:55:49.000Z","comments":true,"path":"2019/01/20/鸟哥Linux基础   Linux的规划与安装/","link":"","permalink":"https://github.com/zdkswd/2019/01/20/鸟哥Linux基础   Linux的规划与安装/","excerpt":"","text":"第零章、计算机概论CPU实际要处理的数据完全来自于内存（不管是程序还是一般文件数据）。CPU架构精简指令集RISC，如ARM架构。目前世界上使用范围最广的CPU就是ARM架构。复杂指令集CISC。AMD，Intel x86。 第一章、Linux是什么与如何学习早期的Linux是针对386开发的。Linux提供了一个完整的操作系统当中最底层的硬件控制与资源管理的完整架构，这个架构是沿袭Unix良好的传统来的，所以相当的稳定而功能强大！ Linux参考了标准的POSIX规范。POSIX是可携式操作系统接口的缩写，重点在规范核心与应用程序之间的接口，这是由美国电器与电子工程师学会（IEEE）所发布的一项标准。 Linux其实就是一个操作系统最底层的核心及其提供的核心工具。它是GNU GPL授权模式，所以任何人均可取得源代码与可执行这个核心程序，并且可以修改。此外，因为Linux参考POSIX设计规范，于是相容于Unix操作系统，亦可称为Unix Like的一种。 Linux distributions就是Kernel+Softwares+Tools+可完整安装程序。一般称为可完整安装套件或Linux发布商套件。 由于Linux核心是由工程师写得，由源代码安装到x86计算机上面成为可以执行的binary文件这个过程不是人人都会的，所以早期确实只有工程师对Linux感兴趣。一直到一些社群与商业公司将Linux核心配合自由软件，并提供完整的安装程序且制成光盘，对于一般人来说，Linux才越来越有吸引力。 每个distributions差异性并不大，主要是套件管理方式上的区分为dpkg和RPM。 到底是要买商业版还是社群版的Linux distribution呢?如果是要装在个人计算机上面做为桌面电脑用的， 建议使用社群版，包括Fedora, Ubuntu, OpenSuSE等等。如果是用在服务器上面的， 建议使用商业版本，包括Red Hat, SuSE等。这是因为社群版通常开发者会加入最新的软件，这些软件可能会有一些bug存在。至于商业版则是经过一段时间的磨合后，才将稳定的软件放进去。 Linux的运用场景企业环境的利用：网络服务器:这是Linux当前最热门的应用了!承袭了Unix高稳定性的良好传统，Linux.上面的网络功能特别的稳定与强大!此外，由于GNU计划与Linux的GPL授权模式，让很多优秀的软件都在Linux上面发展，且这些在Linux上面的服务器软件几乎都是自由软件!因此，做为一部网络服务器，例如WWW, Mail Server, File Server等等， Linux绝对是上上之选!当然，这也是Linux的强项!由于Linux server的需求强烈，因此许多硬件厂商推出产品时，还得要特别说明有支持的Linux distributions呢! 关键任务的应用（金融数据库、大型企业网管环境）由于个人计算机的性能大幅提升且价格便宜，所以金融业与大型企业的环境为了要精实自己机房的机器设备，因此很多企业渐渐的走向Intel相容的x86主机环境。而这些企业所使用的软件大多使用Unix操作系统平台的软件，总不能连过去发展的软件都一口气全部换掉吧!所以，这个时候符合Unix操作系统标准并且可以在x86.上运行的Linux就渐渐崭露头角了! 学术机构的高性能运算任务：学术机构的研究常常需要自行开发软件，所以对于可作为开发环境的操作系统需求非常的迫切!举例来说，非常多技职体系的科技大学就很需要这方面的环境，好进行一些毕业专题的制作呢!又例如工程界流体力学的数值模式运算、娱乐事业的特效功能处理、软件开发者的工作平台等等。由于Linux的创造者本身就是个计算机性能癖，所以Linux有强大的运算能力;并且Linux具有支持度相当广泛的GCC编译软件，因此Linux在这方面的优势可是相当明显的! 个人使用：个人电脑：为了要强化桌面电脑的使用率，Linux与X Window System结合了!要注意的是，X Window System仅只是Linux上面的一套软件，而不是核心喔!所以即使X Window挂了，对Linux也可能不会有直接的影响。 手持系统（PDA、手机）:Android就是Linux核心的一支，专门用来针对手机/平板这类ARM机器所设计的。 嵌入式系统：包括路由器、防火墙、手机、IP分享器、交换器、机器人控制芯片、家电用品的微计算机控制器等等，都可以是Linux操作系统喔! 云端运用：云程序端设备 以服务器或者是嵌入式系统的应用来说，X Window是非必备的软件，因为服务器是要提供用户端来连线的，X Window通常会吃掉很多系统资源。 第二章 主机规划与磁盘划分并非所有的产品都会支持特定的操作系统，这牵涉到硬件开发商是否有意愿提供适当的驱动程序之故。因此，当我们想要购买或者是升级某些计算机元件时，应该要特别注意该硬件是否有针对您的操作系统提供适当的驱动程序，否则可能买了无法使用。 在Linux系统中，每个设备被当成一个文件来对待，几乎所有的硬件设备文件都在/dev这个目录内。 磁盘分区整个磁盘的第一个扇区特别的重要，因为他记录了整个磁盘的重要信息。早期磁盘第一个扇区里面含有重要的信息称为MBR格式，但是由于磁盘的容量不断扩大，造成读写上的一些困扰，甚至有些大于2TB以上的磁盘分区已经让某些操作系统无法存取。因此后来又多了一个新的磁盘分区格式，称为GPT。 MSDOS（MBR）与GPTMSDOS（MBR）分区表格式与限制：早期的Linux系统为了相容于Windows的磁盘，因此使用的是支持Windows的MBR (Master Boot Record,主要开机纪录区)的方式来处理开机管理程序与分区表!而开机管理程序纪录区与分区表则通通放在磁盘的第一个扇区，这个扇区通常是512Bytes的大小(旧的磁盘扇区都是512Bytes喔!)，所以说，第一个扇区512Bytes会有这两个数据: 主要开机记录区（Masrer Boot Record,MBR）：可以安装开机管理程序的地方，有446Bytes 分区表（partition table）:记录整颗硬盘分区的状态，有64Bytes Linux安装模式下，磁盘分区的选择（极重要）目录树结构Linux内所有的数据都是以文件形态来呈现的，Linux系统最重要的地方就是在于目录树架构。就是以根目录为主，然后向下呈现分支状的目录结构的一种文件架构。 所有的文件都是由根目录（_）衍生来的，当要取得mydata那个文件时，系统就由根目录开始找，最终的文件名为: _home_dmtsai_mydata的意思。 文件系统与目录树的关系（挂载）挂载就是利用一个目录当成进入点，将磁盘分区的数据放置在该目录下，也就是说，进入该目录就可以读取该分区的意思。 假设硬盘分为两个分区 partition1是挂载到根目录,至于 partition2则是挂载到/ home这个目录。这也就是说当我的数据放置在 home 内的各次目录时,数据是放置到partition2的如果不是放在/home下面的目录,那么数据就会被放置到 partition1。 至少两个分区但记住至少要有两个分区，一个swap分区，一个/分区。swap分区是linux暂时存储数据的交换分区，它主要是把主内存上暂时不用得数据存起来，在需要的时候再调进内存内，且作为swap使用的分区不用指定“mout point”（载入点），既然它作为交换分区，我们理所当然应给它指定大小，它至少要等于系统上实际内存的量，一般来说它的大小是内存的两倍，如果你是16mb的内存，那么swap分区的大小是32mb左右，以此类推。但必须还要注意一点，swap分区不要大于128mb，因为系统不需要太大的交换分区。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"网络爬虫 爬小说 爬图片 爬视频","slug":"网络爬虫","date":"2019-01-16T12:15:32.000Z","updated":"2019-01-16T12:21:26.000Z","comments":true,"path":"2019/01/16/网络爬虫/","link":"","permalink":"https://github.com/zdkswd/2019/01/16/网络爬虫/","excerpt":"","text":"网络爬虫参考https://cuijiahua.com/blog/2017/10/spider_tutorial_1.html网络爬虫的第一步就是根据URL，获取网页的HTML信息。在Python3中，可以使用urllib.request和requests进行网页爬取。 urllib库是python内置的，无需我们额外安装，只要安装了Python就可以使用这个库。 requests库是第三方库，需要我们自己安装。 requests库的基础方法如下： requests.get()方法，它用于向服务器发起GET请求。requests.get()方法就是从服务器得到、抓住数据，也就是获取数据。 小说下载代码papapachong/爬取小说 at master · zdkswd/papapachong · GitHub 背景小说网站-笔趣看： URL：http:www.biqukan.com/笔趣看是一个盗版小说网站，这里有很多起点中文网的小说，该网站小说的更新速度稍滞后于起点中文网正版小说的更新速度。并且该网站只支持在线浏览，不支持小说打包下载。因此，本次实战就是从该网站爬取并保存一本名为《一念永恒》的小说，该小说是耳根正在连载中的一部玄幻小说。PS：本实例仅为交流学习，支持耳根大大，请上起点中文网订阅。 小试牛刀《一念永恒》小说的第一章内容，URL：http://www.biqukan.com/1_1094/5403177.html 通过result=rq.get(url=target)我们很轻松地获取了HTML信息。但是，很显然，很多信息是我们不想看到的，我们只想获得如右侧所示的正文内容，我们不关心div、br这些html标签。如何把正文内容从这些众多的html标签中提取出来呢？这就是本次实战的主要内容。 Beautiful Soup爬虫的第一步，获取整个网页的HTML信息，我们已经完成。接下来就是爬虫的第二步，解析HTML信息，提取我们感兴趣的内容。对于本小节的实战，我们感兴趣的内容就是文章的正文。提取的方法有很多，例如使用正则表达式、Xpath、Beautiful Soup等。对于初学者而言，最容易理解，并且使用简单的方法就是使用Beautiful Soup提取感兴趣内容。 Beautiful Soup中文的官方文档。URL：http://beautifulsoup.readthedocs.io/zh_CN/latest/ 仔细观察目标网站一番，我们会发现这样一个事实：class属性为showtxt的div标签，独一份！这个标签里面存放的内容，是我们关心的正文部分。 知道这个信息，我们就可以使用Beautiful Soup提取我们想要的内容了。在解析html之前，我们需要创建一个Beautiful Soup对象。BeautifulSoup函数里的参数就是我们已经获得的html信息。然后我们使用find_all方法，获得html信息中所有class属性为showtxt的div标签。find_all方法的第一个参数是获取的标签名，第二个参数class_是标签的属性，为什么不是class，而带了一个下划线呢？因为python中class是关键字，为了防止冲突，这里使用class_表示标签的class属性。 为什么不是find_all(‘div’, id = ‘content’, class_ = ‘showtxt’)?这样其实也是可以的，属性是作为查询时候的约束条件，添加一个class_=’showtxt’条件，我们就已经能够准确匹配到我们想要的标签了，所以我们就不必再添加id这个属性了。 此时结果中有一些我们不想要的东西。比如div标签名，br标签，以及各种空格。怎么去除这些东西呢？ find_all匹配的返回的结果是一个列表。提取匹配结果后，使用text属性，提取文本内容，滤除br标签。随后使用replace方法，剔除空格，替换为回车进行分段。&nbsp;在html中是用来表示空格的。replace(‘\\xa0’*8,’\\n\\n’)就是去掉下图的八个空格符号，并用回车代替。 可以看到，我们很自然的匹配到了所有正文内容，并进行了分段。我们已经顺利获得了一个章节的内容，要想下载正本小说，我们就要获取每个章节的链接。我们先分析下小说目录： URL：http:www.biqukan.com/1_1094/ 根据 标签的href属性值获得每个章节的链接和名称。小说每章的链接放在了class属性为listmain的标签下的标签中。链接具体位置放在html-&gt;body-&gt;div-&gt;dl-&gt;dd-&gt;a的href属性中。先匹配class属性为listmain的标签，再匹配标签。 爬取壁纸papapachong/爬取图片 at master · zdkswd/papapachong · GitHub 背景URL：https:unsplash.com/网站的名字叫做Unsplash，免费高清壁纸分享网是一个坚持每天分享高清的摄影图片的站点，每天更新一张高质量的图片素材，全是生活中的景象作品，清新的生活气息图片可以作为桌面壁纸也可以应用于各种需要的环境。 实战 使用requeusts获取整个网页的HTML信息； 使用Beautiful Soup解析HTML信息，找到所有标签，提取src属性，获取图片存放地址； 根据图片存放地址，下载图片。 照此方法得不到标签，而是\\&lt;script>标签，因为这个网站的所有图片都是动态加载的！网站有静态网站和动态网站之分，上一个实战爬取的网站是静态网站，而这个网站是动态网站，动态加载有一部分的目的就是为了反爬虫。 动态网站使用动态加载常用的手段就是通过调用JavaScript来实现的。一个动态加载的网站可能使用很多JavaScript脚本，我们只要找到负责动态加载图片的JavaScript脚本。强大的抓包工具，它会帮助分析。这个强大的抓包工具就是Fiddler。但是Fiddler只在Windows上才能发挥完全的作用，所以我用的是一个跨平台的抓包工具Charles。 经过抓包发现，在如下数据包中。 有json数据包 id和下载图片有以下的关系 所以可以 获取整个json数据 解析json数据 如果直接获取会出现SSL认证的错误，SSL认证是指客户端到服务器端的认证。一个非常简单的解决这个认证错误的方法就是设置requests.get()方法的verify参数。这个参数默认设置为True，也就是执行认证。我们将其设置为False，绕过认证。 反爬虫的手段除了动态加载，还有一个反爬虫手段，那就是验证Request Headers。Requests Headers里有很多参数，有Accept、Accept-Encoding、Accept-Language、DPR、User-Agent、Viewport-Width、accept-version、Referer、x-unsplash-client、authorization、Connection、Host。 User-Agent：这里面存放浏览器的信息。如果我们不设置这个参数，用Python程序直接发送GET请求，服务器接受到的User-Agent信息就会是一个包含python字样的User-Agent。如果后台设计者验证这个User-Agent参数是否合法，不让带Python字样的User-Agent访问，这样就起到了反爬虫的作用。这是一个最简单的，最常用的反爬虫手段。 Referer：这个参数也可以用于反爬虫，它表示这个请求是从哪发出的。可以看到我们通过浏览器访问网站，这个请求是从https://unsplash.com/，这个地址发出的。如果后台设计者，验证这个参数，对于不是从这个地址跳转过来的请求一律禁止访问，这样就也起到了反爬虫的作用。 authorization：这个参数是基于AAA模型中的身份验证信息允许访问一种资源的行为。在我们用浏览器访问的时候，服务器会为访问者分配这个用户ID。如果后台设计者，验证这个参数，对于没有用户ID的请求一律禁止访问，这样就又起到了反爬虫的作用。 Unsplash是根据authorization参数进行反爬虫的。通过程序手动添加这个参数，然后再发送GET请求，就可以顺利访问了。即requests.get()方法，添加headers参数即可。 现在终于顺利获得json数据了，使用json.load()方法解析数据。解析json数据很简单，跟字典操作一样，就是字典套字典。json.load()里面的参数是原始的json格式的数据。 图片的ID已经获得了，再通过字符串处理一下，就生成了我们需要的图片下载请求地址。根据这个地址，我们就可以下载图片了。下载方式，使用直接写入文件的方法。 每次获取链接加一个1s延时，因为人在浏览页面的时候，翻页的动作不可能太快。我们要让我们的爬虫尽量友好一些。 下载速度还行，有的图片下载慢是因为图片太大。可以看到也打印了一些警报信息，这是因为没有进行SSL验证。 爱奇艺VIP视频下载现在失效了，只能手动抓包了papapachong/爬取视频 at master · zdkswd/papapachong · GitHubvip视频解析,vip视频在线解析有效的url解析网站。解析格式：www.wq114.org/yun.php?url= [视频url]利用网络爬虫进行抓包，可以将视频下载下来。 HTTP请求头Referer的作用：表示请求来源。 编写代码的时候注意一个问题，就是我们需要使用requests.session()保持我们的会话请求。简单理解就是，在初次访问服务器的时候，服务器会给你分配一个身份证明。我们需要拿着这个身份证去继续访问，如果没有这个身份证明，服务器就不会再让你访问。这也就是这个服务器的反爬虫手段，会验证用户的身份。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://github.com/zdkswd/tags/爬虫/"}]},{"title":"SSH","slug":"SSH","date":"2019-01-16T12:09:56.000Z","updated":"2019-01-16T12:11:36.000Z","comments":true,"path":"2019/01/16/SSH/","link":"","permalink":"https://github.com/zdkswd/2019/01/16/SSH/","excerpt":"","text":"SSH参考http://www.ruanyifeng.com/blog/2011/12/ssh_remote_login.html 什么是SSHSSH是一种网络协议，用于计算机之间的加密登录。 如果一个用户从本地计算机，使用SSH协议登录另一台远程计算机，我们就可以认为，这种登录是安全的，即使被中途截获，密码也不会泄露。 最早的时候，互联网通信都是明文通信，一旦被截获，内容就暴露无疑。1995年，芬兰学者Tatu Ylonen设计了SSH协议，将登录信息全部加密，成为互联网安全的一个基本解决方案，迅速在全世界获得推广，目前已经成为Linux系统的标准配置。 SSH只是一种协议，存在多种实现，既有商业实现，也有开源实现。本文针对的实现是OpenSSH，它是自由软件，应用非常广泛。本文只讨论SSH在Linux Shell中的用法。 最基本的用法SSH主要用于远程登录。假定你要以用户名user，登录远程主机host，只要一条简单命令就可以了。 如果本地用户名与远程用户名一致，登录时可以省略用户名。 SSH的默认端口是22，也就是说，你的登录请求会送进远程主机的22端口。使用p参数，可以修改这个端口。 上面这条命令表示，ssh直接连接远程主机的2222端口。 中间人攻击SSH之所以能够保证安全，原因在于它采用了公钥加密。 整个过程是这样的：（1）远程主机收到用户的登录请求，把自己的公钥发给用户。（2）用户使用这个公钥，将登录密码加密后，发送回来。（3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。 这个过程本身是安全的，但是实施的时候存在一个风险：如果有人截获了登录请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪。因为不像https协议，SSH协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。 可以设想，如果攻击者插在用户与远程主机之间（比如在公共的wifi区域），用伪造的公钥，获取用户的登录密码。再用这个密码登录远程主机，那么SSH的安全机制就荡然无存了。这种风险就是著名的”中间人攻击”（Man-in-the-middle attack）。 SSH协议也有应对的方法。 口令登录如果你是第一次登录对方主机，系统会出现下面的提示： 这段话的意思是，无法确认host主机的真实性，只知道它的公钥指纹，问你还想继续连接吗？ 所谓”公钥指纹”，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将它变成一个128位的指纹。上例中是98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d，再进行比较，就容易多了。 很自然的一个问题就是，用户怎么知道远程主机的公钥指纹应该是多少？回答是没有好办法，远程主机必须在自己的网站上贴出公钥指纹，以便用户自行核对。 假定经过风险衡量以后，用户决定接受这个远程主机的公钥。 系统会出现一句提示，表示host主机已经得到认可。然后会要求输入密码。密码正确就可以登录了。 当远程主机的公钥被接受以后，它就会被保存在文件$HOME/ .ssh /known_hosts之中。下次再连接这台主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。 每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/ etc / ssh /ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。 公钥登录使用密码登录，每次都必须输入密码，非常麻烦。好在SSH还提供了公钥登录，可以省去输入密码的步骤。 所谓”公钥登录”，原理很简单，就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。 这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用ssh-keygen生成一个： 运行上面的命令以后，系统会出现一系列提示，可以一路回车。其中有一个问题是，要不要对私钥设置口令（passphrase），如果担心私钥的安全，这里可以设置一个。 运行结束以后，在$HOME/ .ssh /目录下，会新生成两个文件：id_rsa.pub和id_rsa。前者是你的公钥，后者是你的私钥。 这时再输入下面的命令，将公钥传送到远程主机host上面： 从此再登录，就不需要输入密码了。 如果还是不行，就打开远程主机的_etc_ssh/sshd_config这个文件，检查下面几行前面# 注释是否取掉。 然后，重启远程主机的ssh服务。 公钥私钥补充如果只是单方面采用非对称性加密算法,其实有两种方式,用于不同用处。 第一种是签名,使用私钥加密,公钥解密,用于让所有公钥所有者验证私钥所有者的身份并且用来防止私钥所有者发布的内容被篡改.但是不用来保证内容不被他人获得。 第二种是加密,用公钥加密,私钥解密,用于向公钥所有者发布信息,这个信息可能被他人篡改,但是无法被他人获得。 如果甲想给乙发一个安全的保密的数据,那么应该甲乙各自有一个私钥,甲先用乙的公钥加密这段数据,再用自己的私钥加密这段加密后的数据.最后再发给乙,这样确保了内容即不会被读取,也不会被篡改。 远程操作SSH不仅可以用于远程主机登录，还可以直接在远程主机上执行操作。 SSH可以在用户和远程主机之间，建立命令和数据的传输通道，因此很多事情都可以通过SSH来完成。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://github.com/zdkswd/tags/计算机网络/"}]},{"title":"python requests库","slug":"python requests库","date":"2019-01-14T04:03:56.000Z","updated":"2019-01-14T04:20:40.000Z","comments":true,"path":"2019/01/14/python requests库/","link":"","permalink":"https://github.com/zdkswd/2019/01/14/python requests库/","excerpt":"","text":"requests库的使用（廖雪峰）要通过GET访问一个页面，只需要几行代码： 对于带参数的URL，传入一个dict作为params参数： requests自动检测编码，可以使用encoding属性查看： 无论响应是文本还是二进制内容，我们都可以用content属性获得bytes对象： requests的方便之处还在于，对于特定类型的响应，例如JSON，可以直接获取： 需要传入HTTP Header时，我们传入一个dict作为headers参数： 要发送POST请求，只需要把get()方法变成post()，然后传入data参数作为POST请求的数据： requests默认使用application/x-www-form-urlencoded对POST数据编码。如果要传递JSON数据，可以直接传入json参数： 类似的，上传文件需要更复杂的编码格式，但是requests把它简化成files参数： 在读取文件时，注意务必使用’rb’即二进制模式读取，这样获取的bytes长度才是文件的长度。 把post()方法替换为put()，delete()等，就可以以PUT或DELETE方式请求资源。 除了能轻松获取响应内容外，requests对获取HTTP响应的其他信息也非常简单。例如，获取响应头： requests对Cookie做了特殊处理，使得我们不必解析Cookie就可以轻松获取指定的Cookie： 要在请求中传入Cookie，只需准备一个dict传入cookies参数： 最后，要指定超时，传入以秒为单位的timeout参数： requests的使用（博客）https://blog.csdn.net/WuZuoDingFeng/article/details/76156777 requests.get() 参数说明： requests.post() 参数说明： 请求响应体说明 requests.utils中的常用方法 requests.utils.get_encodings_from_content(r.content): 返回原始数据编码; requests.utils.dict_from_cookiejar(r.cookies): 将CookieJar转为字典; requests.utils.cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True): 将字典转为CookieJar; 开启会话，保持cookie s = requests.Session() # 开启会话cookies = json.loads(result) # phantomjs获取的cookies json对象cookie = {}for k in cookies: cookie[k[‘name’]] = k[‘value’] # 获取每个cookie中的name和values.cookies = requests.utils.cookiejar_from_dict(cookie, cookiejar=None,overwrite=True) # 将字典cookie转换为cookieJar,然后放在会话中s.get(url…..) # 此时每个请求都会带上cookie……………………………………………………s.cookies: cookiejar对象;s.cookies.get_dict(): dict,cookie键值对; 设置超时和最大尝试次数 timeout是get/post等的参数, 单位秒. max_retries需要构建一个HTTPAdapter并设置其max_retries, 最后将该Adaptor加载给requests的Session对象. mount时的链接是前端最大匹配, 使用” http: ”和” https: ”可以分别对应两大类网址. 也可以更具体针对某网站. 注：max_retries适用于超时，并不适用于访问出错。 注：在会话中，请求url1所返回的cookies会自动保存，当访问url2的时候也会被自动带入。 requestsSession = requests.Session() # 开启会话requestsAdapterA = requests.adapters.HTTPAdapter(max_retries=3) # 挂载适配器requestsSession.mount(‘http: ‘, requestsAdapterA) # 此会话中适用所有http请求r = requestsSession.get(url , timeout=20) # 打开相应url并设置超时 上传文件 url = ‘http://httpbin.org/post&#39;files = {‘file’: open(‘report.xls’, ‘rb’)} # files = {‘file’: (‘report.xls’, open(‘report.xls’, ‘rb’), ‘application/vnd.ms-excel’, {‘Expires’: ‘0’})} # 显示的设置文件名、文件类型、文件头r = requests.post(url, files=files)r.text 流式上传 文件下载 注意事项 get()或post()中的headers、cookies设置的值，将合并到Requests中去，所以传入 {} 也没关系； 图片、pdf等打开方式应该为 ‘wb’，写入的内容应该是 r.content； 若是响应头Content-Type中不含charset，则 r.text 默认为 ‘ISO-8859-1’； 若是timeout没有显示的设置，理论上requests请求永不超时。 在session中删除一个参数，直接设置其值为None；","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"安卓开发的MVC和MVP模式","slug":"安卓开发的MVC和MVP模式","date":"2019-01-08T12:04:56.000Z","updated":"2019-01-08T12:04:43.000Z","comments":true,"path":"2019/01/08/安卓开发的MVC和MVP模式/","link":"","permalink":"https://github.com/zdkswd/2019/01/08/安卓开发的MVC和MVP模式/","excerpt":"","text":"MVC和MVP示意图 MVP和MVC的区别 Activity职责不同，Activity在MVP中是View层，在MVC中是Controller层，这是MVC和MVP很主要的一个区别，可以说Android从MVC转向MVP开发也主要是优化Activity的代码，避免Activity的代码臃肿庞大。 View层不同，MVC的View层指的是XML布局文件或者是用Java自定义的View，MVP的View层是Activity或者Fragment。使用传统的MVC，其中的View，对应的是各种Layout布局文件，但是这些布局文件中并不像Web端那样强大，能做的事情非常有限。MVP的View层Activity在实际项目中，随着逻辑的复杂度越来越大，Activity臃肿的缺点仍然体现出来了，因为Activity中还是充满了大量与View层无关的代码，比如各种事件的处理派发，就如MVC中的那样View层和Controller代码耦合在一起无法自拔。 控制层不同，MVC的控制层是Activity，或者是Fragment，Controller对应的是Activity，而Activity中却又具有操作UI的功能，我们在实际的项目中也会有很多UI操作在这一层，也做了很多View中应该做的事情，当然Controller层Activity中也包含Controller应该做的事情，比如各种事件的派发回调，而且在一层中我们会根据事件再去调用Model层操作数据，所以这种MVC的方式在实际项目中，Activity所在的Controller是非常重的，各层次之间的耦合情况也比较严重，不方便单元测试。MVP的控制层是Presenter，里面没有很多的实际东西，主要是做Model和View层的交互。 关系链不同，MVP中Model层与View是没有关系的，彼此不会通讯和操作，Model与View的通讯都是Presenter层来传达的。但是在MVC中，Model层和View是曾在交互的。比如我们自定义的View控件里面肯定是要使用Model的数据的，View也要根据不同的Model数据做出不同的展现！这点尤其是体现在自定义的View中，自定义View需要设置数据，用户操作了自定义控件需要改变数据，View要操作Model怎么办？有人说把Controller传到自定义的View啊，现实是不可能没一个自定义View都去持有Controller的引用，其实在MVP中就不会这么尴尬，接口就可以完成。 适用范围不同，在Android中，MVP和MVC都用自己的适用情况，使用MVP可以更好的解耦三大模块，模块之间比较清晰，也很方便使用MVP来组件化架构整体项目。但是MVC也是有用武之地的，在组件化的Module或者中间件我们可以使用MVC来做，Module或者中间件不会存在很复杂的View层，使用MVC可以更加方便我们实现功能。 交互方式不同，MVP中通讯交互基本都是通过接口的，MVC中的通讯交互很多时候都是实打实的调用对象的方法，简单粗暴！ 实现方法不同 ，MVC和MVP的Model几乎一样的，都是处理数据，只要不在Activity或者Fragment中请求数据，其他的所有控制都放在Activity或者Fragment中，这样写就基本是MVC的模式，这样写不麻烦，但是很容易把Activity写出上万行代码。用MVP的时候我们需要写很多View和Presenter接口来实现模块之间的通讯，会增加很多类。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"}]},{"title":"C++内存格局 汇编语言","slug":"C++内存格局","date":"2019-01-05T06:48:56.000Z","updated":"2019-01-05T06:55:53.000Z","comments":true,"path":"2019/01/05/C++内存格局/","link":"","permalink":"https://github.com/zdkswd/2019/01/05/C++内存格局/","excerpt":"","text":"C++内存格局C++程序的内存格局通常分为四个区：全局数据区(data area)，代码区(code area)，栈区(stack area)，堆区(heap area)(即自由存储区)。全局数据区存放全局变量，静态数据和常量；所有类成员函数和非成员函数代码存放在代码区；为运行函数而分配的局部变量、函数参数、返回数据、返回地址等存放在栈区；余下的空间都被称为堆区。根据这个解释，我们可以得知在类的定义时，类成员函数是被放在代码区，而类的静态成员变量在类定义时就已经在全局数据区分配了内存，因而它是属于类的。对于非静态成员变量，我们是在类的实例化过程中(构造对象)才在栈区或者堆区为其分配内存，是为每个对象生成一个拷贝，所以它是属于对象的。 汇编语言 计算机真正能够理解的是低级语言，它专门用来控制硬件。汇编语言就是低级语言，直接描述/控制 CPU 的运行。 汇编语言是什么CPU 只负责计算，本身不具备智能。你输入一条指令（instruction），它就运行一次，然后停下来，等待下一条指令。指令都是二进制的，称为操作码（opcode），比如加法指令就是00000011。编译器的作用，就是将高级语言写好的程序，翻译成一条条操作码。对于人类来说，二进制程序是不可读的，根本看不出来机器干了什么。为了解决可读性的问题，以及偶尔的编辑需求，就诞生了汇编语言。 汇编语言是二进制指令的文本形式，与指令是一一对应的关系。比如，加法指令00000011写成汇编语言就是 ADD。只要还原成二进制，汇编语言就可以被 CPU 直接执行，所以它是最底层的低级语言。 来历最早的时候，编写程序就是手写二进制指令，然后通过各种开关输入计算机，比如要做加法了，就按一下加法开关。后来，发明了纸带打孔机，通过在纸带上打孔，将二进制指令自动输入计算机。 为了解决二进制指令的可读性问题，工程师将那些指令写成了八进制。二进制转八进制是轻而易举的，但是八进制的可读性也不行。很自然地，最后还是用文字表达，加法指令写成 ADD。内存地址也不再直接引用，而是用标签表示。 这样的话，就多出一个步骤，要把这些文字指令翻译成二进制，这个步骤就称为 assembling，完成这个步骤的程序就叫做 assembler。它处理的文本，自然就叫做 aseembly code。标准化以后，称为 assembly language，缩写为 asm，中文译为汇编语言。 每一种 CPU 的机器指令都是不一样的，因此对应的汇编语言也不一样。本文介绍的是目前最常见的 x86 汇编语言，即 Intel 公司的 CPU 使用的那一种。 寄存器CPU 本身只负责运算，不负责储存数据。数据一般都储存在内存之中，CPU 要用的时候就去内存读写数据。但是，CPU 的运算速度远高于内存的读写速度，为了避免被拖慢，CPU 都自带一级缓存和二级缓存。基本上，CPU 缓存可以看作是读写速度较快的内存。 但是，CPU 缓存还是不够快，另外数据在缓存里面的地址是不固定的，CPU 每次读写都要寻址也会拖慢速度。因此，除了缓存之外，CPU 还自带了寄存器（register），用来储存最常用的数据。也就是说，那些最频繁读写的数据（比如循环变量），都会放在寄存器里面，CPU 优先读写寄存器，再由寄存器跟内存交换数据。 寄存器不依靠地址区分数据，而依靠名称。每一个寄存器都有自己的名称，我们告诉 CPU 去具体的哪一个寄存器拿数据，这样的速度是最快的。有人比喻寄存器是 CPU 的零级缓存。 寄存器的种类早期的 x86 CPU 只有8个寄存器，而且每个都有不同的用途。现在的寄存器已经有100多个了，都变成通用寄存器，不特别指定用途了，但是早期寄存器的名字都被保存了下来。EAX，EBX，ECX，EDX，EDI，ESI，EBP，ESP8个寄存器之中，前面七个都是通用的。ESP 寄存器有特定用途，保存当前 Stack 的地址。 32位 CPU、64位 CPU 这样的名称，其实指的就是寄存器的大小。32 位 CPU 的寄存器大小就是4个字节。 内存模型：Heap寄存器只能存放很少量的数据，大多数时候，CPU 要指挥寄存器，直接跟内存交换数据。所以，除了寄存器，还必须了解内存怎么储存数据。 程序运行的时候，操作系统会给它分配一段内存，用来储存程序和运行产生的数据。这段内存有起始地址和结束地址，比如从0x1000到0x8000，起始地址是较小的那个地址，结束地址是较大的那个地址。 程序运行过程中，对于动态的内存占用请求（比如新建对象，或者使用malloc命令），系统就会从预先分配好的那段内存之中，划出一部分给用户，具体规则是从起始地址开始划分（实际上，起始地址会有一段静态数据，这里忽略）。举例来说，用户要求得到10个字节内存，那么从起始地址0x1000开始给他分配，一直分配到地址0x100A，如果再要求得到22个字节，那么就分配到0x1020。 这种因为用户主动请求而划分出来的内存区域，叫做 Heap（堆）。它由起始地址开始，从低位（地址）向高位（地址）增长。Heap 的一个重要特点就是不会自动消失，必须手动释放，或者由垃圾回收机制来回收。 内存模型：Stack除了 Heap 以外，其他的内存占用叫做 Stack（栈）。简单说，Stack 是由于函数运行而临时占用的内存区域。 如 上面代码中，系统开始执行main函数时，会为它在内存里面建立一个帧（frame），所有main的内部变量（比如a和b）都保存在这个帧里面。main函数执行结束后，该帧就会被回收，释放所有的内部变量，不再占用空间。 如果函数内部调用了其他函数，会发生什么情况？ 上面代码中，main函数内部调用了add_a_and_b函数。执行到这一行的时候，系统也会为add_a_and_b新建一个帧，用来储存它的内部变量。也就是说，此时同时存在两个帧：main和add_a_and_b。一般来说，调用栈有多少层，就有多少帧。 等到add_a_and_b运行结束，它的帧就会被回收，系统会回到函数main刚才中断执行的地方，继续往下执行。通过这种机制，就实现了函数的层层调用，并且每一层都能使用自己的本地变量。 所有的帧都存放在 Stack，由于帧是一层层叠加的，所以 Stack 叫做栈。生成新的帧，叫做”入栈”，英文是 push；栈的回收叫做”出栈”，英文是 pop。Stack 的特点就是，最晚入栈的帧最早出栈（因为最内层的函数调用，最先结束运行），这就叫做”后进先出”的数据结构。每一次函数执行结束，就自动释放一个帧，所有函数执行结束，整个 Stack 就都释放了。 Stack 是由内存区域的结束地址开始，从高位（地址）向低位（地址）分配。比如，内存区域的结束地址是0x8000，第一帧假定是16字节，那么下一次分配的地址就会从0x7FF0开始；第二帧假定需要64字节，那么地址就会移动到0x7FB0。 CPU指令一个实例一个简单的程序example.c。 gcc 将这个程序转成汇编语言。 上面的命令执行以后，会生成一个文本文件example.s，里面就是汇编语言，包含了几十行指令。一个高级语言的简单操作，底层可能由几个，甚至几十个 CPU 指令构成。CPU 依次执行这些指令，完成这一步操作。 example.s经过简化以后，大概是下面的样子。 可以看到，原程序的两个函数add_a_and_b和main，对应两个标签_add_a_and_b和_main。每个标签里面是该函数所转成的 CPU 运行流程。每一行就是 CPU 执行的一次操作。它又分成两部分，就以其中一行为例。 这一行里面，push是 CPU 指令，%ebx是该指令要用到的运算子。一个 CPU 指令可以有零个到多个运算子。 push指令根据约定，程序从_main标签开始执行，这时会在 Stack 上为main建立一个帧，并将 Stack 所指向的地址，写入 ESP 寄存器。后面如果有数据要写入main这个帧，就会写在 ESP 寄存器所保存的地址。 然后，开始执行第一行代码。 push指令用于将运算子放入 Stack，这里就是将3写入main这个帧。虽然看上去很简单，push指令其实有一个前置操作。它会先取出 ESP 寄存器里面的地址，将其减去4个字节，然后将新地址写入 ESP 寄存器。使用减法是因为 Stack 从高位向低位发展，4个字节则是因为3的类型是int，占用4个字节。得到新地址以后， 3 就会写入这个地址开始的四个字节。 第二行也是一样，push指令将2写入main这个帧，位置紧贴着前面写入的3。这时，ESP 寄存器会再减去 4个字节（累计减去8）。 call指令第三行的call指令用来调用函数。 上面的代码表示调用add_a_and_b函数。这时，程序就会去找_add_a_and_b标签，并为该函数建立一个新的帧。下面就开始执行_add_a_and_b的代码。 这一行表示将 EBX 寄存器里面的值，写入_add_a_and_b这个帧。这是因为后面要用到这个寄存器，就先把里面的值取出来，用完后再写回去。 这时，push指令会再将 ESP 寄存器里面的地址减去4个字节（累计减去12）。 mov指令mov指令用于将一个值写入某个寄存器。 这一行代码表示，先将 ESP 寄存器里面的地址加上8个字节，得到一个新的地址，然后按照这个地址在 Stack 取出数据。根据前面的步骤，可以推算出这里取出的是2，再将2写入 EAX 寄存器。下一行代码也是干同样的事情。 上面的代码将 ESP 寄存器的值加12个字节，再按照这个地址在 Stack 取出数据，这次取出的是3，将其写入 EBX 寄存器。 add指令add指令用于将两个运算子相加，并将结果写入第一个运算子。 上面的代码将 EAX 寄存器的值（即2）加上 EBX 寄存器的值（即3），得到结果5，再将这个结果写入第一个运算子 EAX 寄存器。 pop指令pop指令用于取出 Stack 最近一个写入的值（即最低位地址的值），并将这个值写入运算子指定的位置。 上面的代码表示，取出 Stack 最近写入的值（即 EBX 寄存器的原始值），再将这个值写回 EBX 寄存器（因为加法已经做完了，EBX 寄存器用不到了）。 注意，pop指令还会将 ESP 寄存器里面的地址加4，即回收4个字节。 ret指令ret指令用于终止当前函数的执行，将运行权交还给上层函数。也就是，当前函数的帧将被回收。 可以看到，该指令没有运算子。 随着add_a_and_b函数终止执行，系统就回到刚才main函数中断的地方，继续往下执行。 上面的代码表示，将 ESP 寄存器里面的地址，手动加上8个字节，再写回 ESP 寄存器。这是因为 ESP 寄存器的是 Stack 的写入开始地址，前面的pop操作已经回收了4个字节，这里再回收8个字节，等于全部回收。 最后，main函数运行结束，ret指令退出程序执行。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://github.com/zdkswd/tags/C/"},{"name":"汇编","slug":"汇编","permalink":"https://github.com/zdkswd/tags/汇编/"}]},{"title":"C++ Primer 对象和类","slug":"C++ Primer 对象和类","date":"2019-01-04T12:32:56.000Z","updated":"2019-01-04T12:39:08.000Z","comments":true,"path":"2019/01/04/C++ Primer 对象和类/","link":"","permalink":"https://github.com/zdkswd/2019/01/04/C++ Primer 对象和类/","excerpt":"","text":"C++ Primer 对象和类C++中的类 类设计尽可能将公有接口与实现细节分开。公有接口表示设计的抽象组件。将实现细节放在一起并将它们与抽象分开被称为封装。数据隐藏(将数据放在类的私有部分中)是一种封装，将实现的细节隐藏在私有部分中，就像Stock类对set tot() 所做的那样，也是一种封装。封装的另一个例子是，将类函数定义和类声明放在不同的文件中。 控制对成员的访问：公有还是私有无论类成员是数据成员还是成员函数，都可以在类的公有部分或私有部分中声明它。但由于隐藏数据是OOP主要的目标之一，因此数据项通常放在私有部分，组成类接口的成员函数放在公有部分:否则，就无法从程序中调用这些函数。也可以把成员函数放在私有部分。不能直接从程序中调用这种函数，但公有方法却可以使用它们。通常，程序员使用私有成员函数来处理不属于公有接口的实现细节。 不必在类声明中使用关键字 private, 因为这是类对象的默认访问控制: 为强调数据隐藏的概念，显式使用private。 类和结构类描述看上去很像是包含成员函数以及public和private可见性标签的结构声明。实际上，C++对结构进行了扩展，使之具有与类相同的特性 它们之间惟一的区别是，结构的默认访问类型是public, 而类为private C++程序员通常使用类来实现类描述，而把结构限制为只表示纯粹的数据对象或没有私有部分的类。 实现类成员函数成员函数定义与常规丽数定义非常相似，它们有函数头和函数体，也可以有返回类型和参数。但是它们还有两个特殊的特征: 定义成员函数时，使用作用域解析操作符(::) 来标识函数所属的类。 类方法可以访问类的private组件。 如： 类方法的完整名称中包括类名。我们说，Stock::update() 是函数的限定名(qualfied name);而简单的update()是全名的缩写(非限定名，unqualified name), 它只能在类作用域中使用。 这些方法定义可以放在单独一个文件中，也可以位于类声明所在的文件中。 内联方法其定义位于类声明中的函数都将自动成为内联函数。如果愿意，也可以在类声明之外定义成员函数，并使其成为内联函数。为此只需要在类实现部分中定义函数时使用inline限定符即可。 内联函数的特殊规则要求在每个使用它们的文件中都对其进行定义。确保内联定义对多文件程序中的所有文件都可用的、最简便的方法是:将内联定义放在定义类的头文件中(有些开发系统包含智能链接程序，允许将内联定义放在一个独立的实现文件)。 方法与对象所创建的每个新对象都有自己的存储空间，用于存储其内部变量和类成员;但同一个类的所有对象共享同一组类方法，即每种方法只有一个副本。例如，假设kate和joe都是Stock对象，则kate.shares将占据一个内存块，而je.shares 占用另一一个内存块， 但kate.show()和joe.show()都调用同一个方法，也就是说，它们将执行同一个代码块，只是将这些代码用于不同的数据。在OOP中，调用成员函数被称为发送消息，因此将同样的消息发送给2个不同的对象将调用同一个方法，但该方法被用于2个不同的对象。 类的构造函数和析构函数C++提供了一个特殊的成员函数—类构造函数，专门用于构造新对象、将值赋给它们的数据成员。更准确地说，C++为这些成员函数提供了名称和使用方法，而程序员需要提供方法定义。构造函数的原型和函数头有一个有趣的特征—虽然没有返回值，但没有被声明为void类型。实际上，构造函数没有声明类型。 声明和定义构造函数原型如下： 构造函数的一种可能定义： 程序声明对象时，将自动调用构造函数。参数名不能与类成员相同，为避免混乱，通常的做法是在数据成员名中使用m_前缀： 使用构造函数C++提供了两种使用构造函数来初始化对象的方式。第一种方式是显式地调用构造函数: 另一种方式是隐式地调用构造函数: 它与下面的显式调用等价： 每次创建类对象(甚至使用new动态分配内存)时，C++都将使用类构造函数。下面是将构造函数与new 起使用的方法: 这条语句创建一个Stock对象，将其初始化为参数提供的值，并将该对象的地址赋给pstock指针。在这种情况下，对象没有名称，但可以使用指针来管理该对象。 无法使用对象来调用构造函数，因为在构造函数构造出对象之前，对象是不存在的。因此构造函数被用来创建对象， 而不能通过对象来调用。 默认构造函数默认构造函数是在未提供显式的初始化值时,被用来创建对象的构造函数。 如果没有提供任何构造函数，则C++将自动提供默认构造函数。它是默认构造函数的隐式版本，不做任何工作。对于Stock类来说，默认构造函数可能如下： 创建 stock 对象,但不初始化其成员,这和下面的语句 创建x,但没有提供值给它一样。默认构造函数没有参数,因为声明中不包含值。 当且仅当没有定义任何构造函数时,编译器才会提供默认构造函数。为类定义了构造函数后,程序员就必须为它提供默认构造函数。如果提供了非默认构造函数但没有提供默认构造函数,则将出错。如果要创建对象,而不显式地初始化, 则必须定义一个不接受任何参数的默认构造函数。 定义默认构造函数的方式有两种。一种是给已有构造函数的所有参数提供默认值: 另一种方式是通过函数重载来定义另一个构造函数一一一个没有参数的构造函数: 由于只能有个默认构造函数， 因此不要同时采用这两种方式。 在设计类时，通常应提供对所有类成员做隐式初始化的默认构造函数。 使用上述任何一种方式(没有参数或所有参数都有默认值)创建了默认构造函数后，便可以声明对象变量，而不对它们进行显式初始化: 隐式地调用默认构造函数时，不要使用圆括号。 析构函数用构造函数创建对象后，程序负责跟踪该对象，直到其过期为止。对象过期时，程序将自动调用一个特殊的成员函数，该函数的名称令人生畏一析构函数。析构函数完成清理工作，因此实际上很有用。如，如果构造函数使用new 来分配内存，则析构函数将使用delete来释放这些内存。如果构造函数没有使用new，析构函数实际上没有需要完成的任务。此时，只需让编译器生成一个什么都不用做的隐式析构函数。 和构造函数一样，析构函数的名称也很特殊:在类名前加上(~)。因此，Stock类的析构函数为~Stock().另外， 和构造函数一样，析构函数也可以没有返回值和声明类型。与构造函数不同的是，析构函数没有参数，因此析构函数的原型必须是这样的: 什么时候调用析构函数由编译器决定，通常不应在代码中显式地调用析构函数。如果创建的是静态存储类对象，则其析构函数将在程序结束时自动被调用。如果创建的是自动存储类对象,则其析构函数将在程序执行完代码块时(该对象是在其中定义的)自动被调用。如果对象是通过new创建的，则它将驻留在堆栈内存或自由存储区中，当使用delete来释放内存时，其析构函数将自动被调用。最后，程序可以创建临时对象来完成特定的操作，在这种情况下，程序将在结束对该对象的使用时自动调用其析构函数。 由于在类对象过期时析构函数将自动被调用，因此必须有- 个析构函数。如果程序员没有提供析构函数，编译器将隐式地声明一个默认析构函数，并在发现导致对象破删除的代码后，提供默认析构函数的定义。 const成员函数 对于当前的C++来说，编译器将拒绝第二行。因为show()的代码无法确保调用对象不被修改一调用对象和const一样，不应被修改。一种新的句法—保证函数不会修改调用对象。C++的解决方法是将const关键字放在函数的括号后面。show（）声明： 函数定义的开头： 以这种方式声明和定义的类函数被称为const成员函数。就像应尽可能将const引用和指针用作函数形参一样， 只要类方法不修改调用对象，就应将其声明为const.从现在开始，我们将遵守这一规则。 新特性接收一个参数的构造函数允许使用赋值句法将对象初始化为一个值。 this指针每个成员函数(包括构造函数和析构函数)都有一个this 指针。this 指针指向调用对象。this是对象的地址，如果方法需要引用整个调用对象，则可以使用表达式 * this。在函数的括号后面使用const 限定符将this限定为const,这样将不能使用this 来修改对象的值。 对象数组声明对象数组的方法与声明标准类型数组相同： 当程序创建未被现实初始化的类对象时，总是调用默认构造函数。此时要么是没有显示地定义任何构造函数，将使用不执行任何操作的隐式默认构造函数。要么定义了一个显式默认构造函数。每个元素都是Stock对象可以使用Stock方法。 可以用构造函数来初始化数组元素。此时，必须为每个元素调用构造函数。 初始化对象数组的方案是，首先使用默认构造函数创建数组元素，然后花括号中的构造函数将创建临时对象，然后将临时对象的内容复制到相应的元素中。因此，要创建类对象数组，则这个类必须有默认构造函数。 类作用域在类中定义的名称(如类数据成员名和类成员函数名)的作用域都为整个类,作用域为整个类的名称只在该类中是已知的,在类外是不可知的。因此,可以在不同类中使用相同的类成员名而不会引起冲突。另外,类作用域意味着不能从外部直接访问类的成员,公有成员函数也是如此。也就是说,要调用公有成员函数,必须通过对象。在定义成员函数时，必须使用作用域解析操作符。 作用域为整个类的常量使用关键字static，在类中定义常量。该常量将与其他静态变量存储在一起，而不是存储在对象中。只能使用这种结束声明值为整数或枚举的静态常量，而不能存储double常量。 使用类操作符重载要重载操作符,需使用被称为操作符函数的特殊函数形式。操作符函数的格式如下: op是将要重载的操作符。operator+()重载+操作符，op必须是有效的C++操作符，不能虚构一个新的符号。例如，不能有operator@()这样的函数，因为C++中没有@操作符。但是，operator函数将重载[]操作符，因为【】是数组索引操作符。 友元简介友元有3种： 友元函数 友元类 友元成员函数 对于重载操作符，左侧的操作数是调用对象。 其中要使用重载运算符就只能将B写在左侧。使用非成员函数，大多数操作符都可以通过成员或非成员函数来重载。非成员函数不是由对象调用的，它使用的所有值都是显示参数。这样编译器能够将表达式中B写到右侧。有一类特殊的非成员函数可以访问类的私有成员，为友元函数。 创建友元创建友元函数的第一步，是将其原型放在类声明中，并在原型声明前加上关键字friend。 该原型意味着两点： 虽然operator * （）函数是在类声明中声明的，但它不是成员函数，因此不能使用成员函数操作符来调用。 虽然operator * （）函数不是成员函数，但它与成员函数的访问权限相同。 第二步是编写函数定义。因为它不是成员函数，所以不要使用Time：：限定符。另外，不要再定义中使用关键字friend，定义如下： 简而言之，类的友元函数是非成员函数，其访问权限与成员函数相同。 友元是否有悖于OOP只有类声明可以决定哪一个函数是友元，因此类声明仍然控制了哪些函数可以访问私有数据。简而言之，类方法和友元只是表达类接口的两种不同机制。 常用的友元：重载&lt;&lt;操作符重载操作符：作为成员函数还是非成员函数对于很多操作符来说，可以选择使用成员函数或非成员函数来实现操作符重载。一般来说，非成员函数应是友元函数， 这样它才能直接访问类的私有数据。例如，Time 类的加法操作符在Time类声明中的原型如下: 加法操作符需要两个操作数。对于成员函数版本来说，一个操作数通过this指针隐式地传递，另一个操作数作为函数参数显式地传递;对于友元版本来说，两个操作数都作为参数来传递。 非成员版本的重载操作符函数所需的形参数目与操作符使用的操作数数目相同;而成员版本所需的参数数目少一个，因为其中的一个操作数是被隐式地传递的调用对象。 类继承一个简单的基类从一个类派生出另一个类，原始类称为基类，继承类称为派生类。 冒号指出RatedPlayer类的基类是TableTennisplayer 类。上述特殊的声明头表明TableTennisPlayer 是一个公有基类，这被称为公有派生。派生类对象包含基类对象。使用公有派生，基类的公有成员将成为派生类的公有成员; 基类的私有部分也将成为派生类的一部分，但只能通过基类的公有和保护方法访问。 构造函数：访问权限的考虑派生类不能直接访问基类的私有成员，而必须通过基类方法进行访问。具体地说，派生类构造函数必须使用基类构造函数。 创建派生类对象时，程序首先创建基类对象。从概念上说，这意味着基类对象应当在程序进入派生类构造函数之前被创建。C++使用成员初始化列表句法来完成这种工作。RatedPlayer构造函数代码： 其中TableTennisPlayer(fn,ln,ht)是成员初始化列表，它调用TableTennisPlayer构造函数。 派生类构造函数要点： 基类对象首先被创建。 派生类构造函数应通过成员初始化列表将基类信息传递给基类构造函数。 派生类构造函数应初始化派生类新增的数据成员。 如果没有提供显示构造函数，因此将使用隐式构造函数。释放对象的顺序与创建对象的顺序相反，即首先执行派生类的析构函数，然后自动调用基类的析构函数。 成员初始化列表 使用派生类要使用派生类，程序必须要能够访问基类声明。可以将这两种类的声明置于同一个头文件中。也可以将每个类放在独立的头文件中，但由于这两个类是相关的，所以把其类声明放在一起更合适。 派生类和基类之间的特殊关系派生类对象可以使用基类的方法，条件是方法不是私有的。基类指针可以在不进行显式类型转换的情况下指向派生类对象。基类引用可以在不进行显式类型转换的情况下引用派生类对象。 不过，基类指针或引用只能用户调用基类方法，而不能调用派生类的方法。通常，C++要求引用和指针类型与赋给的类型匹配，但这一规则对继承来说是例外。不过，这种例外只是单向的，不可以将基类对象和地址赋给派生类引用和指针。 继承——is-a关系派生类和基类之间的特殊关系是基于C++继承的底层模型。C++有3种继承方式：公有继承、保护继承和私有继承。公有继承是最常用的方式，它建立一种is-a关系，即派生类对象也是一个基类对象，可以对基类对象执行任何操作，也可以对派生类对象执行。 多态公有继承希望同一个方法在派生类和基类中的行为是不同的，有两种重要的机制可用于实现多态公有继承： 在派生类中重新定义基类方法。 使用虚方法。 在某基类中声明为 virtual 并在一个或多个派生类中被重新定义的成员函数，实现多态性，使用关键字virtual来声明虚方法。virtual 函数返回类型 函数名（参数表） {函数体}； 静态联编和动态联编将源代码中的函数调用解释为执行特定的函数代码块被称为函数名联编(binding)。在C++中，由于函数重载的缘故，这项任务更复杂。编译器必须查看函数参数以及函数名才能确定使用哪个函数。C/C++编译器可以再编译过程完成这种联编。在编译过程中进行联编被称为静态联编（static binding）又称为早期联编。不过虚函数使这项工作变得更困难，使用哪一个函数是不能在编译时确定的，因为编译器不知道用户将选择哪种类型的对象。所以，编译器必须生成能够在程序运行时选择正确的虚方法的代码，这被称为动态联编（dynamic binding），又称为晚期联编（late binding）。 为什么有两种类型的联编以及为什么默认为静态联编如果动态联编让您能够重新定义类方法，而静态联编在这方面很差; 为何不摒弃静态联编呢?原因有两个—效率和概念模型。 效率：为使程序能够在运行阶段进行决策，必须采取一些方法来跟踪基类指针或引用指向的对象类型，这增加了额外的处理开销。如果类不会用作基类，则不需要动态联编。如果派生类不重新定义基类的任何方法，也不需要使用动态联编。这时，使用静态联编更合理，效率也更高。由于静态联编的效率更高，因此被设置为C++的默认选择。概念模型，在设计类时，可能包含一些不在派生类重新定义的成员函数。不该将函数设置为虚函数，有两方面的好处：首先效率更高；其次指出不要重新定义该函数。 虚函数的工作原理编译器处理虚函数的方法是：给每个对象添加一个隐藏成员。隐藏成员中保存了一个指向函数地址数组的指针。这种数组称为虚函数表（vtbl）。虚函数表中存储了为类对象进行声明的虚函数地址。例如，基类对象包含一个指针，该指针指向基类中所有虚函数的地址表。派生类对象将包含一个指向独立地址表的指针。如果派生类提供了虚函数的新定义，该虚函数表将保存新函数的地址；如果派生类没有重新定义虚函数，该vtbl将保存函数原始版本的地址。无论类中包含的虚函数是一个还是10个，都只需要在对象中添加一个地址成员，只是表的大小不同而已。 调用虚函数时，程序将查看存储在对象中的vtbl地址，然后转向相应的函数地址表。如果使用类声明中定义的第一个虚函数，则程序将使用数组中的第一个函数地址，并执行具有该地址的函数。如果使用类声明中的第三个虚函数，程序将使用地址为数组中第三个元素的函数。 简而言之，使用虚函数时，在内存和执行速度方面有一定的成本，包括： 每个对象都将增大，增大量为存储地址的空间。 对每个类，编译器都创建一个虚函数地址表（数组）。 每个函数调用都需要执行一步额外的操作，即到表中查找地址。虽然非虚函数的效率比虚函数稍高，但不具备动态联编功能。 有关虚函数的注意事项虚函数的要点： 在基类方法的声明中使用关键字virtual可使该方法在基类以及所有的派生类(包括从派生类派生出来的类)中是虚拟的。 如果使用指向对象的引用或指针来调用虚方法，程序将使用为对象类型定义的方法，而不使用为引用或指针类型定义的方法。这称为动态联编或晚期联编。这种行为非常重要，因为这样基类指针或引用可以指向派生类对象。 如果定义的类将被用作基类，则应将那些要在派生类中重新定义的类方法声明为虚拟的。 对于虚函数还有。1.构造函数，构造函数不能是虚函数。2.析构函数，析构函数应当是虚函数，除非类不用做基类。如 如果使用默认的静态联编，delete 语句将调用~Employee()析构函数。这将释放由Singer 对象中的Employee部分指向的内存，但不会释放新的类成员指向的内存。但如果析构函数是虚拟的，则上述代码将先调用~Singer析构函数释放由Singer 组件指向的内存，然后，调用~Employee() 析构函数来释放由Employee组件指向的内存。 通常应给基类提供一个虚拟析构函数，即使它并不需要析构函数。3.友元，友元不能是虚函数，因为友元不是类成员，而只有成员才能是虚函数 访问控制：protected关键字 protected与 private相似,在类外只能用公有类成员来访问protected部分中的类成员。private和 protected之间的区别只有在基类派生的类中才会表现出来。派生类的成员可以直接访问基类的保护成员，但不能直接访问基类的私有成员。因此，对于外部世界来说，保护成员的行为与私有成员相似；但对于派生类来说，保护成员的行为与公有成员相似。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://github.com/zdkswd/tags/C/"}]},{"title":"计算机是怎么启动的","slug":"计算机是怎么启动的","date":"2018-12-26T02:03:47.000Z","updated":"2018-12-26T12:15:22.000Z","comments":true,"path":"2018/12/26/计算机是怎么启动的/","link":"","permalink":"https://github.com/zdkswd/2018/12/26/计算机是怎么启动的/","excerpt":"","text":"计算机是怎么启动的参考：http://www.ruanyifeng.com/blog/2013/02/booting.html 计算机启动是一个很矛盾的过程：必须先运行程序，然后计算机才能启动，但是计算机不启动就无法运行程序！所以启动又称为boot，”pull oneself up by one’s bootstraps”。 第一阶段 BIOS开机程序被刷入ROM（”只读内存”）芯片，计算机通电后，第一件事就是读取它。芯片里的程序叫做”基本輸出輸入系統”（Basic Input/Output System），简称为BIOS。 硬件自检BIOS程序首先检查，计算机硬件能否满足运行的基本条件，这叫做”硬件自检”（Power-On Self-Test），缩写为POST。 如果硬件出现问题，主板会发出不同含义的蜂鸣，启动中止。如果没有问题，屏幕就会显示出CPU、内存、硬盘等信息。 启动顺序硬件自检完成后，BIOS把控制权转交给下一阶段的启动程序。 这时，BIOS需要知道，”下一阶段的启动程序”具体存放在哪一个设备。也就是说，BIOS需要有一个外部储存设备的排序，排在前面的设备就是优先转交控制权的设备。这种排序叫做”启动顺序”（Boot Sequence）。 打开BIOS的操作界面，里面有一项就是”设定启动顺序”。 第二阶段：主引导记录BIOS按照”启动顺序”，把控制权转交给排在第一位的储存设备。 这时，计算机读取该设备的第一个扇区，也就是读取最前面的512个字节。如果这512个字节的最后两个字节是0x55和0xAA，表明这个设备可以用于启动；如果不是，表明设备不能用于启动，控制权于是被转交给”启动顺序”中的下一个设备。 这最前面的512个字节，就叫做”主引导记录”（Master boot record，缩写为MBR）。 主引导记录的结构“主引导记录”只有512个字节，放不了太多东西。它的主要作用是，告诉计算机到硬盘的哪一个位置去找操作系统。 主引导记录由三个部分组成： 其中，第二部分”分区表”的作用，是将硬盘分成若干个区。 分区表硬盘分区有很多好处。考虑到每个区可以安装不同的操作系统，”主引导记录”因此必须知道将控制权转交给哪个区。 分区表的长度只有64个字节，里面又分成四项，每项16个字节。所以，一个硬盘最多只能分四个一级分区，又叫做”主分区”。 每个主分区的16个字节，由6个部分组成： 最后的四个字节（”主分区的扇区总数”），决定了这个主分区的长度。也就是说，一个主分区的扇区总数最多不超过2的32次方。 如果每个扇区为512个字节，就意味着单个分区最大不超过2TB。再考虑到扇区的逻辑地址也是32位，所以单个硬盘可利用的空间最大也不超过2TB。如果想使用更大的硬盘，只有2个方法：一是提高每个扇区的字节数，二是增加扇区总数。 第三阶段：硬盘启动这时，计算机的控制权就要转交给硬盘的某个分区了，这里又分成三种情况。 情况A：卷引导记录四个主分区里面，只有一个是激活的。计算机会读取激活分区的第一个扇区，叫做”卷引导记录”（Volume boot record，缩写为VBR）。 “卷引导记录”的主要作用是，告诉计算机，操作系统在这个分区里的位置。然后，计算机就会加载操作系统了。 情况B：扩展分区和逻辑分区随着硬盘越来越大，四个主分区已经不够了，需要更多的分区。但是，分区表只有四项，因此规定有且仅有一个区可以被定义成”扩展分区”（Extended partition）。 所谓”扩展分区”，就是指这个区里面又分成多个区。这种分区里面的分区，就叫做”逻辑分区”（logical partition）。 计算机先读取扩展分区的第一个扇区，叫做”扩展引导记录”（Extended boot record，缩写为EBR）。它里面也包含一张64字节的分区表，但是最多只有两项（也就是两个逻辑分区）。 计算机接着读取第二个逻辑分区的第一个扇区，再从里面的分区表中找到第三个逻辑分区的位置，以此类推，直到某个逻辑分区的分区表只包含它自身为止（即只有一个分区项）。因此，扩展分区可以包含无数个逻辑分区。 但是，似乎很少通过这种方式启动操作系统。如果操作系统确实安装在扩展分区，一般采用下一种方式启动。 情况C：启动管理器在这种情况下，计算机读取”主引导记录”前面446字节的机器码之后，不再把控制权转交给某一个分区，而是运行事先安装的”启动管理器”（boot loader），由用户选择启动哪一个操作系统。 Linux环境中，目前最流行的启动管理器是Grub。 第四阶段：操作系统控制权转交给操作系统后，操作系统的内核首先被载入内存。 以Linux系统为例，先载入_boot目录下面的kernel。内核加载成功后，第一个运行的程序是_sbin_init。它根据配置文件（Debian系统是_etc/initab）产生init进程。这是Linux启动后的第一个进程，pid进程编号为1，其他进程都是它的后代。 然后，init线程加载系统的各个模块，比如窗口程序和网络程序，直至执行_bin_login程序，跳出登录界面，等待用户输入用户名和密码。 至此，全部启动过程完成。 冯诺依曼体系图","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"计算机科学","slug":"计算机科学","permalink":"https://github.com/zdkswd/tags/计算机科学/"}]},{"title":"TCP","slug":"TCP","date":"2018-12-20T07:19:47.000Z","updated":"2018-12-20T07:25:07.000Z","comments":true,"path":"2018/12/20/TCP/","link":"","permalink":"https://github.com/zdkswd/2018/12/20/TCP/","excerpt":"","text":"参考http://www.ruanyifeng.com/blog/2017/06/tcp-protocol.html《码出高效》 TCP 数据包在 IP 数据包的负载里面。它的头信息最少也需要20字节，因此 TCP 数据包的最大负载是 1480 - 20 = 1460 字节。由于 IP 和 TCP 协议往往有额外的头信息，所以 TCP 负载实际为1400字节左右。 因此，一条1500字节的信息需要两个 TCP 数据包。HTTP/2 协议的一大改进， 就是压缩 HTTP 协议的头信息，使得一个 HTTP 请求可以放在一个 TCP 数据包里面，而不是分成多个，这样就提高了速度。 （图片说明：以太网数据包的负载是1500字节，TCP 数据包的负载在1400字节左右。） 传输控制协议（Transmission Control Protoco,TCP，是一种面向连接、确保数据在端到端间可靠传输的协议。面向连接是指在发送数据前，需要先建立一条虚拟的链路，然后让数据在这条链路上“流动”完成传输。为了确保数据的可靠传输，不仅需要对发出的每一个字节进行编号确认，校验每一个数据包的有效性，在出现超时情况下进行重传，还需要通过实线滑动窗口和拥塞控制等机制，避免网络状况恶化而最终影响数据传输的极端情形。 TCP报文格式 TCP是面向连接的，因此有服务器端和客户端之分。需要服务器端先在相应的端口上进行监听，准备好接受客户端发起的建立连接的请求。客户端发起的，目标机器端口就是服务器端所监听的端口号。比如一些由国际组织定义的广为人知的端口号——代表HTTP的80端口，代表SSH的22端口，代表HTTPS的443端口。 SYN用作建立连接时的同步信号；ACK用于对收到的数据进行确认，所确认的数据有确认序列号表示；FIN表示后面没有数据需要发送，通常意味着所建立的连接需要关闭了。 TCP数据包的编号（SEQ）一个包1400字节，那么一次性发送大量数据，就必须分成多个包。比如，一个 10MB 的文件，需要发送7100多个包。 发送的时候，TCP 协议为每个包编号（sequence number，简称 SEQ），以便接收的一方按照顺序还原。万一发生丢包，也可以知道丢失的是哪一个包。 第一个包的编号是一个随机数。为了便于理解，这里就把它称为1号包。假定这个包的负载长度是100字节，那么可以推算出下一个包的编号应该是101。这就是说，每个数据包都可以得到两个编号：自身的编号，以及下一个包的编号。接收方由此知道，应该按照什么顺序将它们还原成原始文件。 （图片说明：当前包的编号是45943，下一个数据包的编号是46183，由此可知，这个包的负载是240字节。） TCP数据包的组装收到 TCP 数据包以后，组装还原是操作系统完成的。应用程序不会直接处理 TCP 数据包。 对于应用程序来说，不用关心数据通信的细节。除非线路异常，收到的总是完整的数据。应用程序需要的数据放在 TCP 数据包里面，有自己的格式（比如 HTTP 协议）。 TCP 并没有提供任何机制，表示原始文件的大小，这由应用层的协议来规定。比如，HTTP 协议就有一个头信息Content-Length，表示信息体的大小。对于操作系统来说，就是持续地接收 TCP 数据包，将它们按照顺序组装好，一个包都不少。 操作系统不会去处理 TCP 数据包里面的数据。一旦组装好 TCP 数据包，就把它们转交给应用程序。TCP 数据包里面有一个端口（port）参数，就是用来指定转交给监听该端口的应用程序。 应用程序收到组装好的原始数据，以浏览器为例，就会根据 HTTP 协议的Content-Length字段正确读出一段段的数据。这也意味着，一次 TCP 通信可以包括多个 HTTP 通信。 TCP建立连接 三次握手： A机器发出的一个数据包并将SYN置1，表示希望建立连接。这个包中的序列号假设是x。 B机器收到A机器发过来的数据包后，通过SYN得知这是一个建立连接的请求，于是发送一个响应包并将SYN和ACK标记都置1。假设这个包中的序列号为y，而确认序列号必须是x+1，表示收到了A发过来的SYN。在TCP中，SYN被当作数据部分的一个字节。 A收到B的响应包后需进行确认，确认包中将ACK置1，并将确认序列号设置为y+1，表示收到了来自B的SYN。 之所以需要三次握手是为了信息对等和防止超时。在第二次握手完成时，对B来说并不知道A收到了B的第一次回信，就是不确定A有收报的能力以及自己有发报的能力。所以需要A再一次回复来确认。而且还要防止出现请求超时导致的脏连接。 从编程角度来看TCP连接从编程的角度，TCP连接的建立是通过文件描述符（FIle Descripter,fd）完成的。通过创建套接字获得一个fd，然后服务器端和客户端需要机遇所获得的fd调用不同的函数分别进入监听状态和发起连接请求。由于fd的数量将决定服务端进程所能建立连接的数量，对于大规模分布式服务来说，当fd不足时就会出现“open too many files”错误而使得无法建立更多的连接。为此，需要注意调整服务端进程和操作系统所支持的最大文件句柄数。通过使用ulimit -n命令来查看单个进程可以打开文件句柄的数目。如果想查看当前系统各进程产生了多少句柄，可以使用如下命令：1lsof -n | awk &apos;&#123;print $2&#125;&apos;| sort|uniq -c |sort -nr|more 执行结果中左侧是句柄数，右侧是进程号。lsof命令用于查看当前系统所打开fd的数量。在Linux系统中，很多资源都是以fd的形式进行读写的，除了提到的文件和TCP连接，UDP数据报、输入输出设备等都抽象成了fd。1在linux系统中文件句柄（file handles）和文件描述符(file descriptor)是一个一一对应的关系 想知道具体的PID对应的具体应用程序是谁，使用1ps -ax|grep 32764 TCP在协议层面支持Keep Alive功能，即隔段时间通过向对方发送数据表示连接处于健康状态。不少服务将确保连接健康的行为放到了应用层，通过定期发送心跳包检查连接的健康度。一旦心跳包出现异常不仅会主动关闭连接，还会回收与连接相关的其他用于提供服务的资源，确保系统资源最大限度地被有效利用。 TCP断开连接四次挥手。A机器想要关闭连接，则待本方数据发送完毕后，传递FIN信号给B机器。B机器应答ACK，告诉A机器可以断开，但是需要等B机器处理完数据，再主动给A机器发送FIN信号。这时，A机器处于半关闭状态（FIN_WAIT_2）,无法再发送新的数据。B机器做好连接关闭前的准备工作后，发送FIN给A机器，此时B机器也进入半关闭状态（CLOSE_WAIT）。A机器发送针对B机器FIN的ACK后，进入TIME-WAIT状态，经过2MSL后，没有收到B机器传来的报文，则确定B机器已经收到A机器最后发送的ACK指令，此时TCP连接正式释放。 TIME_WAIT和CLOSE_WAIT分别表示主动关闭和被动关闭产生的阶段性状态，如果在线上服务器大量出现这两种状态，就会加重机器负载，也会影响有效连接的创建，因此需要进行有针对性的调优处理。 TIME_WAIT：主动要求关闭的机器表示收到了对方的FIN报文，并发送出ACK报文，进入TIME_WAIT状态，等2MSL后即可进入到CLOSED状态。如果FIN_WAIT_1状态下，同时收到带FIN标志和ACK标志的报文时，可以直接进入TIME_WAIT状态，而无须经过FIN_WAIT_2状态。 CLOSE_WAIT：被动要求关闭的机器收到对方请求关闭连接的FIN报文，在第一次ACK应答后，马上进入CLOSE_WAIT状态。这种状态其实表示在等待关闭，并且通知应用程序发送剩余数据，处理现场信息，关闭相关资源。 2MSL是报文在网络上生存的最长时间，超过阈值便将报文丢弃。一般来说，MSL大于TTL衰减至0的时间。在RFC793中规定MSL为2分钟。但是在当前的高速网络中，2分钟的等待时间会造成资源的极大浪费，在高并发服务器上通常会使用更小的值。不直接关闭，进入CLOSED状态的原因有如下几点： 确认被动关闭方能够顺利进入CLOSED状态。假如最后一个ACK由于网络原因导致无法到达B机器，处于LAST_ACK的B机器通常“自信”地以为对方没有收到自己的FIN+ACK报文，所以会重发。A机器收到第二次的FIN+ACK报文，会重发一次ACK，并且重新计时。如果A机器收到B机器的FIN+ACK报文后，发送一个ACK给B机器，就“自私”地立马进入CLOSED状态，可能会导致B机器无法确保收到最后的ACK指令，也无法进入CLOSED状态。这是A机器不负责任的表现。 防止失效请求。这样做是为了防止已失效连接的请求数据包与正常连接的请求数据包混淆而发生异常。 编程角度看TCP断开因为TIME_WAIT状态下无法真正释放句柄资源，在此期间，Socket中使用的本地端口在默认情况下不能再被使用。该限制对于客户端机器无所谓，但对于高并发服务器来说，会极大地限制有效连接的创建数量，称为性能瓶颈。所以将高并发服务器TIME_WAIT超时时间调小。 在服务器上通过变更/ etc /sysctl.conf文件来修改该省略值（秒）：net.ipv4.tcp_fin_timeout=30(建议小于30秒为宜)。 修改完之后执行/ sbin / sysctl -p让参数生效即可。可通过如下命令：1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a,S[a]&#125;&apos; 查看各连接状态的计数情况。 在sysctl.conf中还有其他连接参数也用来不断地调优服务器TCP连接能力，以提升服务器的有效利用率。毕竟现代网络和路由器处理能力越来越强，跨国时延通常也在1s以内，丢包率极低。如何快速地使用连接资源被释放和复用，参数的优化往往可以取得事半功倍的效果。记得某大公司在大型购物节时，系统宕机，老总下令要加一倍的服务器来解决问题。事实上，如果是参数配置错误导致的系统宕机，即使增加硬件资源，也无法达到好的效果。硬件的增加与性能的提升绝对不是线性相关的，更多的时候是对数曲线关系。 TIME_WAIT是挥手四次断开连接的尾声，如果此状态连接过多，则可以通过优化服务器参数得到解决。如果不是对方连接的异常，一般不会出现连接无法关闭的情况。 CLOSE_WAIT过多很可能是程序自身的问题，如果在对方关闭连接后，程序没有检测到，或者忘记自己关闭连接。在某次故障中，外部请求出现超时的情况，当时的Apache服务器使用的是默认的配置方式，通过命令： netstat -ant|grep -i “443”|grep CLOSE_WAIT|wc -1发现在HTTPS的443端口堆积了2.1万个左右的CLOSE_WAIT状态。经排查发现，原来是某程序处理完业务逻辑后没有释放流操作，但程序一直运行正常，直到运营活动时才大量触发该业务逻辑，最终导致故障的产生。 慢启动和ACK 服务器发送数据包，当然越快越好，最好一次性全发出去。但是，发得太快，就有可能丢包。带宽小、路由器过热、缓存溢出等许多因素都会导致丢包。线路不好的话，发得越快，丢得越多。 最理想的状态是，在线路允许的情况下，达到最高速率。但是我们怎么知道，对方线路的理想速率是多少呢？答案就是慢慢试。 TCP 协议为了做到效率与可靠性的统一，设计了一个慢启动（slow start）机制。开始的时候，发送得较慢，然后根据丢包的情况，调整速率：如果不丢包，就加快发送速度；如果丢包，就降低发送速度。 Linux 内核里面设定了（常量TCP_INIT_CWND），刚开始通信的时候，发送方一次性发送10个数据包，即”发送窗口”的大小为10。然后停下来，等待接收方的确认，再继续发送。 默认情况下，接收方每收到两个 TCP 数据包，就要发送一个确认消息。”确认”的英语是 acknowledgement，所以这个确认消息就简称 ACK。 ACK 携带两个信息。 发送方有了这两个信息，再加上自己已经发出的数据包的最新编号，就会推测出接收方大概的接收速度，从而降低或增加发送速率。这被称为”发送窗口”，这个窗口的大小是可变的。 （图片说明：每个 ACK 都带有下一个数据包的编号，以及接收窗口的剩余容量。双方都会发送 ACK。） 注意，由于 TCP 通信是双向的，所以双方都需要发送 ACK。两方的窗口大小，很可能是不一样的。而且 ACK 只是很简单的几个字段，通常与数据合并在一个数据包里面发送。 （图片说明：上图一共4次通信。第一次通信，A 主机发给B 主机的数据包编号是1，长度是100字节，因此第二次通信 B 主机的 ACK 编号是 1 + 100 = 101，第三次通信 A 主机的数据包编号也是 101。同理，第二次通信 B 主机发给 A 主机的数据包编号是1，长度是200字节，因此第三次通信 A 主机的 ACK 是201，第四次通信 B 主机的数据包编号也是201。） 即使对于带宽很大、线路很好的连接，TCP 也总是从10个数据包开始慢慢试，过了一段时间以后，才达到最高的传输速率。这就是 TCP 的慢启动。 数据包的遗失处理TCP 协议可以保证数据通信的完整性，这是怎么做到的？ 前面说过，每一个数据包都带有下一个数据包的编号。如果下一个数据包没有收到，那么 ACK 的编号就不会发生变化。 举例来说，现在收到了4号包，但是没有收到5号包。ACK 就会记录，期待收到5号包。过了一段时间，5号包收到了，那么下一轮 ACK 会更新编号。如果5号包还是没收到，但是收到了6号包或7号包，那么 ACK 里面的编号不会变化，总是显示5号包。这会导致大量重复内容的 ACK。 如果发送方发现收到三个连续的重复 ACK，或者超时了还没有收到任何 ACK，就会确认丢包，即5号包遗失了，从而再次发送这个包。通过这种机制，TCP 保证了不会有数据包丢失。 （图片说明：Host B 没有收到100号数据包，会连续发出相同的 ACK，触发 Host A 重发100号数据包。）","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://github.com/zdkswd/tags/计算机网络/"}]},{"title":"HTTP协议  SSL/TLS协议 HTTPS","slug":"HTTP协议  SSL:TLS协议","date":"2018-12-19T12:12:47.000Z","updated":"2018-12-25T04:21:44.000Z","comments":true,"path":"2018/12/19/HTTP协议  SSL:TLS协议/","link":"","permalink":"https://github.com/zdkswd/2018/12/19/HTTP协议  SSL:TLS协议/","excerpt":"","text":"已修改参考HTTP 协议入门 - 阮一峰的网络日志HTTP 协议是互联网的基础协议，也是网页开发的必备知识，最新版本 HTTP/2 更是让它成为技术热点。 HTTP/0.9HTTP 是基于 TCP/IP 协议的应用层协议。它不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，默认使用80端口。 最早版本是1991年发布的0.9版。该版本极其简单，只有一个命令GET。 上面命令表示，TCP 连接（connection）建立后，客户端向服务器请求（request）网页index.html。 协议规定，服务器只能回应HTML格式的字符串，不能回应别的格式。 服务器发送完毕，就关闭TCP连接。 HTTP/1.0简介1996年5月，HTTP/1.0 版本发布，内容大大增加。首先，任何格式的内容都可以发送。这使得互联网不仅可以传输文字，还能传输图像、视频、二进制文件。这为互联网的大发展奠定了基础。 除了GET命令，还引入了POST命令和HEAD命令，丰富了浏览器与服务器的互动手段。 HTTP请求和回应的格式也变了。除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据。 其他的新增功能还包括状态码（status code）、多字符集支持、多部分发送（multi-part type）、权限（authorization）、缓存（cache）、内容编码（content encoding）等。 请求格式下面是一个1.0版的HTTP请求的例子。 第一行是请求命令，必须在尾部添加协议版本（HTTP/1.0）。后面就是多行头信息，描述客户端的情况。 回应格式服务器的回应如下。 回应的格式是”头信息 + 一个空行（ \\ r \\ n） + 数据”。其中，第一行是”协议版本 + 状态码（status code） + 状态描述”。 Content-Type 字段关于字符的编码，1.0版规定，头信息必须是 ASCII 码，后面的数据可以是任何格式。因此，服务器回应的时候，必须告诉客户端，数据是什么格式，这就是Content-Type字段的作用。 这些数据类型总称为MIME type，每个值包括一级类型和二级类型，之间用斜杠分隔。除了预定义的类型，厂商也可以自定义类型。 上面的类型表明，发送的是Debian系统的二进制数据包。MIME type还可以在尾部使用分号，添加参数。 上面的类型表明，发送的是网页，而且编码是UTF-8。 客户端请求的时候，可以使用Accept字段声明自己可以接受哪些数据格式。 上面代码中，客户端声明自己可以接受任何格式的数据。MIME type不仅用在HTTP协议，还可以用在其他地方，比如HTML网页。 Content-Encoding 字段由于发送的数据可以是任何格式，因此可以把数据压缩后再发送。Content-Encoding字段说明数据的压缩方法。 客户端在请求时，用Accept-Encoding字段说明自己可以接受哪些压缩方法。 缺点HTTP/1.0 版的主要缺点是，每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。 TCP连接的新建成本很高，因为需要客户端和服务器三次握手，并且开始时发送速率较慢（slow start）。所以，HTTP 1.0版本的性能比较差。随着网页加载的外部资源越来越多，这个问题就愈发突出了。 为了解决这个问题，有些浏览器在请求时，用了一个非标准的Connection字段。 这个字段要求服务器不要关闭TCP连接，以便其他请求复用。服务器同样回应这个字段。 一个可以复用的TCP连接就建立了，直到客户端或服务器主动关闭连接。但是，这不是标准字段，不同实现的行为可能不一致，因此不是根本的解决办法。 HTTP/1.11997年1月，HTTP/1.1 版本发布，只比 1.0 版本晚了半年。它进一步完善了 HTTP 协议，一直用到了20年后的今天，直到现在还是最流行的版本。 持久连接1.1 版的最大变化，就是引入了持久连接（persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive。 客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。不过，规范的做法是，客户端在最后一个请求时，发送Connection: close，明确要求服务器关闭TCP连接。 管道机制1.1 版还引入了管道机制（pipelining），即在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进了HTTP协议的效率。 举例来说，客户端需要请求两个资源。以前的做法是，在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发出B请求。管道机制则是允许浏览器同时发出A请求和B请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。 Content-Length 字段一个TCP连接现在可以传送多个回应，势必就要有一种机制，区分数据包是属于哪一个回应的。这就是Content-length字段的作用，声明本次回应的数据长度。 上面代码告诉浏览器，本次回应的长度是3495个字节，后面的字节就属于下一个回应了。 在1.0版中，Content-Length字段不是必需的，因为浏览器发现服务器关闭了TCP连接，就表明收到的数据包已经全了。 分块传输编码使用Content-Length字段的前提条件是，服务器发送回应之前，必须知道回应的数据长度。 对于一些很耗时的动态操作来说，这意味着，服务器要等到所有操作完成，才能发送数据，显然这样的效率不高。更好的处理方法是，产生一块数据，就发送一块，采用”流模式”（stream）取代”缓存模式”（buffer）。 因此，1.1版规定可以不使用Content-Length字段，而使用”分块传输编码”（chunked transfer encoding）。只要请求或回应的头信息有Transfer-Encoding字段，就表明回应将由数量未定的数据块组成。 每个非空的数据块之前，会有一个16进制的数值，表示这个块的长度。最后是一个大小为0的块，就表示本次回应的数据发送完了。下面是一个例子。 其他功能1.1版还新增了许多动词方法：PUT、PATCH、HEAD、 OPTIONS、DELETE。 另外，客户端请求的头信息新增了Host字段，用来指定服务器的域名。 有了Host字段，就可以将请求发往同一台服务器上的不同网站，为虚拟主机的兴起打下了基础。 缺点虽然1.1版允许复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为”队头堵塞”（Head-of-line blocking）。 为了避免这个问题，只有两种方法：一是减少请求数，二是同时多开持久连接。这导致了很多的网页优化技巧，比如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等等。如果HTTP协议设计得更好一些，这些额外的工作是可以避免的。 SPDY 协议2009年，谷歌公开了自行研发的 SPDY 协议，主要解决 HTTP/1.1 效率不高的问题。 这个协议在Chrome浏览器上证明可行以后，就被当作 HTTP/2 的基础，主要特性都在 HTTP/2 之中得到继承。 HTTP/22015年，HTTP/2 发布。它不叫 HTTP/2.0，是因为标准委员会不打算再发布子版本了，下一个新版本将是 HTTP/3。 二进制协议HTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为”帧”（frame）：头信息帧和数据帧。 二进制协议的一个好处是，可以定义额外的帧。HTTP/2 定义了近十种帧，为将来的高级应用打好了基础。如果使用文本实现这种功能，解析数据将会变得非常麻烦，二进制解析则方便得多。 多工HTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了”队头堵塞”。 举例来说，在一个TCP连接里面，服务器同时收到了A请求和B请求，于是先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分， 接着回应B请求，完成后，再发送A请求剩下的部分。 这样双向的、实时的通信，就叫做多工（Multiplexing）。 数据流因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。 HTTP/2 将每个请求或回应的所有数据包，称为一个数据流（stream）。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流ID，用来区分它属于哪个数据流。另外还规定，客户端发出的数据流，ID一律为奇数，服务器发出的，ID为偶数。 数据流发送到一半的时候，客户端和服务器都可以发送信号（RST_STREAM帧），取消这个数据流。1.1版取消数据流的唯一方法，就是关闭TCP连接。这就是说，HTTP/2 可以取消某一次请求，同时保证TCP连接还打开着，可以被其他请求使用。 客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应。 头信息压缩HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如Cookie和User Agent，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。 HTTP/2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息使用gzip或compress压缩后再发送；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。 服务器推送HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。 常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析HTML源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。 HTTPSHTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer 或 Hypertext Transfer Protocol Secure，超文本传输安全协议），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。 SSL/TLS协议运行机制的概述互联网的通信安全，建立在SSL/TLS协议之上。不使用SSL/TLS的HTTP通信，就是不加密的通信。所有信息明文传播，带来了三大风险。 SSL/TLS协议是为了解决这三大风险而设计的，希望达到： 互联网是开放环境，通信双方都是未知身份，这为协议的设计带来了很大的难度。而且，协议还必须能够经受所有匪夷所思的攻击，这使得SSL/TLS协议变得异常复杂。 SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。 如何保证公钥不被篡改？解决方法：将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。 公钥加密计算量太大，如何减少耗用的时间？解决方法：每一次对话（session），客户端和服务器端都生成一个”对话密钥”（session key），用它来加密信息。由于”对话密钥”是对称加密，所以运算速度非常快，而服务器公钥只用于加密”对话密钥”本身，这样就减少了加密运算的消耗时间。 因此，SSL/TLS协议的基本过程是这样的： 上面过程的前两步，又称为”握手阶段”（handshake）。 握手阶段的详细过程 “握手阶段”涉及四次通信，我们一个个来看。需要注意的是，”握手阶段”的所有通信都是明文的。 第一步，客户端（通常是浏览器）先向服务器发出加密通信的请求，这被叫做ClientHello请求。在这一步，客户端主要向服务器提供以下信息。 这里需要注意的是，客户端发送的信息之中不包括服务器的域名。也就是说，理论上服务器只能包含一个网站，否则会分不清应该向客户端提供哪一个网站的数字证书。这就是为什么通常一台服务器只能有一张数字证书的原因。 对于虚拟主机的用户来说，这当然很不方便。2006年，TLS协议加入了一个Server Name Indication扩展，允许客户端向服务器提供它所请求的域名。 第二步，服务器收到客户端请求后，向客户端发出回应，这叫做SeverHello。 除了上面这些信息，如果服务器需要确认客户端的身份，就会再包含一项请求，要求客户端提供”客户端证书”。比如，金融机构往往只允许认证客户连入自己的网络，就会向正式客户提供USB密钥，里面就包含了一张客户端证书。 第三步，客户端回应。客户端收到服务器回应以后，首先验证服务器证书。如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。 如果证书没有问题，客户端就会从证书中取出服务器的公钥。然后，向服务器发送下面三项信息。 上面第一项的随机数，是整个握手阶段出现的第三个随机数，又称”pre-master key”。有了它以后，客户端和服务器就同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的同一把”会话密钥”。 至于为什么一定要用三个随机数，来生成”会话密钥” 此外，如果前一步，服务器要求客户端证书，客户端会在这一步发送证书及相关信息。 第四步，服务器的最后回应，服务器收到客户端的第三个随机数pre-master key之后，计算生成本次会话所用的”会话密钥”。然后，向客户端最后发送下面信息。 至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过用”会话密钥”加密内容。 HTTPS 要比 HTTP 多用多少服务器资源？里面还有关于SSL握手的各步需要的原因以及解释https://www.zhihu.com/question/21518760/answer/19698894 码出高效HTTPS对称加密算法，比如DES。访问一个HTTPS的网站流程如下： 浏览器向服务器发送请求，请求中包括浏览器支持的协议，并附带一个随机数。 服务器收到请求后，选择某种非对称加密算法，把数字证书签名公钥、身份信息发送给浏览器，同时也附带一个随机数。 浏览器收到后，验证证书的真实性，用服务器的公钥发送握手信息给服务器。 服务器解密后，使用之前的随机数计算出一个对称加密的秘钥，以此作为加密信息并发送。 后续所有的信息发送都是以对称加密方式进行的 TLS和SSL的区别。TLS可以理解成SSL协议3.0版本的升级，所以TLS的1.0版本也被标识为SSL3.1版本。但对于大的协议栈而言，SSL和TLS并没有太大的区别，因此在Wireshark里，分层依然用的是安全套接字（SSL） 标识。 在整个HTTPS的传输过程中，主要分两个部分：首先是HTTPS的握手，然后是数据的传输。前者是建立一个HTTPS的通道，并确定连接使用的加密套件及数据传输使用的秘钥。而后者主要使用秘钥对数据加密并传输。 第一，客户端发送了一个Client Hello协议的请求：在Client Hello中最重要的信息是Cipher Suites字段，这里客户端会告诉服务端自己支持哪些加密的套件。 第二，服务端在收到客户端发来的Client Hello的请求后，会返回一系列的协议数据，并以一个没有数据内容的Server Hello Done作为结束。这些协议数据有的是单独发送，有的是合并发送。这里解释几个比较重要的协议。（1）Server Hello协议。主要告知客户端后续协议中要使用的TLS协议版本，这个版本主要和客户端与服务器端支持的最高版本有关。并为本次连接分配一个会话ID（Session ID）。此外，还会确认后续采用的加密套件（Cipher Suite），比如加密套件为TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256。该加密套件的基本含义为：使用非对称协议加密（RSA）进行对称协议加密（AES）密钥的加密，并使用对称加密协议（AES）进行信息的加密。（2）Certificate协议。主要传输服务端的证书内容。（3）Server Key Exchange。如果在Certificate协议中未给出客户端足够的信息，则会在Server Key Exchange进行补充。比如在连接中Certificate未给出证书的公钥（Public Key），这个公钥的信息将会通过Server Key Exchange送给客户端。（4）Certificate Request。这个协议是一个可选项，当服务端需要对客户端进行证书验证时，才会向客户端发送一个证书请求（Certificate Request）。（5）最后以Server Hello Done作为结束信息，告知客户端整个Server Hello过程结束。 第三，客户端在收到服务端的握手信息后，根据服务端的请求，也会发送一系列的协议。（1）Certificate。可选项。上文中服务端发送了Certificate Request需要对客户端进行证书验证，所以客户端要发送自己的证书信息。（2）Client Key Exchange。它与上文中Server Key Exchange类似，是对客户端Certificate信息的补充，在本次请求中同样是补充了客户端证书的公钥信息。（3）Certification Verity。对服务端发送的证书信息进行确认。（4）Change Cipher Spec。该协议不同于其他握手协议（Handshake Protocol）,而是作为一个独立协议告知服务端，客户端已经接受之前服务端确认的加密套件，并会在后续通信中使用该加密套件进行加密。（5）Encrypted Handshake Message。用于客户端给服务端加密套件加密一段Finish的数据，用以验证这条建立起来的加解密通道的正确性。 第四，服务端在接受客户端的确认信息及验证信息后，会对客户端发送的数据进行确认，这里也分为几个协议进行回复。（1）Change Cipher Spec。通过使用私钥对客户端发送的数据进行解密，并告知后续将使用协商好的加密套件进行加密传输数据。（2）Encrypted Handshake Message。与客户端的操作相同，发送一段Finish的加密数据验证加密通道的正确性。 最后，如果客户端和服务端都确认加解密无误后，各自按照之前约定的Session Secret对Application Data进行加密传输。 解析HTTP协议六种请求方法GetGET可以说是最常见的了，它本质就是发送一个请求来取得服务器上的某一资源。资源通过一组HTTP头和呈现据（如HTML文本，或者图片或者视频等）返回给客户端。GET请求中，永远不会包含呈现数据。 POST向服务器提交数据。这个方法用途广泛，几乎目前所有的提交操作都是靠这个完成。 HEADHEAD和GET本质是一样的，区别在于HEAD不含有呈现数据，而仅仅是HTTP头信息。有的人可能觉得这个方法没什么用，其实不是这样的。想象一个业务情景：欲判断某个资源是否存在，我们通常使用GET，但这里用HEAD则意义更加明确。 DELETE删除某一个资源。基本上这个也很少见，不过还是有一些地方比如amazon的S3云服务里面就用的这个方法来删除资源。 PUT这个方法比较少见。HTML表单也不支持这个。本质上来讲， PUT和POST极为相似，都是向服务器发送数据，但它们之间有一个重要区别，PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。 OPTIONS这个方法很有趣，但极少使用。它用于获取当前URL所支持的方法。若请求成功，则它会在HTTP头中包含一个名为“Allow”的头，值是所支持的方法，如“GET, POST”。 RESTURL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作。增加一个朋友，uri: generalcode.cn/v1/friends 接口类型：POST删除一个朋友，uri: generalcode.cn/va/friends 接口类型：DELETE修改一个朋友，uri: generalcode.cn/va/friends 接口类型：PUT查找朋友，uri: generalcode.cn/va/friends 接口类型：GET上面我们定义的四个接口就是符合REST协议的，请注意，这几个接口都没有动词，只有名词friends，都是通过Http请求的接口类型来判断是什么业务操作。 GET和POST的区别最直观的区别就是GET把参数包含在URL中，POST通过request body传递参数。GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？ GET与POST都有自己的语义，不能随便混用。 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。 HTTP中CookieCookie总是保存在客户端中，按在客户端中的存储位置，可分为内存Cookie和硬盘Cookie。内存Cookie由浏览器维护，保存在内存中，浏览器关闭后就消失了，其存在时间是短暂的。硬盘Cookie保存在硬盘里，有一个过期时间，除非用户手工清理或到了过期时间，硬盘Cookie不会被删除，其存在时间是长期的。所以，按存在时间，可分为非持久Cookie和持久Cookie。 cookie存在哪Cookie是存在硬盘上， IE存cookie的地方和Firefox存cookie的地方不一样。 不同的操作系统也可能存cookie的地方不一样。不同的浏览器会在各自的独立空间存放Cookie, 互不干涉。不同的网站会有不同的cookie文件。 浏览器把cookie通过HTTP Request 中的“Cookie: header”发送给Web服务器。Web服务器通过HTTP Response中的”Set-Cookie: header”把cookie发送给浏览器。 网站自动登陆的原理以”博客园自动登陆“的例子，来说明cookie是如何传递的。大家知道博客园是可以自动登陆的。假如我已经在登陆页面输入了用户名，密码，选择了保存密码，登陆。下次访问博客园流程如下。 用户打开IE浏览器，在地址栏上输入www.cnblogs.com. IE首先会在硬盘中查找关于cnblogs.com的cookie. 然后把cookie放到HTTP Request中，再把Request发给Web服务器。 Web服务器返回博客园首页（你会看到你已经登陆了）。 截获Cookie，冒充别人身份通过上面这个例子，可以看到cookie是很重要的，识别是否是登陆用户，就是通过cookie。 假如截获了别人的cookie是否可以冒充他人的身份登陆呢。 当然可以， 这就是一种黑客技术叫Cookie欺骗。利用Cookie 欺骗， 不需要知道用户名密码。就可以直接登录，使用别人的账户做坏事。 有两种方法可以截获他人的cookie 通过XSS脚步攻击， 获取他人的cookie. 想办法获取别人电脑上保存的cookie文件（这个比较难） 拿到cookie后，就可以冒充别人的身份了。 cookie和文件缓存，这两个完全是不一样的东西。唯一的相同之处可能是它们俩都存在硬盘上，而且是存在同一个文件夹下。Cookies是当你浏览某网站时，由Web服务器置于你硬盘上的一个非常小的文本文件，它可以记录你的用户ID、密码、浏览过的网页、停留的时间等信息。 HTTP报文分为请求报文和响应报文。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://github.com/zdkswd/tags/计算机网络/"}]},{"title":"互联网协议复习","slug":"互联网协议复习","date":"2018-12-19T11:55:47.000Z","updated":"2018-12-19T09:56:54.000Z","comments":true,"path":"2018/12/19/互联网协议复习/","link":"","permalink":"https://github.com/zdkswd/2018/12/19/互联网协议复习/","excerpt":"","text":"参考：http://www.ruanyifeng.com/blog/2012/05/internet_protocol_suite_part_i.html 五层模型 实体层电脑要组网，第一件事要干什么？当然是先把电脑连起来，可以用光缆、电缆、双绞线、无线电波等方式。 这就叫做”实体层”，它就是把电脑连接起来的物理手段。它主要规定了网络的一些电气特性，作用是负责传送0和1的电信号。 链接层定义单纯的0和1没有任何意义，必须规定解读方式：多少个电信号算一组？每个信号位有何意义？这就是”链接层”的功能，它在”实体层”的上方，确定了0和1的分组方式。 以太网协议早期的时候，每家公司都有自己的电信号分组方式。逐渐地，一种叫做”以太网”（Ethernet）的协议，占据了主导地位。 以太网规定，一组电信号构成一个数据包，叫做”帧”（Frame）。每一帧分成两个部分：标头（Head）和数据（Data）。 “标头”包含数据包的一些说明项，比如发送者、接受者、数据类型等等；”数据”则是数据包的具体内容。 “标头”的长度，固定为18字节。”数据”的长度，最短为46字节，最长为1500字节。因此，整个”帧”最短为64字节，最长为1518字节。如果数据很长，就必须分割成多个帧进行发送。 MAC地址上面提到，以太网数据包的”标头”，包含了发送者和接受者的信息。那么，发送者和接受者是如何标识呢？ 以太网规定，连入网络的所有设备，都必须具有”网卡”接口。数据包必须是从一块网卡，传送到另一块网卡。网卡的地址，就是数据包的发送地址和接收地址，这叫做MAC地址。 每块网卡出厂的时候，都有一个全世界独一无二的MAC地址，长度是48个二进制位，通常用12个十六进制数表示。前6个十六进制数是厂商编号，后6个是该厂商的网卡流水号。有了MAC地址，就可以定位网卡和数据包的路径了。 广播一块网卡怎么会知道另一块网卡的MAC地址？有一种ARP协议，可以解决这个问题。 有了MAC地址，系统怎样才能把数据包准确送到接收方？ 以太网采用了一种很”原始”的方式，它不是把数据包准确送到接收方，而是向本网络内所有计算机发送，让每台计算机自己判断，是否为接收方。 上图中，1号计算机向2号计算机发送一个数据包，同一个子网络的3号、4号、5号计算机都会收到这个包。它们读取这个包的”标头”，找到接收方的MAC地址，然后与自身的MAC地址相比较，如果两者相同，就接受这个包，做进一步处理，否则就丢弃这个包。这种发送方式就叫做”广播”（broadcasting）。 网络层网络层的由来以太网协议，依靠MAC地址发送数据。理论上，单单依靠MAC地址，上海的网卡就可以找到洛杉矶的网卡了，技术上是可以实现的。 但是，这样做有一个重大的缺点。以太网采用广播方式发送数据包，所有成员人手一”包”，不仅效率低，而且局限在发送者所在的子网络。也就是说，如果两台计算机不在同一个子网络，广播是传不过去的。这种设计是合理的，否则互联网上每一台计算机都会收到所有包，那会引起灾难。 互联网是无数子网络共同组成的一个巨型网络，很像想象上海和洛杉矶的电脑会在同一个子网络，这几乎是不可能的。 因此，必须找到一种方法，能够区分哪些MAC地址属于同一个子网络，哪些不是。如果是同一个子网络，就采用广播方式发送，否则就采用”路由”方式发送。（”路由”的意思，就是指如何向不同的子网络分发数据包。）遗憾的是，MAC地址本身无法做到这一点。它只与厂商有关，与所处网络无关。 这就导致了”网络层”的诞生。它的作用是引进一套新的地址，使得我们能够区分不同的计算机是否属于同一个子网络。这套地址就叫做”网络地址”，简称”网址”。 于是，”网络层”出现以后，每台计算机有了两种地址，一种是MAC地址，另一种是网络地址。两种地址之间没有任何联系，MAC地址是绑定在网卡上的，网络地址则是管理员分配的，它们只是随机组合在一起。 网络地址帮助我们确定计算机所在的子网络，MAC地址则将数据包送到该子网络中的目标网卡。因此，从逻辑上可以推断，必定是先处理网络地址，然后再处理MAC地址。 IP协议网络地址的协议，叫做IP协议。它所定义的地址，就被称为IP地址。 目前，广泛采用的是IP协议第四版，简称IPv4。这个版本规定，网络地址由32个二进制位组成。 习惯上，我们用分成四段的十进制数表示IP地址，从0.0.0.0一直到255.255.255.255。 互联网上的每一台计算机，都会分配到一个IP地址。这个地址分成两个部分，前一部分代表网络，后一部分代表主机。比如，IP地址172.16.254.1，这是一个32位的地址，假定它的网络部分是前24位（172.16.254），那么主机部分就是后8位（最后的那个1）。处于同一个子网络的电脑，它们IP地址的网络部分必定是相同的，也就是说172.16.254.2应该与172.16.254.1处在同一个子网络。 但是，问题在于单单从IP地址，我们无法判断网络部分。还是以172.16.254.1为例，它的网络部分，到底是前24位，还是前16位，甚至前28位，从IP地址上是看不出来的。 那么，怎样才能从IP地址，判断两台计算机是否属于同一个子网络呢？这就要用到另一个参数”子网掩码“（subnet mask）。 所谓”子网掩码”，就是表示子网络特征的一个参数。它在形式上等同于IP地址，也是一个32位二进制数字，它的网络部分全部为1，主机部分全部为0。比如，IP地址172.16.254.1，如果已知网络部分是前24位，主机部分是后8位，那么子网络掩码就是11111111.11111111.11111111.00000000，写成十进制就是255.255.255.0。 知道”子网掩码”，我们就能判断，任意两个IP地址是否处在同一个子网络。方法是将两个IP地址与子网掩码分别进行AND运算（两个数位都为1，运算结果为1，否则为0），然后比较结果是否相同，如果是的话，就表明它们在同一个子网络中，否则就不是。 总结一下，IP协议的作用主要有两个，一个是为每一台计算机分配IP地址，另一个是确定哪些地址在同一个子网络。 IP数据包根据IP协议发送的数据，就叫做IP数据包。不难想象，其中必定包括IP地址信息。 我们可以把IP数据包直接放进以太网数据包的”数据”部分，因此完全不用修改以太网的规格。这就是互联网分层结构的好处：上层的变动完全不涉及下层的结构。 具体来说，IP数据包也分为”标头”和”数据”两个部分。 “标头”部分主要包括版本、长度、IP地址等信息，”数据”部分则是IP数据包的具体内容。它放进以太网数据包后，以太网数据包就变成了下面这样。 IP数据包的”标头”部分的长度为20到60字节，整个数据包的总长度最大为65,535字节。因此，理论上，一个IP数据包的”数据”部分，最长为65,515字节。前面说过，以太网数据包的”数据”部分，最长只有1500字节。因此，如果IP数据包超过了1500字节，它就需要分割成几个以太网数据包，分开发送了。 ARP协议因为IP数据包是放在以太网数据包里发送的，所以我们必须同时知道两个地址，一个是对方的MAC地址，另一个是对方的IP地址。通常情况下，对方的IP地址是已知的，但是我们不知道它的MAC地址。 我们需要一种机制，能够从IP地址得到MAC地址。 这里又可以分成两种情况。第一种情况，如果两台主机不在同一个子网络，那么事实上没有办法得到对方的MAC地址，只能把数据包传送到两个子网络连接处的”网关”（gateway），让网关去处理。 第二种情况，如果两台主机在同一个子网络，那么我们可以用ARP协议，得到对方的MAC地址。ARP协议也是发出一个数据包（包含在以太网数据包中），其中包含它所要查询主机的IP地址，在对方的MAC地址这一栏，填的是FF:FF:FF:FF:FF:FF，表示这是一个”广播”地址。它所在子网络的每一台主机，都会收到这个数据包，从中取出IP地址，与自身的IP地址进行比较。如果两者相同，都做出回复，向对方报告自己的MAC地址，否则就丢弃这个包。 总之，有了ARP协议之后，我们就可以得到同一个子网络内的主机MAC地址，可以把数据包发送到任意一台主机之上了。 传输层传输层的由来有了MAC地址和IP地址，我们已经可以在互联网上任意两台主机上建立通信。 接下来的问题是，同一台主机上有许多程序都需要用到网络，比如，你一边浏览网页，一边与朋友在线聊天。当一个数据包从互联网上发来的时候，你怎么知道，它是表示网页的内容，还是表示在线聊天的内容？ 也就是说，我们还需要一个参数，表示这个数据包到底供哪个程序（进程）使用。这个参数就叫做”端口”（port），它其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。 “端口”是0到65535之间的一个整数，正好16个二进制位。0到1023的端口被系统占用，用户只能选用大于1023的端口。不管是浏览网页还是在线聊天，应用程序会随机选用一个端口，然后与服务器的相应端口联系。 “传输层”的功能，就是建立”端口到端口”的通信。相比之下，”网络层”的功能是建立”主机到主机”的通信。只要确定主机和端口，我们就能实现程序之间的交流。因此，Unix系统就把主机+端口，叫做”套接字”（socket）。有了它，就可以进行网络应用程序开发了。 UDP协议现在，我们必须在数据包中加入端口信息，这就需要新的协议。最简单的实现叫做UDP协议，它的格式几乎就是在数据前面，加上端口号。 UDP数据包，也是由”标头”和”数据”两部分组成。 “标头”部分主要定义了发出端口和接收端口，”数据”部分就是具体的内容。然后，把整个UDP数据包放入IP数据包的”数据”部分，而前面说过，IP数据包又是放在以太网数据包之中的，所以整个以太网数据包现在变成了下面这样： UDP数据包非常简单，”标头”部分一共只有8个字节，总长度不超过65,535字节，正好放进一个IP数据包。 TCP协议UDP协议的优点是比较简单，容易实现，但是缺点是可靠性较差，一旦数据包发出，无法知道对方是否收到。 为了解决这个问题，提高网络可靠性，TCP协议就诞生了。这个协议非常复杂，但可以近似认为，它就是有确认机制的UDP协议，每发出一个数据包都要求确认。如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。 因此，TCP协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。 TCP数据包和UDP数据包一样，都是内嵌在IP数据包的”数据”部分。TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。 应用层应用程序收到”传输层”的数据，接下来就要进行解读。由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。 “应用层”的作用，就是规定应用程序的数据格式。 举例来说，TCP协议可以为各种各样的程序传递数据，比如Email、WWW、FTP等等。那么，必须有不同协议规定电子邮件、网页、FTP数据的格式，这些应用程序协议就构成了”应用层”。 这是最高的一层，直接面对用户。它的数据就放在TCP数据包的”数据”部分。因此，现在的以太网的数据包就变成下面这样。 网关转发 上图中，1号电脑要向4号电脑发送一个数据包。它先判断4号电脑是否在同一个子网络，结果发现不是，于是就把这个数据包发到网关A。网关A通过路由协议，发现4号电脑位于子网络B，又把数据包发给网关B，网关B再转发到4号电脑。 1号电脑把数据包发到网关A，必须知道网关A的MAC地址。所以，数据包的目标地址，实际上分成两种情况： 发送数据包之前，电脑必须判断对方是否在同一个子网络，然后选择相应的MAC地址。 用户的上网设置静态IP地址一个电脑想要上网需要填入以下的内容： 由于它们是给定的，计算机每次开机，都会分到同样的IP地址，所以这种情况被称作”静态IP地址上网”。 这样的设置很专业，普通用户望而生畏，而且如果一台电脑的IP地址保持不变，其他电脑就不能使用这个地址，不够灵活。出于这两个原因，大多数用户使用”动态IP地址上网”。 动态IP地址所谓”动态IP地址”，指计算机开机后，会自动分配到一个IP地址，不用人为设定。它使用的协议叫做DHCP协议。 这个协议规定，每一个子网络中，有一台计算机负责管理本网络的所有IP地址，它叫做”DHCP服务器”。新的计算机加入网络，必须向”DHCP服务器”发送一个”DHCP请求”数据包，申请IP地址和相关的网络参数。 如果两台计算机在同一个子网络，必须知道对方的MAC地址和IP地址，才能发送数据包。但是，新加入的计算机不知道这两个地址，怎么发送数据包呢？ DHCP协议做了一些巧妙的规定。 DHCP协议首先，它是一种应用层协议，建立在UDP协议之上，所以整个数据包是这样的： （1）最前面的”以太网标头”，设置发出方（本机）的MAC地址和接收方（DHCP服务器）的MAC地址。前者就是本机网卡的MAC地址，后者这时不知道，就填入一个广播地址：FF-FF-FF-FF-FF-FF。（2）后面的”IP标头”，设置发出方的IP地址和接收方的IP地址。这时，对于这两者，本机都不知道。于是，发出方的IP地址就设为0.0.0.0，接收方的IP地址设为255.255.255.255。（3）最后的”UDP标头”，设置发出方的端口和接收方的端口。这一部分是DHCP协议规定好的，发出方是68端口，接收方是67端口。 这个数据包构造完成后，就可以发出了。以太网是广播发送，同一个子网络的每台计算机都收到了这个包。因为接收方的MAC地址是FF-FF-FF-FF-FF-FF，看不出是发给谁的，所以每台收到这个包的计算机，还必须分析这个包的IP地址，才能确定是不是发给自己的。当看到发出方IP地址是0.0.0.0，接收方是255.255.255.255，于是DHCP服务器知道”这个包是发给我的”，而其他计算机就可以丢弃这个包。 接下来，DHCP服务器读出这个包的数据内容，分配好IP地址，发送回去一个”DHCP响应”数据包。这个响应包的结构也是类似的，以太网标头的MAC地址是双方的网卡地址，IP标头的IP地址是DHCP服务器的IP地址（发出方）和255.255.255.255（接收方），UDP标头的端口是67（发出方）和68（接收方），分配给请求端的IP地址和本网络的具体参数则包含在Data部分。 新加入的计算机收到这个响应包，于是就知道了自己的IP地址、子网掩码、网关地址、DNS服务器等等参数。 访问网页本机参数假定用户设置好了网络参数： 想要访问Google，在地址栏输入了网址：www.google.com。这意味着，浏览器要向Google发送一个网页请求的数据包。 DNS协议我们知道，发送数据包，必须要知道对方的IP地址。但是，现在，我们只知道网址www.google.com，不知道它的IP地址。 DNS协议可以帮助我们，将这个网址转换成IP地址。已知DNS服务器为8.8.8.8，于是我们向这个地址发送一个DNS数据包（53端口）。 然后，DNS服务器做出响应，告诉我们Google的IP地址是172.194.72.105。于是，我们知道了对方的IP地址。 子网掩码要判断，这个IP地址是不是在同一个子网络，这就要用到子网掩码。 已知子网掩码是255.255.255.0，本机用它对自己的IP地址192.168.1.100，做一个二进制的AND运算（两个数位都为1，结果为1，否则为0），计算结果为192.168.1.0；然后对Google的IP地址172.194.72.105也做一个AND运算，计算结果为172.194.72.0。这两个结果不相等，所以结论是，Google与本机不在同一个子网络。 因此，我们要向Google发送数据包，必须通过网关192.168.1.1转发，也就是说，接收方的MAC地址将是网关的MAC地址。 应用层协议浏览网页用的是HTTP协议，它的整个数据包构造是这样的： HTTP部分的内容，类似于下面这样： 我们假定这个部分的长度为4960字节，它会被嵌在TCP数据包之中。 TCP协议TCP数据包需要设置端口，接收方（Google）的HTTP端口默认是80，发送方（本机）的端口是一个随机生成的1024-65535之间的整数，假定为51775。 TCP数据包的标头长度为20字节，加上嵌入HTTP的数据包，总长度变为4980字节。 IP协议然后，TCP数据包再嵌入IP数据包。IP数据包需要设置双方的IP地址，这是已知的，发送方是192.168.1.100（本机），接收方是172.194.72.105（Google）。 IP数据包的标头长度为20字节，加上嵌入的TCP数据包，总长度变为5000字节。 以太网协议最后，IP数据包嵌入以太网数据包。以太网数据包需要设置双方的MAC地址，发送方为本机的网卡MAC地址，接收方为网关192.168.1.1的MAC地址（通过ARP协议得到）。 以太网数据包的数据部分，最大长度为1500字节，而现在的IP数据包长度为5000字节。因此，IP数据包必须分割成四个包。因为每个包都有自己的IP标头（20字节），所以四个包的IP数据包的长度分别为1500、1500、1500、560。 服务器端响应经过多个网关的转发，Google的服务器172.194.72.105，收到了这四个以太网数据包。 根据IP标头的序号，Google将四个包拼起来，取出完整的TCP数据包，然后读出里面的”HTTP请求”，接着做出”HTTP响应”，再用TCP协议发回来。 本机收到HTTP响应以后，就可以将网页显示出来，完成一次网络通信。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://github.com/zdkswd/tags/计算机网络/"}]},{"title":"C C++程序的构筑过程","slug":"C C++程序的构筑过程","date":"2018-12-18T10:13:56.000Z","updated":"2018-12-18T10:14:22.000Z","comments":true,"path":"2018/12/18/C C++程序的构筑过程/","link":"","permalink":"https://github.com/zdkswd/2018/12/18/C C++程序的构筑过程/","excerpt":"","text":"C C++程序的构筑过程参考：http://www.ruanyifeng.com/blog/2014/11/compiler.html源码要运行，必须先转成二进制的机器码。这是编译器的任务。如源码test.c 要编译器处理一下才能运行。 对于复杂的项目，编译过程还必须分成三步。 第一步 配置（configure）编译器在开始工作之前，需要知道当前的系统环境，比如标准库在哪里、软件的安装位置在哪里、需要安装哪些组件等等。这是因为不同计算机的系统环境不一样，通过指定编译参数，编译器就可以灵活适应环境，编译出各种环境都能运行的机器码。这个确定编译参数的步骤，就叫做”配置”（configure）。 这些配置信息保存在一个配置文件之中，约定俗成是一个叫做configure的脚本文件。通常它是由autoconf工具生成的。编译器通过运行这个脚本，获知编译参数。 configure脚本已经尽量考虑到不同系统的差异，并且对各种编译参数给出了默认值。如果用户的系统环境比较特别，或者有一些特定的需求，就需要手动向configure脚本提供编译参数。 第二步 确定标准库和头文件的位置源码肯定会用到标准库函数（standard library）和头文件（header）。它们可以存放在系统的任意目录中，编译器实际上没办法自动检测它们的位置，只有通过配置文件才能知道。 编译的第二步，就是从配置文件中知道标准库和头文件的位置。一般来说，配置文件会给出一个清单，列出几个具体的目录。等到编译时，编译器就按顺序到这几个目录中，寻找目标。 第三步 确定依赖关系对于大型项目来说，源码文件之间往往存在依赖关系，编译器需要确定编译的先后顺序。假定A文件依赖于B文件，编译器应该保证做到下面两点。 编译顺序保存在一个叫做makefile的文件中，里面列出哪个文件先编译，哪个文件后编译。而makefile文件由configure脚本运行生成，这就是为什么编译时configure必须首先运行的原因。 在确定依赖关系的同时，编译器也确定了，编译时会用到哪些头文件。 第四步 头文件的预编译不同的源码文件，可能引用同一个头文件（比如stdio.h）。编译的时候，头文件也必须一起编译。为了节省时间，编译器会在编译源码之前，先编译头文件。这保证了头文件只需编译一次，不必每次用到的时候，都重新编译了。 不过，并不是头文件的所有内容，都会被预编译。用来声明宏的#define命令，就不会被预编译。 第五步 预处理（Preprocessing）预编译完成后，编译器就开始替换掉源码中bash的头文件和宏。以本文开头的那段源码为例，它包含头文件stdio.h，替换后的样子如下。 为了便于阅读，上面代码只截取了头文件中与源码相关的那部分，即fputs和FILE的声明，省略了stdio.h的其他部分（因为它们非常长）。另外，上面代码的头文件没有经过预编译，而实际上，插入源码的是预编译后的结果。编译器在这一步还会移除注释。 这一步称为”预处理”（Preprocessing），因为完成之后，就要开始真正的处理了。 第六步 编译（Compilation）预处理之后，编译器就开始生成机器码。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码。 下面是本文开头的那段源码转成的汇编码。 这种转码后的文件称为对象文件（object file）。 第七步 连接（Linking）对象文件还不能运行，必须进一步转成可执行文件。如果你仔细看上一步的转码结果，会发现其中引用了stdout函数和fwrite函数。也就是说，程序要正常运行，除了上面的代码以外，还必须有stdout和fwrite这两个函数的代码，它们是由C语言的标准库提供的。 编译器的下一步工作，就是把外部函数的代码（通常是后缀名为.lib和.a的文件），添加到可执行文件中。这就叫做连接（linking）。这种通过拷贝，将外部函数库添加到可执行文件的方式，叫做静态连接（static linking），后文会提到还有动态连接（dynamic linking）。 make命令的作用，就是从第四步头文件预编译开始，一直到做完这一步。 第八步 安装（Installation）上一步的连接是在内存中进行的，即编译器在内存中生成了可执行文件。下一步，必须将可执行文件保存到用户事先指定的安装目录。 表面上，这一步很简单，就是将可执行文件（连带相关的数据文件）拷贝过去就行了。但是实际上，这一步还必须完成创建目录、保存文件、设置权限等步骤。这整个的保存过程就称为”安装”（Installation）。 第九步 操作系统连接可执行文件安装后，必须以某种方式通知操作系统，让其知道可以使用这个程序了。比如，我们安装了一个文本阅读程序，往往希望双击txt文件，该程序就会自动运行。 这就要求在操作系统中，登记这个程序的元数据：文件名、文件描述、关联后缀名等等。Linux系统中，这些信息通常保存在 / usr/ share/ applications目录下的.desktop文件中。另外，在Windows操作系统中，还需要在Start启动菜单中，建立一个快捷方式。 这些事情就叫做”操作系统连接”。make install命令，就用来完成”安装”和”操作系统连接”这两步。 生成安装包写到这里，源码编译的整个过程就基本完成了。但是只有很少一部分用户，愿意耐着性子，从头到尾做一遍这个过程。事实上，如果你只有源码可以交给用户，他们会认定你是一个不友好的家伙。大部分用户要的是一个二进制的可执行程序，立刻就能运行。这就要求开发者，将上一步生成的可执行文件，做成可以分发的安装包。 所以，编译器还必须有生成安装包的功能。通常是将可执行文件（连带相关的数据文件），以某种目录结构，保存成压缩文件包，交给用户。 动态连接（Dynamic linking）正常情况下，到这一步，程序已经可以运行了。至于运行期间（runtime）发生的事情，与编译器一概无关。但是，开发者可以在编译阶段选择可执行文件连接外部函数库的方式，到底是静态连接（编译时连接），还是动态连接（运行时连接）。所以，最后还要提一下，什么叫做动态连接。 前面已经说过，静态连接就是把外部函数库，拷贝到可执行文件中。这样做的好处是，适用范围比较广，不用担心用户机器缺少某个库文件；缺点是安装包会比较大，而且多个应用程序之间，无法共享库文件。动态连接的做法正好相反，外部函数库不进入安装包，只在运行时动态引用。好处是安装包会比较小，多个应用程序可以共享库文件；缺点是用户必须事先安装好库文件，而且版本和安装位置都必须符合要求，否则就不能正常运行。 现实中，大部分软件采用动态连接，共享库文件。这种动态共享的库文件，Linux平台是后缀名为.so的文件，Windows平台是.dll文件，Mac平台是.dylib文件。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://github.com/zdkswd/tags/C/"}]},{"title":"C++ Primer 函数 内存 名称空间","slug":"C++ Primer 函数 内存 名称空间","date":"2018-12-18T07:07:56.000Z","updated":"2019-01-07T06:26:17.000Z","comments":true,"path":"2018/12/18/C++ Primer 函数 内存 名称空间/","link":"","permalink":"https://github.com/zdkswd/2018/12/18/C++ Primer 函数 内存 名称空间/","excerpt":"","text":"函数定义函数:分为有返回值函数和无返回值函数。void： 有返回值： C++对于返回值的类型有一定的限制:不能是数组，但可以是其他任何类型，如整数、浮点数、指针，甚至可以是结构和对象(有趣的是，虽然C++函数不能直接返回数组，但可以将数组作为结构或对象组成部分来返回)。 通常，函数通过将返回值复制到指定的CPU寄存器或内存单元中来将其返回。随后，调用程序将查看该内存单元。返回函数和调用函数必须就该内存单元中存储的数据的类型达成一致。函数原型将返回值类型告知调用程序，而函数定义命令被调用函数应返回什么类型的数据。 函数原型和函数调用 为什么需要原型:原型描述了函数到编译器的接口，即，将函数的返回值类型（如果有的话）以及参数的类型和数量告诉编译器。 原型的句法:函数原型是一条语句，因此必须以分号结束。获得原型最简单的方法是，复制函数定义中的函数头，并添加分号。 在函数原型中不要求提供变量名，有类型列表就足够了。 在原型的参数列表中，可以包括变量名，也可以不包括。原型中的变量名相当于占位符，因此不必与函数定义中的变量名相同。原型的功能:原型可以帮助编译器完成许多工作，可以极大地降低程序出错的几率，具体说，原型确保： 编译器正确处理函数返回值。 编译器检查使用的参数数目是否正确。 编译器检查使用的参数类型是否正确，如果不正确，则转换为正确的类型（如果可能的话）。 静态类型检查可捕获许多在运行阶段非常难以捕获的错误。 函数参数和按值传递C++使用参数（argument）来表示实参，使用参量（parameter）来表示形参。 函数和数组 方括号指出arr是一个数组，而方括号为空则表明，可以将任何长度的数组传递给该函数。arr实际上并不是数组，而是一个指针。在编写函数的其余部分时，可以将arr看作是数组。 其中使用int * arr 替换了int arr [] 。这证明这两个函数头都是正确的，因为在C++中，当(且仅当)用于函数头或函数原型中，int * arr 和int arr[ ]的含义才是相同的。它们都意味着arr是一个int指针。不过，数组表示法(int arr[]) 提醒用户，arr 不仅指向int, 还指向int数组的第一个int。当指针指向数组的第一个元素时， 本书使用数组表示法;而当指针指向一个独立的值时，使用指针表示法。 别忘了，在其他的上下文中，int * arr和int arr[]的含义并不相同。例如， 不能在函数体中使用int tip[ ]来声明指针。两个恒等式： 将指针（包括数组名）加1，实际上是加上了一个与指针指向的类型长度相等的值。对于遍历数组而言，使用指针加法和数组下标是等效的。 将数组作为参数意味着什么 将数组地址作为参数可以节省复制整个数组所需的时间和内存。 如果数组很大，则使用拷贝的系统开销将非常大;程序不仅需要更多的计算机内存，还需要花费时间来复制大块的数据。另一方面，使用原始数据增加了破坏数据的风险。可以使用const来解决这个问题。 使用数组区间的函数对于处理数组的C++函数，必须将数组中的数据种类、数组的起始位置和数组中元素数量提交给它；传统的C、C++方法是，将指向数组起始处的指针作为一个参数，将数组长度作为第二个参数（指针指出数组的位置和数据类型），这样便给函数提供了找到所有数据所需的信息。 还有另一种给两数提供所需信息的方法，即指定元素区间(range), 这可以通过传递两个指针来完成:一个指针标识数组的开头，另一个指针标识数组的尾部。 指针和const可以用两种不同的方式将const用于指针。第一种是让指针指向一个常量对象，这样可以防止使用该指针来修改所指向的值。第二种是将指针本身声明为常量，这样可以防止改变指针指向的位置。指向常量的指针pt: pt的声明并不意味着它指向的值实际上就是一个常量，而只是意味着对pt而言，这个值是常量。例如，pt 指向age, 而age不是const。可以直接通过age变量来修改age的值，但不能使用pt指针来修改它。 可以将const变量的地址赋给指向const的指针，但不能将const地址赋给常规指针。 上述函数调用试图将const指针赋给非const指针，编译器将禁止这种函数调用。 第二种使用const的方式使得无法修改指针的值。 关键字const的位置与之前不同。这种声明格式使得finger只能指向sloth,但允许使用finger来修改sloth的值。中间的声明不允许使用ps来修改sloth的值，但允许将ps指向另一个位置。 函数和二维数组 data是一个数组名，该数组有3个元素。每个元素都是数组，由4个int值组成。 函数和C-风格字符串将c-风格字符串作为参数的函数假设要将字符串作为参数传递给函数，表示字符串的方式有3种： char数组。 用引号括起的字符串常量。 被设置为字符串的地址的char指针 3种选择的类型都是char指针（即char * ），可将其作为字符串处理函数的参数。字符串函数原型应将其表示字符串的形参声明为char * 指针。 返回C-风格字符串的函数函数无法返回一个字符串，但可以返回字符串的地址，这样做的效率更高。 要创建包含n个字符的字符串，需要能够存储n+1个字符的空间，以便能够存储空值字符。 函数指针分为以下三个步骤。 获取函数地址获取函数的地址很简单，只要使用函数名（后面不跟参数）即可。一定要区分传递的是函数的地址还是函数的返回值。 声明函数指针声明指向某种数据类型的指针时，必须指定指针指向的类型。同样，声明指向函数的指针时，也必须指定指针指向的函数类型。 提示:通常，要声明指向特定类型的函数的指针，可以首先编写这种函数的原型，然后用( * pf)替换函数名，这样pf就是这类函数的指针。 正确地声明pf后，便可以将对应函数的地址赋给它： 使用指针来调用函数使用指针来调用被指向的函数。（ * pf）扮演的角色与函数名相同，因此使用（ * pf）时，只需将它看做函数名即可。 C++进行了折衷，这2种方式都是正确的。 函数探幽C++内联函数内联函数是C++为提高程序运行速度所做的一项改进。常规函数和内联函数之间的主要区别不在于编写方式，而在于C++编译器如何将它们组合到程序中。 内联函数的编译代码与其他程序代码“内联”起来了。也就是说，编译器将使用相应的函数代码替换函数调用。对于内联代码，程序无需跳到另一个位置处执行代码，然后再跳回来。因此，内联函数的运行速度比常规函数稍快，但代价是需要占用更多的内存。如果程序在10个不同的地方调用同一个内联函数，则该程序将包含该函数的10个代码拷贝。 要使用这项特性，必须采用下述措施之一： 在函数声明前加关键字inline。 在函数定义前加上关键字inline。 程序员请求将函数作为内联函数时，编译器并不一定会满足这种要求。它可能认为该函数过大或注意到函数调用了自己(内联函数不能递归)，因此不将其作为内联函数;而有些编译器没有启用或实现这种特性。 引用变量创建引用变量C和C++使用&amp;符号来指示变量的地址。C++给&amp;符号赋了了另一个含义，将其用来声明引用。例如，要将rodents作为rats变量的别名，可以这样做: 其中, &amp; 不是地址操作符，而是类型标识符的一部分。就像声明中的char * 指的是指向char的指针一样,int &amp; 指的是指向int的引用。 看似引用和指针用法很类似，其实是有差别的，差别之一是，必须在声明引用时将其初始化，而不能像指针那样，先声明，再赋值。 引用更接近const指针，鼻血在创建时进行初始化，一旦与某个变量关联起来，就将一直效忠于它。 将引用用作函数参数 引用的属性和特别之处临时变量、引用参数和const如果实参与引用参数不匹配，C++将生成临时变量。仅当参数为const引用时，C++才允许这样做。 如果引用参数时const，则编译器将在下面两种情况下生成临时变量： 实参的类型正确，但不是左值。 实参的类型不正确，但可以转换为正确的类型。 左值参数时可被引用的数据对象，例如，变量、数组元素、结构成员、引用和被解除引用的指针都是左值。非左值包括字面常量和包含多项的表达式。 记住:如果函数调用的参数不是左值或与相应的const引用参数的类型不匹配，则C++将创建类型正确的匿名变量，将函数调用的参数的值传递给该匿名变量，并让参数来引用该变量。 应尽可能使用const将引用参数声明为常量数据的引用的理由有3个: 使用const可以避免无意中修改数据的编程错误。 使用const使函数能够处理const和非const实参，否则将只能接受非const数据。 使用const引用使函数能够正确生成并使用临时变量。 因此，应尽可能将引用形参声明为const。 将引用用于结构引用非常适合用于结构和类(C++的用户定义类型).确实，引入引用主要是为了用于这些类型的，而不是基本的内置类型。 何时使用引用参数使用引用参数的主要原因有两个： 程序员能够修改调用函数的数据对象。 通过传递引用而不是整个数据对象，可以提高程序的运行速度。 当数据对象较大时(如结构和类对象),第二个原因最重要。这些也是使用指针参数的原因。这是有道理的,因为引用参数实际上是基于指针的代码的另一个接口。 指导原则对于使用传递的值而不作修改的函数: 如果数据对象很小,如内置数据类型或小型结构,则按值传递。 如果数据对象是数组,则使用指针,因为这是惟一的选择,并将指针声明为指向 const的指针。 如果数据对象是较大的结构,则使用 const指针或 const引用,以提高程序的效率。这样可以节省复制结构所需的时间和空间。 如果数据对象是类对象,则使用 const引用。类设计的语义常常要求使用引用,这是C+新增这项特性的主要原因。因此,传递类对象参数的标准方式是按引用传递。 对于修改调用函数中数据的函数。 如果数据对象是内置数据类型，则使用指针。 如果数据对象是数组，则只能使用指针。 如果数据对象是结构， 则使用引用或指针。 如果数据对象是类对象，则使用引用。 默认参数对于带参数列表的函数，必须从右向左添加默认值。也就是说，要为某个参数设置默认值，则必须为它右边所有的参数提供默认值： 实参按从左到右的顺序依次被賦给相应的形参，而不能跳过任何参数。下面的调用是不允许的。 默认参数不是编程方面的重大突破，而只是提供了一种便捷的方式。 函数重载所数重载的关键是函数的参数列表一也称为函数特 征标( function signature). 如果两个函数的参数数目和类型相同， 同时参数的排列顺序也相同，则它们的特征标相同， 而变量名是无关紧要的。C++ 允许定义名称相同的函数，条件是它们的特征标不同。如果参数数目和或参数类型不同，则特征标也不同。 一些看起来彼此不同的特征标是不能共存的。 为避免混乱，编译器在检查函数特征标时，将把类型引用和类型本身视为同一个特征标。 何时使用函数重载函数重载很吸引人，但也不能滥用。仅当函数基本上执行相同的任务，但使用不同形式的数据时才应采用函数重载。 使用一个带默认参数的函数要简单些。只需编写一个函数(而不是两个函数)，程序也只需为一个函数(而不是两个)请求内存:需要修改函数时，只需修改一个。不过，如果需要使用不同类型的参数时，则默认参数便不管用了， 在这种情况下，应该使用函数重载。 名称修饰使用C++开发工具中的编辑器编写和编译程序时，C++将执行一些神奇的操作，名称修饰或名称矫正。根据函数原型中指定的形参类型对每个函数名进行加密。 函数模板函数模板是通用的函数描述，就是使用通用类型来定义函数，其中的通用类型可用具体的类型（如int或double）替换。通过将类型作为参数传递给模板，可使编译器生成该类型的函数。 建立一个模板，将类型命名为Any。关键字template和class是必需的，类型名可以任意选择。关键字typename可用来替换关键字class，就是说可以编写模板定义： 提示: 如果需要多个将同一种算法用于不同类型的函数，请使用模板，如果不考虑向后兼容的问题，并愿意键入较长的单词, 则声明类型参数时，应使用关键字typename而不使用class。 重载的模板需要多个对不同类型使用同一种算法的函数时，可使用模板。 显式具体化在代码中包含函数模板本身并不会生成函数定义，它只是一个用于生成函数定义的方案。编译器使用模板为特定类型生成函数定义时，得到的是模板实例。模板并非函数定义，但使用int的模板实例是函数定义。这种实例化方式被称为隐式实例化，因为编译器之所以知道需要进行定义，是由于程序调用Swap（）函数时提供了int参数。 最初，编译器只能通过隐式实例化，来使用模板生成函数定义，C++还允许显示实例化。这意味着可以直接命令编译器创建特定的实例，Swap()。 显示具体化使用下面两个等价声明之一： 显示具体化声明在关键字Template后包含&lt;&gt;，而显式实例化没有。 警告：试图在同一个编程单元中使用同一类型的显示实例和显示具体化将出错。 实例化就是不用单独的再有个实现了，具体化是还要有一个单独的实现。 隐式实例化、显式实例化和显式具体化统称为具体化(specialization)。 它们的相同之处在于，它们表示的都是使用具体类型的函数定义，而不是通用描述。 内存模型和名称空间C++为在内存中存储数据方面提供了多种选择。可以选择数据保留在内存中的时间长度（存储持续性）以及程序的哪一部分可以访问数据（作用域和链接）等。可以使用new来动态地分配内存而布局new操作符提供了这种技术的一种变种。C++名称空间是另一种控制访问权的方式。通常，大型程序都由多个源代码文件组成，这些文件可能共享一些数据。这样的程序涉及到程序文件的单独编译。 单独编译和C语言一样，C++也允许甚至鼓励程序员将组件函数放在独立的文件中。可以单独编译这些文件，然后将它们链接成可执行的程序(通常，C++编译器既编译程序，也管理链接器)。如果只修改了一个文件，则可以只重新编译该文件，然后将它与其他文件的编译版本链接。这使得大程序的管理更便捷。另外，大多数C++环境都提供了其他工具来帮助管理。例如，UNIX和Linux系统都具有make程序，可以跟踪程序依赖的文件以及这些文件的最后修改时间。运行make时，如果它检测到上次编译后修改了源文件，make将记住重新构建程序所需的步骤。 可以将原来的程序分为三部分： 头文件：包含结构声明和使用这些结构的函数的原型 源代码文件：包含与结构有关的函数的代码。 源代码文件：包含调用与结构相关的函数的代码。 不要将函数定义或变量声明放到头文件中。例如，如果在头文件包含—个函数定义，然后在其他两个文件(属于同一个程序)中包含该头文件，则同一个程序中将包含同一个函数的两个定义，除非函数是内联的， 否则这将出错。 下面列出了头文件中常包含的内容: 函数原型 使用# define或const定义的符号常量 结构声明 类声明 模板声明 内联函数 模板声明不是将被编译的代码，它们指示编译器如何生成与源代码中的函数调用相匹配的函数定义。被声明为const的数据和内联函数有特殊的链接属性，因此可将其放在头文件而不会引起问题。 注意，在包含头文件时，我们使用“coordin.h”,而不是&lt; coodin.h &gt;。如果文件名包含在尖括号中，则C++编译器将在存储标准头文件的主机系统的文件系统中查找:但如果文件名包含在双引号中，则编译器将首先查找当前的工作目录或源代码目录(或其他目录，这取决于编译器)。如果没有在那里找到头文件，则将在标准位置查找。因此在包含自己的头文件时，应使用引号而不是尖括号。 在IDE中，不要将头文件加入到工程列表中，也不要在源代码文件中使用# include 来包含其他源代码文件。 头文件管理在同一个文件中只能将同一个头文件包含一次。记住这个规则很容易，但很可能在不知情的情况下将头文件包含多次。例如， 可能使用包含了另外一个头文件的头文件。有一种标准的C/C++技术可以避免多次包含同一个头文件。它是基于预处理器编译指令#ifndef(即if not defined)的。下面的代码片段: 意味着仅当以前没有使用预处理器编译指令# define定义名称COORDIN_H_时，才处理# ifndef和# endif之间的语句。 通常，使用# define语句来创建符号常量。 但只要将# define用于名称，就足以完成该名称的定义。 编译器首次遇到该文件时，名称COORDIN_H_没有定义（我们根据include文件名来选择名称，并加一些下划线，以创建一个在其他地方不太可能被定义的名称）。如果在同一个文件中遇到其他包含coordin.h的代码，编译器将知道COORDIN_H_已经被定义了，从而跳到# endif后面的一行上。这种方法并不能防止编译器将文件包含两次，而只是让它忽略了第一次包含之外的所有内容。大多数标准C和C++头文件都使用这种防护(guarding)方案。 存储持续性、作用域和链接性链接性链接性（linkage）描述了名称如何在不同单元间共享。链接性为外部的名称，可在文件间共享，连接性为内部的名称，只能由一个文件中的函数共享。自动变量的名称没有链接性，因为它不能共享。 作用域和链接作用域（scope）描述了名称在文件的多大范围内可见。链接性(linkage) 描述了名称如何在不同单元间共享。链接性为外部的名称可在文件间共享，链接性为内部的名称只能由一个文件中的函数共享。自动变量的名称没有链接性，因为它们不能共享。 自动存储持续性在默认情况下，在函数中声明的函数参数和变量的存储持续性为自动， 作用域为局部，没有链接性。当程序开始执行这些变量所属的代码块时，将为其分配内存;当函数结束时，这些变量都将消失(注意，执行到代码块时，将为变量分配内存， 但其作用域的起点为其声明位置)。 可以使用C++ (和C)关键字auto 来显式地指出存储类别: 自动变量和堆栈由于自动变量的数目随函数的开始和结束而增减，因此程序必须在运行时对自动变量进行管理。常用的方法是留出一段内存，并将其视为堆栈，以管理变量的增减。之所以被称为堆栈，是由于新数据被象征性地放在原有数据的上面(也就是说，在相邻的内存单元中，而不是在同一个内存单元中)，当程序使用完后，将其从堆栈中删除。堆栈的默认长度取决于实现，但编译器通常提供改变堆栈长度的选项。程序使用两个指针来跟踪堆栈，一个指针指向栈底即堆栈的开始位置，另一个指针指向堆顶即下一个可用内存单元。当函数被调用时，其自动变量将被加入到堆栈中，栈顶指针指向变量后面的下一个可用的内存单元。函数结束时，栈顶指针被重置为函数被调用前的值，从而释放新变量使用的内存。 堆栈是后进先出的，即最后加入到堆栈中的变量首先被弹出。这种设计简化了参数传递。函数调用将其参数的值放在栈顶，然后重新设置栈顶指针。被调用的函数根据其形参描述来确定每个参数的地址。 所以说形参存在于堆栈。堆栈是内存留出的一小段。 寄存器变量和C语言一样，C++也支持使用register关键字来声明局部变量。寄存器变量是另一种形式的自动变量，因此其存储持续性为自动，作用域为局部，但没有链接性。关键字register提醒编译器，用户希望它通过使用CPU寄存器，而不是堆栈来处理特定的变量，从而提供对变量的快速访问。这里的理念是，CPU访问寄存器中的值的速度比访问堆栈中内存快。要声明寄存器变量，请在类型前加上关键字register: 现代编译器已经足够聪明，在编写for循环时，编译器可能自动使用寄存器来存储循环计数。 如果变量被存储在寄存器则没有内存地址，因此不能讲地址操作符用于寄存器变量。 简而言之，常规局部变量、使用auto 声明的局部变量以及使用register 声明的局部变量的存储持续性都是自动的， 作用域都是局部的，也都没有链接性。 声明局部变量时，如果没有使用说明符，则与使用auto声明变量等效。通常， 处理这种变量的方式是将其放置到内存堆栈中。使用register说明符指出该变量将被频繁使用，编译器可能会选择使用内存堆栈之外的其他方式(如使用CPU寄存器)来存储它。 静态持续变量和C语言一样，C++也为静态存储持续性变量提供了3种链接性:外部链接性、内部链接性和无链接性。这3种链接性都在整个程序执行期间存在，与自动变量相比，它们的寿命更长。由于静态变量的数目在程序运行期间是不变的，因此程序不需要使用特殊的装置(如堆栈)来管理它们。编译器将分配固定的内存块来存储所有的静态变量，这些变量在整个程序执行期间一直存在。另外， 如果没有显式地初始化静态变量，编译器就将把它设置为0。在默认情况下，静态数组和结构将每个元素或成员的所有位都设置为0。 要想创建链接性为外部的静态持续变量，必须在代码块的外面声明它; 要创建链接性为内部的静态持续变量，必须在代码块的外面声明它，并使用static限定符:要创建没有链接性的静态持续变量，必须在代码块内声明它，并使用static限定符。 所有静态持续变量在整个程序执行期间都存在。在funct1（）中声明的变量count的作用域为局部，没有链接性，这意味着只能在funct1（）函数中使用它，就像自动变量一样，但不同之处在于，即使函数没有执行时，count也留在内存中。global和one_file的作用域为整个文件，即在从声明位置到文件结尾的范围内都可以被使用。由于one_file的链接性为内部，因此只能在包含上述代码的文件中；由于global的链接性为外部，因此可以在程序的其他文件中使用它。 所有静态持续变量只能使用常量表达式来初始化静态变量。 链接性为外部的变量通常简称为外部变量，它们的存储持续性为静态，作用域为整个文件。外部变量是在函数外部定义的，因此对所有函数而言都是外部的。外部变量也称为全局变量。如果定义了与外部变量同名的自动变量，该自动变量将隐藏同名的外部变量。 关键字extern的意思是“通过以前被外部定义的名称使用该变量”。外部变量声明： 称为定义声明，给该变量分配存储空间。重新声明： 称为引用声明，或简称为声明。它不给变量分配存储空间，因为它引用已有的变量。只能在引用其他地方（或函数）定义的变量的声明中使用关键字extern。当试图赋值时将会报错。 仅当声明将为变量分配存储空间时（即定义声明），才能在声明中初始化变量。毕竟，初始化指的是在分配内存单元时给它赋值。 全局变量和局部变量过多使用全局变量会破坏数据的完整性，外部存储尤其适于表示常量数据，因为这样可以使用关键字const来防止数据被修改。 静态持续性、内部链接性对于外部链接变量，有且只有一个文件中包含了该变量的外部定义，其他文件要使用该变量，必须在引用声明中使用关键字extern。 如果文件试图定义另一个同名的外部变量将出错： 如果文件定义了一个静态外部变量，其名称与另一个文件中声明的常规外部变量相同，则在该文件中，静态变量将隐藏常规外部变量。 静态存储持续性、无连接性如果初始化了静态局部变量，则程序只在启动时进行一次初始化，以后再调用函数时，将不会像自动变量那样再次被初始化。 说明符和限定符存储说明符： auto register static extern mutable 在同一个声明中不能使用多个说明符。mutable 是为了突破 const 的限制而设置的。可以用来修饰一个类的成员变量。被 mutable 修饰的变量，将永远处于可变的状态，即使是 const 函数中也可以改变这个变量的值。 cv限定符： const volatile(易变的，不稳定的) volatile关键字表明，即使程序代码没有对内存单元进行修改，其值也可能发生变化。听起来似乎很神秘，实际上并非如此。例如，可以将一个指针指向某个硬件位置，其中包含了来自串行端口的时间或信息。在这种情况下，硬件(而不是程序)可能修改其中的内容。或者两个程序可能互相影响，共享数据。该关键字的作用是为了改善编译器的优化能力。例如，假设编译器发现，程序在几条语句中两次使用了某个变量的值，则编译器可能不是让程序查找这个值两次，而是将这个值缓存到寄存器中。这种优化假设变量的值在这两次使用之间不会变化。如果不将变量声明为volatile, 则编译器将进行这种优化;将变量声明为volatile,相当于告诉编译器，不要进行这种优化。避免出现和想象结果不一致的情况。 再谈const在C++中，const限定符对默认存储类型稍有影响。在默认情况下全局变量的链接性为外部的，但const全局变量的链接性为内部的。也就是说，在C++看来， 全局const定义就像使用了static说明符一样。（就链接性而言） 内部链接还意味着，每个文件都有自己的一组常量，而不是所有文件共享一组常量。每个定义都是共所属文件私有的，这就是能够将常量定义放在头文件中的原因。这样，只要在两个源代码文件中包括同一个头文件，则它们将获得同一组常量。 如果出于某种原因，程序员希望某个常量的链接性为外部的，则可以使用extern关键字来覆盖默认的内部链接性: 这种情况下，必须在所有使用该常量的文件中使用extem关键字来声明它。这与常规外部变量不同，定义常规外部变量时，不必使用extem关键字，但在使用该变量的其他文件中必须使用extem。 函数和链接性C++不允许在一个函数中定义另一个函数，因此所有函数的存储持续性都自动为静态的，即在整个程序执行期间都一直存在。在默认情况下，函数的链接性为外部的，即可以在文件间共享。可以在函数原型中使用关键字extern来指出函数时再另一个文件中定义的，不过这是可选的（要让程序在另一个文件中查找函数， 该文件必须作为程序的组成部分被编译，或者是由链接程序搜索的库文件)。还可以使用关键字static将函数的链接性设置为内部的，使之只能在一个文件中使用。必须同时在原型和函数定义汇总使用该关键字。 这意味着该函数以在这个文件中可见，还意味着可以在其他文件中定义同名的的函数。和变量一样，在定义静态函数的文件中，静态函数将覆盖外部定义，因此即使在外部定义了同名的函数，该文件仍将使用静态函数。 C++有一个“单定义规则”，即对于每个非内联函数，程序中只能包含一个定义。对于链接性为外部的函数来说，这意味着在多文件程序中，只能有一个文件包含该函数的定义，但使用该函数的每个文件都应包含其函数原型。 内联函数不受这项规则的约束，这允许程序员能够将内联函数的定义放在头文件中。这样，包含了头文件的每个文件都有内联函数的定义。不过，C++要求同一个函数的所有内联定义都必须相同。 C++在哪里查找函数如果该文件中的函数原型指出该函数是静态的，则编译器将只在该文件中查找函数定义;否则， 编译器(包括链接程序)将在所有的程序文件中查找。如果找到两个定义，编译器将发出错误消息，因为每个外部函数只能有一个定义。如果在程序文件中没有找到， 编译器将在库中搜索。这意味着如果定义了一个与库函数同名的函数， 编译器将使用程序员定义的版本， 而不是库函数(不过，C++保留了标准库函数的名称，即程序员不应使用它们).一些编译器-链接程序要求显式地指出要搜索哪些库。 语言链接性另一种形式的链接性称为语言链接性，也对函数有影响。链接程序要求每个不同的函数都有不同的符号名。在C++中，同一个名称可能对应多个函数，必须将这些函数翻译为不同的符号名称。因此，C++编译器执行名称矫正或名称修饰，为重载函数生成不同的符号名称。例如， 可能将spiff (int)转换为_spof_i,而将spiff (double, double) 转换为_spif_d_d.这种方法被称为C++语言链接(C++ language linkage)。 链接程序寻找与C++函数调用匹配的函数时，使用的方法与c语言不同。但如果要在c++程序中使用C库中预编译的函数，将出现什么情况呢?例如，假设有下面的代码: 它在C库文件中的符号名称为_spif, 但对于我们假设的链接程序来说，C++查询约定是查找符号名称_spiff_ i。为解决这种问题，可以用函数原型来指出要使用的约定: 第一个原型使用C语言链接性:而后面的两个使用C+语言链接性。第二个原型是通过默认方式指出这一点的，而第三个显式地指出了这一点。 存储方案和动态分配与自动内存不同，动态内存不是LIFO,其分配和释放顺序要取决于new和delete 在何时以何种方式被使用。通常，编译器使用3块独立的内存:一块用于静态变量(可能再细分)，一块用于自动变量， 另外一块用于动态存储。 如果将p_fees的链接性声明为外部的，则文件中位于该声明后面的所有函数都可以使用它。另外，通过在另一个文件中使用： 可以在这个文件中使用该指针。不过，请注意， 使用new来设置p_ fees 的语句必须位于函数中(如下面的代码段所示)，这是因为只能使用常量表达式来初始化静态存储变量: 注意: 在程序结束时，由new分配的内存通常都将被释放，不过情况也并不总是这样。例如,在不那么健壮的操作系统中，在某些情况下，请求大型内存块将导致该代码块在程序结束不会被自动释放。最佳的做法是， 使用delete 来释放new分配的内存。 布局new操作符new负责在堆(heap) 中找到一个足以能够满足要求的内存块。new操作符还有另一种变体，被称为布局(placement)new操作符，它能够指定要使用的位置。程序员可能使用这种特性来设置其内存管理规程或处理需要通过特定地址进行访问的硬件。要使用布局new特性，首先需要包含头文件new。 它提供了new操作符原型，下面是new操作符的四种用法： 其中如果buffer是静态存储区，那么就new到了静态存储区。而常规new就到了动态管理的堆中。 由于buffer指定的内存是静态内存，而delete只能指向常规new操作符分配的堆内存，就是说数组buffer位于delete的管辖区域之外。 名称空间当随着工程的增大，名称相互冲突的可能性也将增加。使用多个厂商的类库时，可能导致名称冲突。C++标准提供了名称空间工具，以便更好地控制名称的作用域。 传统的C++名称空间几个概念：声明区域(declaration region)。 声明区域是可以在其中进行声明的区域。例如，可以在函数外面声明全局变量，对于这种变量，其声明区域为其声明所在的文件。对于在函数中声明的变量，其声明区域为其声明所在的代码块。 潜在作用域。变量的潜在作用域从声明点开始,到其声明域的结尾。因此潜在作用域比声明区域小,这是由于变量必须定义后才能使用。 新的名称空间特性C++新增了这样一种功能,即通过定义一种新的声明区域来创建命名的名称空间,这样做的目的之一是提供一个声明名称的区域。一个名称空间中的名称不会与另外一个名称空间的相同名称发生冲突,同时允许程序的其他部分使用该名称空间中声明的东西。例如,下面的代码使用新的关键字 namespace创建了两个名称空间:Jack和Jill。 名称空间可以是全局的,也可以位于另一个名称空间中,但不能位于代码块中。因此,在默认情况下,在名称空间中声明的名称的链接性为外部的(除非它引用了常量) 除了用户定义的名称空间外，还存在另一个名称空间一全局名称空间(global namespace)。 它对应于文件级声明区域，因此前面所说的全局变量现在被描述为位于全局名称空间中。 任何名称空间中的名称都不会与其他名称空间中的名称发生冲突。 当然, 需要有一种方法来访问给定名称空间中的名称。最简单的方法是，通过作用域解析操作符::,使用名称空间来限定该名称。未被装饰的名称(如pail)被称为未限定的名称(unqualifed name);包含名称空间的名称(如Jack;pail)被称为限定的名称(qualified name). using声明和using编译指令如果不希望每次使用名称都使用：：，C++提供了两种机制（using声明和using编译指令）来简化对名称空间中名称的使用。using声明使特定的表示符可用，using编译指令使整个名称空间可用。 using声明由限定的名称和它前面的关键字using组成： using编译命令使所有的名称都可用。using编译命令由名称空间名和它前面的关键字using namespace组成，它使名称空间中的所有名称都可用，而不需要使用作用域解析操作符： using编译指令和using声明值比较使用using编译指令导入一个名称空间中所有的名称与使用using声明是不一样的，而更像是大量使用作用域解析操作符。使用 using声明时,就好像声明了相应的名称一样。如果某个名称已经在函数中声明了,则不能用 using声明导入相同的名称。然而,使用 using编译指令时,将进行名称解析,就像在包含 using声明和名称空间本身的最小声明区域中声明了名称一样。在下面的范例中,名称空间为全局的。如果使用 using编译指令导入一个已经在函数中声明的名称,则局部名称将隐藏名称空间名,就像隐藏同名的全局变量样。 一般来说，使用using声明比使用using编译指令更安全，这是由于它只导入指定的名称。如果该名称与局部名称发生冲突，编译器将发出指示。using编译指令导入所有名称，包括可能并不需要的名称。如果与局部名称发生冲突，则局部名称将覆盖名称空间版本，而编译器并不会发出警告。另外，名称空间的开放性意味着名称空间的名称可能分散在多个地方，这使得难以准确知道添加了哪些名称。 名称空间的其他特性可以将名称空间声明进行嵌套。 这里flame指的是element:: fire ::flame。 未命名的名称空间可以通过省略名称空间的名称来创建未命名的名称空间： 不能再未命名名称空间所属文件之外的其他文件中，使用该名称空间中的名称，因此这种方法可以替代链接性为内部的静态变量。 名称空间的指导原则 使用在已命名的名称空间中声明的变量，而不是使用外部全局变量。 使用在已命名的名称空间中声明的变量，而不是使用静态全局变量。 如果开发了一个函数库或类库，将其放在一个名称空间中。 仅将编译指令using作为一种将旧代码转换为使用名称空间的权宜之计。（其实若冲突IDE中会报含糊不清错误） 不要在头文件中使用using 编译指令。首先，这样做掩盖了要让哪些名称可用;另外， 包含头文件的顺序可能影响程序的行为。 如果非要使用编译指令using,应将其放在所有预处理器编译指令#include之后。 导入名称时， 首选使用作用域解析操作符或using声明的方法。 对于using声明，首选将其作用域设置为局部而不是全局。 对于简单程序，使用using编译指令并非什么大逆不道的事。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://github.com/zdkswd/tags/C/"}]},{"title":"C++ Primer 数据 语句","slug":"C++ Primer 数据 语句","date":"2018-12-18T07:06:56.000Z","updated":"2019-01-06T07:04:50.000Z","comments":true,"path":"2018/12/18/C++ Primer 数据 语句/","link":"","permalink":"https://github.com/zdkswd/2018/12/18/C++ Primer 数据 语句/","excerpt":"","text":"开始学习C++进入C++通常main()被启动代码调用，而启动代码是由编译器添加到程序中的，是程序和操作系统的桥梁。 C++必修包含一个名为main()的函数，大小写拼写都要正确。如果没有main(),程序将不完整，编译器将指出未定义main()函数。 存在一些例外情况。例如,在 Windows编程中,可以编写一个动态链接库(DLL)模块,这是其他 Windows程序可以使用的代码。由于DLL模块不是独立的程序,因此不需要 main （）。 C++注释 （/ / ）以及（/ 和 /） C++预处理器和iostream文件C++和C一样,也使用一种预处理器,该程序在进行主编译之前对源文件进行处理(有些C++实现使用翻译器程序将C++程序转换为C程序。虽然翻译器也是一种预处理器,但这里不讨论这种预处理器,而只讨论处理名称以 # 开头的编译指令的预处理器)。不必执行任何特殊的操作来调用该预处理器,它会在编译程序时自动运行。 实际上，iostream文件的内容将取代程序中的代码行# include &lt; iostream&gt;。原始文件没有被修改，而是将源代码文件和iostream组合成一个复合文件，编译的下一阶段将使用该文件。 头文件名 像iostream这样的文件由于它们被包含在其他文件中叫做包含文件(include file)；由于它们被包含在文件起始处，也叫头文件(header file)。C++编译器自带了很多头文件，每个头文件都支持一组特定的工具。 C++的用法发生了变化。现在,对老式C的头文件保留了扩展名h(C++程序仍可以使用这种文件),而C++头文件则没有扩展名。有些C头文件被转换为C++头文件,这些文件被重新命名,去掉了扩展名h(使之成为C++风格的名称),并在文件名称前面加上前缀c(表明来自C语言)。例如,C++版本的math.h为 cmath头文件。有时C头文件的C版本和C++版本相同,而有时候新版本做了些修改。对于纯粹的C++头文件(如 iostream)来说,去掉h不只是形式上的变化,没有h的头文件也可以包含名称空间。 名称空间 这叫做using编译指令。 名称空间支持是C++中一项较新的特性,它是为了使编写将多个厂商已有的代码组合起来的程序更简单而设计的。一个潜在的问题是:可能使用两个已封装好的产品,而它们都包含一个名为 wanda()的函数。这样,使用 wanda函数时,编译器将不知道指的是哪个版本。名称空间让厂商能够将其产品封装在一个叫做名称空间的单元中,这样就可以用名称空间的名称来指出想使用哪个厂商的产品。因此, Microflop Industries可以将其定义放到一个名为 Microflop的名称空间中。这样,其 wanda函数的全称为Microflop:: wanda():同样, Piscine公司的 wandao版本可以表示为 Piscine: :wanda()。这样,程序就可以使用名称空间来区分不同的版本了: iostream是C++的标准库，标准库都被放置在命名空间std（standard）中。仅当头文件没有扩展名h时，情况才这样，也就是采用c++的新式风格，即采用了名称空间。头文件为.h由于没有采用名称空间，所以在采用不同库时，是存在命名冲突的风险的，没办法，自己想办法解决吧；）。123C语言与c++，C语言确实是最底层，但是语法不完善，开发效率很低，c++就是为了解决某些问题才诞生的。鸡先生蛋还是蛋先生鸡，许多语言的编译都是c写的，那么c语言的编译器又是谁写的呢。1970年Tomphson和Ritchie在BCPL（一种解释型语言）的基础上开发了B语言，1973年又在B语言的基础上成功开发出了现在的C语言。在C语言被用作系统编程语言之前，Tomphson也用过B语言编写过操作系统。可见在C语言实现以前，B语言已经可以投入实用了。因此第一个C语言编译器的原型完全可能是用B语言或者混合B语言与PDP汇编语言编写的。我们现在都知道，B语言的执行效率比较低，但是如果全部用汇编语言来编写，不仅开发周期长、维护难度大，更可怕的是失去了高级程序设计语言必需的移植性。所以早期的C语言编译器就采取了一个取巧的办法：先用汇编语言编写一个C语言的一个子集的编译器，再通过这个子集去递推完成完整的C语言编译器。 1234编译器为什么会生成汇编语言而不是机器语言？1)其中有一个好处是方便优化，因为，编译器也是工具，也是机器，毕竟是机器生成的程序，不可以非常 完美的,而汇编是机器指令的助记符，一个汇编指令就对应一条机器指令（特殊指令除外）调试起来肯定会比 机器指令方便的方便，这样优化起来也方便。2)高级语言只需要编译成汇编代码就可以了,汇编代码到机器码的转换是由硬件实现即可,有必要用软件实 现这样分层可以有效地减弱编译器编写的复杂性,提高了效率.就像网络通讯的实现需要分成很多层一样,主要 目的就是为了从人脑可分析的粒度来减弱复杂性.3)如果把高级语言的源代码直接编译成机器码的话，那要做高级语言到机器码之间的映射,如果这样做的 话，每个写编译器的都必须熟练机器码。这个不是在做重复劳动么。 c++在使用函数前需要有函数声明，有了函数声明还要有函数定义。c++不允许将函数定义嵌套在另一个函数定义中。每个函数定义都是独立的，所有函数的创建都是平等的。 int main（）时return 0将返回值返回给了操作系统。例如。UNIX外壳脚本和DOS批处理文件都被设计成运行程序。很多操作系统都可以使用程序的返回值（通常也叫退出值）。通常的约定是，退出值为0则意味着程序运行成功，为非0则意味着存在问题。因此，如果c++程序无法打开文件，可以将它设计为返回一个非零值。然后，便可以设计一个外壳脚本或批处理文件来运行该程序，如果程序发出指示失败的消息，则采取其他措施。 处理数据简单变量变量名整型short、int和long如果在所有的系统中，每种类型的宽度都相同，则使用起来将非常方便。但是生活并非那么简单，C++提供了一种灵活的标准，它确保了最小长度（从C语言借鉴而来）： short至少16位 int至少和short一样长。 long至少32位，且至少与int一样长。 当前很多系统都使用最小长度,即shot为16位,long为32位。这仍然为int提供了多种选择,其宽度可以是16位、24位或32位,同时又符合标准。通常,在老IMPC的实现中,int的宽度为16位(与short相同),而在 Windows98、 Windows nt、 Windows XP、 Macintosh OS X、VAX和很多其他微型计算机的实现中,为32位(与long相同)。有些实现允许选择如何处理int类型的宽度随实现而异,这可能在将C艹程序从种环境移到另…种环境时引发问题。但只要小心一点就可以最大限度地减少这种问题。 实际上，short是short int的简称，而long是long int的简称。这三种类型（int,short和long）都是符号类型，意思是有一位的符号位。 sizeof操作符返回类型或变量的长度，单位为字节。头文件 climits(在老式实现中为 limits h)中包含了关于整型限制的信息。具体地说,它定义了表示各种限制的符号名称。例如, INT_MAX为int的最大取值, CHAR_BIT为字节的位数。 符号常量—预处理器方式 # define编译指令是C语言遗留下来的。C艹有一种更好的创建符号常量的方法(使用关键字 const）,所以不会经常使用 # define。不过,有些头文件,尤其是那些被设计成可用于C和C艹中的头文件,必须使用 # define 无符号类型要创建无符号版本的基本整形，只需要使用关键字unsigned来修改声明即可： climits文件与limits.h文件；老式编译器可能需要使用文件limits.h，有些非常老的编译器可能根本没有这两个文件。 选择整型的类型通常,int被设置为对目标计算机而言最为“自然”的长度。自然长度( natural size)指的是计算机处理起来效率最高的长度。如果没有非常有说服力的理由来选择其他类型,则应使用int。 如果知道变量可能表示的整数值大于16位整数的最大可能值,则使用long。即使系统上int为32位也应这样做。这样,当程序移植到16位的系统中时,程序就不会突然无法正常工作。 如果 short比int小,则使用 short可以节省内存。通常,仅当有大型整型数组时,才有必要使用 short(数组是一种数据结构,在内存中连续存储同类型的多个值)。如果节省内存很重要,则应使用 short而不是使用int,即使它们的长度是一样的。例如,假设要将程序从int为16位的 DOS PC系统移到int为32位的Windows XP系统,则用于存储int数组的内存量将加倍,但 short数组不受影响。记住,节省一点是一点。如果只需要一个字节，可使用char。 整型常量十进制，八进制，十六进制。不管书写为10、012还是0xA，都将以相同的方式存储在计算机中—被存储为二进制数。 C++如何确定常量的类型程序将把常量1492存储为int、long还是其他整型呢?答案是,除非有理由存储为其他类型(如使用了特殊的后缀来表示特定的类型,或者值太大,不能存储为int),否则C++将整型常量存储为int类型。 首先来看看后缀。后缀是放在数字常量后面的字母,用于表示类型。整数后面的1或L后缀表示该整数为long常量,u或U后缀表示 unsigned int常量,ul(可以采用任何一种顺序,大写小写均可)表示 unsigned long常量(由于小写1看上去像1,因此应使用大写L作后缀)。例如,在int为16位、long为32位的系统上,数字22022被存储为int,占16位,数字2022L被存储为long,占32位。同样,22022LU和2202UL都被存储为 unsigned long。 接下来考察长度。在C艹中,对十进制整数采用的规则,与十六进制和八进制稍微有些不同。对于不带后缀的十进制整数,将使用下面几种类型中能够存储该数的最小类型来表示:int、long或 unsigned long。在int为16位、long为32位的计算机系统上,20000表示为int类型,40000被表示为long类型,3000000被表示为 unsigned long类型。对于不带后缀的十六进制或八进制整数,将使用下面几种类型中能够存储该数的最小类型来表示;int、 unsigned int、long或 unsigned long。在将40000表示为long的计算机系统中,六进制数Ox9C40(40000.将被表示为 unsigned int这是因为十六进制常用来表示内存地址,而内存地址是没有符号的,因此unsigned int比long更适合用来表示16位的地址。 char类型：字符和小整数顾名思义，char类型是专为存储类型（如字母和数字）而设计的。编程语言通过字母的数值编码解决了字母的存储问题。因此，char类型是另一种整型（所以可以加1）。它足够长，能够表示目标计算机系统中所有基本符号—所有的字母、数字、标点符号等。实际上，多数系统所支持的字符都不超过256种，因此用一个字节就可以表示所有的符号。因此，虽然char最常被用来处理字符，但也可以将它用做比short更小的整型。在美国，最常用的符号集是ASCII字符集，不过不能很好的满足国际需要，c++支持的宽字符类型可以存储更多的值，如国际Unicode字符集使用的值。 wcha_t const限定符 提示:如果读者在学习C艹之前学习过C语言,并打算使用 # define来定义符号常量,请不要这样做,而应使用 const。 浮点数书写浮点数第一种是标准小数点表示法12.34。第二种表示浮点值的方法叫做E表示法3.45E(e)6 浮点类型C++也有3种浮点类型float、double和long double。这些类型是按它们可以表示的有效位数和允许的指数最小范围来描述的。有效位是数字中有意义的位。事实上,C和C++对于有效位数的要求是,foat至少32位, double至少48位,且不少于float, long double至少和 double样多。这种类型的有效位数可以一样多。不过,通常foat为32位, double为64位,long double为80、96或128位。另外,这3种类型的指数范围至少是-37到37。可以从头文件cfloat或 float. h中找到系统的限制( float是C语言的 float h文件的C++版本)。 浮点数的优缺点与整数相比,浮点数有两大优点。首先,它们可以表示整数之间的值。其次,由于有缩放因子,它们可以表示的范围大得多。另一方面,浮点运算的速度比整数运算慢,至少在没有数学协处理器的计算机上是如此,而且精度将降低。 C++算术操作符操作符优先级和结合性除法分支 求模操作符类型转换C++自动执行很多类型转换： 将一种算术类型的值赋给另一种算术类型的变量时，c++将对值进行转换。 表达式中包含不同的类型时，C++将对值进行转换。 将参数传递给函数时，C++将对值进行转换。赋值时进行的转换 将0赋值给bool变量时，将被转换为false，而非零值将被转换为true。表达式中的转换当同一个表达式中包含两种不同的算术类型时，C++将执行两种自动转换：首先，一些类型在出现时便会自动转换。其次，有些类型在与其他类型同时出现在表达式中将被转换。 还有其他些整型提升: 如果short比int短，则unsigned short 类型将被转换为int;如果两种类型的长度相同，则unsigned short类型将被转换为unsigned int。这种规则确保了在对unsigned short进行提升时不会损失数据。 同样，wchar_t被提升成为下列类型中第一个宽度足够存储wchar_ t 取值范围的类型: int. unsigned int、long或unsigned long. 将不同类型进行算术运算时， 也会进行一些转换，例如将int和float相加时。当运算涉及到两种类型时，较小的类型将破转换为较大的类型。例如，程序清单3.11中的程序用9.0除以5。 由于9.0的类型为double, 因此程序在用5除之前，将5转换为double类型。总之，编译器通过校验表来确定在算术表达式中执行的转换。下面是一一个列表， 编译器将依次查阅该列表:①如果有一个操作数的类型是long double, 则将另一个操作数转换为long double. ANSI C遵循的规则与C++相同，但传统K&amp;R C的规则稍有不同。例如，传统C语言总是将float提升为double,即使两个操作数都是float。 传递参数时转换传递参数时的类型转换通常由C++函数原型控制。不过,也可以取消原型对参 数传递的控制,尽管这样做并不明智。在这种情况下,C++将对char和 short类型( signed和 unsigned)应用整型提升。另外,为保持与传统C语言中大量代码的兼容性,在将参数传递给取消原型对参数传递控制的函数时,C+将float参数提升为 double。 强制类型转换C++还允许通过强制类型转换机制显式地进行类型转换，强制类型转换的格式有两种。 第一种格式来自C语言,第二种格式是纯粹的C++。新格式的想法是,要让强制类型转换就像是函数调用。这样对内置类型的强制类型转换就像是为用户定义的类设计的类型转换。 复合类型数组计算机在内存中依次存储数组的各个元素。数组中的每一个元素可以看做一个简单变量。要创建数组，可使用声明语句，应指出三点。 存储在每个元素中的值的类型 数组名 数组中的元素数 数组的声明 表达式arraySize指定元素数目，它必须是整型常数(如10)或const值，也可以是常量表达式(如8*sizeof (in)),即其中所有的值在编译时都是已知的。具体地说，arraySize 不能是变量，变量的值是在程序运行时设置的。不过，可以使用new操作符来避开这种限制。 数组的初始化规则只有在定义数组时才能使用初始化，此后就不能使用了， 也不能将一 个数组赋给另一个数组: 不过， 可以使用下标分别给数组中的元素赋值。初始化数组时，提供的值可以少于数组的元素数目。如果只对数组的部分进行初始化， 则编译器将把其他元素设置为0。如果初始化数组时方括号内([])为空，C++编译器将计算元素个数。 通常，让编译器计算元素个数是一种很糟的做法，因为其计数可能与您想象的不一样。不过，这种方法对于将字符数组初始化为一个字符串来说比较安全。C++标准模板库（STL）一种数组替代品—模板类vector，它比内置复合类型数组更复杂，也更灵活。 字符串字符串是存储在内存的连续字节中的一系列字符。C++处理字符串有两种方式。一，来自C语言，被称为C-风格字符串，还有一种就是基于string类库的方法。 存储在连续字节中的一-系列字符意味着可以将字符串存储在char数组中，每个字符都位于自己的数组元素中。C风格具有一种特殊的性质，以空字符结尾，空字符被写作\\ 0 ，其ASCII码为0，用来标记字符串的结尾。 这两个数组都是char数组，但只有第二个数组是子符串。空子符对C-风格子付事心后里大里安。例如，C++有很多处理字符串的函数，其中包括cout使用的那些函数。它们都逐个地处理字符串中的字符， 直到到达空字符为止。如果使用cout显示上面的cat这样的字符串，则将显示前4个字符，发现空字符后停止。但是，如果使用cout显示上面的dog数组(它不是字符串)，cout 将打印出数组中的5个字母，并接着将内存中随后的各个字节解释为要打印的字符，直到遇到空字符为止。由于空字符(实际上是被设置为0的字节)在内存中很常见，因此这一过程将很快停止。但尽管如此，还是不应将不是字符串的字符数组当作字符串来处理。 有一种更好地将字符数组初始化为字符串的方法，使用用引号括起来的字符串 用引号括起的字符串隐式地包括结尾的空字符,因此不用显式地包括它。 应确保数组足够大,能够存储字符串中所有字符包括空字符。使用字符串常量初始化字符数组是这样的一种情况,即让编译器计算元素数目更为安全。让数组比字符串长没有什么害处,只是会浪费一些空间而已。这是因为处理字符串的函数根据空字符的位置,而不是数组长度来进行处理。C++对字符串长度没有限制。记住：在确定存储字符串所需的最短数组时，记得将结尾的空字符计算在内。 注意,字符串常量(使用双引号)不能与字符常量(使用单引号)互换。字符常量(如S)是字符串编码的简写表示。在ASCⅡ系统上,S只是83的另一种写法。因此,下面的语句: 是将内存地址赋给变量。 拼接字符串常量任何两个由空白（空格、制表符和换行符）分隔的字符串常量都将自动拼接成一个。 拼接时不会在被连接的字符串之间添加空格，第二个字符串的第一个字符将紧跟在第一个字符串的最后一个字符（不考虑\\ 0 )后面。第一个字符串的\\ 0 字符将会被第二个字符串的第一个字符取代。 在数组中使用字符串要将字符串存储到数组中，最常用的方法有两种，一是将数组初始化为字符串常量、二将键盘或文件输入读入数组中。 字符串输入cin 每次读取一行字符串输入面向行的输入：getline()getline()函数读取整行,它使用通过回车键输入的换行符来确定输入结尾。要调用这种方法,可以使用 cin. getline()。该函数有两个参数。第一个参数是用来存储输入行的数组的名称,第二个参数是要读取的字符数。 面向行的输入：get()混合输入字符串和数字混合输入数字和面向行的字符串会导致问题。 string类简介string类使用起来比数组简单，同时提供了将字符串作为一种数据类型的表示方法。 要使用string类，必须在程序中包含头文件string。string类位于名称空间std中，需要提供一条using编译指令，或者使用std::string来引用它。string类定义隐藏了字符串的数组性质，可以像处理普通变量那样处理字符串。 赋值、拼接和附加使用 string类时,某些操作比使用数组时更简单。例如,不能将一个数组赋给另一个数组,但可以将个 string对象赋给另一个string对象。string类简化的字符串合并操作。可以使用操作符+将两个string对象合并起来,还可以使用操作符+ =一个字符串附加到个 string对象的末尾。 string类的其他操作在C艹新增 string类之前,程序员也需要完成诸如给字符串赋值等工作。对于C语言式的字符串,程序员使用C语言库中的函数来完成这些任务。头文件cstring(以前为 string. h)提供了这些函数。例如,可以使用函数 strcpy()将字符串复制到字符数组中,使用函数 strcat()将字符串附加到字符数组末尾: string类I/O正如读者知道的,可以使用cin和操作符&lt;&lt;来将输入存储到 string对象中,使用cout和操作符&gt;&gt;来显示 string对象,其句法与处理C-风格字符串相同。但每次读取一行而不是一个单词时,使用的句法不同。 结构简介 C++运行在声明结构变量时省略关键字struct。可以使用成员操作符（.）来访问各个成员。访问类成员函数的方式也是类似的。 在程序中使用结构结构声明的位置很重要。可以将声明放在main()函数中，紧跟在开始括号的后面，另一种选择是将声明放在main()的前面。 C++不提倡使用外部变量但提倡使用外部结构声明。初始化结构： 当然也可以把它们放在同一行中。 结构可以将string类作为成员吗大体上说，答案是肯定的。 其他结构属性C++使用户定义的类型与内置类型尽可能相似。例如， 可以将结构作为参数传递给函数, 也可以让函数返同—个结构。另外，还可以使用赋值操作符(=) 将结构賦给另一个同类型的结构， 这样结构中每个成员都将被设置为另一个结构中相应成员的值，即使成员是数组。这种赋值被称为成员赋值。 结构数组 结构中的位字段与C语言一样，C++也允许指定占用特定位数的结构成员，这使得创建与某个硬件设备上的寄存器对应的数据结构非常方便。字段的类型应为整型或枚举(稍后将介绍),接下来是冒号，冒号后面是一一个数字，它指定了使用的位数。可以使用没有名称的字段来提供间距。每个成员都被称为位字段(bit field)。下面是一个例子: 位字段通常用在低级编程中。 共用体共用体（union）是一种数据格式，能够存储不同的数据类型，但只能同时存储其中的一种类型。也就是说，结构可以同时存储int、long和double,共用体只能存储int、long或double。共用体的句法与结构相似，但含义不同。声明： 可以使用one4all变量来存储int、long或double，条件是在不同的时间进行： 因此，pail 有时可以是int变量，而有时义可以是double变量。成员名称标识了变量的容量。由于共用体每次只能存储一个值，因此它必须有足够的空间来存储最大的成员，所以，共用体的长度为其最大成员的长度。在存储了double后int值就丢失了。 由于共用体是匿名的，因此id_ num和id_ char被视为prize 的两个成员，它们的地址相同，所以不需要中间标识符id_ val。程序员负责确定当前哪个成员是活动的。 枚举C++的enum工具提供了另一种创建符号常量的方式，这种方式可以代替const。使用enum的句法与使用结构相似。 这条语句完成两项工作：第一让spectrum称为新类型的名称，spectrum被称为枚举，就像struct变量被称为结构一样。第二将red,orange,yellow等作为符号常量，它们对应整数值0-7.这些常量叫做枚举量。可以用枚举名来声明这种类型的变量： 在不进行强制类型转换的情况下，只能将定义枚举时使用的枚举量赋给这种枚举的变量。 对于枚举，只定义了赋值操作符，具体说就是没有为枚举定义算术运算： 对于最后一个式子 枚举时整型，可被提升为Int类型，但int类型不能自动转换为枚举类型： 枚举的规则相当严格，实际上，枚举更常被用来定义相关的符号常量，而不是新类型。如果打算只使用常量而不创建枚举类型的变量，则可以省略枚举类型的名称。 设置枚举量的值可以使用赋值操作符来显示地设置枚举量的值。 指定的值必须是整数。 也可以只显式地定义其中一些枚举量的值: 这里，first在默认情况下为0，后面没有被初始化的枚举量的值将比其前面的枚举量大1，因此，third的值为101。还可以创建多个值相同的枚举量： 在早期版本中，只能将int值（或提升为int的值）赋给枚举量，现在这种限制已经取消了，因此可以使用long类型的值。 枚举的取值范围最初，对于枚举来说，只有声明中指出的那些值是有效的。不过，C++现在通过强制类型转换，增加了可赋给枚举变量的合法值。每个枚举都有取值范围(range)， 通过强制类型转换， 可以将取值范围中的任何整数值赋给枚举变量， 即使这个值不是枚举值。 则如下代码将是合法的： 其中6不是枚举值，但它位于枚举定义的取值范围中。取值范围的定义如下。首先， 要找出上限，需要知道枚举量的最大值。找到大于这个最大值的、最小的2的幂，将它减去1, 得到的便是取值范围的上限。例如， 前面定义的bigstep的最大值枚举值是101。在2的幂中，比这个数大的最小值为128，因此取值范围的上限为127。要计算下限，需要知道枚举量的最小值。如果它不小于0,则取值范围的下限为0;否则，采用与寻找上限方式相同的方式， 但加上负号。例如， 如果最小的枚举量为-6， 而比它小的、最大的2的幂是-8 (加上负号)，因此下限为-7。 选择用多少空间来存储枚举由编译器决定。对于取值范围较小的枚举,使用一个字节或更少的空间而对于包含long类型值的枚举,则使用4个字节。 指针和自由存储空间指针是一个变量，其存储的是值的地址而不是值本身，对变量应用地址操作符（&amp;）就可以获得它的位置，如home是一个变量，则&amp;home是它的地址。 面向对象编程与传统过程性编程的区别在于，OOP强调的是在运行阶段（而不是编译阶段）进行决策。即使用new和指定固定长度的数组的区别。 声明和初始化指针计算机需要跟踪指针指向的值的类型。例如，char 的地址与double的地址看上去没什么两样，但char和double使用的字节数是不同的，它们存储值时使用的内部格式也不同。因此，指针声明必须指定指针指向的数据的类型。但是地址的格式是相同的。 需要强调的是，int * 是一种类型，是指向int的指针。在哪里添加空格对于编译器是没有任何区别的。以下声明： 将创建一个指针p1和一个常规int变量p2。对每个指针变量名，都需要使用一个 * 。 指针的危险在C++中创建指针时，计算机将分配用来存储地址的内存，但不会分配用来存储指针所指向的数据的内存。 警告：一定要在对指针应用解除引用操作符（ * ）之前，将指针初始化为一个确定的、适当的地址。 指针和数字指针不是整型，虽然计算机通常把地址当做整数来处理。在C99标准发布前，C语言允许直接对指针赋值整数，但C++在类型一致性上要求更严格，编译器将显示一条错误信息，要将数字值作为地址来使用，应通过强制类型转换将数字转换为适当的地址类型： 注意，pt是int值的地址，并不意味着pt本身的类型是int。 使用new来分配内存指针的真正的用武之地在于，在运行阶段分配未命名的内存以存储值。在这种情况下，只能通过指针来访问内存。在C语言中，可以用库函数malloc()来分配内存；在C++中仍然可以这样做，但C++还有更好的方法—使用new操作符。 在运行阶段为一个int值分配未命名的内存，并使用指针来访问这个值。这里的关键所在是C++的new操作符。程序员要告诉new,需要为哪种数据类型分配内存; new将找到一个长度正确的内存块，并返回该内存块的地址。程序员的责任是将该地址赋给一个指针。 在之前是通过如下方式指定指针的地址的。 两种情况都是将一个int变量的地址赋给了指针。第二种情况下还可以通过名称来访问该int，第一种情况下，则只能通过该指针进行访问。pn指向的内存没有名称，该怎么称呼呢？我们称pn指向一个数据对象。这里的对象不是面向对象中的那个对象，术语数据对象比变量更通用，指为数据项分配的内存块，因此，变量也是数据对象，但pn指向的内存不是变量。乍一看，处理数据对象的指针方法可能不太好用，但它使程序在管理内存方面有更大的控制权。 为一个数据对象(可以是结构，也可以是基本类型)获得并指定分配内存的通用格式如下: 需要在两个地方指定数据类型:用来指定需要什么样的内存和用来声明合适的指针。由于内存地址形式一样，所以得通过指针的类型知道需要读几个内存单元的值。 内存被耗尽计算机可能会由于没有足够的内存而无法满足new的请求。此时，new将返回0。在C++中，值为0的指针被称为空值指针（null pointer）。C++确保空值指针不会指向有效的数据，因此它常被用来表示操作符或函数失效，如果成功，它们将返回一个有用的指针。可以通过if语句来检查new是否返回的是空值指针，从而防止程序超界。如果无法分配内存，new除返回空值指针外，还可能引发bad_alloc异常。 使用delete来释放内存当需要内存时，可以使用new来请求，这只是C++内存管理数据包中有魅力的一个方面。另一个方面是delete操作符，它使得在使用完内存后， 能够将其归还给内存池，这是通向最有效地使用内存的关键一步。归还或释放(free)的内存可供程序的其他部分使用。使用delete时，后面要加.比指向内存块的指针(这些内存块最初是用new分配的): 这将释放ps指向的内存，但不会删除指针ps本身。例如，可以将ps重新指向另一个新分配的内存块。一定要配对地使用new和delete: 否则将发生内存泄漏(memory leak), 也就是说，被分配的内存再也无法使用了。如果内存泄漏严重，则程序将由于不断寻找更多内存而终止。 不要尝试释放已经释放的内存，这样做的结果是不确定的，不能使用delete来释放声明变量获得的内存。 只能用delete来释放使用new分配的内存，不过对空指针使用delete是安全的。 使用delete的关键在于，将它用于new分配的内存。这并不意味着要使用用于new的指针，而是用于new的地址: 一般来说， 不要创建两个指向同一个内存块的指针，因为这将增加错误地删除同一个内存块两次的可能性。 使用new来创建动态数组如果通过声明来创建数组,则在程序被编译时将为它分配内存空间。不管程序最终是否使用数组,数组都在那里,它占用了内存。在编译时给数组分配内存被称为静态联编( static binding),意味着数组是在编译时加入到程序中的。但使用new时,如果在运行阶段需要数组,则创建它:如果不需要, 则不创建。还可以在程序运行时选择数组的长度。这被称为动态联编(dynamic binding),意味着数组是在程序运行时创建的。这种数组叫作动态数组(dynamic array)使用静态联编时,必须在编写程序时指定数组的长度;使用动态联编时,程序将在运行时确定数组的长度。 使用new创建动态数组在C++中,创建动态数组很容易;只要将数组的元素类型和元素数目告诉new即可。必须在类型名后加上方括号,其中包含元素数目。 new操作符返回第一个元素的地址，当程序结束使用内存块后，应使用delete释放它们。 使用new创建数组时，应使用另一种格式的delete,它能指出所要释放的是一个数组。 方括号告诉程序，应释放整个数组，而不仅仅是指针指向的元素。请注意delete和指针之间的方括号。如果使用new时，不带方括号，则使用delete时，也不应带方括号。如果使用new时带方括号，则使用delete时也应带方括号。 总之, 使用new和delete时，应遵守以下规则: 不要使用delete来释放不是new分配的内存。 不要使用delete释放同一个内存块两次。 如果使用new[ ]为数组分配内存，则应使用delete[ ]来释放。 如果使用new[ ]为一个实体分配内存，则应使用delete (没有方括号)来释放。 对空值指针应用delete是安全的。 由于动态数组返回的是指向第一个元素的指针，所以程序员需要跟踪内存块中的元素个数，实际上程序跟踪了分配的内存量以便在使用delete[]操作符时能正确地释放这些内存。但是这些信息是不公用的，如，不能使用sizeof操作符来确定动态分配的数组包含的字节数。 为数组分配内存的通用格式： 使用new操作符可以确保内存块足以存储num_elements 个类型为type_ name的元素，而pointer_ name将指向第1个元素。12对于new与delete的问题一般来说在程序结束后操作系统会收回分配的所有资源，不delete也不会造成影响。但是如果程序常驻内存只new不delete就会很快耗尽内存，造成内存泄露，所以要养成new delete的习惯。 使用动态数组将指针当做数组名使用即可，对于第一个元素，即为p[0]。数组名和指针的根本区别在于，不能修改数组名的值，但指针是变量，因此可以修改它的值。相邻的int地址通常相差2个字节或4个字节，而将p3加1后，它将指向下一个元素的地址，这表明指针算术有:些特别的地方。情况确实如此。 指针、数组和指针算术指针和数组基本等价的原因在于指针算术( pointer arithmetic和C++内部处理数组的方式。算术。将整数变量加1后,其值将增加1;但将指针变量加1后,增加的量等于它指向的类型的字节数。将指向double的指针加1后,如果系统对double使用8个字节存储,则数值将增加8;将指向short的指针加1后,如果系统对 short使用2个字节存储,则指针值（存储的地址值）将增加2。C++将数组名解释为地址。 如数组表达式stack[1]，C++编译器将该表达式看作是*(stacks+1)，这意味着先计算数组第2个元素的地址，然后找到存储在那里的值。区别之一在于可以修改指针的值，而数组名是常量。 另一个区别是，对数组应用sizeof操作符得到的数组的长度，而对指针应用sizeof得到的是指针的长度，即使指针指向的是一个数组。 指针算术：C++允许将指针和整数相加。加1的结果等于原来的地址值加上指向的对象占用的总字节数。还可以将一个指针减去另一个指针，获得两个指针的差。后一种运算将得到一个整数，仅当两个指针指向同一个数组(也可以指向超出结尾的一个位置)时，这种运算才有意义;这将得到两个元素的间隔。 指针和字符串cout提供一个字符的地址，则它将从该字符开始打印，直到遇到空字符为止。在C++中，用引号括起来的字符串像数组名一样，也是第一个元素的地址。 在cout和多数C++表达式中, char数组名、指向char的指针以及用引号括起的宇符串常量都被解释为字符串第一个字符的地址。 使用new创建动态结构将new用于结构由两步组成:创建结构和访问其成员。要创建结构，需要同时使用结构类型和new。 这将把足以存储infatable结构的 块可用内存的地址赋给ps。 这种句法和C++的内置类型完全相同。 箭头成员操作符（-&gt;），可用于指向结构的指针，就像点操作符可用于结构名一样。如ps指向一个inflatable结构，则ps-&gt;price是被指向的结构的price成员。如果结构标识符是结构名，则使用句点操作符;如果标识符是指向结构的指针，则使用箭头操作符。 另一种访问结构成员的方法是，如果ps是指向结构的指针，则 * ps 就是被指向的值一结构本身。 由于 * ps是一个结构，因此( * ps) .price 是该结构的price 成员。C++的操作符优先规则要求使用括号。 自动存储、静态存储和动态存储根据用于分配内存的方法，C++有3种管理数据内存的方式: 自助存储、静态存储和动态存储(有时也叫作自由存储空间或堆)。 自动存储在函数内部定义的常规变量使用自助存储空间，被称为自动变量(automatic variable),这意味着它们在所属的函数被调用时自动产生，在该函数结束时消亡。 实际上，自动变量是一个局部变量，其作用域为包它的代码块。代码块是被包含在花括号中的一段代码。 静态存储静态存储是整个程序执行期间都存在的存储方式。使变量成为静态的方式有两种:一种是在函数外面定义它:另一种是在声明变量时使用关键字static。 自动存储和静态存储的关键在于:这些方法严格地限制了变量的寿命。变量可能存在于程序的整个生命周期(静态变量)，也可能只是在特定函数被执行时存在(自动变量)。 动态存储new和delete操作符提供了一种比自动变量和静态变量更灵活的方法。它们管理了一个内存池，这在C++中被称为自由存储空间(free store)。内存池同用于静态变量和自动变量的内存是分开的。new和delete允许在一个函数中分配内存，而在另一个函数中释放它。因此，数据的生命周期就不完全受到程序或函数的生存时间的控制了。与使用常规变量相比， 使用new和delete使程序员对程序如何使用内存有更大的控制权。 堆栈、堆和内存泄露如果使用new在自由空间（或堆）上创建变量后，没有调用delete，即使指针由于作用域规则和对象声明周期的原因而被释放，在自由存储空间上动态分配的变量或结构也将继续存在。实际上，将会无法访问自由存储空间中的结构，因为指向这些内存的指针无效。这将导致内存泄露。被泄露的内存将在程序的整个生命周期都不可使用。 循环和关系表达式for循环 循环只执行一次初始化。 测试表达式结果为真，则程序将执行循环体，为假循环结束。C++并没有将test expression的值限制为只能为真或假。可以使用任意表达式，C++将把结果强制转换为bool类型。因此， 值为0的表达式将被转换为bool值false,导致循环结束。 如果表达式的值为非零，则被强制转换为bool值true。 表达式与语句在C++中，每个表达式都有值。通常值是很明显的，如22+27但x=20这个表达式由两个值和一个赋值操作符组成。C++将赋值表达式的值定义为左侧成员的值。因此maids=（x=20）+2可得maids为22。对于x=y=z=0，赋值操作符是从右向左结合的，因此首先将0赋给z，然后将z=0赋给y，以此类推。 从表达式到语句的转变是很小的一步，只要加一个分号就可以完成。 递增操作符（++）和递减操作符（—）a++意味着使用a的当前值计算表达式，然后将a的值加1;而++b的意思是先将b的值加1, 然后使用新的值来计算表达式。 组合赋值操作符 关系表达式 可能犯的错误==与= while循环 for与while在C++中， for和while循环本质上是相同的。可以相互改写。 类型别名C++为类型建立别名的方式有两种。一种是使用预处理器 这样，预处理器将在编译程序时用char替换所有的BYTE,从而使BYTE成为char的别名。第二种方法是使用C++(和C)的关键字typedef来创建别名。 如 也可以使用#define，不过声明一系列变量时，这种方法不适用。 typedef方法不会有这样的问题。它能够处理更复杂的类型别名，这使得与使用#define相比，使用typedef时一种更佳的选择，有时也是唯一的选择。 注意, typedef不会创建新类型,而只是为已有的类型建立一个新名称。 do while循环 嵌套循环和二维数组声明数组： 初始化二维数组 对于二维数组，由于每个元素本身就是一个数组，因此可以使用与上述代码类似的格式来初始化每一个元素。 }； 分支语句和逻辑操作符if语句 if else语句 格式化if else语句如果需要多条语句，需要用花括号将它们括起来，组成一个块语句。和有些语言不同的是，由于C++不会自动将if和else之间的所有代码视为一个代码块，因此必须使用花括号将这些语句组合成一个语句块。 if else if else结构 逻辑表达式逻辑OR操作符：| |逻辑AND操作符：&amp;&amp;逻辑NOT操作符：！逻辑操作符细节OR和AND操作符的优先级都低于关系操作符。这意味着 另一方面！操作符的优先级高于所有的关系操作符和算术操作符。因此，要对表达式求反，必须用括号将其括起来。 逻辑AND操作符的优先级高于逻辑OR操作符。 其他表示方式 字符函数库cctypeC++从C语言继承了一个与字符相关的、非常方便的函数软件包，它可以简化诸如确定字符是否为大写字母、数字、标点符号等工作，这些函数的原型是在头文件cctype（老式风格为ctype.h）中定义的。 ？：操作符C++有一个常被用来代替if else语句的操作符，这个操作符被称为条件操作符（?:），它是C++中唯一一个需要3个操作数的操作符。该操作符通用格式如下： 如果expressionl 为true, 则整个条件表达式的值为expression2 的值; 否则，整个表达式的值为expression3的值。 switch语句 注意使用break。 将枚举量作为标签switch和if elseswitch并不是为处理取值范围而设计的。switch语句中的每一个case标签都必须是一个单独的值。另外这个值必须是整数（包括char），因此switch无法处理浮点测试。如果既可以使用if else语句，也可以使用switch语句，则当选项不少于3个时，应使用switch语句。 break和continue语句简单文件输入/输出文本输入 必须包含头文件iostream 头文件iostream定义了个用处理输入的istream类。 头文件iostream声明了一个名为cin的istream变量(对象)。 必须指明名称空间std;例如,为引用元素cin,必须使用编译指令 using或前缀std::。 可以结合使用cin和操作符&lt;&lt;来读取各种类型的数据。 可以使用cin和get（）方法来读取一个字符,使用cin和 getline（）来读取一行字符。 可以结合使用cin和eof()、fail()方法来判断输入是否成功。 对象cin本身被用作测试条件时，如果最后一个读取操作成功，它将被转换为布尔值true，否则被转换为false。 文件输出 必须包含头文件fstream 头文件 fstream定义了一个用于处理输入的 ifstream类。 需要声明一个或多个 ifstream变量(对象),并以自己喜欢的方式对其进行命名,条件是遵守常用的命名规则。 必须指明名称空间std:例如，为引用元素ifstream, 必须使用编译指令using 或前缀std:.。 需要将ifstream对象与文件关联起来。为此， 方法之一是使用open()方法。 使用完文件后，应使用close()方法将其关闭。 可结合使用ifstream对象和操作符&lt;&lt;来读取各种类型的数据。 可以使用ifstream 对象和get() 方法来读取一个字符， 使用ifstream对象和getine()来读取一行字符。 可以结合使用ifstream 和eof()、 fail()等方法来判断输入是否成功。 ifstream对象本身被用作测试条件时，如果最后一个读取操作成功，它将被转换为布尔值true,否则被转换为false。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://github.com/zdkswd/tags/C/"}]},{"title":"具体数学 Interger Functions","slug":"具体数学 Interger Functions","date":"2018-12-07T09:15:32.000Z","updated":"2018-12-07T09:18:27.000Z","comments":true,"path":"2018/12/07/具体数学 Interger Functions/","link":"","permalink":"https://github.com/zdkswd/2018/12/07/具体数学 Interger Functions/","excerpt":"","text":"取整基础符号定义向下取整函数⌊x⌋定义为小于等于x的最大整数。向上取整函数⌈x⌉定义为大于等于x的最小整数。{x}定义为实数x的小数部分，即 性质性质1 表示x是整数则取0，x不是整数则取1。 性质2取整函数范围： 性质3负数的取整： 性质4取整函数中的整数可以提取出来： 应用应用1证明： 更一般的，我们还可以证明，对于任意连续、递增的函数f(x)，如果它满足 那么有 我们证明第2个式子，第1个同理可证。如果x=⌈x⌉，显然成立。否则x&lt;⌈x⌉，因为f(x)递增，所以有 两边同时取整，有 若是想要证左右两边相等，只需要证 不成立即可。假设上式成立，那么由中间值定理，一定存在x≤y&lt;⌈x⌉，使得 由上图可以看出，当下面式子成立时，满足中间值定理 但是，我们假设是 那么由⌈f(x)⌉&lt;⌈f(⌈x⌉)⌉能否推出⌈f(x)⌉&lt;f(⌈x⌉)呢？当然是可以的。 所以 （怎么得到的。。）又因为x≤y&lt;⌈x⌉，所以不存在整数y，矛盾！所以证得 另一个特殊的例子是 其中m和n都是整数，并且n是正整数。 应用2求1到1000中使得下列式子成立的n一共有多少个？ 求解方法如下： 继续推广，求1到N中使得上面式子成立的n有多少个，令 也就是小于等于的最大整数。所以 渐进地等于 应用3定义一个实数的谱为： 很容易证明如果两个实数α≠β，那么 假设α&lt;β，那么令 所以 所以集合Spec(β)中小于⌊mα⌋的元素个数小于m。而集合Spec(α)中小于⌊mα⌋的元素个数大于等于m。所以两个集合不相等。 谱有很多奇妙的性质，例如下面两个谱： 可以发现，这两个谱正好划分了正整数集。证明方法也很简单，只要证明对任意正整数n，两个集合中小于n的元素个数之和为n，过程如下： 所以第一个集合中小于n的元素个数为 同理第二个集合中小于n的元素个数为 所以总个数为 得证。 取整进阶约瑟夫环新解这里我们继续推广到一般情况，如果有n个人，每隔q个人踢掉一个人，最后剩下的是几号？初始编号为1…n，现在考虑一种新的编号方式。第一个人不会被踢掉，编号加1，变成n+1，然后第二个人编号变为n+2，直到第q个人，他被踢掉了。然后第q+1个人编号继续加1，变成了n+q，依次下去。考虑当前踢到的人编号为kq，那么此时已经踢掉了k个人，所以接下去的人新的编号为n+k(q−1)+1…。所以编号为kq+d的人编号变成了n+k(q−1)+d，其中1≤d&lt;q。直到最后，可以发现活下来的人编号为qn，问题是怎么根据这个编号推出他原来的编号？以n=10，q=3为例，下图就是每个人新的编号： 令N=n+k(q−1)+d所以他上一次的编号是kq+d=kq+N−n−k(q−1)=k+N−n因为 所以上一次编号可以写为 如果我们用D=qn+1−N替代N，将会进一步简化算法： 模的性质定义与性质模定义如下： 特别的 与此类似，定义一个与模类似的运算： 模有一些性质： 应用考虑如下问题，怎么平均分配n个东西给m个人？很容易想到，首先分给每个人⌊n/m⌋个东西，剩下n mod m件东西分给前n mod m个人，一人多一件就行。概括起来就是，前n mod m个人，每人⌈ n / m⌉件，剩下的人，每人⌊n / m⌋件。统一表示呢？有的，每个人分到的件数为 为什么呢？假设 那么 当1≤k≤r时， 当r&lt;k≤m时， 得证，因此可以得到如下等式： 由n=⌊n / 2⌋+⌈n / 2⌉可以进一步将其转换为下取整形式： 令n=⌊mx⌋我们得到了一个令人惊奇的等式： 习题题3题目：求⌊nx⌋=n⌊x⌋的充要条件。解答：因为x=⌊x⌋+{x}，所以 要使得⌊nx⌋=n⌊x⌋，就必须有⌊n{x}⌋=0，所以n{x}&lt;1即 题7题目：求下列递推式 解答：因为 所以 题8题目：n个物品放到m个盒子中，求证至少有一个盒子物品数大于等于⌈n / m⌉，至少有一个盒子物品数小于等于⌊n / m⌋。解答：假设所有的盒子物品数都小于⌈n / m⌉，那么总物品数S满足 令n=qm+r,0≤r&lt;m，那么有 如果r=0，那么有 如果r&gt;0，那么有 这与S=n矛盾！所以至少有一个盒子物品数大于等于⌈n / m⌉。假设所有的盒子物品数都大于⌊n / m⌋，那么总物品数S满足 令n=qm+r,0≤r&lt;m，那么有 这与S=n矛盾！所以至少有一个盒子物品数小于等于⌊n / m⌋。 取整进阶例题1求和： 方法一首先令m=⌊√k⌋那么有 我们先算左半部分，先假设n=a的2次方，那么有 而对于一般的n，令a=⌊√n⌋，我们只需要计算a的2次方≤k&lt;n的部分，而这部分√k=a，所以结果为 所以总的结果为： 为什么没有算右半部分？因为右半部分就是a2≤k&lt;n的这部分，已经计算过了。 方法2 定理1 这个公式说明了，无理数α的整数倍的小数部分均匀分布在(0,1)之间。这就给了我们一个启示，我们可以用它来生成随机数啊！其他用处还有很多。 例题2求如下和式： 其中整数m&gt;0，n也是整数。通过枚举m=1,2,3,…，可以发现和式满足如下形式： 如何进行计算：首先做一个变形： 这就将原来的和式分为了三个部分求和。第一个部分为： 这里通过枚举可以发现它的值是有周期的，周期重复次数是d=gcd(m,n)。所以算出来结果为： 第二个部分为： 第三个部分为： 所以总的结果为： 对结果稍稍变形，可以得到另一个结果： 可以发现，m和n是对称的！所以可以得到如下结论： 这有什么用呢？当m特别大、n很小的时候可以大大减少项的个数！如果我们令n=1，就会发现，得到的式子和之前证过的一个式子一模一样！","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"}]},{"title":"具体数学 第二章","slug":"具体数学 第二章","date":"2018-12-06T05:24:32.000Z","updated":"2018-12-06T05:27:59.000Z","comments":true,"path":"2018/12/06/具体数学 第二章/","link":"","permalink":"https://github.com/zdkswd/2018/12/06/具体数学 第二章/","excerpt":"","text":"求递推式本身的表达式将递归式转化为求和再求出递推式本身的表达式。考虑如下递归式： 两边同时乘以sn得到： 观察Tn项和Tn-1项之前的系数，要想转化为可以求和的递归式，必须有： 即 此时令 得到： 此时再求和可得： 所以 例题1设n个数快速排序的操作次数为Cn，那么有 用n-1取代n可以得到 两式相减可以得到 观察形式，由上面方法可以得到 所以得 进而带入公式。可以求得 其中调和级数为： 所以最后结果为 求和三大定律结合律、分配率、交换律。 例题2求 这里使用求和定律来做用n-k取代k,得到 即 两式相加得 所以 例题3求 这里用到另一种求和的方法。两边同时加上第n+1项，得到 所以 还可以这样求解： 求导得到： 所以 同样可以得到 多重求和多重求和，也就是一个和式由多个下标来指定。 例题1一个对称矩阵 求： 这是这个矩阵的上三角加对角线求和，因为是对称的嘛，可以补全下三角，加上对角线就行了。 所以 例题2有如下式子， 调换j,k位置，得到： 所以 至此解完，可以推出一个著名不等式—-切比雪夫不等式： 例题3 使用三种方法解这个式子： 调和级数调和级数： 方法一首先将j和k分开，首先计算对j求和： 方法二先计算对k求和： 方法三按对角线求和： 由此得到了一个完全不同的表示形式，所以得到了： 几种求和方法针对以下求和式，使用八种方法来求解： 它的答案为： 扰动法令 所以 解出 最终得到 可以看出，我们本来是要对k的二次方求和的，但是只要对k的三次方用扰动法求和即可，因为求和过程中k的三次方项会被抵消掉。 扩展成二重指标求和 用有限微分求和微分的形式为 如果定义 则有 似乎不能和导数形式统一起来，用起来也不方便，定义一个新的函数，叫下降阶乘幂： 这个函数有一个很好的性质，那就是 令 和积分类似，有 所以 因为有 所以有 同样可以得到 下降阶乘幂性质一 性质二给出下降阶乘幂为负数的定义： 性质三 性质四定义下降阶乘幂的好处就是为了求差分方便，下降阶乘幂的差分为： 类比不定积分，不定和为： 但是这里m≠−1，若是m=−1，直接运用差分定义可以求出： 所以 性质五什么函数的差分是自身。 进一步推广可得： 所以得到一种新的等比数列计算方法： 性质六结合律和分配率在差分运算中也适用。 性质七类似分部积分，这里也可以分部来求差分。 给出一个新的记号移位运算： 所以得到了差分的分部运算法则： 对两边求和，又可以得到不定求和的分布运算法则： 例一计算 首先计算 这里可以令 所以 求和式就可以转化为不定求和来算了： 例二计算 首先计算 这里注意要令 不能倒过来，因为Hx的不定和很难求出来。所以 所以 无限求和之前求和式。 两边同时乘2，得： 解得： 但是同样的方式计算式子： 两边同时乘2，得： 解出： 显然是不可能的，因为这里T是发散的，所以不能这么求。 比如 再如： 求有正有负的和式。可以考虑用不同的配对，将正负组合在一起，从而相消求和。 我们可以将正数和负数分开求和，因为正数求和已经解决了。定义： 其中 求和式对两部分分别求和： 最后可以推广到二重求和。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"}]},{"title":"具体数学 第一章","slug":"具体数学 第一章","date":"2018-12-04T04:33:32.000Z","updated":"2018-12-04T04:37:58.000Z","comments":true,"path":"2018/12/04/具体数学 第一章/","link":"","permalink":"https://github.com/zdkswd/2018/12/04/具体数学 第一章/","excerpt":"","text":"汉诺塔问题3个柱子的汉诺塔问题，最少移动次数记为T(n)。T(n)=2T(n−1)+1边界条件为T(0)=0。解出 其中等比数列求和公式为： 递归 移动的时候的原则就如下表示：第一阶段：（n-1）A—&gt;B（把所有的n-1个盘子从A移动到B上）第二阶段：n A—&gt;C（把最底下的n号盘从A移动到C上）第三阶段：（n-1）B—&gt;C（把n-1个盘子从B移动到C上） 直线分割平面问题n条直线最多分割平面为几部分，记为L(n)。所以。 边界条件为L(0)=1。得。 这题有个扩展，n个V型最多分割平面为几部分？ 将V型补全（红色虚线部分），那么就转化为了2n条直线划分平面数，那么n个V型划分数只要减去2n就行了，所以答案为： 约瑟夫环问题约瑟夫问题是个有名的问题：N个人围成一圈，从第一个开始报数，第M个将被杀掉，最后剩下一个，其余人都将被杀掉。例如N=6，M=5，被杀掉的顺序是：5，4，6，2，3，1。书中的例子是每隔一个人杀死一个。J（n）是最后一个幸存者的位置。 分两种情况讨论：当有2n个人时，踢掉n个人之后，情况如下图所示 观察发现一圈当中的对应位置相同，且左图的数字为右图数字*2-1。所以最后幸存者的位置也有着相同的关系。 同理，当有2n+1个人时，踢掉n+1个人之后 观察对应关系可以得出 边界条件为，J(1)=1。这个递推式很难求解，但是枚举出前面几项可以发现，如果令n=2的m次方+l，其中2的m次方是小于等于n的最大2的幂，那么 将n写成二进制可以发现，f(n)就是n的二进制循环左移1位。如n=10，即1010，f(10)=0101=5。现在将其推广到一般形式，原始的式子中α=1，β=-1，r=1。 由此可见可以设 令 通过观察得出： 将递推式继续推广： 可以得到解为： 具体为： 递推式求和使用成套方法。成套方法的一般步骤是：寻求一组已知其解的通用参数，然后将特殊情况组合起来得到一般的情形，有多少个独立的参数就需要多少个独立的特解。求解如下递推式： 用成套方法求解，设 对于更复杂得递推式： 同样设","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"}]},{"title":"SVM","slug":"SVM","date":"2018-11-28T12:48:47.000Z","updated":"2018-12-02T11:49:41.000Z","comments":true,"path":"2018/11/28/SVM/","link":"","permalink":"https://github.com/zdkswd/2018/11/28/SVM/","excerpt":"","text":"已修改 统计学习方法 支持向量机支持向量机（support vector machines,SVM）是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；支持向量机还包括核技巧，这使它成为实质上的非线性分类器。支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划（convex quadratic programming）的问题，也等价于正则化的合页损失函数的最小化问题。支持向量机的学习算法是求解凸二次规划的最优化算法。 支持向量机学习方法包括构建由简至繁的模型：线性可分支持向量机（linear support vector machine in linearly separable case），线性支持向量机（linear support vector machine）及非线性支持向量机（non-linear support vector machine）。简单的模型是复杂模型的基础，也是复杂模型的特殊情况。当训练数据线性可分时，通过硬间隔最大化（hard margin maximization），学习一个线性的分类器，即线性可分支持向量机，又称为硬间隔支持向量机；当训练数据近似线性可分时，通过软间隔最大化（soft margin maximization），也学习一个线性的分类器，即线性支持向量机，又称为软间隔支持向量机；当训练数据线性不可分时，通过使用核技巧（kernel trick）及软间隔最大化，学习非线性支持向量机。 当输入空间为欧式空间或离散集合、特征空间为希尔贝特空间时，核函数（kernel function）表示将输入从输入空间映射到特征空间得到的特征向量之间的内积。通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。这样的方法称为核技巧。核方法（kernel method）是比支持向量机更为一般的机器学习方法。 线性可分支持向量机与硬间隔最大化线性可分支持向量机考虑一个二类分类问题。假设输入空间与特征空间为两个不同的空间。输入空间为欧式空间或离散集合，特征空间为欧式空间或希尔伯特空间，线性可分支持向量机、线性支持向量机假设这两个空间的元素一一对应，并将输入空间的输入映射为特征空间中的特征向量。非线性支持向量机利用一个从输入空间到特征空间的非线性映射将输入映射为特征向量。支持向量机的学习是在特征空间进行的。 定义（线性可分支持向量机）给定线性可分训练数据集，通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为 函数间隔和几何间隔 函数间隔不是距离，注意上句话中所说的“能够相对地表示”。 定义（函数间隔）对于给定的训练数据集T和超平面（w,b），定义超平 函数间隔可以表示分类预测的正确性及确信度。但是选择分离超平面时，只有函数间隔还不够。因为只要成比例改变w和b，如改为2w和2b，超平面并没有改变，但函数间隔却成为原来的2倍，所以应该对分离超平面的法向量w加以约束，如规范化||w||=1,使得间隔是确定的。这时函数间隔成为几何间隔。 定义（几何间隔）对于给定的训练数据集T和超平面（w,b）,定义超平 间隔最大化支持向量机学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面.对线性可分的训练数据集而言,线性可分分离超平面有无穷多个(等价于感知机),但是几何间隔最大的分离超平面是唯一的.这里的间隔最大化又称为硬间隔最大化(与将要讨论的训练数据集近似线性可分时的软间隔最大化相对应). 间隔最大化的直观解释是;对训练数据集找到几何间隔最大的超平面意味着以充分大的确信度对训练数据进行分类.也就是说,不仅将正负实例点分开,而 且对最难分的实例点(离超平面最近的点)也有足够大的确信度将它们分开.这样的超平面应该对未知的新实例有很好的分类预测能力。 最大间隔分离超平面考虑如何求得一个几何间隔最大的分离超平面,即最大间隔分离超平面.具体地,这个问题可以表示为下面的约束最优化问题: 函数间隔yhat的取值并不影响最优化问题的解。事实上，假设将w和b按比例改变为λw和λb,这时函数间隔称为λyhat。函数间隔的这一改变对上面最优化问题的不等式约束没有影响，对目标函数的优化也没有影响，也就是说，它产生一 这是一个凸二次规划(convex quadratic programming)问题。 仿射函数，即最高次数为1的多项式函数。常数项为零的仿射函数称为线性函数。 线性可分支持向量机学习——最大间隔法 最大间隔分离超平面的存在唯一性线性可分训练集的最大间隔分离超平面是存在且唯一的。 定理（最大间隔分离超平面的存在唯一性）若训练数据集T线性可分，则可将训练数据集中的样本点完全正确分开的最大间隔分离超平面存在且唯一。 支持向量和间隔边界在线性可分情况下,训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量( support vector).支持向量是使约束条件式(7.14)等号成立的点,即 在决定分离超平面时只有支持向量起作用,而其他实例点并不起作用.如果移动支持向量将改变所求的解;但是如果在间隔边界以外移动其他实例点,甚至去掉这些点,则解是不会改变的.由于支持向量在确定分离超平面中起着决定性作用,所以将这种分类模型称为支持向量机.支持向量的个数一般很少,所以支持向量机由很少的“重要的”训练样本确定. 例 学习的对偶算法为了求解线性可分支持向量机的最优化问题(7.13,7.14)，将它作为原始最优化问题,应用拉格朗日对偶性,通过求解对偶问题(dual problem)得到原始问题( primal problem)的最优解,这就是线性可分支持向量机的对偶算法( dual algorithm).这样做的优点,一是对偶问题往往更容易求解;二是自然引入核函数,进而推广到非线性分类问题。 首先构建拉格朗日函数( Lagrange function).为此,对每一个不等式约束(7.14)引进拉格朗日乘子( Lagrange multiplier )αi≥0,i=1,2,…,N,定义拉格朗日函数: 定理 这种算法称为线性可分支持向量机的对偶学习算法，是线性可分支持向量机学习的基本算法。 算法（线性可分支持向量机学习算法） 支持向量 例 对于线性可分问题,上述线性可分支持向量机的学习(硬间隔最大化)算法是完美的,但是,训练数据集线性可分是理想的情形.在现实问题中,训练数据集往往是线性不可分的,即在样本中出现噪声或特异点.此时,有更一般的学习算法。 线性支持向量机与软间隔最大化线性支持向量机线性可分问题的支持向量机学习方法,对线性不可分训练数据是不适用的,因为这时上述方法中的不等式约束并不能都成立.怎么才能将它扩展到线性不可分问题呢?这就需要修改硬间隔最大化,使其成为软间隔最大化. 有了上面的思路,可以和训练数据集线性可分时一样来考虑训练数据集线性不可分时的线性支持向量机学习问题相应于硬间隔最大化,它称为软间隔最大化。 定义（线性支持向量机） 学习的对偶算法 可以通过求解对偶问题而得到原始问题的解，进而确定分离超平面和决策函数.为此，就可以定理的形式叙述原始问题的最优解和对偶问题的最优解的关系. 定理 算法（线性支持向量机学习算法） 符合条件的样本点上的平均值。 支持向量 合页损失函数 目标函数的第一项是经验损失或经验风险，函数 定理 序列最小最优化算法支持向量机的学习问题可以形式化为求解凸二次规划问题，这样的图二次规划问题具有全局最优解，且有许多最优化算法可以用于这一问题的求解。但当训练样本容量很大时，这些算法往往变得非常低效，以致于无法使用。序列最小最优化算法就是一种快速实现算法。 SMO算法是一种启发式算法，其基本思路是:如果所有变量的解都满足此最优化问题的KKT条件(Karush-Kuhn-Tucker conditions),那么这个最优化问题的解就得到了。因为KKT条件是该最优化问题的充分必要条件.否则， 选择两个变量，固定其他变量，针对这两个变量构建一个二次规划问题，这个二次规划问题关于这两个变量的解应该更接近原始二次规划问题的解，因为这会使得原始二次规划问题的目标函数值变得更小.重要的是，这时子问题可以通过解析方法求解，这样就可以大大提高整个算法的计算速度.子问题有两个变量，一个是违反KKT条件最严重的那一个，另一个由约束条件自动确定.如此，SMO算法将原问题不断分解为子问题并对子问题求解，进而达到求解原问题的目的. 整个SMO算法包括两个部分:求解两个变量二次规划的解析方法和选择变量的启发式方法. 两个变量二次规划的求解方法不失一般性，假设选择的两个变量是α1，α2，其他变量αi（i=3，4，…，N）是固定的。于是SMO的最优化问题（7.98~7.100）的子问题可以写成： 为了求解两个变量的二次规划问题(7.101)-(7.103)，首先分析约束条件，然后在此约束条件下求极小。 不等式约束(7.103)使得(a,a2)在盒子[0,C]x[0,C]内，等式约束(7.102)使(α1，α2)在平行于盒子[0,C]x[0,C]的对角线的直线上.因此要求的是目标函数在一条平行于对角线的线段.上的最优值.这使得两个变量的最优化问题成为实质上的单变量的最优化问题，不妨考患为变量α2的最优化问题. 定理 变量的选择方法SMO算法在每个子问题中选择两个变量优化，其中至少一个变量是违反KKT条件的。 第一个变量的选择 第二个变量的选择 计算阈值b和差值Ei SMO算法 非线性支持向量机与核函数对解线性分类问题，线性分类支持向量机是一种非常有效的方法。但是，有时分类问题是非线性的，这时可以使用非线性支持向量机，其主要特点是利用核技巧(kernel trick)。核技巧不仅应用于支持向量机，而且应用于其他统计学习问题。 核技巧非线性分类问题非线性分类问题是指通过利用非线性模型才能很好地进行分类的问题.先看一个例子:如7.7 左图，是一个分类问题，图中“。”表示正实例点，“x”表示负实例点. 由图可，见， 无法用直线(线性模型)将正负实例正确分开，但可以用一条椭圆曲线(非线性模型)将它们正确分开. 非线性问题往往不好求解，所以希望能用解线性分类问题的方法解决这个问题.所采取的方法是进行一个非线性变换，将非线性问题变换为线性问题，通过解变换后的线性问题的方法求解原来的非线性问题、对图7.7所示的例子， 通过变换，将左图中椭圆变换成右图中的直线,将非线性分类问题变换为线性分类问题. 用线性分类方法求解非线性分类问题分为两步: 首先使用一个变换将原空间的数据映射到新空间;然后在新空间里用线性分类学习方法从训练数据中学习分类模型. 核技巧就属于这样的方法. 核函数的定义 核技巧在支持向量机中的应用 正定核 定理（正定核的充要条件） 定理给出了正定核的充要条件，因此可以作为正定核，即核函数的另一定义。 定义（正定核的等价定义） 常用核函数多项式核函数 高斯核函数 字符串核函数核函数不仅可以定义在欧氏空间上，还可以定义在离散数据的集合上.比如，字符串核是定义在字符串集合上的核函数.字符串核函数在文本分类信息检索、生物信息学等方面都有应用. 字符串核函数k,(s,t)给出了字符串s和t中长度等于n的所有子串组成的特征向量的余弦相似度(cosine similarity).直观上，两个字符串相同的子串越多， 它们就越相似，字符串核函数的值就越大.字符串核函数可以由动态规划快速地计算. 非线性支持向量机利用核技巧，可以将线性分类的学习方法应用到非线性分类问题中去.将线性支持向量机扩展到非线性支持向量机，只需将线性支持向量机对偶形式中的内积换成核函数. 定义 非线性支持向量机从非线性分类训练集，通过核函数与软间隔最大化，或凸二次规划(7.95~7.97)，学习得到的分类决策函数 算法 非线性支持向量机学习算法 博客机器学习实战教程（八）：支持向量机原理篇之手撕线性SVM 决策面方程在二维空间下一条直线的方程为y=ax+b现在我们做一个小小的改变，让原来的x轴变成x1,y轴变成x2x2=ax1+b移项得：ax1-x2+b=0将公式向量化得： 进一步向量化，用w列向量和标量r进一步向量化。 其中向量w和x分别为： 这里w1=a,w2=-1。最初的直线方程a和b的几何意义，a表示直线的斜率，b表示截距，向量化后的直线的w和r的几何意义为 向量w和直线的关系为垂直的，标量r的作用也没有变，依然决定了直线的截距。 将其推广到n维空间，就变成了超平面方程，公式没变，依然是： 不同在于： “分类间隔”方程 间隔的大小实际上就是支持向量对应的样本点到决策面的距离的二倍。d的求法如下：点到直线的距离距离公式： 公式中的直线方程为Ax0+By0+C=0，点P的坐标为(x0,y0)。将直线方程扩展到多维，求得我们现在的超平面方程，对公式进行如下变形： 这个d就是”分类间隔”。其中||w||表示w的二范数，求所有元素的平方和，然后再开方。 核函数与超平面 线性1.我们的最优化问题是： 我们要求解的是最小化问题，所以一个直观的想法是如果我能够构造一个函数，使得该函数在可行解区域内与原目标函数完全一致，而在可行解区域外的数值非常大，甚至是无穷大，那么这个没有约束条件的新目标函数的优化问题就与原来有约束条件的原始目标函数的优化问题是等价的问题。这就是使用拉格朗日方程的目的，它将约束条件放到目标函数中，从而将有约束优化问题转换为无约束优化问题。 2.将有约束的原始目标函数转换为无约束的新构造的拉格朗日目标函数 其中αi是拉格朗日乘子，αi大于等于0，是我们构造新目标函数时引入的系数变量(我们自己设置)。现在我们令： 当样本点不满足约束条件时，即在可行解区域外： 此时，我们将αi设置为正无穷，此时θ(w)显然也是正无穷。当样本点满足约束条件时，即在可行解区域内： 此时，显然θ(w)为原目标函数本身。我们将上述两种情况结合一下，就得到了新的目标函数： 此时，再看我们的初衷，就是为了建立一个在可行解区域内与原目标函数相同，在可行解区域外函数值趋近于无穷大的新函数，现在我们做到了。现在，我们的问题变成了求新目标函数的最小值，即： 这里用p*表示这个问题的最优值，且和最初的问题是等价的。 3.将不易求解的优化问题转化为易求解的优化我们看一下我们的新目标函数，先求最大值，再求最小值。这样的话，我们首先就要面对带有需要求解的参数w和b的方程，而αi又是不等式约束，这个求解过程不好做。所以，我们需要使用拉格朗日函数对偶性，将最小和最大的位置交换一下，这样就变成了： 交换以后的新问题是原始问题的对偶问题，这个新问题的最优值用d来表示。而且d&lt;=p*。我们关心的是d=p的时候，这才是我们要的解。需要什么条件才能让d=p呢？首先必须满足这个优化问题是凸优化问题。其次，需要满足KKT条件。求取最小值的目标函数为凸函数的一类优化问题。目标函数是凸函数我们已经知道，这个优化问题又是求最小值。所以我们的最优化问题就是凸优化问题。而且KKT条件也满足了。 求解这个对偶学习问题，可以分为三个步骤：首先要让L(w,b,α)关于w和b最小化，然后求对α的极大，最后利用SMO算法求解对偶问题中的拉格朗日乘子。 4.让L(w,b,α)关于w和b最小化根据上述推导已知： 首先固定α，要让L(w,b,α)关于w和b最小化，我们分别对w和b偏导数，令其等于0，即： 将上述结果带回L(w,b,α)得到： 从上面的最后一个式子，我们可以看出，此时的L(w,b,α)函数只含有一个变量，即αi。 5.对α求极大 现在我们的优化问题变成了如上的形式。对于这个问题，我们有更高效的优化算法，即序列最小优化（SMO）算法。我们通过这个优化算法能得到α，再根据α，我们就可以求解出w和b，进而求得我们最初的目的：找到超平面，即”决策平面”。 6.使用SMO算法步骤一：计算误差 步骤二：计算上下界L和H： 步骤三：计算η： 步骤四：更新αj 步骤五：根据取值范围修剪αj： 步骤六：更新αi： 步骤七：更新b1和b2： 步骤八：根据b1和b2更新b： 非线性对于非线性的情况，SVM的处理方式就是选择一个核函数。简而言之：在线性不可分的情况下，SVM通过某种事先选择的非线性映射（核函数）将输入变量映到一个高维特征空间，将其变成在高维空间线性可分，在这个高维空间中构造最优分类超平面。 线性可分的情况下，可知最终的超平面方程为： 将上述公式用内积来表示： 对于线性不可分，我们使用一个非线性映射，将数据映射到特征空间，在特征空间中使用线性学习器，分类函数变形如下： 其中ϕ从输入空间(X)到某个特征空间(F)的映射，这意味着建立非线性学习器分为两步：首先使用一个非线性映射将数据变换到一个特征空间F；然后在特征空间使用线性学习器分类。 如果有一种方法可以在特征空间中直接计算内积 &lt;ϕ(xi),ϕ(x)&gt;，就像在原始输入点的函数中一样，就有可能将两个步骤融合到一起建立一个分线性的学习器，这样直接计算的方法称为核函数方法。 这种将内积替换成核函数的方式被称为核技巧(kernel trick)。如：假设已知映射函数为： 对于两个向量a1=(x1,x2)和a2=(y1,y2)有 如果我们不进行映射计算，直接运算下面的公式： 这两个公式的计算结果是相同的。区别在于：一个是根据映射函数，映射到高维空间中，然后再根据内积的公式进行计算，计算量大；另一个则直接在原来的低维空间中进行计算，而不需要显式地写出映射后的结果，计算量小。 核函数就是： 实践SVM-simple简化版的SMO算法，第二个α的选择是随机的。https://github.com/zdkswd/MLcode/blob/master/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/svm/svm-simple.py 完整SMO算法完整的SMO算法可以启发式选择第二个α值。在实现SMO算法的时候，先计算η，再更新αj。为了加快第二个αj乘子的迭代速度，需要让直线的斜率增大，对于αj的更新公式，其中η值没有什么文章可做，于是只能令:max|Ei-Ej|。因此，优化方法为： 最外层循环，首先在样本中选择违反KKT条件的一个乘子作为最外层循环，然后用”启发式选择”选择另外一个乘子并进行这两个乘子的优化。 在非边界乘子中寻找使得 |Ei - Ej| 最大的样本3.如果没有找到，则从整个样本中随机选择一个样本 完整版SMO算法覆盖整个数据集进行计算，而简化版SMO算法是随机选择的。可以看出，完整版SMO算法选出的支持向量样点更多，更接近理想的分隔超平面。 对比两种算法的运算时间，结果是完整版SMO算法的速度比简化版SMO算法的速度快6倍左右。https://github.com/zdkswd/MLcode/blob/master/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/svm/svm-smo.py 非线性SVMhttps://github.com/zdkswd/MLcode/blob/master/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/svm/svmMLiA.py高斯核函数 从图像中我们可以看出，离中心点越近，函数值就越接近于1。 因此以任意一种颜色的同心圆作为决策边界，我们都可以完成对数据集的简单非线性划分。那么问题来了，如何映射到高维空间上去呢？——————高斯核函数！ sklearn.svm.SVC参数说明：C:惩罚项，float类型，可选参数，默认为1.0，C越大，即对分错样本的惩罚程度越大，因此在训练样本中准确率越高，但是泛化能力降低，也就是对测试数据的分类准确率降低。相反，减小C的话，容许训练样本中有一些误分类错误样本，泛化能力强。对于训练样本带有噪声的情况，一般采用后者，把训练样本集中错误分类的样本作为噪声。 kernel：核函数类型，str类型，默认为’rbf’。可选参数为：’linear’：线性核函数，’poly’：多项式核函数，’rbf’：径像核函数/高斯核，’sigmod’：sigmod核函数，’precomputed’：核矩阵，precomputed表示自己提前计算好核函数矩阵，这时候算法内部就不再用核函数去计算核矩阵，而是直接用你给的核矩阵，核矩阵需要为n*n的。 degree：多项式核函数的阶数，int类型，可选参数，默认为3。这个参数只对多项式核函数有用，是指多项式核函数的阶数n，如果给的核函数参数是其他核函数，则会自动忽略该参数。 gamma：核函数系数，float类型，可选参数，默认为auto。只对’rbf’ ,’poly’ ,’sigmod’有效。如果gamma为auto，代表其值为样本特征数的倒数，即1/n_features。 coef0：核函数中的独立项，float类型，可选参数，默认为0.0。只有对’poly’ 和,’sigmod’核函数有用，是指其中的参数c。 probability：是否启用概率估计，bool类型，可选参数，默认为False，这必须在调用fit()之前启用，并且会fit()方法速度变慢。 shrinking：是否采用启发式收缩方式，bool类型，可选参数，默认为True。 tol：svm停止训练的误差精度，float类型，可选参数，默认为1e^-3。 cache_size：内存大小，float类型，可选参数，默认为200。指定训练所需要的内存，以MB为单位，默认为200MB。 class_weight：类别权重，dict类型或str类型，可选参数，默认为None。给每个类别分别设置不同的惩罚参数C，如果没有给，则会给所有类别都给C=1，即前面参数指出的参数C。如果给定参数’balance’，则使用y的值自动调整与输入数据中的类频率成反比的权重。 verbose：是否启用详细输出，bool类型，默认为False，此设置利用libsvm中的每个进程运行时设置，如果启用，可能无法在多线程上下文中正常工作。一般情况都设为False，不用管它。 max_iter：最大迭代次数，int类型，默认为-1，表示不限制。 decision_function_shape：决策函数类型，可选参数’ovo’和’ovr’，默认为’ovr’。’ovo’表示one vs one，’ovr’表示one vs rest。 random_state：数据洗牌时的种子值，int类型，可选参数，默认为None。伪随机数发生器的种子,在混洗数据时用于概率估计。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"贝叶斯概率","slug":"贝叶斯概率","date":"2018-11-22T08:49:47.000Z","updated":"2018-11-23T05:50:35.000Z","comments":true,"path":"2018/11/22/贝叶斯概率/","link":"","permalink":"https://github.com/zdkswd/2018/11/22/贝叶斯概率/","excerpt":"","text":"已修改 人工智能课上内容你对贝叶斯统计都有怎样的理解？ - 知乎 贝叶斯概率vs经典概率关于统计推断的主张和想法，大体可以纳入到两个体系之内，其一叫频率学派，其特征是把需要推断的参数θ视作固定且未知的常数，而样本X是随机的，其着眼点在样本空间，有关的概率计算都是针对X的分布。另一派叫做贝叶斯学派，他们把参数θ视作随机变量，而样本X是固定的，其着眼点在参数空间，重视参数θ的分布，固定的操作模式是通过参数的先验分布结合样本信息得到参数的后验分布。 经典概率即我们学习的概率论呀。方法：MLE（极大似然估计）认为世界是确定的。θ是唯一的。 贝叶斯概率方法：MAP（最大后验估计）频率派认为估计对象（参数）是一个未知的固定值。而贝叶斯却认为未知的参数都是随机变量。 我们要通过一些事实估计“爱因斯坦在1905年12月25日晚上八点吸烟”的真假。定义参数:，吸烟；，没吸烟。那么频率派认为，爱因斯坦有没有曾经在这时刻吸烟是事实，是取值0或者1的固定数，不能说”=1的概率是xxx”；然而贝叶斯派认为可以说“=1概率是30%”。而且随着所得资料（样本x）的增多，我们可以把这个概率加以变化，记得到的分布。这个概率其实是“信心”的含义。 后验（输出）=先验（输入）*似然（输入） 贝叶斯思想的优势1、 对于某一种独立重复随机事件，如果采用最大似然法计算出两个极值点，例如99、100，此时最大似然法只会取最大值点100的概率值。但是使用贝叶斯思想，我们就可以同时考虑极值点99、100的概率。 在实际应用中，事件A的概率可能不是一成不变的（实验难以重复独立，或者事件A的概率就是随机的）。比如考虑一个人生病的概率，幼年时生病概率高，中年时生病概率低，老年时生病概率高，或者冬天生病概率高，夏天生病概率低。频率派思想认为的概率是事件A的固定属性在这些状况下就不适用。严格的来说，任何场景下你都无法保证事件A概率是固定的。 2、 频率派使用的最大似然法，只能得到概率的最大似然估计。但是通过贝叶斯公式得到概率后验分布函数后，我们可以进行各种处理，比如取概率期望，概率中位数，概率极大值等等。 后验分布以前我们想知道一个参数，要通过大量的观测值才能得出，而且是只能得出一个参数值。而现在运用了贝叶斯统计思想，这个后验概率分布其实是一系列参数值的概率分布，再说简单点就是我们得到了许多个参数及其对应的可能性，我们只需要从中选取我们想要的值就可以了：有时我们想要概率最大的那个参数，那这就是 后验众数估计(posterior mode estimator)；有时我们想知道参数分布的中位数，那这就是 后验中位数估计(posterior median estimator);有时我们想知道的是这个参数分布的均值，那就是 后验期望估计。这三种估计没有谁好谁坏，只是提供了三种方法得出参数，看需要来选择。现在这样看来得到的参数是不是更具有说服力？ 先验分布说完了后验分布，现在就来说说先验分布。先验分布就是你在取得实验观测值以前对一个参数概率分布的 主观判断，这也就是为什么贝叶斯统计学一直不被认可的原因，统计学或者数学都是客观的，怎么能加入主观因素呢？但事实证明这样的效果会非常好！再拿掷硬币的例子来看(怎么老是拿这个举例，是有多爱钱。。。)，在扔之前你会有判断正面的概率是50%，这就是所谓的先验概率，但如果是在打赌，为了让自己的描述准确点，我们可能会说正面的概率为0.5的可能性最大，0.45的几率小点，0.4的几率再小点，0.1的几率几乎没有等等，这就形成了一个先验概率分布。 你这个硬币的材质是不均匀的，那正面的可能性是多少呢？这就让人犯糊涂了，我们想有主观判断也无从下手，于是我们就想说那就先认为0~1之间每一种的可能性都是相同的吧，也就是设置成0~1之间的均匀分布 作为先验分布吧，这就是贝叶斯统计学当中的 无信息先验(noninformative prior)！那么下面我们就通过不断掷硬币来看看，这个概率到是多少，贝叶斯过程如下： (图来自[3]) 从图中我们可以看出，0次试验的时候就是我们的先验假设——均匀分布，然后掷了第一次是正面，于是概率分布倾向于1，第二次又是正，概率是1的可能性更大了，但 注意：这时候在0.5的概率还是有的，只不过概率很小，在0.2的概率变得更小。第三次是反面，于是概率分布被修正了一下，从为1的概率最大变成了2/3左右最大(3次试验，2次正1次反当然概率是2/3的概率最大)。再下面就是进行更多次的试验，后验概率不断根据观测值在改变，当次数很大的时候，结果趋向于0.5(哈哈，结果这还是一枚普通的硬币，不过这个事件告诉我们，直觉是不可靠的，一定亲自实验才行~)。有的人会说，这还不是在大量数据下得到了正面概率为0.5嘛，有什么好稀奇的？ 注意了！画重点了！(敲黑板) 记住，不要和一个统计学家或者数学家打赌！跑题了，跑题了。。。说回来，我们上面就说到了古典概率学的弊端就是如果掷了2次都是正面，那我们就会认为正面的概率是1，而在贝叶斯统计学中，如果我们掷了2次都是正面，只能说明正面是1的可能性最大，但还是有可能为0.5, 0.6, 0.7等等的，这就是对古典统计学的一种完善和补充，于是我们也就是解释了，我们所谓的 地震的概率为5%；生病的概率为10%等等这些概率的意义了，这就是贝叶斯统计学的哲学思想。 所以贝叶斯得到的是θ的分布。 贝叶斯分析贝叶斯分析的思路对于由证据的积累来推测一个事物发生的概率具有重大作用， 它告诉我们当我们要预测一个事物， 我们需要的是首先根据已有的经验和知识推断一个先验概率， 然后在新证据不断积累的情况下调整这个概率，整个通过积累证据来得到一个事件发生概率的过程我们称为贝叶斯分析。 贝叶斯决策如果一旦变成自动化的计算机算法， 它就是机器学习。 统计学习方法 朴素贝叶斯法朴素贝叶斯法的学习与分类基本方法注意：朴素贝叶斯法与贝叶斯估计是不同的概念。 朴素贝叶斯法对条件概率分布作了条件独立性的假设.由于这是一个较强的假设, 朴素贝叶斯法也由此得名.具体地，条件独立性假设是 朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型.条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的.这一假设使朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。 这是朴素贝叶斯法分类的基本公式，于是，朴素贝叶斯分类器可表示为： 后验概率最大化的含义朴素贝叶斯法将实例分到后验概率最大的类中.这等价于期望风险最小化.假设选择0-1损失函数: 朴素贝叶斯的参数估计极大似然估计 学习与分类算法朴素贝叶斯算法（naive Bayes algorithm） 例 贝叶斯估计 例 西瓜书 关于朴素贝叶斯分类器的补充在现实任务中朴素贝叶斯分类器有多种使用方式.例如，若任务对预测速度要求较高，则对给定训练集,可将朴素贝叶斯分类器涉及的所有概率估值事先计算好存储起来,这样在进行预测时只需“查表”即可进行判别;若任务数据更替频繁，则可采用“懒惰学习”(lazy learning) 方式，先不进行任何训练，待收到预测请求时再根据当前数据集进行概率估值;若数据不断增加，则可在现有估值基础_上，仅对新增样本的属性值所涉及的概率估值进行计数修正即可实现增量学习。 西瓜书 半朴素贝叶斯分类器为了降低贝叶斯公式中估计后验概率P(c|x)的困难，朴素贝叶斯分类器采用了属性条件独立性假设,但在现实任务中这个假设往往很难成立.于是，人们尝试对属性条件独立性假设进行一定程度的放松,由此产生了一类称为“半朴素贝叶斯分类器”(semi-naive Bayes clasifers)的学习方法。 半朴素贝叶斯分类器的基本思想是适当考虑一部分属性间的互相依赖信息，从而既不需要进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。“独依赖估计”（One-Dependent Estimator,简称ODE）是半朴素贝叶斯分类器最常用的一种策略。顾名思义，所谓“独依赖”就是假设每个属性在类别之外最多仅依赖一个其他属性，即： 于是，问题的关键就转化为如何确定每个属性的父属性，不同的做法产生不同的独依赖分类器 最直接的做法是假设所有属性都依赖同一个属性，称为“超父”（super-parent),然后通过交叉验证等模型选择方法来确定超父属性，由此形成了SPODE方法。 按下不表 西瓜书 贝叶斯网贝叶斯网亦称“信念网”，它借助有向无环图（Directed Acyclic Graph,简称DAG）来刻画属性间的依赖关系，并使用条件概率表（Conditional Probability Table,简称CPT）来描述属性的联合概率分布。 按下不表。 博客贝叶斯推断 P(A)称为”先验概率”（Prior probability），即在B事件发生之前，我们对A事件概率的一个判断。 P(A|B)称为”后验概率”（Posterior probability），即在B事件发生之后，我们对A事件概率的重新评估。 P(B|A)/P(B)称为”可能性函数”（Likelyhood），这是一个调整因子，使得预估概率更接近真实概率。 这就是贝叶斯推断的含义。我们先预估一个”先验概率”，然后加入实验结果，看这个实验到底是增强还是削弱了”先验概率”，由此得到更接近事实的”后验概率”。 在这里，如果”可能性函数”P(B|A)/P(B)&gt;1，意味着”先验概率”被增强，事件A的发生的可能性变大；如果”可能性函数”=1，意味着B事件无助于判断事件A的可能性；如果”可能性函数”&lt;1，意味着”先验概率”被削弱，事件A的可能性变小。 要知道我们只需要比较 P(H1|E)和P(H2|E)的大小，找到那个最大的概率就可以。既然如此，两者的分母都是相同的，那我们只需要比较分子即可。即比较P(E|H1)P(H1)和P(E|H2)P(H2)的大小，所以为了减少计算量，全概率公式在实际编程中可以不使用。 其中P(B): 朴素贝叶斯推断 由于每个特征都是独立的，我们可以进一步拆分公式： 实践朴素贝叶斯https://github.com/zdkswd/MLcode/blob/master/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/bayes.py sklearn-朴素贝叶斯在sklearn中一共有三个朴素贝叶斯分类算法类。分别是GaussianNB,MultinomialNB和BernoulliNB。其中GaussianNB就是先验为高斯分布的朴素贝叶斯，MultinomialNB就是先验为多项式分布的朴素贝叶斯，而BernoulliNB就是先验为伯努利分布的朴素贝叶斯。 对于新闻分类，属于多分类问题。我们可以使用MultinamialNB()完成我们的新闻分类问题。MultinomialNB假设特征的先验概率为多项式分布，即如下式： 其中， P(Xj = Xjl | Y = Ck)是第k个类别的第j维特征的第l个取值条件概率。mk是训练集中输出为第k类的样本个数。λ为一个大于0的常数，常常取值为1，即拉普拉斯平滑，也可以取其他值。 MultinamialNB这个函数，只有3个参数：参数说明如下: alpha：浮点型可选参数，默认为1.0，其实就是添加拉普拉斯平滑，即为上述公式中的λ ，如果这个参数设置为0，就是不添加平滑； fit_prior：布尔型可选参数，默认为True。布尔参数fit_prior表示是否要考虑先验概率，如果是false,则所有的样本类别输出都有相同的类别先验概率。否则可以自己用第三个参数class_prior输入先验概率，或者不输入第三个参数class_prior让MultinomialNB自己从训练集样本来计算先验概率，此时的先验概率为P(Y=Ck)=mk/m。其中m为训练集样本总数量，mk为输出为第k类别的训练集样本数。 class_prior：可选参数，默认为None。 MultinomialNB一个重要的功能是有partial_fit方法，这个方法的一般用在如果训练集数据量非常大，一次不能全部载入内存的时候。这时我们可以把训练集分成若干等分，重复调用partial_fit来一步步的学习训练集，非常方便。GaussianNB和BernoulliNB也有类似的功能。 在使用MultinomialNB的fit方法或者partial_fit方法拟合数据后，我们可以进行预测。此时预测有三种方法，包括predict，predict_log_proba和predict_proba。predict方法就是我们最常用的预测方法，直接给出测试集的预测类别输出。predict_proba则不同，它会给出测试集样本在各个类别上预测的概率。容易理解，predict_proba预测出的各个类别概率里的最大值对应的类别，也就是predict方法得到类别。predict_log_proba和predict_proba类似，它会给出测试集样本在各个类别上预测的概率的一个对数转化。转化后predict_log_proba预测出的各个类别对数概率里的最大值对应的类别，也就是predict方法得到类别。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"AutoEncoder by Forest","slug":"AutoEncoder by Forest","date":"2018-11-21T12:16:32.000Z","updated":"2018-11-21T12:20:34.000Z","comments":true,"path":"2018/11/21/AutoEncoder by Forest/","link":"","permalink":"https://github.com/zdkswd/2018/11/21/AutoEncoder by Forest/","excerpt":"","text":"https://arxiv.org/abs/1709.09018 摘要自动编码是一个重要的任务，通常由深度神经网络比如CNN来实现。在这篇论文中，我们提出了EncoderForest （eForest）这是第一个基于树集成的自编码器。我们提出了一种方法，让森林能够利用树的决策路径所定义的等效类来进行后向重建，并在监督和无监督环境中展示了其使用情况。实验结果表明，与DNN自编码器相比，eForest能够以较快的训练速度获得更低的重建误差，同时模型本身具有可重用性和容损性。 引言自动编码器是一类将输入数据映射到隐藏空间，然后再映射到原始空间的模型，它使用重建误差作为目标函数。自动编码器分为两个过程：编码和解码。编码过程将原始数据映射到隐藏空间，解码数据将数据从隐藏空间映射到原始数据空间。传统实现这两个过程的方式是使用神经网络。 文章提出了一种编码森林（EncoderForest），通过一个集成树模型进行前向编码和反向解码，而且可以使用监督或者无监督训练。实验显示EncoderFroest有如下优点: 准确： 它的实验重建误差比使用MLP和CNN的自动编码器低。 有效： efroest在一个单一KNL(多核CPU)上运行比CNN-Base自动编码器在一个Titan-X GPU上运行还快。 容错率：训练好的模型能够正常运行即使模型部分损坏。 重利用： 在同一个领域下，使用一个数据集训练的模型可以直接应用到另一个数据集下。 模型自动编码器有两个基本的功能，编码和解码。对于一个森林来说，编码并不困难，因为至少其叶节点信息可以被看做一种编码，甚至可以说，结点集合的一个子集或者路径的分支都能够为编码提供更多的信息。 编码过程对于给定的一个训练过的有T棵树的集成树模型（也可以是空的森林，编码过程即森林形成过程），前向编码过程将输入数据送到每棵树的根节点，并计算每棵树，得到其所属的叶节点，最后返回一个T维向量，这个T维向量的每一项是每棵树中求到的上述叶节点在树中的编号。注意，算法跟决策树的分割规则无关。只需要是T棵树即可。 解码过程一般来说，决策树都是用来前向预测，将数据计算从树的根节点到叶子结点，但是其反向重建是未定义的。下面通过一个小例子来探索解码过程。 假设我们正在解决一个二分类问题，数据有三个属性，第一个和第二个属性是数值型属性，第三个属性是布尔型属性（取值为YES, NO），第四个属性是一个三值属性，取值可以是RED，BLUE，GREEN。给定一个实例x，xi代表x的第i个属性值。 现在我们只知道，实例x落在每棵树的哪个结点，上图中的红色结点，我们的目标是重构实例x。文章提出了一种简洁有效的反向重建方法。首先，在树中的每个叶子结点对应于一条唯一的从根到叶子的路径。在上面的图中已经用红色标出这样的路径。然后，每条路径都会对应一条符号规则，所以我们就得到了n条（树的数目）符号规则： 然后，我们可以根据上面的规则推出MCR(最大完备规则)，最大完备规则的意思是，在规则中的每一个约束的范围不能再扩大。如果扩大，则会产生冲突。 例如，由上面的规则集我们可以得到MCR: 那么显然，原始的数据肯定落在有MCR定义的范围内。 计算完MCR之后，就可以根据MCR重构原始样本了，目录型属性如上面的第三和第四属性只需要根据MCR中的指定取即可，而数值型属性则可以根据MCR中的范围取一个特殊值即可（中位数、均值、或者最大最小值）。 首先根据编码完的T维向量从树中得到T个决策规则，再根据这些规则得到MCR，再根据MCR重构得到x，算法如下： 实验","categories":[{"name":"论文","slug":"论文","permalink":"https://github.com/zdkswd/categories/论文/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"特征工程与表示学习,数据的粒度,数据量","slug":"特征工程与表示学习,数据的粒度,数据量","date":"2018-11-21T10:48:47.000Z","updated":"2018-11-21T10:48:55.000Z","comments":true,"path":"2018/11/21/特征工程与表示学习,数据的粒度,数据量/","link":"","permalink":"https://github.com/zdkswd/2018/11/21/特征工程与表示学习,数据的粒度,数据量/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/41521695 正因为数据表示的重要性，机器学习一般有两种思路来提升原始数据的表达 特征学习(feature learning)，又叫表示学习(representation learning)或者表征学习，一般指的是自动学习有用的数据特征。 特征工程(feature engineering)，主要指对于数据的人为处理提取，有时候也代指“洗数据”。 表示学习模型自动对输入数据进行学习，得到更有利于使用的特征(*可能同时做出了预测)。代表的算法大致包括： 深度学习，包括大部分常见的模型如CNN_RNN_DBN等。 某些无监督学习算法，如主成分分析(PCA)及自编码器（autoencoder）通过对数据转化而使得输入数据更有意义。 某些树模型可以自动的学习到数据中的特征并同时作出预测。 模型选择什么时候用「手工提取」什么时候用「表示学习」。一种简单的看法是，要想自动学习到数据的良好表达，就需要大量的数据。这个现象也解释了为什么「特征工程」往往在中小数据集上表现良好，而「表示学习」在大量复杂数据上更有用武之地。 比如我们会假设数据分布，会假设映射函数的性质，也会假设预测值与输入值间的关系。这一切假设其实并非凭空猜想，而是基于我们对于问题的理解，从某种角度来看，这是一种先验，是贝叶斯模型。在中小数据集上的机器学习往往使用的就是强假设模型（人类知识先验）+一个简单线性分类器。当数据愈发复杂，数据量逐渐加大后，我们对于数据的理解越来越肤浅，做出的假设也越来越倾向于随机，那么此时人工特征工程往往是有害的，而需要使用摆脱了人类先验的模型，比如深度学习或者集成模型。 模型选择的过程其实也是在衡量我们对于问题及数据的理解是否深刻，是在人类先验与数据量之间的一场博弈。从这个角度来看，深度学习首先革的是传统机器学习模型的命：最先被淘汰的不是工人，而是特定场景下的传统机器学习模型。 数据的粒度数据的粒度可以理解为数据的细分程度。随着细分程度的改变，那么数据量也会有明显的变化。数据的粒度越细，数据量越大。 过于具体的数据缺失了特征，有效的特征仅在某个特定的粒度才存在。打个比方，人是由原子、分子、细胞、组织、器官构成，但在分子层面我们不一定能分辨它是人，只有到达一定的粒度才可以。因此，数据收集的第一个重点是搞清楚，在什么粒度可以解决我们的问题，而不是盲目的收集一大堆数据，或者收集过于抽象的数据。 到底需要多少数据？数据量与特征量的比例谈论数据量，不能光说有多少条数据n，一定也要考虑数据的特征数m。 人们讨论数据量，往往讨论的是n，也就是有多少条数据。但这个是不准确的，因为更加适合的评估应该是n/m，也就是样本量除以特征数，原因很简单。如果你只有100条数据，但只有2个特征。如果用线性函数来拟合，相当于给你100个点来拟合到二次函数上，这个数据量一般来说是比较充裕的。但还是100个数据点，每个数据的特征数是200，那么很明显你的数据是不够的，过拟合的风险极高。 特征间的相关性和有效性数据间重复性低：包括样本间重复性比较低，特征间重复性比较低，即特征间线性无关 数据的有效性：此处的有效性指的是你的变量对于解决问题有帮助，而不是完全无关或者关联性极低的数据。 数据是否越多越好？数据比模型更重要，数据重要性 &gt;&gt; 模型重要性。机器学习模型的表现高度依赖于数据量，选择对的模型只是其次，因为巧妇难为无米之炊。 数据不是越多越好，随机数据中也可能因为巧合而存在某种关联。 数据量与模型选择数据量很小，用朴素贝叶斯、逻辑回归或支持向量机数据量适中或者较大，用树模型，优先 xgboost和lightgbm数据量较大，尝试使用神经网络所以说到底，依然不存在定式，而依赖于经验和理解。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"Deep Forest: Towards An Alternative to Deep Neural Networks","slug":"Deep Forest: Towards An Alternative to Deep Neural Networks","date":"2018-11-21T10:44:32.000Z","updated":"2018-11-21T10:44:51.000Z","comments":true,"path":"2018/11/21/Deep Forest: Towards An Alternative to Deep Neural Networks/","link":"","permalink":"https://github.com/zdkswd/2018/11/21/Deep Forest: Towards An Alternative to Deep Neural Networks/","excerpt":"","text":"https://www.ijcai.org/proceedings/2017/0497.pdf 摘要提出了gcForest,一种能够与深层神经网络的表现高度抗衡的决策树集成方法。相比于深层神经网络需要化大力气调整超参数，gcForest更容易去训练。实际上，就算gcForest被应用于不同领域使用不同的数据，也可以通过设置几乎相同的超参数获得极好的表现。gcForest的训练时高效的可扩展的。在作者的实验中使用PC进行gcForest的训练和使用GPU设备进行训练时间差不多，并且效率的优势可能会比这更加明显，因为gcForest更容易并行实现。更重要的是，深层神经网络需要大规模的训练数据，但是gcForest即使只有小规模的训练数据也能表现很好。还有，作为以树为基础的方法，gcForest比深层神经网络更容易进行理论分析。 介绍深度神经网络的不足： 需要大量数据。然而就算是大数据领域也有待带标签数据不足等问题。 模型复杂，需要强计算力设备进行训练。 最重要的是有太多超参数，学习的表现又很依赖它们。即使是使用同样的网络模型也由于各种参数设置的不同而变得实际上使用的是不同的学习模型。这让深层学习的训练变得棘手，更像是一门艺术而不是一门科学。同时由于影响的因素太多而难以理论分析深层神经网络。 作者设想能不能给一些学习模型赋予一些属性让其具有深层学习网络的能力而又没有上述的不足。 所以论文提出gcForest(multi-Grained Cascade forest ) k折交叉验证常用的精度测试方法主要是交叉验证，例如10折交叉验证(10-fold cross validation)，将数据集分成十份，轮流将其中9份做训练1份做验证，10次的结果的均值作为对算法精度的估计，一般还需要进行多次10折交叉验证求均值，例如：10次10折交叉验证，以求更精确一点。交叉验证有时也称为交叉比对，如：10折交叉比对。 博客级联森林 级联的每个级别包括两个随机森林（蓝色字体标出）和两个完全随机树木森林（黑色）。假设有三个类要预测; 因此，每个森林将输出三维类向量，然后将其连接以重新表示原始输入。注意，要将前一级的特征和这一级的特征连接在一起。 论文中为了简单起见，在实现中，使用了两个完全随机的树森林（complete-random tree forests）和两个随机森林[Breiman，2001]。每个完全随机的树森林包含1000个完全随机树[Liu et al。，2008]，每棵树通过随机选择一个特征在树的每个节点进行分割实现生成，树一直生长，直到每个叶节点只包含相同类的实例或不超过10个实例。类似地，每个随机森林也包含1000棵树，通过随机选择sqrt(d) 数量的特征作为候选（d是输入特征的数量），然后选择具有最佳 gini 值的特征作为分割。每个森林中的树的数值是一个超参数。 给定一个实例（就是一个样本），每个森林会通过计算在相关实例落入的叶节点处的不同类的训练样本的百分比，然后对森林中的所有树计平均值，以生成对类的分布的估计。如下图所示，其中红色部分突出了每个实例遍历到叶节点的路径。叶节点中的不同标记表示了不同的类。 被估计的类分布形成类向量（class vector），该类向量接着与输入到级联的下一级的原始特征向量相连接。例如，假设有三个类，则四个森林每一个都将产生一个三维的类向量，因此，级联的下一级将接收12 = 3×4个增强特征（augmented feature）。 为了降低过拟合风险，每个森林产生的类向量由k折交叉验证（k-fold cross validation）产生。具体来说，每个实例都将被用作 k -1 次训练数据，产生 k -1 个类向量，然后对其取平均值以产生作为级联中下一级的增强特征的最终类向量。需要注意的是，在扩展一个新的级后，整个级联的性能将在验证集上进行估计，如果没有显着的性能增益，训练过程将终止；因此，级联中级的数量是自动确定的。与模型的复杂性固定的大多数深度神经网络相反，gcForest 能够适当地通过终止训练来决定其模型的复杂度（early stop）。这使得 gcForest 能够适用于不同规模的训练数据，而不局限于大规模训练数据。 多粒度扫描（Multi-Grained Scanning） 滑动窗口用于扫描原始特征。假设有400个原始特征，并且使用100个特征的窗口大小。对于序列数据，将通过滑动一个特征的窗口来生成100维的特征向量；总共产生301个特征向量。如果原始特征具有空间关系，比如图像像素为400的20×20的面板，则10×10窗口将产生121个特征向量（即121个10×10的面板）。从正负训练样例中提取的所有特征向量被视为正负实例；它们将被用于生成类向量：从相同大小的窗口提取的实例将用于训练完全随机树森林和随机森林，然后生成类向量并连接为转换后的像素。如上图的上半部分所示，假设有3个类，并且使用100维的窗口；然后，每个森林产生301个三维类向量，导致对应于原始400维原始特征向量的1,806维变换特征向量。 通过使用多个尺寸的滑动窗口，最终的变换特征矢量将包括更多的特征，如下图所示。 concat成一个3618-dim的原始数据，表示原始的一个数据样本，第一级的输出是12+3618=3630，后面也是一样，直到最后第N级，只有12个输出，然后在每一类别上做avg，然后输出max那一类的label，那就是最终的预测类别。 总结带着深度学习的关键在于特征学习和巨大模型的能力这一认识，我们在本文中试图赋予树集成这些属性，并提出了 gcForest 方法。与深度神经网络相比，gcForest在我们的实验中表现了极高的竞争力或更好的性能。更重要的是，gcForest 具有少得多的超参数，并且对参数设置不太敏感；实际上在我们的实验中，通过使用相同的参数设置在不同的域中都获得了优异的性能，并且无论是大规模还是小规模的数据，它的工作都很好。此外，作为一种基于树的方法，gcForest 应该比深度神经网络更容易进行理论分析。","categories":[{"name":"论文","slug":"论文","permalink":"https://github.com/zdkswd/categories/论文/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线","slug":"精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线","date":"2018-11-20T12:21:47.000Z","updated":"2018-11-23T13:38:32.000Z","comments":true,"path":"2018/11/20/精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线/","link":"","permalink":"https://github.com/zdkswd/2018/11/20/精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线/","excerpt":"","text":"已修改 精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线针对二分类问题。 精确率 = TP / (TP + FP)，表示返回的正例中真正例所占的比例；召回率 = TP / (TP + FN)，表示返回的真正例占所有正例的比例。真正类率（TPR），TPR = TP / (TP + FN)，返回的正类占所有正类的比例；（没错，跟召回率一个公式）TPR越大越好。假正类率（FPR），FPR = FP / (FP + TN)，返回的负类占所有负类的比例。FPR越小越好ROC curve:FPR越小越好。 对于ROC来说，横坐标就是FPR，而纵坐标就是TPR，因此可以想见，当 TPR越大，而FPR越小时，说明分类结果是较好的。 AUC:AUC 即ROC曲线下的面积，计算方式即为ROC Curve的微积分值，其物理意义可以表示为：随机给定一正一负两个样本，将正样本排在负样本之前的概率，因此AUC越大，说明正样本越有可能被排在负样本之前，即分类的结果越好。 ROC的总结： ROC 可以反映二分类器的总体分类性能，但是无法直接从图中识别出分类最好的阈值，事实上最好的阈值也是视具体的场景所定； ROC Curve 对应的AUC越大说明分类性能越好; ROC曲线一定是需要在 y = x之上的，否则就是一个不理想的分类器；","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"GBDT+LR","slug":"GBDT+LR","date":"2018-11-20T07:56:56.000Z","updated":"2018-11-20T12:03:32.000Z","comments":true,"path":"2018/11/20/GBDT+LR/","link":"","permalink":"https://github.com/zdkswd/2018/11/20/GBDT+LR/","excerpt":"","text":"GBDTgbdt在各种竞赛是大放异彩。原因大概有几个，一是效果确实挺不错。二是即可以用于分类也可以用于回归。三是可以筛选特征。 GBDT如何选择特征gbdt选择特征的细节其实是想问你CART Tree生成的过程。这里有一个前提，gbdt的弱分类器默认选择的是CART TREE。其实也可以选择其他弱分类器的，选择的前提是低方差和高偏差。框架服从boosting 框架即可。 GBDT如何构建特征其实说gbdt 能够构建特征并非很准确，gbdt 本身是不能产生特征的，但是我们可以利用gbdt去产生特征的组合。逻辑回归本身是适合处理线性可分的数据，如果我们想让逻辑回归处理非线性的数据，其中一种方式便是组合不同特征，增强逻辑回归对非线性分布的拟合能力。 GBDT如何用于分类GBDT 无论用于分类还是回归一直都是使用的CART 回归树。不会因为我们所选择的任务是分类任务就选用分类树。 GB训练强学习器的思路 GBDT原理对于任意的基分类器都可以利用GB的思想训练一个强分类器。而把基分类器选为决策树（DT)时，就是我们常用的GBDT。 对于回归任务，当选择的loss function为Least-square。 伪代码为： GBDT例 GDBT分类篇对于回归和分类，其实GBDT过程简直就是一模一样的。如果说最大的不同的话，那就是在于由于loss function不同而引起的初始化不同、叶子节点取值不同。 分类例 多分类：GBDT原理与实践-多分类篇 - SCUT_Sam - CSDN博客 GBDT+LR背景CTR预估（Click-Through Rate Prediction）是互联网计算广告中的关键环节，预估准确性直接影响公司广告收入。CTR预估中用的最多的模型是LR（Logistic Regression），LR是广义线性模型，与传统线性模型相比，LR使用了Logit变换将函数值映射到0~1区间，映射后的函数值就是CTR的预估值。LR这种线性模型很容易并行化，处理上亿条训练样本不是问题，但线性模型学习能力有限，需要大量特征工程预先分析出有效的特征、特征组合，从而去间接增强LR的非线性学习能力。 LR模型中的特征组合很关键， 但又无法直接通过特征笛卡尔积解决，只能依靠人工经验，耗时耗力同时并不一定会带来效果提升。如何自动发现有效的特征、特征组合，弥补人工经验不足，缩短LR特征实验周期，是亟需解决的问题。Facebook 2014年的文章介绍了通过GBDT（Gradient Boost Decision Tree）解决LR的特征组合问题，随后Kaggle竞赛也有实践此思路，GBDT与LR融合开始引起了业界关注。 GBDT（Gradient Boost Decision Tree）是一种常用的非线性模型，它基于集成学习中的boosting思想，每次迭代都在减少残差的梯度方向新建立一颗决策树，迭代多少次就会生成多少颗决策树。GBDT的思想使其具有天然优势可以发现多种有区分性的特征以及特征组合，决策树的路径可以直接作为LR输入特征使用，省去了人工寻找特征、特征组合的步骤。这种通过GBDT生成LR特征的方式（GBDT+LR），业界已有实践（Facebook，Kaggle-2014），且效果不错，是非常值得尝试的思路。 融合前人工寻找有区分性特征（raw feature）、特征组合、融合后直接通过黑盒子（Tree模型GBDT）进行特征、特种组合的自动发现。 在介绍这个模型之前，我们先来介绍两个问题： 为什么要使用集成的决策树模型而不是单颗的决策树模型：一棵树的表达能力很弱，不足以表达多个有区分性的特征组合，多棵树的表达能力更强一些。GBDT每棵树都在学习前面棵树尚存的不足，迭代多少次就会生成多少颗树。按paper以及Kaggle竞赛中的GBDT+LR融合方式，多棵树正好满足LR每条训练样本可以通过GBDT映射成多个特征的需求。 为什么建树采用GBDT而非RF：RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。 GBDT+LR的结构GBDT用来对训练集提取特征作为新的训练输入数据，LR作为新训练输入数据的分类器。 具体步骤： GBDT首先对原始训练数据做训练，得到一个二分类器，当然这里也需要利用网格搜索寻找最佳参数组合。 与通常做法不同的是，当GBDT训练好做预测的时候，输出的并不是最终的二分类概率值，而是要把模型中的每棵树计算得到的预测概率值所属的叶子结点位置记为1，这样，就构造出了新的训练数据。在用GBDT构造新的训练数据时，采用的正是One-hot方法。并且由于每一弱分类器有且只有一个叶子节点输出预测结果，所以在一个具有n个弱分类器、共计m个叶子结点的GBDT中，每一条训练数据都会被转换为1*m维稀疏向量，且有n个元素为1，其余m-n 个元素全为0。 新的训练数据构造完成后，下一步就要与原始的训练数据中的label(输出)数据一并输入到Logistic Regression分类器中进行最终分类器的训练。思考一下，在对原始数据进行GBDT提取为新的数据这一操作之后，数据不仅变得稀疏，而且由于弱分类器个数，叶子结点个数的影响，可能会导致新的训练数据特征维度过大的问题，因此，在Logistic Regression这一层中，可使用正则化来减少过拟合的风险，在Facebook的论文中采用的是L1正则化。 GBDT与LR的融合方式，Facebook的paper有个例子如下图2所示，图中Tree1、Tree2为通过GBDT模型学出来的两颗树，x为一条输入样本，遍历两棵树后，x样本分别落到两颗树的叶子节点上，每个叶子节点对应LR一维特征，那么通过遍历树，就得到了该样本对应的所有LR特征。由于树的每条路径，是通过最小化均方差等方法最终分割出来的有区分性路径，根据该路径得到的特征、特征组合都相对有区分性，效果理论上不会亚于人工经验的处理方式。 论文中GBDT的参数，树的数量最多500颗（500以上就没有提升了），每棵树的节点不多于12。 GBDT模型的特点，非常适合用来挖掘有效的特征、特征组合。业界不仅GBDT+LR融合有实践，GBDT+FM也有实践，2014 Kaggle CTR竞赛冠军就是使用GBDT+FM（因子分解机），可见，使用GBDT融合其它模型是非常值得尝试的思路。 RF + LR ? Xgb + LR?例如Random Forest以及Xgboost等是并不是也可以按类似的方式来构造新的训练样本呢？没错，所有这些基于树的模型都可以和Logistic Regression分类器组合。 RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。 GBDT与LR融合具体方案在CTR预估中，如何利用AD ID是一个问题。直接将AD ID作为特征建树不可行，而onehot编码过于稀疏，为每个AD ID建GBDT树，相当于发掘出区分每个广告的特征。而对于曝光不充分的样本即长尾部分，无法单独建树。 综合方案为：使用GBDT对非ID和ID分别建一类树。 非ID类树：不以细粒度的ID建树，此类树作为base，即这些ID一起构建GBDT。即便曝光少的广告、广告主，仍可以通过此类树得到有区分性的特征、特征组合。 ID类树：以细粒度 的ID建一类树（每个ID构建GBDT），用于发现曝光充分的ID对应有区分性的特征、特征组合。 如何根据GBDT建的两类树，对原始特征进行映射？当一条样本x进来之后，遍历两类树到叶子节点，得到的特征作为LR的输入。当AD曝光不充分不足以训练树时，其它树恰好作为补充。 通过GBDT转换得到特征空间相比于原始ID低了很多。 如何使用得到的特征？通过GBDT生成的特征，可直接作为LR的特征使用，省去人工处理分析特征的环节，LR的输入特征完全依赖于通过GBDT得到的特征。此思路已尝试，通过实验发现GBDT+LR在曝光充分的广告上确实有效果，但整体效果需要权衡优化各类树的使用。同时，也可考虑将GBDT生成特征与LR原有特征结合起来使用，待尝试。 总结对于样本量大的数据，线性模型具有训练速度快的特点，但线性模型学习能力限于线性可分数据，所以就需要特征工程将数据尽可能地从输入空间转换到线性可分的特征空间。GBDT与LR的融合模型，其实使用GBDT来发掘有区分度的特征以及组合特征，来替代人工组合特征 GBDT + LR 代码sklearn多种模型ROC比较MLcode/sklearn-gbdt+lr.py at master · zdkswd/MLcode · GitHub","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"提升 boosting","slug":"提升 boosting","date":"2018-11-16T08:08:47.000Z","updated":"2018-11-16T08:14:52.000Z","comments":true,"path":"2018/11/16/提升 boosting/","link":"","permalink":"https://github.com/zdkswd/2018/11/16/提升 boosting/","excerpt":"","text":"机器学习升级版 提升 把分错的样本权值调高，把分对的样本权值调低。会存在本来已经分对的点在下次划分时被分错的情况。基本上可以避免这种情况。 对树求梯度，一个树就是一个函数的样子。 yhat（t-1）是前t-1棵树累加对样本的预测值，ft(x)是第t棵树对样本的预测值。 ft没什么意义，只有变成w才有意义。 wj就是样本落在叶子节点的预测值，Gj就是落在节点的一阶梯度的加和，Hj是落在节点的二阶梯度的加和。λ是一个超参数。 XGBoost小结 αm是第m个分类器的权值。 统计学习方法 提升方法AdaBoost在概率近似正确(probably approximately correct, PAC)学习的框架中，一个概念(一个类)，如果存在一个多项式的学习算法能够学习它，并且正确率很高，那么就称这个概念是强可学习的;一个概念，如果存在一个多项式的学习算法能够学习它,学习的正确率仅比随机猜测略好，那么就称这个概念是弱可学习的. 如果已经发现了“弱学习算法”，将它提升(boost) 为“强学习算法”.大家知道，发现弱学习算法通常要比发现强学习算法容易得多.那么如何具体实施提升，便成为开发提升方法时所要解决的问题.关于提升方法的研究很多，有很多算法被提出.最具代表性的是AdaBoost算法。 对于分类问题而言，给定一个训练样本集，求比较粗糙的分类规则(弱分类器)要比求精确的分类规则(强分类器)容易得多.提升方法就是从弱学习算法出发， 反复学习，得到一系列弱分类器(又称为基本分类器)，然后组合这些弱分类器，构成一个强分类器.大多数的提升方法都是改变训练数据的概率分布(训练数据的权值分布)，针对不同的训练数据分布调用弱学习算法学习一系列弱分类器. 对提升方法来说，有两个问题需要回答:一是在每一轮如何改变训练数据的权值或概率分布;二是如何将弱分类器组合成一个强分类器.关于第1个问题，AdaBoost的做法是，提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值.这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注.于是，分类问题被一系列的弱分类器“分而治之”.至于第2个问题，即弱分类器的组合，AdaBoost 采取加权多数表决的方法.具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用. AdaBoost算法给定一个二类分类的训练数据集。 算法（AdaBoost） AdaBoost的例子 AdaBoost算法的训练误差分析AdaBoost最基本的性质是它能在学习过程中不断减少训练误差，即在训练数据集上的分类误差率。 定理（AdaBoost的训练误差界）AdaBoost算法最终分类器的训练误差界为： 这一定理说明，可以在每一轮选取适当的Gm使得Zm最小，从而使训练误差下降最快。对二类分类问题，有如下结果： 定理（二类分类问题AdaBoost的训练误差界） 推论 这表明在此条件下AdaBoost的训练误差是以指数速率下降的。这一性质当然很有吸引力。 AdaBoost算法不需要知道下界y.与早期的提升方法不同，AdaBoost具有适应性，即它能适应弱分类器各自的训练误差率。 AdaBoost算法的解释AdaBoost算法还有另一个解释，即可以认为AdaBoost算法是模型为加法模型、损失函数为指数函数、学习算法为前向分布算法时的二类分类学习方法。 前向分布算法考虑加法模型 其中b（x;ym）为基函数，ym为基函数的参数，Bm为基函数的系数。 在给定训练数据及损失函数L（y，f（x））的条件下，学习加法模型f(x)成为损失函数极小化问题。 通常这是一个复杂得优化问题。前向分步算法求解这一优化问题的想法是，因为学习的是加法模型，如果能够从前向后，每一步只学习一个基函数及其系数，逐步逼近目标函数式，就可以简化优化的复杂度。具体的，每步只需优化损失函数： 前向分步算法 前向分步算法与AdaBoost定理AdaBoost算法是前向分步算法加法算法的特例。这时模型是由基本分类器组成的加法模型，损失函数是指数函数。 提升树提升树是以分类树或回归树为基本分类器的提升方法.提升树被认为是统计学习中性能最好的方法之一。 提升树模型提升方法实际采用加法模型（即基函数的线性组合）与前向分步算法。以决策树为基函数的提升方法称为提升树（boosting tree）。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。基本分类器x&lt;v,或x&gt;v，可以看做是由一个根结点直接连接两个叶节点的简单决策树，即所谓的决策树桩。提升树模型可以表示为决策树的加法模型： 提升树算法提升树算法采用前向分步算法.首先确定初始提升树f0(x)=0,第m步的模型是 其中，fm-1(x)为当前模型，通过最小化损失函数确定下一棵决策树的参数θm。 由于树的线性组合可以很好地拟合训练数据，即使数据中的输入与输出之间的关系很复杂也是如此，所以提升树是一个高功能的学习算法. 针对不同问题的提升树学习算法，其主要区别在于使用的损失函数不同.包括用平方误差损失函数的回归问题，用指数损失函数的分类问题，以及用一般损失函数的一般决策问题. 基函数是分类树（二叉分类树）对于基函数是分类树时，我们使用指数损失函数，此时正是AdaBoost算法的特殊情况，即将AdaBoost算法中的基分类器使用分类树即可。 回归问题的提升树算法（基函数是回归树） 例 梯度提升提升树利用加法模型与前向分步算法实现学习的优化过程.当损失函数是平方损失和指数损失函数时，每一步优化是很简单的.但对一一般损失函数而言，往往每一步优化并不那么容易.针对这一问题，Freidman 提出了梯度提升(gradientboosting)算法，这是利用最速下降法的近似方法，其关键是利用损失函数负梯度在当前模型的值 作为回归问题提升树算法中的残差的近似值，拟合一个回归树。 梯度提升算法 博客Bagging + 决策树 = 随机森林AdaBoost + 决策树 = 提升树Gradient Boosting + 决策树 = GBDT 实践AdaBoost单层决策树分类问题。 可以看到，如果想要试着从某个坐标轴上选择一个值（即选择一条与坐标轴平行的直线）来将所有的蓝色圆点和橘色圆点分开，这显然是不可能的。这就是单层决策树难以处理的一个著名问题。通过使用多颗单层决策树，我们可以构建出一个能够对该数据集完全正确分类的分类器。 蓝横线上边的是一个类别，蓝横线下边是一个类别。显然，此时有一个蓝点分类错误，计算此时的分类误差，误差为1/5 = 0.2。这个横线与坐标轴的y轴的交点，就是我们设置的阈值，通过不断改变阈值的大小，找到使单层决策树的分类误差最小的阈值。同理，竖线也是如此，找到最佳分类的阈值，就找到了最佳单层决策树。 通过遍历，改变不同的阈值，计算最终的分类误差，找到分类误差最小的分类方式，即为我们要找的最佳单层决策树。这里lt表示less than，表示分类方式，对于小于阈值的样本点赋值为-1，gt表示greater than，也是表示分类方式，对于大于阈值的样本点赋值为-1。经过遍历，我们找到，训练好的最佳单层决策树的最小分类误差为0.2，就是对于该数据集，无论用什么样的单层决策树，分类误差最小就是0.2。这就是我们训练好的弱分类器。接下来，使用AdaBoost算法提升分类器性能，将分类误差缩短到0。此时使用AdaBoost提升分类器性能。MLcode/AdaBoost单层决策树.py at master · zdkswd/MLcode · GitHub 通过改变样本的权值，会改变分类误差率，以选择分类误差率最小的弱选择器。 scikit-learn AdaBoostsklearn.ensemble.AdaBoostClassifier共有五个参数，参数说明。 base_estimator:默认为DecisionTreeClassifier。理论上可以选择任何一个分类或者回归学习器，不过需要支持样本权重。AdaBoostClassifier默认使用CART分类树DecisionTreeClassifier，而AdaBoostRegressor默认使用CART回归树DecisionTreeRegressor。另外有一个要注意的点是，如果我们选择的AdaBoostClassifier算法是SAMME.R，则我们的弱分类学习器还需要支持概率预测，也就是在scikit-learn中弱分类学习器对应的预测方法除了predict还需要有predict_proba。 algorithm：可选参数，默认为SAMME.R。scikit-learn实现了两种Adaboost分类算法，SAMME和SAMME.R。两者的主要区别是弱学习器权重的度量，SAMME使用对样本集分类效果作为弱学习器权重，而SAMME.R使用了对样本集分类的预测概率大小来作为弱学习器权重。由于SAMME.R使用了概率度量的连续值，迭代一般比SAMME快，因此AdaBoostClassifier的默认算法algorithm的值也是SAMME.R。我们一般使用默认的SAMME.R就够了，但是要注意的是使用了SAMME.R， 则弱分类学习器参数base_estimator必须限制使用支持概率预测的分类器。SAMME算法则没有这个限制。 n_estimators：整数型，可选参数，默认为50。弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合，一般选择一个适中的数值。默认是50。在实际调参的过程中，我们常常将n_estimators和下面介绍的参数learning_rate一起考虑。 learning_rate：浮点型，可选参数，默认为1.0。每个弱学习器的权重缩减系数，取值范围为0到1，对于同样的训练集拟合效果，较小的v意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。所以这两个参数n_estimators和learning_rate要一起调参。一般来说，可以从一个小一点的v开始调参，默认是1。 random_state：整数型，可选参数，默认为None。如果RandomState的实例，random_state是随机数生成器; 如果None，则随机数生成器是由np.random使用的RandomState实例。https://github.com/zdkswd/MLcode/tree/master/scikit-learn-code/scikit-learn-AdaBoost","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"Practical Lessons from Predicting Clicks on Ads at Facebook","slug":"Practical Lessons from Predicting Clicks on Ads at Facebook","date":"2018-11-16T07:48:56.000Z","updated":"2018-11-16T07:49:40.000Z","comments":true,"path":"2018/11/16/Practical Lessons from Predicting Clicks on Ads at Facebook/","link":"","permalink":"https://github.com/zdkswd/2018/11/16/Practical Lessons from Predicting Clicks on Ads at Facebook/","excerpt":"","text":"https://dl.acm.org/citation.cfm?id=2648589 摘要在线广告允许广告商只投标和支付可测量的用户响应，比如广告的点击。所以，点击预测系统时大多数广告系统的中心。有超过7.5亿的日活用户和超过一百万的活跃广告商，预测Facebook广告点击是一项有挑战的机器学习任务。这篇论文介绍一个决策树加逻辑回归的组合模型，使用组合模型的效果比单独使用模型的效果提升3%，这会对整体系统的表现的提升产生重大影响。作者探索了一些基础参数怎么影响系统的最终预测表现。不出意外的是，最重要的事情是拥有正确的特征：捕获到的用户和广告的历史信息支配着其他类型的特征。一旦我们有了正确的特征和正确的模型（决策树加逻辑回归），其他的因素就影响很小（虽然小的改进在规模上很重要）。选择对数据新鲜度，学习率模式，和数据采样的最佳处理能够轻微的改变模型，但远不如一开始就选择高价值的特征或选择正确的模型。 介绍这篇论文的目的就是分享用真实世界的数据，并且具有鲁棒性和适应性的实验中得到的见解。 Facebook由于其特殊性，不能使用搜索记录进行广告推荐，而是基于对用户的定位，所以可展示广告的量也更多。Facebook为此建立的级联分类器。这篇文章专注于级联分类器的最后一个阶段点击预测模型，就是这个模型对最终的候选广告集的广告进行预测是否会被点击。12*级联分类器*级联是基于几个分类器的串联的集合学习的特定情况，使用从给定分类器的输出收集的所有信息作为级联中的下一个分类器的附加信息。与投票或堆叠合奏（多专家系统）不同，级联是多阶段的。 实验主要介绍实验计划。实验数据：2013年第4季度任意1周的离线训练数据，与线上数据相似。分为训练集和测试集，并且使用它们模拟在线训练和预测的流数据。论文中实验使用的都是相同的训练/测试数据。 评估指标：Normalized Entropy （NE），NE定义为： 其中yi属于{-1，+1}，p为经验点击通过率CTR（即广告实际点击次数除以广告展示量）。NE在计算相关的信息增益时是至关重要的。上面是逻辑回归的损失函数，也就是交叉熵。下面是个常数，所以越小值，模型越好。 Calibration （刻度标度）：评价估计CTR和经验CTR的比率。即预期点击次数与实际观察点击次数的比率。越接近1模型效果越好。 预测模型结构评估不同的概率线性分类器和不同的在线学习算法。混合模型结构：提升决策树和概率稀疏线性分类器的串联。学习算法是用的是Stochastic Gradient Descent(SGD)，或者Bayesian online learning scheme for probit regression(BOPR)都可以。但是最终选择的是SGD，原因是资源消耗要小一些。SGD和BOPR都可以针对单个样本进行训练，所以他们可以做成流式的学习器(stream learner)。 决策树特征转换对于一个样本，针对每一颗树得到一个类别型特征。该特征取值为样本在树中落入的叶节点的编号。 上图中的提升决策树包含两棵子树，第一棵树包含3个叶节点，第二棵树包含2个叶节点。输入样本x，在两棵树种分别落入叶子节点2和叶子节点1。那么特征转换就得到特征向量[0 1 0 1 0]。也就是说，把叶节点编号进行one-hot编码。 直观的理解这种特征变化： 看做是一种有监督的特征编码。把实值的vector转化为紧凑的二值的vector。 从根节点到叶节点的一条路径，表示的是在特征上的一个特定的规则。所以，叶节点的编号代表了这种规则。表征了样本中的信息，而且进行了非线性的组合变换。 最后再对叶节点编号组合，相当于学习这些规则的权重。 Data freshness一天的数据作为训练集，其后的一天活几天作为测试数据。 可以发现随着天数的增加，data freshness也变得越来越差，模型的性能也越来越差。 一种做法是说每天都重新训练。即使是mini-batch来训练，也会非常耗时。提升树的训练时间受很多因素的影响，比如：样本数量、树深度、树数量、叶子节点个数等。为了加快速度，可以在多CPU上通过并行化来实现。 我们可以： 提升树可以一天或者几天来训练一次。 LR可以实现在线学习，几乎是实时训练。 LR线性分类器针对Logistic Regression进行在线增量训练。也就是说只要用户点击了广告，生成了新的样本，就进行增量训练。 Facebook针对SGD-based online learning研究了5中学习速率的设置方式。 前三种使得不同的参数有不同的学习速率 后两种对于所有的参数都是用相同的学习速率实验结果显示Per-coordinate learning rate效果最好： 线上模型架构最关键的步骤就是把labels(click/no-click)和训练输入(ad impressions)以一种在线的方式连起(join)起来。所以系统被称为online data joiner。label标注首先设定一个足够长的阈值。一个广告展示给用户之后，如果用户在阈值的时间内没有点击广告就标记为no-click，点击了的话就标记为click。这个等待的时间窗口需要非常小心的调整。如果太长了，会增加缓存impression的内存消耗，而且影响实时数据的产生；如果太短了则会导致丢失一部分的点击样本，会影响click converage 点击覆盖。click converage 点击覆盖表示有多少个点击行为被记录了下来生成了样本。online data joiner必须保证尽可能高的点击覆盖，也就是尽可能多的来记录下来所有的点击行为。但是如果等待太久就会增加缓存开销等影响。所以online data joiner必须在click converage和资源消耗之间做出平衡模型架构 处理大量的训练数据很多的计算广告领域的训练数据量都是非常巨大的，那么如何有效的控制训练带来的开销就非常重要。常用的办法是采样均匀采样均匀采样非常的简单，易于实现。而且使用均匀采样没有改变训练数据的分布，所以模型不需要修改就可以直接应用于测试数据。 不同采样率对模型性能的影响： Negative down sampling计算广告中大部分的训练样本都极度不平衡，这对模型会造成很大影响。一种解决办法就是对负样本进行欠采样。 可以看到采样率不同，对模型性能影响很大。采样率为0.025的时候取得最好结果。 Model Re-Calibration负样本欠采样可以加快训练速度并提升模型性能。但是同样带来了问题：改变了训练数据分布。所以需要进行校准。举例来说，采样之前CTR均值为0.1%，使用0.01采样之后，CTR均值变为10%。我们需要对模型进行Calibration(校准)使得模型在实际预测的时候恢复成0.1%。调整公式如下： 其中w是采样率，p是在采样后空间中给出的CTR预估值，计算得到的q就是修正后的结果。 其他实验结果所有的这些探索都是为了能够平衡模型性能(accuracy)和资源消耗(内存、CPU)。只有当你充分了解模型和数据每个部分后，才能根据实际情况做出最佳的取舍。 Number of boosting trees boosting tree数量从1到2000，叶节点个数被限制为最大12个。submodel之间的区别在于训练数据大小的不同，比如submodel 2的训练数据只有前面两个的1/4。可以看到随着boosting tree数量的增加，模型的性能有所提升。但是几乎所有的提升都来自于前500个trees，而后面的1000个trees的提升甚至都不到0.1%。submodel 2在1000颗trees甚至模型效果在变差，原因是过拟合。 Boosting feature importance 上图首先对特征按照重要程度来进行排序，编号后再画图。特征重要程度按照使用该特征进行分裂，所带来的loss减小的累积量。因为一个特征可以在多颗树上进行使用，所以累积要在所有的树上进行。 上图中，黄线表示对特征进行累加后的值，然后进行log变换。可以看到最终结果是1，表示所有特征的重要度总和是1. 最重要的是期初非常陡峭，上升的非常快，说明特征重要度主要集中在top10这些特征中。前10个特征，贡献了50%的重要度，后面300个特征，贡献了1%的重要度。 显然，全部去掉是不行的。说明大量弱特征的累积也是很重要的，但是去掉部分不那么重要的特征，对模型的影响比较小，比如从400到200。 Historical features VS Context features针对两大类特征：历史信息特征（用户+广告）、上下文特征。论文还研究了这两类特征对模型性能的贡献程度。先给出结论：历史信息特征占主导地位。 同样，先把特征按照重要程度排序，再画图。横轴是特征数量，纵轴是historical特征在top k个重要特征中所占的百分比。可以看到前10个特征中，全是历史信息特征；前20个特征中，只有2个上下文特征。所以：历史信息特征比上下文特征重要太多了。 总结Facebook提出的LR + GBDT来提取非线性特征进行特征组合的方式非常经典，主要特性总结如下： Data Freshness很重要。模型至少一天需要重新训练一次 使用Boosted Decision Tree进行特征转换很大程度上提高了模型的性能 最好的在线学习方法：LR + per-coordinate learning rate 关于平衡计算开销和模型性能所采用的技巧： 调整Boosted decision trees数量 去掉部分重要性低的特征，对模型的影响比较小。但是不能全去掉 相比于上下文特征，用户/广告历史特征要重要的多 针对大量训练数据可以进行欠采样","categories":[{"name":"论文","slug":"论文","permalink":"https://github.com/zdkswd/categories/论文/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"回归","slug":"回归","date":"2018-11-16T04:34:47.000Z","updated":"2018-11-16T10:30:09.000Z","comments":true,"path":"2018/11/16/回归/","link":"","permalink":"https://github.com/zdkswd/2018/11/16/回归/","excerpt":"","text":"机器学习升级版 回归线性回归 通过样本拟合直线，线性回归。 做一个理论的假定。 目标函数不就是个最小二乘法了吗。 关于假设： 至于为什么要跟西塔有关，因为在震荡很大的函数中θ系数很大。 Ridge是θ的平方和，LASSO是θ绝对值相加。 L2范数，L1范数与混合。 LASSO有一定的特征选择能力，随着次数的增高，高次项系数趋近于0了。 L1的形式很像拉格拉日乘子法，正方形区域内是可行域，当取最小值时，某些轴上会取0值。推广一下，轴数高了，某些权值是0，也就具有了一定选择能力。 对于L1范数中的λ，就是超参数，我们无法从样本中确定λ的值，只能通过验证数据去选。 这个函数是个凸函数，解出来的一定是全局最小的。可以看到式中的求和符号，所有样本求和下降一回。BSD 式中没有求和符号，一个样本下降一回。SGD，适合做在线学习。适合跳出局部极小值。 mini-batchSGD，简称了SGD，其实这种叫法并不严谨。习惯用语。 我们的线性回归是对参数的线性。对样本无所谓。 Logistic回归分类问题的首选算法，多分类：softmax回归。 这里的目标函数取最大值，因为是最大似然估计。 逻辑回归是一个对数上的线性模型。 若是想让一个几率是线性的函数，反过来求概率，就是逻辑回归的形式。 损失函数就是似然函数取负号。 这个损失函数不那么漂亮，我们可以把它写得漂亮一些。 Softmax回归 关于似然函数的解释：最靠近p的那个乘积由于是one-hot编码所以其实连乘的话只有一项就是表达式其他项均为1。由于是求随机梯度下降，所以可以不管第一个求和符号，目标函数为后一部分。logistic回归中式子中的1其实是e的零次方。 定义信息量 期望的结果就是信息熵。 底无所谓是几，因为有换底公式，无非就是多了个系数。 这个图像说明当两点分布时如果概率相同，熵是最大的。 联合熵和条件熵 相对熵（relative entropy）就是KL散度（Kullback–Leibler divergence），用于衡量两个概率分布之间的差异。相对熵的特点，是只有p(x)=q(x)时，其值为0。若p(x)和q(x)略有差异，其值就会大于0。 假设我们想知道某个策略和最优策略之间的差异，我们就可以用相对熵来衡量这两者之间的差异。即，相对熵 = 某个策略的交叉熵 - 信息熵（根据系统真实分布计算而得的信息熵，为最优策略） 后半部分相当于了一个常数，相对熵达到最小值的时候，也意味着交叉熵达到了最小值。 交叉熵负对数似然就等于交叉熵损失。我们可以把Logstic回归损失叫做交叉熵损失。其中p表示真实分布，q表示非真实分布。p表示真实标记的分布，q则为训练后的模型的预测标记分布。 统计学习方法 逻辑斯蒂回归与最大熵模型逻辑斯蒂回归与最大熵模型都属于对数线性模型。 逻辑斯蒂回归模型逻辑斯蒂分布定义设X是连续随机变量，X服从逻辑斯蒂分布时指X具有下列分布函数和密度函数： u为位置参数，y&gt;0为形状参数。 二项逻辑斯蒂回归模型二项逻辑斯蒂回归模型是一种分类模型，形式为参数化的逻辑斯蒂分布。随机变量X取值为实数，随机变量Y取值为1或0。我们通过监督学习方法来估计模型参数。 定义（逻辑斯蒂回归模型）二项逻辑斯蒂回归模型是如下的条件概率分布： x是输入，Y取{0，1}是输出，w，b是参数，w称为权值向量，b称为偏置。对于输入实例x，逻辑回归比较两个条件概率值的大小，将x分到概率值较大的那一类。 一个事件的几率（odds）指该事件发生的概率与该事件不发生的概率的比值，事件发生的概率为p，则事件的对数几率（log odds）或logit函数是 即输出Y=1的对数几率是由输入x的线性函数表示的模型，即逻辑斯蒂回归模型。换一个角度看，考虑对输入x进行分类的线性函数wx,其值域为实数域。通过逻辑斯蒂回归模型可以将线性函数wx转换为概率： 这时，线性函数的值越接近正无穷，概率值就越接近1，线性函数的值越接近负无穷，概率值就越接近0. 模型参数估计可以应用极大似然估计法估计模型参数，从而得到逻辑斯蒂回归模型。 多项逻辑斯蒂回归假设离散型随机变量Y的取值集合是{1,2,…,K}，那么多项逻辑斯蒂回归模型是： 二项逻辑斯蒂回归的参数估计法也可以推广到多项逻辑斯蒂回归。 最大熵模型最大熵原理是概率模型学习的一个准则.最大熵原理认为，学习概率模型时，在所有可能的概率模型(分布)中，熵最大的模型是最好的模型.通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型. 假设离散随机变量X的概率分布是P（X），则其熵是 当X服从均匀分布时，熵最大。 博客梯度上升算法 z是一个矩阵，θ是参数列向量(要求解的)，x是样本列向量(给定的数据集)。θ^T表示θ的转置。g(z)函数实现了任意实数到[0,1]的映射，这样我们的数据集([x0,x1,…,xn])，不管是大于1或者小于0，都可以映射到[0,1]区间进行分类。hθ(x)给出了输出为1的概率。比如当hθ(x)=0.7，那么说明有70%的概率输出为1。输出为0的概率是输出为1的补集，也就是30%。如果这个概率大于0.5，我们就可以说样本是正样本，否则样本是负样本。 对于正样本，概率越接近一，分类效果越好，对于负样本，1-负样本的值越接近1越好。对于正样本和负样本两个公式合二为一： 为了简化问题，对表达式求对数。 至此，针对一个样本的代价函数已经出来了，假定样本与样本之间相互独立，整个样本集生成的概率即为所有样本生成概率的乘积，再将公式对数化，便得到公式： 满足J(θ)的最大的θ值即是我们需要求解的模型。由于是求最大值，所以我们需要使用梯度上升算法，也就是求负值的最小也就是梯度下降。 逻辑回归的优缺点如何凸显你是一个对逻辑回归已经非常了解的人呢。那就是用一句话概括它！逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的。 逻辑回归应用到工业界中的一些优点： 形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。 模型效果不错。在工程上是可以接受的（作为baseline)，如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。 训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过堆机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。 资源占用小,尤其是内存。因为只需要存储各个维度的特征值。 方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)。 缺点： 准确率并不是很高。因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布。 很难处理数据不平衡的问题。 处理非线性数据较麻烦。逻辑回归在不引进其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题。 逻辑回归本身无法筛选特征。有时候，我们会用gbdt来筛选特征，然后再上逻辑回归。 实践AUC评价分类的指标。 差分与取对数 滑动平均值是从一个有n项的时间序列中来计算多个连续m项序列的平均值。 多项式回归关键词：正则化，get_Variable,sess.runhttps://github.com/zdkswd/myTensorflowExamples/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92.py 逻辑回归与Softmax回归softmax就是多分类的逻辑回归，使用的损失函数是交叉熵，交叉熵就是负的逻辑回归的极大似然估计。softmax成为了激活函数。https://github.com/zdkswd/TensorFlow-Examples/blob/master/examples/2_BasicModels/logistic_regression.py 逻辑回归从博客内容可知，为了使J(θ)最大，就尽可能的分对。https://github.com/zdkswd/MLcode/tree/master/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92这个分类结果相当不错，从上图可以看出，只分错了几个点而已。但是，尽管例子简单切数据集很小，但是这个方法却需要大量的计算(300次乘法)。因此将对改算法稍作改进，从而减少计算量，使其可以应用于大数据集上。 逻辑回归算法的改进梯度上升算法在每次更新回归系数(最优参数)时，都需要遍历整个数据集。假设，我们使用的数据集一共有100个样本。那么，dataMatrix就是一个1003的矩阵。每次计算h的时候，都要计算dataMatrixweights这个矩阵乘法运算，要进行1003次乘法运算和1002次加法运算。同理，更新回归系数(最优参数)weights时，也需要用到整个数据集，要进行矩阵乘法运算。总而言之，该方法处理100个左右的数据集时尚可，但如果有数十亿样本和成千上万的特征，那么该方法的计算复杂度就太高了。因此，需要对算法进行改进，我们每次更新回归系数(最优参数)的时候，能不能不用所有样本呢？一次只用一个样本点去更新回归系数(最优参数)？这样就可以有效减少计算量了，这种方法就叫做随机梯度上升算法。 算法改进的第一点在于alpha在每次迭代都会调整，并且，虽然alpha会随着迭代次数不断减小，但永远不会减小到0，因为这里还存在一个常数项。必须这样做的原因是为了保证在多次迭代之后新数据仍然具有一定的影响。如果需要处理的问题是动态变化的，那么可以适当加大上述常数项，来确保新的值获得更大的回归系数。另一点值得注意的是，在降低alpha的函数中，alpha每次减少1/(j+i)，其中j是迭代次数，i是样本点的下标。第二个改进的地方在于更新回归系数(最优参数)时，只使用一个样本点，并且选择的样本点是随机的，每次迭代不使用已经用过的样本点。这样的方法，就有效地减少了计算量，并保证了回归效果。MLcode/逻辑回归随机梯度下降.py at master · zdkswd/MLcode · GitHub当数据集较小时，我们使用梯度上升算法当数据集较大时，我们使用改进的随机梯度上升算法对应的，在Sklearn中，我们就可以根据数据情况选择优化算法，比如数据较小的时候，我们使用liblinear，数据较大时，我们使用sag和saga。 使用Sklearn构建Logistic回归分类器LogisticRegression这个函数，一共有14个参数：https://cuijiahua.com/blog/2017/11/ml_7_logistic_2.html看文中的参数说明。代码：https://github.com/zdkswd/MLcode/tree/master/scikit-learn-code/sklearn-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92 总结1、Logistic回归的优缺点优点：实现简单，易于理解和实现；计算代价不高，速度很快，存储资源低。缺点：容易欠拟合，分类精度可能不高。2、其他Logistic回归的目的是寻找一个非线性函数Sigmoid的最佳拟合参数，求解过程可以由最优化算法完成。改进的一些最优化算法，比如sag。它可以在新数据到来时就完成参数更新，而不需要重新读取整个数据集来进行批量处理。机器学习的一个重要问题就是如何处理缺失数据。这个问题没有标准答案，取决于实际应用中的需求。现有一些解决方案，每种方案都各有优缺点。我们需要根据数据的情况，这是Sklearn的参数，以期达到更好的分类效果。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"决策树和随机森林","slug":"决策树和随机森林","date":"2018-11-10T12:01:47.000Z","updated":"2018-11-10T12:02:23.000Z","comments":true,"path":"2018/11/10/决策树和随机森林/","link":"","permalink":"https://github.com/zdkswd/2018/11/10/决策树和随机森林/","excerpt":"","text":"机器学习升级版 决策树和随机森林 基于样本和特征的双重随机性。 之所以有那么多种的处理办法，是因为没有某一种是十分有效的。 CARTclassification and regression tree 统计学习方法 决策树决策树( decision tree)是一种基本的分类与回归方法。这里主要是用于分类的决策树.决策树模型呈树形结构,在分类问题中,表示基于特征对实例进行分类的过程。它可以认为是 if-then规则的集合,也可以认为是定义在特征空间与类空间上的条件概率分布。 其主要优点是模型具有可读性,分类速度快。学习时,利用训练数据根据损失函数最小化的原则建立决策树模型。预测时,对新的数据,利用决策树模型进行分类。 决策树学习通常包括3个步骤:特征选择、决策树的生成和决策树的修剪。 决策树模型与学习决策树模型分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点(node)和有向边( directed edge)组成。结点有两种类型:内部结点( internal node)和叶结点( leaf node)。内部结点表示一个特征或属性,叶结点表示一个类。 用决策树分类,从根结点开始,对实例的某一特征进行测试,根据测试结果,将实例分配到其子结点;这时,每一个子结点对应着该特征的一个取值.如此递归地对实例进行测试并分配,直至达到叶结点.最后将实例分到叶结点的类中。 圆代表内部节点，方框代表叶节点。 决策树与if-then规则可以将决策树看成一个 if-then规则的集合.将决策树转换成 if-then规则的过程是这样的:由决策树的根结点到叶结点的每一条路径构建一条规则;路径上内部结点的特征对应着规则的条件,而叶结点的类对应着规则的结论.决策树的路径或其对应的 if-then规则集合具有一个重要的性质:互斥并且完备.这就是说,每一个实例都被一条路径或一条规则所覆盖,而且只被一条路径或一条规则所覆盖.这里所谓覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。 决策树与条件概率分布决策树还表示给定特征条件下类的条件概率分布。假设X为表示特征的随机变量,Y为表示类的随机变量,那么这个条件概率分布可以表示为： X取值与给定划分下单元的集合，Y取值于类的集合。各叶节点上的条件概率往往偏向某一类，即属于某一类的概率较大。决策树分类时将该节点的实例强行分到条件概率大的那一类去。 决策树学习决策树学习本质上是从训练数据集中归纳出一组分类规则。与训练数据集不相矛盾的决策树(即能对训练数据进行正确分类的决策树)可能有多个,也可能一个也没有。我们需要的是一个与训练数据矛盾较小的决策树,同时具有很好的泛化能力。 决策树学习用损失函数表示这一目标,如下所述,决策树学习的损失函数通常是正则化的极大似然函数.决策树学习的策略是以损失函数为目标函数的最小化。 当损失函数确定以后,学习问题就变为在损失函数意义下选择最优决策树的问题,因为从所有可能的决策树中选取最优决策树是NP完全问题,所以现实中决策树学习算法通常采用启发式方法,近似求解这一最优化问题.这样得到的决策树是次最优(sub- optimal)的。 决策树学习的算法通常是一个递归地选择最优特征，并根据该特征对训练数据进行分割，使得对各个子数据集有一个最好的分类的过程。 生成的决策树可能对训练数据有很好的分类能力,但对未知的测试数据却未必有很好的分类能力,即可能发生过拟合现象.我们需要对已生成的树自下而上进行剪枝,将树变得更简单,从而使它具有更好的泛化能力。 如果特征数量很多,也可以在决策树学习开始的时候,对特征进行选择,只留下对训练数据有足够分类能力的特征。 决策树学习算法包含特征选择、决策树的生成与决策树的剪枝过程.由于决策树表示一个条件概率分布,所以深浅不同的决策树对应着不同复杂度的概率模型.决策树的生成对应于模型的局部选择,决策树的剪枝对应于模型的全局选择.决策树的生成只考虑局部最优,相对地,决策树的剪枝则考虑全局最优。 特征选择特征选择问题特征选择在于选取对训练数据具有分类能力的特征.这样可以提高决策树学习的效率.如果利用一个特征进行分类的结果与随机分类的结果没有很大差别,则称这个特征是没有分类能力的,经验上扔掉这样的特征对决策树学习的精度影响不大,通常特征选择的准则是信息增益或信息增益比。 信息增益信息增益的算法输入训练集D和特征A：输出：特征A对训练数据集D的信息增益g(D,A)。 A3，A4类似，最后比较各特征的信息增益值。由于特征A3的信息增益值最大，所以选择特征A3作为最优特征。 信息增益比信息增益比定义 决策树的生成ID3算法ID3算法的核心是在决策树各个结点上应用信息增益准则选择特征,递归地构建决策树.具体方法是:从根结点( root node)开始,对结点计算所有可能的特征的信息增益,选择信息增益最大的特征作为结点的特征,由该特征的不同取值建立子结点;再对子结点递归地调用以上方法,构建决策树;直到所有特征的信息增益均很小或没有特征可以选择为止,最后得到一个决策树.ID3相当于用极大似然法进行概率模型的选择。 算法（ID3算法） ID3算法只有树的生成，所以该算法生成的树容易产生过拟合。而且ID3还存在着不能直接处理连续型特征的问题。只有事先将连续型特征离散化，才能在ID3算法中使用，但这种转换过程会破坏连续型变量的内在特性。 C4.5的生成算法C4.5算法与ID3算法相似，C4.5算法对ID3算法进行了改进。C4.5在生成的过程中，用信息增益比来选择特征。 算法（C4.5的生成算法） 决策树的剪枝决策树生成算法递归地产生决策树,直到不能继续下去为止,这样产生的树往往对训练数据的分类很准确,但对未知的测试数据的分类却没有那么准确,即出现过拟合现象.过拟合的原因在于学习时过多地考虑如何提高对训练数据的正确分类,从而构建出过于复杂的决策树,解决这个问题的办法是考虑决策树的复杂度,对已生成的决策树进行简化。 在决策树学习中将已生成的树进行简化的过程称为剪枝( pruning).具体地,剪枝从已生成的树上裁掉一些子树或叶结点,并将其根结点或父结点作为新的叶结点,从而简化分类树模型。 决策树的剪枝往往通过极小化决策树整体的损失函数或代价函数来实现。设树T的叶节点个数为|T|，t是树T的叶节点，该 C（T）表示模型对训练数据的预测误差，即模型与训练数据的拟合程度，|T|表示模型复杂度，参数α≥0控制两者之间的影响。较大的α促使选择较简单的模型（树），较小的α促使选择较复杂的模型（树）。α=0意味着只考虑模型与训练数据的拟合程度，不考虑模型的复杂度。 剪枝,就是当α确定时,选择损失函数最小的模型,即损失函数最小的子树.当α值确定时,子树越大,往往与训练数据的拟合越好,但是模型的复杂度就越髙;相反,子树越小,模型的复杂度就越低,但是往往与训练数据的拟合不好,损失函数正好表示了对两者的平衡。 算法（树的剪枝算法）输入：生成算法产生的整个树T，参数α；输出：修剪后的子树Tα。 计算每个结点的经验熵。 递归地从树的叶节点向上回缩。 返回2，直至不能继续为止，得到损失函数最小的子树Tα。 式(515)只需考虑两个树的损失函数的差,其计算可以在局部进行,所以,决策树的剪枝算法可以由一种动态规划的算法实现。 CART算法CART：classification and regression treeCART算法有两步： 决策树生成，基于训练数据集生成决策树，生成的决策树要尽量大 决策树剪枝，用验证数据集对已生成的树进行剪枝并选择最优子树，这时用损失函数最小作为剪枝的标准。 CART生成决策树的生成就是递归地构建二叉决策树的过程。对回归树用平方误差最小化准则，对分类树用基尼指数最小化准则，进行特征选择，生成二叉树。 回归树的生成 用人话解释：回归树的原理及Python实现 - 李小文的文章 - 知乎https://zhuanlan.zhihu.com/p/43939904就是把连续的数据分为几个区间，问题的关键就是分割点的选取。 分类树的生成分类树用基尼指数选择最优特征，同时决定该特征的最优二值切分点。 生成方法与ID3决策树类似。 CART剪枝CART剪枝算法从“完全生长”的决策树的底端剪去一些子树，使决策树变小(模型变简单)，从而能够对未知数据有更准确的预测。 CART剪枝算法由两步组成:首先从生成算法产生的决策树To底端开始不断剪枝,直到To的根结点，形成一个子树序列{T1,…,Tn};然后通过交叉验证法在独立的验证数据集上对子树序列进行测试，从中选择最优子树。 剪枝，形成一个子树序列在剪枝过程中，计算子树的损失函数: T为任意子树，C（T）为训练数据的预测误差（如基尼指数），|T|为子树的叶节点个数，α≥0为参数，Cα（T）为参数是α时的子树T的整体损失。参数α权衡训练数据的拟合程度与模型的复杂度。 对固定的α,一定存在使损失函数C(T)最小的子树，将其表示为Tα. Tα在损失函数Cα(T)最小的意义下是最优的.容易验证这样的最优子树是唯一的.当α大的时候，最优子树Tα偏小;当α小的时候，最优子树Tα偏大. 极端情况，当α=0时，整体树是最优的，当α趋近正无穷时，根结点组成的单结点树是最优的. 从整体树T0开始剪枝，对T0的任意内部节点t，以t为单结点树的损失函数是 以t为根结点的子树Tt的损失函数是 当α=0及α充分小时，有不等式 当α增大时，在某一α有 当α再增大时，不等式反向。只要 Tt与t有相同的损失函数值，而t的节点少，因此t比Tt更可取，对Tt进行剪枝。 为此，对T0中每一内部结点t，计算 它表示剪枝后整体损失函数减少的程度.在T0中剪去g(t)最小的Tt,将得到的子树作为T1，同时将最小的g(t)设为α1. T1为区间[α1,α2)的最优子树. 如此剪枝下去，直到得到根节点。在这一过程中，不断增加α的值，产生新的区间。 在剪枝得到的子树序列T0,T1,…,Tn中通过交叉验证选取最优子树Tα具体地，利用独立的验证数据集，测试子树序列T0,T1,…,Tn中各棵子树的平方误差或基尼指数.平方误差或基尼指数最小的决策树被认为是最优的决策树.在子树序列中，每棵子树T1,T2,.,Tn都对应于一个参数α1,α2,…,αn,.所以，当最优子树Tk确定时，对应的ak也确定了，即得到最优决策树Tα。 CART剪枝算法 西瓜书 树剪枝可以采用留出法，即预留一部分数据用作“验证集”以进行性能评估。 预剪枝 预剪枝使得决策树的很多分支都没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。但在另一方面，有些分支的当前划分虽不能提高泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高；预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策树带来了欠拟合的风险。 后剪枝后剪枝先从训练集生成一颗完整决策树。 对比可得，后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般来说，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶节点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大。 博客回归树： 回归树与线性回归的对比： 西瓜书 Bagging与随机森林欲得到泛化性能强的集成,集成中的个体学习器应尽可能相互独立;虽然“独立”在现实任务中无法做到，但可以设法使基学习器尽可能具有较大的差异.给定一个训练数据集,一种可能的做法是对训练样本进行采样，产生出若干个不同的子集，再从每个数据子集中训练出一个基学习器.这样，由于训练数据不同,我们获得的基学习器可望具有比较大的差异.然而，为获得好的集成，我们同时还希望个体学习器不能太差.如果采样出的每个子集都完全不同，则每个基学习器只用到了一小部分训练数据，甚至不足以进行有效学习,这显然无法确保产生出比较好的基学习器.为解决这个问题，我们可考虑使用相互有交叠的采样子集. BaggingBagging是并行式集成学习最著名的代表，直接基于自助采样法（bootstrap sampling）。给定包含m个样本的数据集,我们先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中,这样,经过m次随机采样操作,我们得到含m个样本的采样集，初始训练集中有的样本在采样集里多次出现，有的则从未出现，由式(2.1)可知, 初始训练集中约有63.2%的样本出现在采样集中. 我们可采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合.这就是Bagging的基本流程.在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法.若分类预测时出现两个类收到同样票数的情形,则最简单的做法是随机选择一个,也可进一步考察学习器投票的置信度来确定最终胜者. 自助采样过程还给Bagging带来了另一个优点:由于每个基学习器只使用了初始训练集中约63.2%的样本,剩下约36.8%的样本可用作验证集来对泛化性能进行“包外估计”。 包外样本还有许多其他用途.例如当基学习器是决策树时，可使用包外样本来辅助剪枝,或用于估计决策树中各结点的后验概率以辅助对零训练样本结点的处理;当基学习器是神经网络时，可使用包外样本来辅助早期停止以减小过拟合风险. 从偏差方差分解的角度看，Bagging主要关注降低方差，因此它在不剪枝决策树、神经网络等易受样本扰动的学习器上效用更为明显。 随机森林随机森林(Random Forest,简称RF) 是Bagging的一个扩展变体. RF在以决策树为基学习器构建Bagging集成的基础上,进一步在决策树的训练过程中引入了随机属性选择.具体来说，传统决策树在选择划分属性时是在当前结点的属性集合(假定有d个属性)中选择一个最优属性;而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这里的参数k控制了随机性的引入程度。若k=d则基决策树的构建与传统决策树相同，一般，推荐k=log2d。 随机森林简单、容易实现、计算开销小，令人惊奇的是，它在很多现实任务中展现出强大的性能,被誉为“代表集成学习技术水平的方法”.可以看出，随机森林对Bagging只做了小改动,但是与Bagging中基学习器的“多样性”仅通过样本扰动(通过对初始训练集采样)而来不同，随机森林中基学习器的多样性不仅来自样本扰动,还来自属性扰动，这就使得最终集成的泛化性能可通过个体学习器之间差异度的增加而进一步提升. 随机森林的收敛性与Bagging相似，起始性能往往相对较差，特别是在集成中只包含一个基学习器时。这不难理解，因为通过引入属性扰动，随机森林中个体学习器的性能往往有所降低，但是随着个体学习器数目的增加，随机森林通常会收敛到更低的泛化误差值得一提的是,随机森林的训练效率常优于Bagging,因为在个体决策树的构建过程中, Bagging使用的是“确定型”决策树,在选择划分属性时要对结点的所有属性进行考察，而随机森林使用的“随机型”央策树则只需考察一个属性子集. 结合策略学习器结合的好处学习器结合会带来三个方面的好处： 统计方面，可能有多个假设在训练集上达到同等性能，此时若使用单学习器可能会因为误选而导致泛化性能不佳，结合多个学习器则会减小这一风险。 计算方面，学习算法往往会陷入局部极小,有的局部极小点所对应的泛化性能可能很糟糕，而通过多次运行之后进行结合，可降低陷入糟糕局部极小点的风险。 表示方面，某些学习任务的真实假设可能不在当前学习算法所考虑的假设空间中，此时若使用单学习器则肯定无效,而通过结合多个学习器，由于相应的假设空间有所扩大，有可能学得更好的近似。平均法对于数值型输出，最常见的就是平均法。简单平均法 加权平均法 加权平均法的权重一般是从训练数据中学习而得，现实任务中的训练样本通常不充分或存在噪声，这将使得学出的权重不完全可靠.尤其是对规模比较大的集成来说，要学习的权重比较多,较容易导致过拟合.因此,实验和应用均显示出，加权平均法未必一定优于简单平均法.一般而言,在个体学习器性能相差较大时宜使用加权平均法，而在个体学习器性能相近时宜使用简单平均法.投票法绝对多数投票法即若某标记得票过半数，则预测为该标记，否则拒绝预测。相对多数投票法即预测为得票最多的标记，若同时又多个标记获最高票，则从中随机选取一个。加权投票法与加权平均法类似。 标准的绝对多数投票法提供了“拒绝预测”选项,这在可靠性要求较高的学习任务中是一个很好的机制.但若学习任务要求必须提供预测结果，则绝对多数投票法将退化为相对多数投票法.因此,在不允许拒绝预测的任务中,绝对多数、相对多数投票法统称为“多数投票法”。 硬投票：输出预测的类标记，软投票，输出一个概率估计。 实践决策树算法实现。背景：贷款放贷与否https://github.com/zdkswd/MLcode/blob/master/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%86%B3%E7%AD%96%E6%A0%91.py scikit-learn决策树使用scikit-learn实现。背景：配隐形眼镜https://github.com/zdkswd/MLcode/tree/master/scikit-learn-code/scikit-learn%E5%86%B3%E7%AD%96%E6%A0%91 回归树关键词：CART，预剪枝，后剪枝 回归树与分类树比较类似，不同的是分类树最后的决策的结果是离散型的值，回归树决策的结果是输出一个实数。实例中的实数输出（就是叶子节点）的是四个样本的平均值（四个样本是在进行预剪枝时设置的值）。 CART回归树这里使用最小总方差法选取划分特征。示例中采用的是REP（错误率降低剪枝）。还有一种方法叫做PEP（悲观剪枝）把一颗子树（具有多个叶子节点）用一个叶子节点来替代的话，比起REP剪枝法，它不需要一个单独的测试数据集。 本例中既有预剪枝又有后剪枝。一般来说都是结合着使用。 背景：连续数据的离散的点https://github.com/zdkswd/MLcode/tree/master/%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/%E5%9B%9E%E5%BD%92%E6%A0%91 scikit-learn随机森林待解决问题，在scikit-learn的随机森林中如何决定k值。https://github.com/zdkswd/MLcode/blob/master/scikit-learn-code/scikit-learn%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97.py","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"scikit-learn介绍","slug":"scikit-learn介绍","date":"2018-11-08T07:56:56.000Z","updated":"2018-11-12T09:30:11.000Z","comments":true,"path":"2018/11/08/scikit-learn介绍/","link":"","permalink":"https://github.com/zdkswd/2018/11/08/scikit-learn介绍/","excerpt":"","text":"机器学习：问题背景学习问题分以下几类： 有监督学习分类回归无监督学习聚类，密度估计等 加载示例数据集有几个标准数据集，鸢尾花和手写字用于分类，以及波士顿房价数据集用于回归。鸢尾花与手写字数据集的导入。 数据集就是一个字典对象，包含了所有的数据以及一些关于数据的元数据。数据存储在.data成员中，它是一个n个样本，n个特征的数组。在监督学习的问题中，因变量存在.target成员中。 数据数组的形状数据总是二维数组，（n_sample,n_features）的形状，即使原始数据可能有着不同的形状。在手写字识别中，每个原始例子是（8 * 8）。 但是在data中变成了（1 * 64）。 学习以及预测在scikit-learn中，分类器是一个实现了方法fit(x,y)和predict(T)的Python对象。 先把分类器当做是一个黑盒。 选择模型的参数在这个例子中我们是人工选择的参数，为了寻找这些参数的更好的值，我们能使用例如网格搜索和交叉验证的工具。 分类器实例拟合模型是通过传递训练集给fit方法。对于训练集，我们使用除了最后一张图片的所有图片，最后一张图片用来做预测。 来预测： 模型持久化使用pickle。 使用joblib，joblib在大数据方面更加高效，但是遗憾的是它只能把数据持久化到硬盘而不是字符串（搬到字符串意味着数据在内存中）。 之后可以重新加载模型（也可以在其他的Python进程中） 注意：joblib.dump和joblib.load也接收像文件一样的对象而不是文件名。 惯例类型转换除非特别指明，输入将被转换为float64: x是float32型，可以通过fit_transform(x)转换为float64。 回归的目标类型转化为float64，分类的目标类型保留下来。 改装和更新参数超参数在通过set_params()方法创建后能够更新。调用fit()函数超过一次将会重写之前fit()所学的内容。 多类别vs多标签拟合当使用多类别分类器，所执行的学习和预测任务取决于适合于目标数据的格式。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"TensorFlow基础知识上","slug":"TensorFlow基础知识上","date":"2018-11-04T10:56:41.000Z","updated":"2018-11-05T04:51:56.000Z","comments":true,"path":"2018/11/04/TensorFlow基础知识上/","link":"","permalink":"https://github.com/zdkswd/2018/11/04/TensorFlow基础知识上/","excerpt":"","text":"系统架构 自底向上为设备层和网络层、数据操作层、图计算层、API层、应用层。 其中设备层和网络层、数据操作层、图计算层是TensorFlow的核心层。 网络通信层和设备管理层网络通信层包括gRPC( google Remote Procedure Call Protocol)和远程直接数据存取( Remote direct Memory Access,RDMA),这都是在分布式计算时需要用到的。设备管理层包括 TensorFlow分别在CPU、GPU、FPGA等设备上的实现,也就是对上层提供了一个统一的接口,使上层只需要处理卷积等逻辑,而不需要关心在硬件上的卷积的实现过程。 数据操作层主要包括卷积函数、激活函数等操作。 图计算层（了解的核心）包含本地计算图和分布式计算图的实现。 API层和应用层设计理念TensorFlow的设计理念主要体现在以下两个方面。 将图的定义和图的运行完全分开编程模式通常分为命令式编程和符号式编程。命令式编程就是我们理解的通常意义上的程序，很容易理解和调试，按照原有的逻辑执行。符号式编程涉及很多的嵌入和优化,不容易理解和调试,但运行速度相对有所提升。现有的深度学习框架中, Torch是典型的命令式的,Cafe、 MXNet采用了两种编程模式混合的方法,而 TensorFlow完全釆用符号式编程。 符号式计算一般是先定义各种变量,然后建立一个数据流图,在数据流图中规定各个变量之间的计算关系,最后需要对数据流图进行编译,但此时的数据流图还是一个空壳儿,里面没有任何实际数据,只有把需要运算的输入放进去后,才能在整个模型中形成数据流,从而形成输出值。 在传统的程序操作中,定义了t的运算,在运行时就执行了,并输出17。而在TensorFlow中,数据流图中的节点,实际上对应的是 Tensor Flow APi中的一个操作,并没有真正去运行: TensorFlow中涉及的运算都要放在图中,而图的运行只发生在会话( session)中开启会话后,就可以用数据去填充节点,进行运算;关闭会话后,就不能进行计算了。因此,会话提供了操作运行和 Tensor求值的环境。 编程模型边TensorFlow的边有两种连接关系:数据依赖和控制依赖。 实线边表示数据依赖代表数据，即张量。任意纬度的数据统称为张量。在机器学习算法中，张量在数据流图中从前往后流动一遍就完成了一次前向传播，而残差从后向前流动一遍就完成了一次反向传播。（在数理统计中，残差是指实际观察值与训练的估计值之间的差。） 虚线边表示控制依赖（control dependency ）可以用于控制操作的运行，这被确保happens-before关系，这类边上没有数据流过，但源节点必须在目的节点开始执行前完成执行。 TensorFlow 支持的张量具有表 4-1 所示的数据属性。 节点图中的节点又称为算子，它代表一个操作(operation，OP)，一般用来表示施加的数学运算，也可以表示数据输入(feed in)的起点以及输出(push out)的终点，或者是读取/写入持久变量(persistent variable)的终点。 表 4-2 列举了一些 TensorFlow 实现的算子。算子支持表 4-1 所示的张量的各种数据属性，并且需要在建立图的时候确定下来。 与操作相关的代码位于 tensorflow-1.1.0/tensorflow_python_ops_目录下。以数学运算为例，代 码为上述目录下的 math_ops.py，里面定义了 add、subtract、multiply、scalar_mul、div、divide、 truediv、floordiv 等数学运算，每个函数里面调用了 gen_math_ops.py 中的方法，这个文件是在 编译(安装时)TensorFlow 时生成的，位于 Python 库 site-packages_tensorflow_python_ops_gen_ math_ops.py 中，随后又调用了 tensorflow-1.1.0_tensorflow_core_kernels/下面的核函数实现。 其他概念图把操作任务描述成有向无环图。构建图的第一步是创建各个节点。 会话启动图的第一步是创建一个 Session对象。会话( session)提供在图中执行操作的一些方法。一般的模式是,建立会话,此时会生成一张空图,在会话中添加节点和边,形成一张图,然后执行。 要创建一张图并运行操作的类,在 Python的API中使用tf. Session,在C++的API中使用tensorflow: Session。 在调用 Session对象的run（）方法来执行图时,传入一些 Tensor,这个过程叫填充(feed)返回的结果类型根据输入的类型而定,这个过程叫取回( fetch)。 与会话相关的源代码位于 tensorfow-11.0/ tensorfow/ python/ client/session. py。 会话是图交互的一个桥梁,一个会话可以有多个图,会话可以修改图的结构,也可以往图中注入数据进行计算。因此,会话主要有两个AP接口: Extend和Run。 Extend操作是在 Graph中添加节点和边,Run操作是输入计算的节点和填充必要的数据后,进行运算,并输出运算结果。 设备设备（device）是指一块可以用来运算并且拥有自己的地址空间的硬件，如GPU和CPU。 TensorFlow为了实现分布式执行操作,充分利用计算资源,可以明确指定操作在哪个设备上执行。 与设备相关的源代码位于 tensorfow-1.1.0 tensorflow_python_ framework/device. py。 变量变量( variable）是一种特殊的数据,它在图中有固定的位置,不像普通张量那样可以流动。例如,创建一个变量张量,使用tf.Variable()构造函数,这个构造函数需要一个初始值,初始值的形状和类型决定了这个变量的形状和类型。 创建一个常量张量： TensorFlow还提供了填充机制,可以在构建图时使用tf.placeholder临时替代任意操作的张量,在调用 Session对象的run（）方法去执行图时,使用填充数据作为调用的参数,调用结束后,填充数据就消失。 与变量相关的源代码位于 tensorflow/ tensorflow/ python_ops_ variables. py。 内核我们知道操作( operation)是对抽象操作(如 matmul或者ad)的一个统称,而内核( kemel)则是能够运行在特定设备(如CPU、GPU)上的一种对操作的实现。因此,同一个操作可能会对应多个内核。 常用API图、操作和张量与图相关的API均位于tf.Graph类中。 tf.Operation类代表图中的一个节点，用于计算张量数据。该类型由节点构造器（如tf.matmul()或者Graph.create_op()）产生。例如，c=tf.matmul(a,b)创建一个Operation类，其类型为MatMul的操作类。与操作相关的API均位于tf.Operation类中。 tf.Tensor类是操作输出的符号句柄,它不包含操作输出的值,而是提供了一种在tf.Session中计算这些值的方法。这样就可以在操作之间构建一个数据流连接,使 TensorFlow能够执行一个表示大量多步计算的图形。与张量相关的API均位于tf.Tensor类中。 变量作用域在 TensorFlow中有两个作用域( scope),一个是 name_scope,另一个是 variable_scope。简而言之, name_scope主要是给 variable_name加前缀,也可以给 op_ name加前缀; name_scope是给 op_name加前缀。 variable_scopevariable_scope变量作用域机制在 TensorFlow中主要由两部分组成: 创建或是返回一个变量，或是为变量指定命名空间。 当 tf. get_variable_scope. reuse==False时, variable_scope作用域只能用来创建新变量: 上述程序会抛出ValueError错误，因为v这个变量已经被定义过了，但tf.get_variable_scope().reuse默认为False，所以不能重用。 当tf.get_variable_scope().reuse=True时,作用域可以共享变量: 获取变量作用域可以直接通过 tf.variable_scope()来获取变量作用域: 如果在开启的一个变量作用域里使用之前预先定义的一个作用域,则会跳过当前变量的作用域,保持预先存在的作用域不变。 变量作用域的初始化变量作用域可以默认携带一个初始化器,在这个作用域中的子作用域或变量都可以继承或者重写父作用域初始化器中的值。 在variable_scope作用域下的操作op_name也会被加上前缀。 variable scope主要用在循环神经网络(RNN)的操作中,其中需要大量的共享变量。 name_scope示例TensorFlow中常常会有数以千计的节点,在可视化的过程中很难一下子展示出来,因此用name_scope为变量划分范围,在可视化中,这表示在计算图中的一个层级。name_scope会影响op_name,不会影响get_variableo创建的变量,而会影响通过 Variableo创建的变量。 批标准化批标准化( batch normalization,BN)是为了克服神经网络层数加深导致难以训练而诞生的我们知道,深度神经网络随着网络深度加深,训练起来会越来越困难,收敛速度会很慢,常常会导致梯度弥散问题( vanishing gradient problem)。 统计机器学习中有一个ICS( Internal Covariate shift)理论,这是一个经典假设:源域( source domain)和目标域( target domain)的数据分布是一致的。也就是说,训练数据和测试数据是满足相同分布的。这是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。 Covariate shift是指训练集的样本数据和目标样本集分布不一致时,训练得到的模型无法很好地泛化( generalization)。它是分布不一致假设之下的一个分支问题,也就是指源域和目标域的条件概率是一致的,但是其边缘概率不同。的确,对于神经网络的各层输出,在经过了层内操作后,各层输出分布就会与对应的输入信号分布不同,而且差异会随着网络深度增大而加大,但是每一层所指向的样本标记( label)仍然是不变的。 解决思路一般是根据训练样本和目标样本的比例对训练样本做一个矫正。因此，通过引入批标准化来规范化某些层或者所有层的输入，从而固定每层输入信号的均值与方差。 方法批标准化一般用在非线性映射(激活函数)之前,对x=Wu+b做规范化,使结果(输出信号各个维度)的均值为0,方差为1。让每一层的输入有一个稳定的分布会有利于网络的训练。 优点批标准化通过规范化让激活函数分布在线性区间,结果就是加大了梯度,让模型更加大胆地进行梯度下降,于是有如下优点： 加大探索的步长，加快收敛的速度。 更容易跳出局部最小值。 破坏原来的数据分布，一定程度上缓解过拟合。 在遇到神经网络收敛速度很慢或梯度爆炸等无法训练的情况下，都可以尝试用批标准化来解决。 示例对每层的Wx_plus_b进行批标准化，这个步骤在激活函数之前。 规范化，也可以称为标准化，是将数据按比例缩放，使之落在一个小的特定区间。这里是指数据减去平均值，再除以标准差。 tf.add(a, b) 与 a+b","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://github.com/zdkswd/tags/TensorFlow/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"Python数据科学手册 Matplotlib数据可视化","slug":"Python数据科学手册 Matplotlib数据可视化","date":"2018-11-01T13:00:56.000Z","updated":"2018-11-01T13:04:58.000Z","comments":true,"path":"2018/11/01/Python数据科学手册 Matplotlib数据可视化/","link":"","permalink":"https://github.com/zdkswd/2018/11/01/Python数据科学手册 Matplotlib数据可视化/","excerpt":"","text":"Matplotlib是建立在 NumPy数组基础上的多平台数据可视化程序库。 Matplotlib最重要的特性之一就是具有良好的操作系统兼容性和图形显示底层接口兼容性( graphics backend)。 Matplotlib支持几十种图形显示接口与输出格式,这使得用户无论在哪种操作系统上都可以输出自己想要的图形格式。这种跨平台、面面俱到的特点已经成为 Matplotlib最强大的功能之一, Matplotlib也因此吸引了大量用户,进而形成了一个活跃的开发者团队,晋升为 Python科学领域不可或缺的强大武器。 Matplotlib常用技巧导入 Matplotlib 设置绘图样式 用不用show()?如何显示图形在脚本中画图如果你在一个脚本文件中使用 Matplotlib,那么显示图形的时候必须使用plt.show()。plt.show()会启动一个事件循环( event lop),并找到所有当前可用的图形对象,然后打开一个或多个交互式窗口显示图形。 plt,show()这行代码在后面完成了许多事情,它需要与你使用的操作系统的图形显示接口进行交互。虽然具体的操作细节会因操作系统和安装过程不同而有很大的差异,但是 Matplotlib为你隐藏所有的细节,非常省心。 不过有一点需要注意,一个 Python会话( session)中只能使用一次plt.show(),因此通常都把它放在脚本的最后。多个plt.show()命令会导致难以预料的显示异常,应该尽量避免。 在IPython shell中画图在IPython Notebook中画图将图形保存为文件 当你保存图形文件时,不需要使用plt.show()。 两种画图接口 Matplotlib有一个容易让人混淆的特性,就是它的两种画图接口,一个是便捷的 MATLAB风格接口,另一个是功能更强大的面向对象接口。 MATLAB风格接口Matplotlib最初作为 MATLAB用户的 Python替代品,许多语法都和MATLAB类似。 MATLAB风格的工具位于 pyplot(plt)接口中。 这种接口最重要的特性是有状态的( stateful):它会持续跟踪“当前的图形和坐标轴,所有plt命令都可以应用。你可以用plt.gcf()(获取当前图形)和plt,gca()(获取当前坐标轴)来查看具体信息。 虽然这个有状态的接口画起来图又快又方便，但是也很容易出问题。当创建上面的第二个子图时,怎么才能回到第一个子图,并增加新内容呢?虽然用 MATLAB风格接口也能实现,但未免过于复杂,好在还有一种更好的办法! 面向对象接口面向对象接口可以适应更复杂的场景,更好地控制你自己的图形。在面向对象接口中,画图函数不再受到当前“活动”图形或坐标轴的限制,而变成了显式的 Figure和Axes的方法。 虽然在画简单图形时,选择哪种绘图风格主要看个人喜好,但是在画比较复杂的图形时,面向对象方法会更方便。在本章中,我们将在MATLAB风格接口与面向对象接口间来回转换,具体内容根据实际情况而定。在绝大多数场中,plt.plot()与ax.plot()的差异非常小,但是其中会有一些陷阱。 简易线形图 在 Matplotlib里面, figure(plt.Figure类的一个实例)可以被看成是个能够容纳各种坐标轴、图形、文字和标签的容器。就像你在图中看到的那样,axes(plt.Axes类的一个实例)是一个带有刻度和标签的矩形,最终会包含所有可视化的图形元素。 调整图形：线条的颜色与风格 如果不指定颜色, Matplotlib就会为多条线自动循环使用一组默认的颜色。 与之类似，也可以用linestyle调整线条的风格。 一种更简洁的方式,则可以将linstyle和 color编码组合起来,作为plt.plot()函数的一个非关键字参数使用。 调整图形：坐标轴上下限 如果你想要让坐标轴逆序显示,那么也可以逆序设置坐标轴刻度值。 还有一个方法是plt,axis()(注意不要搞混axes和axis)。通过传入[xmin,xmax,ymin,ymax]对应的值,plt,axis()方法可以让你用一行代码设置x或y的限值。 plt axis（）还可以按照图形的内容自动收紧坐标轴，不留空白区域。 还可以xy轴单位长度相等。 设置图形标签图形标题与坐标轴标题是最简单的标签。 Matplotlib内置了一个简单快速的方法,可以用来创建图例,那就是plt. legend()。 在用面向对象接口画图时，不需要单独调用这些函数，通常采用ax.set()方法一次性设置所有的属性是更简便的方法。 简易散点图另一种常用的图形是简易散点图( scatter plot),与线形图类似。这种图形不再由线段连接,而是由独立的点、圆圈或其他形状构成。开始的时候需要导入函数。 用plt.plot画散点图 函数的第三个参数是一个字符，表示图形符号的类型。 这些代码还可以与线条、颜色代码组合起来，画出一条连接散点的线。 用plt.scatter画散点图另一个可以创建散点图的函数是plt.scatter。它的功能非常强大其用法与plt.plot函数类似。 plt scatter与p1t.plot的主要差别在于,前者在创建散点图时具有更高的灵活性,可以单独控制每个散点与数据匹配,也可以让每个散点具有不同的属性(大小、表面颜色、边框颜色、透明度等)。 plot与scatter：效率对比plt.plot与plt.scatter除了特征上的差异之外,还有什么影响我们选择的因素呢?在数据量较小的时候,两者在效率上的差异不大。但是当数据变大到几千个散点时,plt.plot的效率将大大高于plt.scatter。这是由于plt.scatter会对每个散点进行单独的大小与颜色的渲染,因此渲染器会消耗更多的资源。而在plt.plot中,散点基本都彼此复制,因此整个数据集中所有点的颜色、尺寸只需要配置一次。由于这两种方法在处理大型数据集时有很大的性能差异,因此面对大型数据集时,plt.plot方法比plt.scatter方法好。 可视化异常处理基本误差线基本误差线( errorbar)可以通过一个 Matplotlib函数来创建。 除了这些选项之外,你还可以设置水平方向的误差线(xerr)、单侧误差线( one-sided errorbar),以及其他形式的误差线。 连续误差密度图与等高线图Matplotlib提供了三个函数来解决这个问题:用plt.contour画等高线图、用plt.contourf画带有填充色的等高线图( filled contour plot)的色彩、用plt.imshow显示图形。 三维函数的可视化 当图形中只使用一种颜色时,默认使用虚线表示负数,使用实线表示正数。我们可以通过plt.contourf()函数来填充等高线图，它的语法和plt.contour()是一样的。 还可以通过plt. colorbar()命令自动创建一个表示图形各种颜色对应标签信息的颜色条。但是图形还有一点不尽如人意的地方,就是看起来有点儿“污渍斑斑“不是那么干净。这是由于颜色的改变是一个离散而非连续的过程,这并不是我们想要的效果。你当然可以通过将等高线的数量设置得非常多来解决这个问题,但是最终获得的图形性能会很不好,因为 Matplotlib必须渲染每一级的等高线。其实有更好的做法,那就是通过plt.imshow()函数来处理,它可以将二维数组渲染成渐变图。 使用imshow（）函数有一些注意事项。 plt.imshow()不支持用x轴和y轴数据设置网格，而是必须通过extent参数设置图形的坐标范围[xmin,xmax,ymin,ymax]。 plt.imshow()默认使用标准的图形数组定义，就是原点位于左上角，而不是绝大多数等高线图中使用的左下角，这一点在显示网格数据图形时必须调整。 plt.imshow()会自动调整坐标轴的精度以适应数据显示。可以通过plt.axis(aspect=‘image’)来设置x轴与y轴的单位。 频次直方图、数据区间划分和分布密度 hist()有许多用来调整计算过程和显示效果的选项。 histtype=‘ stepfilled’与透明性设置参数 alpha搭配使用的效果: 二维频次直方图与数据区间划分就像将一维数组分为区间创建一维频次直方图一样,我们也可以将二维数组按照二维区间进行切分,来创建二维频次直方图。 plt.hist2d:二维频次直方图 plt.hist2d类似的函数式np.histogram2d。 plt.hexbin:六边形区间划分二维频次直方图是由于坐标轴正交的方块分割而成的，还有一种常用的方式是用正六边形分割。Matplotlib提供的plt.hexbin满足此类需求，将二维数据集分割成蜂窝状。 核密度估计有一种评估多维数据分布密度的常用方法是核密度估计KDE。KDE方法通过不同的平滑带宽长度( smoothing length)在拟合函数的准确性与平滑性之间作出权衡(无处不在的偏差与方差的取舍问题的一个例子)。想找到恰当的平滑带宽长度是件很困难的事, gaussian_kde通过一种经验方法试图找到输入数据平滑长度的近似最优解。 配置图例设置图例的位置，并取消外框。 还可以用ncol参数设置图例的标签列数。还可以为图例定义圆角边框( fancybox)、增加阴影、改变外边框透明度( framealpha值),或者改变文字间距。 选择图例显示的元素图例会默认显示所有元素的标签。如果你不想显示全部,可以通过一些图形命令来指定显示图例中的哪些元素和标签。plt.plot()命令可以一次创建多条线,返回线条实例列表。一种方法是将需要显示的线条传入plt.legend(),另一种方法是只为需要在图例中显示的线条设置标签。默认情况下图例会忽略那些不带标签的元素。 在图例中显示不同尺寸的点同时显示多个图例我们可以通过从头开始创建一个图例艺术家对象（legend artist），然后用底层的（lower-level）ax.add_artiest()方法在图上添加第二个图例。 配置颜色条在Matplotlib中，颜色条是一个独立的坐标轴，可以指明图形中颜色的含义。 配置颜色条可以通过cmap参数为图形设置颜色条的配色方案。 选择配色方案顺序配色方案由一组连续的颜色构成的配色方案(例如 binary或viridis)。 互逆配色方案通常由两种互补的颜色构成,表示正反两种含义(例如RdBu或PuOr)。 定性配色方案随机顺序的一组颜色(例如 rainbow或jet)。 颜色条刻度的限制与扩展功能的设置Matplotlib提供了丰富的颜色条配置功能。由于可以将颜色条本身仅看作是一个plt.Axes实例,因此前面所学的所有关于坐标轴和刻度值的格式配置技巧都可以派上用场。 离散型颜色条虽然颜色条默认都是连续的,但有时你可能也需要表示离散数据。最简单的做法就是使用plt.cm.get_cmap()函数,将适当的配色方案的名称以及需要的区间数量传进去即可。 多子图plt.axes:手动创建子图创建坐标轴最基本的方法就是使用p1t.axes函数。前面已经介绍过,这个函数的默认配置是创建一个标准的坐标轴,填满整张图。它还有个可选参数,由图形坐标系统的四个值构成。这四个值分别表示图形坐标系统的[bottom,Left, width, height](底坐标、左坐标、宽度、高度),数值的取值范围是左下角(原点)为0,右上角为1。 如果想要在右上角创建一个画中画,那么可以首先将x与y设置为0.65(就是坐标轴原点位于图形高度65%和宽度65%的位置),然后将x与y扩展到0,2(也就是将坐标轴的宽度与高度设置为图形的20%)。 面向对象画图接口中类似的命令有fig.add_axes()。 plt.subplot:简易网格子图最底层的方法是用plt.subplot()在一个网格中创建一个子图。这个命令有三个整型参数—将要创建的网格子图行数、列数和索引值,索引值从1开始,从左上角到右下角依次增大。 plt.subplots_adjust命令可以调整子图之间的间隔。用面向对象接口的命令fig.ad_subplot()可以取得同样的效果。 plt.subplots:用一行代码创建网格想隐藏内部子图的x轴与y轴标题时。出于这一需求,plt.subplots()实现了你想要的功能(需要注意此处 subplots结尾多了个s)。这个函数不是用来创建单个子图的,而是用一行代码创建多个子图,并返回一个包含子图的 NumPy数组。关键参数是行数与列数,以及可选参数 sharex与 sharey,通过它们可以设置不同子图之间的关联关系。 设置 sharex与 sharey参数之后,我们就可以自动去掉网格内部子图的标签,让图形看起来更整洁。坐标轴实例网格的返回结果是一个NumPy数组,这样就可以通过标准的数组取值方式轻松获取想要的坐标轴了。 与plt.subplot()相比,p1t. subplots()与 Python索引从0开始的习惯保持一致。 plt.Gridspec:实现更复杂的排列方式如果想实现不规则的多行多列子图网格,plt. Gridspec()是最好的工具。plt.Gridspec()对象本身不能直接创建一个图形,它只是plt.subplot()命令可以识别的简易接口。 文字与注释坐标变换与文字位置 ax.transData，以数据为基准的坐标变换。 ax.transAxes，以坐标轴为基准的坐标变换（以坐标轴维度为单位）。 fig.transFigure，以图形为基准的坐标变换（以图形维度为单位）。 transData坐标用x轴与y轴的标签作为数据坐标。 transAxes坐标以坐标轴(图中白色矩形)左下角的位置为原点,按坐标轴尺寸的比例呈现坐标。 trans Figure坐标与之类似,不过是以图形(图中灰色矩形)左下角的位置为原点,按图形尺寸的比例呈现坐标。 箭头与注释在 Matplotlib里面画箭头通常比你想象的要困难。虽然有一个plt.arrow()函数可以实现这个功能,但是我不推荐使用它,因为它创建出的箭头是SvG向量图对象,会随着图形分辨率的变化而改变,最终的结果可能完全不是用户想要的。我要推荐的是plt.annotate()函数。这个函数既可以创建文字,也可以创建箭头,而且它创建的箭头能够进行非常灵活的配置。 箭头的风格是通过arrowprops字典控制的。 自定义坐标轴刻度在介绍示例之前,我们最好先对 Matplotlib图形的对象层级有更深入的理解。 Matplotlib的目标是用 Python对象表现任意图形元素。例如,figure对象其实就是一个盛放图形元素的包围盒( bounding box)。可以将每个 Matplotlib对象都看成是子对象(sub-object)的容器,例如每个 figure都会包含一个或多个axes对象,每个aXes对象又会包含其他表示图形内容的对象。 坐标轴刻度线也不例外。每个axeS都有 axis和 yaxis属性,每个属性同样包含构成坐标轴的线条、刻度和标签的全部属性。 主要刻度与次要刻度我们发现每个主要刻度都显示为一个较大的刻度线和标签,而次要刻度都显示为一个较小的刻度线,且不显示标签。 可以通过设置每个坐标轴的 formatter与 locator对象,自定义这些刻度属性(包括刻度线的位置和标签)。 主要刻度标签和次要刻度标签的位置都是通过一个LogLocator对象(在对数图中可以看到)设置的。然而,次要刻度有个NullFormatter对象处理标签,这样标签就不会在图上显示了。 隐藏刻度与标签最常用的刻度/标签格式化操作可能就是隐藏刻度与标签了,可以通过plt. NullLocator()与plt.NullFormatter()实现。 增减刻度数量默认刻度标签有一个问题,就是显示较小图形时,通常刻度显得十分拥挤。数字几乎都重叠在一起,辨识起来非常困难。我们可以用plt. MaxNLocator()来解决这个问题,通过它可以设置最多需要显示多少刻度。根据设置的最多刻度数量, Matplotlib会自动为刻度安排恰当的位置。 花哨的刻度格式可以通过设置一个MultipleLocator来实现将刻度放在你提供的数值的倍数上。让图形会更加自然。 格式生成器与定位器小结 Matplotlib自定义：配置文件与样式表手动配置图形 每次都要手动配置一番太麻烦了，可以配置一次默认图形将其应用到所有图形上。 修改默认配置：rcParamsMatplotlib每次加载时,都会定义一个运行时配置(rc),其中包含了所有你创建的图形元素的默认风格。你可以用plt.rc简便方法随时修改这个配置。 样式表默认风格FiveThirtyEight风格ggplot风格bmh风格黑色背景风格灰度风格Seaborn风格用Matplotlib画三维图我们可以导入 Matplotlib自带的plot3d工具箱来画三维图。 导入这个子模块之后,就可以在创建任意一个普通坐标轴的过程中加入projection=‘3d’关键字,从而创建一个三维坐标轴。 三维数据点与线最基本的三维图是由(x,y,z)三维坐标点构成的线图与散点图。与前面介绍的普通二维图类似,可以用 ax.plot3D与ax.scatter3D函数来创建它们。三维图函数的参数与前面二维图函数的参数基本相同。 默认情况下，散点会自动改变透明度，以在平面上呈现出立体感。 三维等高线与之前的等高线类似,mplot3d也有用同样的输入数据创建三维晕渲( relief)图的工具。与二维ax.contour图形一样,ax.contour3D要求所有数据都是二维网格数据的形式,并且由函数计算z轴数值。 线框图和曲面图 曲面图与线框图类似,只不过线框图的每个面都是由多边形构成的。只要增加一个配色方案来填充这些多边形。 画曲面图需要二维数据,但可以不是直角坐标系(也可以用极坐标)。 曲面三角剖分用Basemap可视化地理数据地理数据可视化是数据科学中一种十分常见的可视化类型。 Matplotlib做此类可视化的主要工具是 Basemap工具箱。 安装并导入 Basemap工具箱后,只用几行代码就可以画出地理图形。 用Seaborn做数据可视化虽然 Matplotlib已经证明了自己绝对是一款超级实用且流行的数据可视化工具,但是即使骨灰粉也不得不承认它不支持的功能还有很多。 Seaborn在Matplotlib的基础上开发了一套API,为默认的图形样式和颜色设置提供了理智的选择,为常用的统计图形定义了许多简单的高级函数,并与Pandas dataFrame的功能有机结合。 Seaborn与MatplotlibSeaborn不仅有许多高级的画图功能,而且可以改写 Matplotlib的默认参数,从而用简单的Matplotlib脚本获得更好的效果。可以用 Seaborn的set()方法设置样式。 Seaborn图形介绍频次直方图、KDE和密度图","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"Python数据科学手册 Pandas数据处理","slug":"Python数据科学手册 Pandas数据处理","date":"2018-10-31T13:00:56.000Z","updated":"2018-10-31T13:07:25.000Z","comments":true,"path":"2018/10/31/Python数据科学手册 Pandas数据处理/","link":"","permalink":"https://github.com/zdkswd/2018/10/31/Python数据科学手册 Pandas数据处理/","excerpt":"","text":"Pandas是在NumPy基础上建立的新程序库,提供了一种高效的 DataFrame数据结构。 DataFrame本质上是一种带行标签和列标签、支持相同类型数据和缺失值的多维数组。 Pandas不仅为带各种标签的数据提供了便利的存储界面,还实现了许多强大的操作,这些操作对数据库框架和电子表格程序的用户来说非常熟悉。 建立在NumPy数组结构上的 Pandas,尤其是它的 Series和 DataFrame对象,为数据科学家们处理那些消耗大量时间的“数据清理”(data munging)任务提供了捷径。 安装并使用Pandas在安装Pandas之前，确保操作系统中有NumPy。 Pandas对象简介如果从底层视角观察Pandas对象，可以把它们看成增强版的NumPy结构化数组，行列都不再只是简单的整数索引，还可以带上标签。Pandas的三个基本数据结构：Series、DataFrame和Index。 Pandas的Series对象Pandas的 Series对象是一个带索引数据构成的一维数组。可以用一个数组创建 Series对象。 从上面的结果中,你会发现 Series对象将一组数据和一组索引绑定在一起,我们可以通过 values属性和 index属性获取数据。 values属性返回的结果与 NumPy数组类似。 index属性返回的结果是一个类型为pd. Index的类数组对象。 和 NumPy数组一样,数据可以通过 Python的中括号索引标签获取。 Pandas的 Series对象比它模仿的一维 NumPy数组更加通用、灵活。 Serise是通用的 NumPy数组Series对象和一维 NumPy数组两者间的本质差异其实是索引: NumPy数组通过隐式定义的整数索引获取数值,而 Pandas的 Series对象用一种显式定义的索引与数值关联。显式索引的定义让 Series对象拥有了更强的能力。例如,索引不再仅仅是整数,还可以是任意想要的类型。如果需要,完全可以用字符串定义索引。也可以使用不连续或不按顺序的索引。 Series是特殊的字典可以把 Pandas的 Series对象看成一种特殊的 Python字典。字典是一种将任意键映射到一组任意值的数据结构,而 Series对象其实是一种将类型键映射到一组类型值的数据结构。类型至关重要:就像 NumPy数组背后特定类型的经过编译的代码使得它在某些操作上比普通的 Python列表更加高效一样, Pandas series的类型信息使得它在某些操作上比 Python的字典更高效。用字典创建 Series对象时,其索引默认按照顺序排列。典型的字典数值获取方式仍然有效。和字典不同, Series对象还支持数组形式的操作,比如切片。 创建Series对象 其中，index是一个可选参数，data参数支持多种数据类型。data可以是列表或 NumPy数组,这时 index默认值为整数序列，data也可以是一个标量,创建 Series对象时会重复填充到每个索引上。 data还可以是一个字典，index默认是排序的字典键。每一种形式都可以通过显式指定索引筛选需要的结果，这里需要注意的是, Series对象只会保留显式定义的键值对。 Pandas的 DataFrame对象DataFrame既可以作为一个通用型 NumPy数组,也可以看作特殊的 Python字典。 Dataframe是通用的 NumPy数组把 DataFrame看成是有序排列的若干 Series对象。这里的“排列指的是它们拥有共同的索引。 再结合之前创建的 population的 Series对象,用一个字典创建个包含这些信息的二维对象 和 Series对象一样, DataFrame也有一个 index属性可以获取索引标签。 另外, DataFrame还有一个 columns属性,是存放列标签的Index对象。 Dataframe可以看作一种通用的 NumPy二维数组,它的行与列都可以通过索引获取。 DataFrame是特殊的字典与 Series类似,我们也可以把 DataFrame看成一种特殊的字典。字典是一个键映射一个值,而 DataFrame是一列映射一个Series的数据。例如,通过’area’的列属性可以返回包含面积数据的Series对象。 创建DataFrame对象通过单个Series对象创建DataFrame是一组 Series对象的集合,可以用单个 Series创建一个单列的 Dataframe。 通过字典列表创建任何元素是字典的列表都可以变成DataFrame。 即使字典中有些键不存在, Pandas也会用缺失值NaN(不是数字,not a number)来表示。 通过Series对象字典创建DataFrame也可以用一个由 Series对象构成的字典创建。 通过NumPy二维数组创建假如有一个二维数组,就可以创建个可以指定行列索引值的 DataFrame。如果不指定行列索引值那么行列默认都是整数索引值。 通过NumPy结构化数组创建由于 Pandas的 DataFrame与结构化数组十分相似,因此可以通过结构化数组创建 Dataframe。 Pandas的Index对象Series和 DataFrame对象都使用便于引用和调整的显式索引。 Pandas的 Index对象是一个很有趣的数据结构,可以将它看作是一个不可变数组或有序集合(实际上是一个多集,因为 Index对象可能会包含重复值)。这两种观点使得 Index对象能呈现一些有趣的功能。让我们用一个简单的整数列表来创建一个 Index对象。 将Index看作不可变数组Index对象的许多操作都像数组。例如,可以通过标准 Python的取值方法获取数值,也可以通过切片获取数值。 Index对象与 NumPy数组之间的不同在于, Index对象的索引是不可变的,也就是说不能通过通常的方式进行调整。Index对象的不可变特征使得多个DataFrame和数组之间进行索引共享时更加安全,尤其是可以避免因修改索引时粗心大意而导致的副作用。 将Index看作有序集合Pandas对象被设计用于实现许多操作,如连接(join)数据集,其中会涉及许多集合操作。Index对象遵循 Python标准库的集合(set)数据结构的许多习惯用法,包括并集、交集、差集等。 数据取值与选择Series数据选择方法将 Series看作字典 我们还可以用 Python字典的表达式和方法来检测键/索引和值。 Series对象还可以用字典语法调整数据。就像你可以通过增加新的键扩展字典一样,你也可以通过增加新的索引值扩展 Series。 Series对象的可变性是一个非常方便的特性: Pandas在底层已经为可能发生的内存布局和数据复制自动决策,用户不需要担心这些问题。 将 Series看作一维数组Series不仅有着和字典一样的接口,而且还具备和 NumPy数组一样的数组数据选择功能,包括索引、掩码、花哨的索引等操作。切片是绝大部分混乱之源。需要注意的是,当使用显式索引(即data[‘a’:’c’])作切片时,结果包含最后一个索引;而当使用隐式索引(即data[0:2])作切片时,结果不包含最后一个索引。 索引器：loc、iloc和ix这些切片和取值的习惯用法经常会造成混乱。例如,如果你的Series是显式整数索引,那么data[1]这样的取值操作会使用显式索引,而data[1:3]这样的切片操作却会使用隐式索引。由于整数索引很容易造成混淆,所以 Pandas提供了一些索引器( indexer)属性来作为取值的方法。它们不是 Series对象的函数方法,而是暴露切片接口的属性。 即从0开始，左闭右开区间。第三种取值属性是ix,它是前两种索引器的混合形式,在 Series对象中ix等价于标准的取值方式。ix索引器主要用于DataFrame对象。 Python代码的设计原则之一是“显式优于隐式”。使用loc和iloc可以让代码更容易维护,可读性更高。特别是在处理整数索引的对象时,强烈推荐使用这两种索引器。它们既可以让代码阅读和理解起来更容易,也能避免因误用索引/切片而产生的小bug。 DataFrame数据选择方法Dataframe在有些方面像二维或结构化数组,在有些方面又像一个共享索引的若干 Series对象构成的字典。 将 Dataframe看作字典 两个 Series分别构成 Dataframe的一列,可以通过对列名进行字典形式( dictionary- style)的取值获取数据。 虽然属性形式的数据选择方法很方便,但是它并不是通用的。如果列名不是纯字符串,或者列名与 DataFrame的方法同名,那么就不能用属性索引。例如, Dataframe有一个pop()方法,如果用data.pop就不会获取’pop’列,而是显示为方法。另外,还应该避免对用属性形式选择的列直接赋值(即可以用data[‘pop’]=z,但不要用data.pop=z)。 将DataFrame看作二维数组可以把 Dataframe看成是一个增强版的二维数组。 理解了这一点,就可以把许多数组操作方式用在 DataFrame上。例如,可以对 DataFrame进行行列转置。获取一行数据时。 获取一列。 在进行数组形式的取值时，我们就需要用另一种方法。loc、iloc和ix。通过iloc索引器，我们就可以像对待NumPy数组一样索引Pandas的底层数组（Python的隐式索引） 使用ix索引器可以实现一种混合效果。 需要注意的是,ix索引器对于整数索引的处理和之前在 Series对象中介绍的一样,都容易让人混淆。任何用于处理 NumPy形式数据的方法都可以用于这些索引器。 其他取值方法还有一些取值方法看着有点奇怪，但在实践中还是好用。首先，如果对单个标签取值就选择列，而对多个标签用切边就选择行。 切片也可以不用索引值，而直接用行数来实现。 与此类似，掩码操作也可以直接对每一行进行过滤，而不需要使用loc索引器。 Pandas数值运算方法NumPy的基本能力之一是快速对每个元素进行运算,既包括基本算术运算(加、减、乘、除),也包括更复杂的运算(三角函数、指数函数和对数函数等)。 Pandas继承了 NumPy的功能,通用函数是关键。 通用函数：保留索引因为 Pandas是建立在 NumPy基础之上的,所以 NumPy的通用函数同样适用于 Pandas的 Series和 DataFrame对象。 通用函数：索引对齐当在两个 Series或 DataFrame对象上进行二元计算时, Pandas会在计算过程中对齐两个对象的索引。 Series索引对齐 对于缺失位置的数据, Pandas会用NaN填充,表示“此处无数”。这种索引对齐方式是通过 Python内置的集合运算规则实现的,任何缺失值默认都用NaN填充。 如果用NaN值不是我们想要的结果,那么可以用适当的对象方法代替运算符。例如，A.add(B)等价于A+B，也可以设置参数自定义A或B缺失的数据。 DataFrame索引对齐在计算两个 DataFrame时,类似的索引对齐规则也同样会出现在共同(并集)列中。 你会发现,两个对象的行列索引可以是不同顺序的,结果的索引会自动按顺序排列。 通用函数: DataFrame与 Series的运算对一个 DataFrame和一个 Series进行计算,行列对齐方式与之前类似。也就是说, DataFrame和 Series的运算规则,与NumPy中二维数组与一维数组的运算规则是一样的。 根据 NumPy的广播规则，让二维数组减自身的行数据会按行计算。在 Pandas里默认也是按行运算的。 如果你想按列计算,那么就需要利用前面介绍过的运算符方法,通过axis参数设置。 处理缺失值大多数教程里使用的数据与现实工作中的数据的区别在于后者很少是干净整齐的,许多目前流行的数据集都会有数据缺失的现象。更为甚者处理不同数据源缺失值的方法还不同。 选择处理缺失值的方法在数据表或 DataFrame中有很多识别缺失值的方法。一般情况下可以分为两种:一种方法是通过一个覆盖全局的掩码表示缺失值,另一种方法是用一个标签值( sentinel value)表示缺失值。在掩码方法中,掩码可能是一个与原数组维度相同的完整布尔类型数组,也可能是用一个比特(0或1)表示有缺失值的局部状态。在标签方法中,标签值可能是具体的数据(例如用9999表示缺失的整数),也可能是些极少出现的形式。另外,标签值还可能是更全局的值,比如用NaN(不是一个数)表示缺失的浮点数,它是IEEE浮点数规范中指定的特殊字符。 使用这两种方法之前都需要先综合考量:使用单独的掩码数组会额外出现一个布尔类型数组,从而增加存储与计算的负担;而标签值方法缩小了可以被表示为有效值的范围,可能需要在CPU或GPU算术逻辑单元中增加额外的(往往也不是最优的)计算逻辑。通常使用的NaN也不能表示所有数据类型。 大多数情况下,都不存在最佳选择,不同的编程语言与系统使用不同的方法。 Pandas的缺失值Pandas里处理缺失值的方式延续了 NumPy程序包的方式,并没有为浮点数据类型提供内置的NA作为缺失值。 Pandas原本也可以按照R语言采用的比特模式为每一种数据类型标注缺失值，但是这种方法非常笨拙。其工作量几乎相当于创建一个新的NumPy程序包。另外，对于一些较小的数据类型，牺牲一个比特作为缺失值标注的掩码还会导致其数据范围缩小。当然, NumPy也是支持掩码数据的,也就是说可以用一个布尔掩码数组为原数组标注“无缺失值”或“有缺失值”。 Pandas也集成了这个功能,但是在存储、计算和编码维护方面都需要耗费不必要的资源,因此这种方式并不可取。 综合考虑各种方法的优缺点, Pandas最终选择用标签方法表示缺失值,包括两种 Python原有的缺失值:浮点数据类型的NaN值,以及 Python的None对象。后面我们将会发现,虽然这么做也会有一些副作用,但是在实际运用中的效果还是不错的。 None：Python对象类型的缺失值Pandas可以使用的第一种缺失值标签是None,它是一个 Python单体对象,经常在代码中表示缺失值。由于None是一个 Python对象,所以不能作为任何 NumPy/ Pandas数组类型的缺失值,只能用于object数组类型。 这里 dtype= object表示 NumPy认为由于这个数组是 Python对象构成的,因此将其类型判断为 object。虽然这种类型在某些情景中非常有用,对数据的任何操作最终都会在 Python层面完成,但是在进行常见的快速操作时,这种类型比其他原生类型数组要消耗更多的资源。 使用 Python对象构成的数组就意味着如果你对一个包含None的数组进行累计操作,如sum()或者min(),那么通常会出现类型错误。这就是说,在 Python中没有定义整数与None之间的加法运算。 NaN:数值类型的缺失值另一种缺失值的标签是NaN(全称 Not a number,不是一个数字),是一种按照IEEE浮点数标准设计、在任何系统中都兼容的特殊浮点数。 NumPy会为这个数组选择一个原生浮点类型,这意味着和之前的 object类型数组不同,这个数组会被编译成C代码从而实现快速操作。你可以把NaN看作是一个数据类病毒它会将与它接触过的数据同化。无论和NaN进行何种操作,最终结果都是NaN。 NumPy也提供了一些特殊的累计函数,它们可以忽略缺失值的影响。 谨记,NaN是一种特殊的浮点数,不是整数、字符串以及其他数据类型。 Pandas中NaN与None的差异虽然NaN与None各有各的用处,但是 Pandas把它们看成是可以等价交换的,在适当的时候会将两者进行替换。 Pandas会将没有标签值的数据类型自动转换为NA。例如,当我们将整型数组中的一个值设置为np.nan时,这个值就会强制转换成浮点数缺失值NA。除了将整型数组的缺失值强制转换为浮点数, Pandas还会自动将None转换为NaN。 需要注意的是, Pandas中字符串类型的数据通常是用 object类型存储的。 处理缺失值Pandas基本上把None和NaN看成是可以等价交换的缺失值形式。 返回一个填充看缺失值的数据副本。 发现缺失值Pandas数据结构有两种有效的方法可以发现缺失值:isnull()和notnull()。每种方法都返回布尔类型的掩码数据。 布尔类型掩码数组可以直接作为 Series或 DataFrame的索引使用。 在 Series里使用的isnull()和notnull()同样适用于Dataframe,产生的结果同样是布尔类型。 剔除缺失值dropna（）（剔除缺失值）和fillna（）（填充缺失值）。 我们没法从 DataFrame中单独剔除一个值,要么是剔除缺失值所在的整行,要么是整列。根据实际需求,有时你需要剔除整行,有时可能是整列, DataFrame中的 drona()会有一些参数可以配置。默认情况下, drona()会剔除任何包含缺失值的整行数据。可以设置按不同的坐标轴剔除缺失值,比如axis=1(或axis=‘ columns’)会剔除任何包含缺失值的整列数据。 但是这么做也会把非缺失值一并剔除,因为可能有时候只需要剔除全部是缺失值的行或列,或者绝大多数是缺失值的行或列。这些需求可以通过设置how或 thresh参数来满足,它们可以设置剔除行或列缺失值的数量阈值。 默认设置是how=‘any’,也就是说只要有缺失值就剔除整行或整列(通过axis设置坐标轴)。你还可以设置how=‘all’,这样就只会剔除全部是缺失值的行或列了。 还可以通过 thresh参数设置行或列中非缺失值的最小数量,从而实现更加个性化的配置。 填充缺失值有时候你可能并不想移除缺失值,而是想把它们替换成有效的数值。有效的值可能是像0、1、2那样单独的值,也可能是经过填充( Imputation)或转换( interpolation)得到的。Pandas为此专门提供了一个fillna（）方法，将返回填充了缺失值后的数组副本。 可以用缺失值前面的有效值来从前往后填充。也可以用缺失值后面的有效值来从后往前填充(back-fil)。 Dataframe的操作方法与 Series类似,只是在填充时需要设置坐标轴参数axis。 需要注意的是,假如在从前往后填充时,需要填充的缺失值前面没有值,那么它就仍然是缺失值。 层级索引当目前为止,我们接触的都是一维数据和二维数据,用 Pandas的Series和 DataFrame对象就可以存储。但我们也经常会遇到存储多维数据的需求,数据索引超过一两个键。因此, Pandas提供了 Panel和Pane4D对象解决三维数据与四维数据。而在实践中,更直观的形式是通过层级索引( hierarchical indexing,也被称为多级索引,muli- indexing)配合多个有不同等级( level)的一级索引一起使用,这样就可以将高维数组转换成类似一维 Series和二维DataFrame对象的形式。 所及索引Series笨方法使用元组。 好方法：Pandas多级索引用元组表示索引其实是多级索引的基础。Pandas的 MultiIndex类型提供了更丰富的操作方法。我们可以用元组创建一个多级索引。 高维数据的多级索引unstack()方法可以快速将一个多级索引的 Series转化为普通索引的DataFrame。 当然了，也有stack（）方法实现相反的效果。 如果我们可以用含多级索引的一维 Series数据表示二维数据,那么我们就可以用 Series或 Dataframe表示三维甚至更高维度的数据。多级索引每增加一级,就表示数据增加一维,利用这一特点就可以轻松表示任意维度的数据了。假如要增加一列显示每一年各州的人口统计指标(例如18岁以下的人口),那么对于这种带有Multiindexⅹ的对象,增加一列就像 DataFrame的操作一样简单。 多级索引的创建方法为 Series或 DataFrame创建多级索引最直接的办法就是将 index参数设置为至少二维的索引数组。 Multiindex的创建工作将在后台完成。同理,如果你把将元组作为键的字典传递给 Pandas, Pandas也会默认转MultiIndex。 显式地创建多级索引可以通过一个有不同等级的若干简单数组组成的列表来构建 Multiindex。 也可以通过包含多个索引值的元组构成的列表创建 MultiIndex。 还可以用两个索引的笛卡尔积( Cartesian product)创建Multiindex。 更可以直接提供levels(包含每个等级的索引值列表的列表)和labels(包含每个索引值标签列表的列表)创建 MultiIndex。 在创建 Series或 Dataframe时,可以将这些对象作为 index参数,或者通过 reindex方法更新 Series或 Dataframe的索引。 多级索引的等级名称给MultIindex的等级加上名称会为一些操作提供便利。你可以在前面任何一个 Multiindex构造器中通过 names参数设置等级名称,也可以在创建之后通过索引的names属性来修改名称。 多级列索引每个 Dataframe的行与列都是对称的,也就是说既然有多级行索引,那么同样可以有多级列索引。 多级索引的取值与切片Series多级索引 MultIindex也支持局部取值( partial indexing),即只取索引的某一个层级。假如只取最高级的索引,获得的结果是一个新的Series,未被选中的低层索引值会被保留。 类似的还有局部切片,不过要求MultiIndex是按顺序排列的。 如果索引已经排序,那么可以用较低层级的索引取值,第一层级的索引可以用空切片。 其他取值与数据选择的方法也都起作用。下面的例子是通过布尔掩码选择数据。 也可以用花哨的索引选择数据。 DataFrame多级索引DataFrame多级索引的用法与 Series类似。 由于Dataframe的基本索引是列索引,因此 Series中多级索引的用法到了 DataFrame中就应用在列上了。 与单索引类似，loc、iloc和ix索引器都可以使用。 虽然这些索引器将多维数据当作二维数据处理,但是在loc和iloc中可以传递多个层级的索引元组。 这种索引元组的用法不是很方便,如果在元组中使用切片还会导致语法错误。虽然可以用Python内置的slice（）函数获取想要的切片，但是还可以使用IndexSlice对象，Pandas专门用它解决这些问题。 多级索引行列转换有序的索引和无序的索引如果MultiIndex不是有序的索引，那么大多数切片操作都会失败。局部切片和许多其他相似的操作都要求MultiIndex的各级索引是有序的（即按照字典顺序由A至Z）。为此Pandas提供了许多便捷的操作完成排序，如sort_index()和sortlevel()方法。 索引排序之后,局部切片就可以正常使用了。 索引stack与unstack我们可以将一个多级索引数据集转换成简单的二维形式,可以通过level参数设置转换的索引层级。 unstack()是 stack()的逆操作,同时使用这两种方法让数据保持不变。 索引的设置与重置层级数据维度转换的另一种方法是行列标签转换,可以通过reset_index方法实现。 多级索引的数据累计方法对于层级索引数据，可以设置参数level实现对数据子集的累计操作。 需要计算每一年的各项平均值，可以将参数level设置为索引year。 如果再设置axis参数,就可以对列索引进行类似的累计操作了。 合并数据集：Concat与Append操作使用pd.concat实现简易合并Pandas有一个pd.concat()函数与 np. concatenate语法类似,但是配置参数更多,功能也更强大。 pd. concat()可以简单地合并一维的 Series或 Dataframe对象,与np. concatenate()合并数组一样。 它也可以用来合并高维数据。 默认情况下，DataFrame的合并都是逐行进行的（默认设置是axis=0）。 这里使用axis=1效果是一样的，但是用axis=‘col’会更直观。 索引重复np. concatenate与pd. concat最主要的差异之一就是 Pandas在合并时会保留索引,即使索引是重复的! 捕捉索引重复的错误可以设置verify_integrity参数为True，合并时若有索引重复就会触发异常。 忽略索引有时索引无关紧要，那么合并时就可以忽略它们，可以通过设置ignore_index参数来实现，如果参数设置为True，那么合并时会创建一个新的整数索引。 增加多级索引另一种处理方法是通过keys参数为数据源设置多级索引标签。 结果是多级索引的DataFrame。 类似join的合并实际中，需要合并的数据往往不带有相同的列名。 默认下，某个位置上的缺失会用NaN表示。如果不想这样，可以用join和join_axes参数设置合并方式。默认的合并方式是对所有的输入列进行并集合并（join=‘outer’）,当然也可以用join=‘inner’实现对输入列的交集合并。 另一种合并方式是直接确定结果使用的列名,设置 join_axes参数,里面是索引对象构成的列表(是列表的列表)。 append()方法可以使用df1. append(df2),效果与pd. concat([df1,df2])一样。Pandas的 append()不直接更新原有对象的值,而是为合并后的数据创建一个新对象。因此,它不能被称之为一个非常高效的解决方案,因为每次合并都需要重新创建索引和数据缓存。总之,如果你需要进行多个 append操作,还是建议先创建一个 Dataframe列表,然后用 concat()函数一次性解决所有合并任务。 合并数据集：合并与连接关系代数pd. merge()实现的功能基于关系代数( relational algebra)的一部分关系代数是处理关系型数据的通用理论,绝大部分数据库的可用操作都以此为理论基础。 数据连接的类型一对一连接 多对一连接多对一连接是指,在需要连接的两个列中,有一列的值有重复。通过多对一连接获得的结果 DataFrame将会保留重复值。 多对多连接 设置数据合并的键参数on的用法最简单的方法就是直接将参数on设置为一个列名字符串或者一个包含多列名称的列表。这个参数只能在两个 DataFrame有共同列名的时候才可以使用。 left_on与right_on参数有时你也需要合并两个列名不同的数据集,例如前面的员工信息表中有一个字段不是“ employee’,而是 name”。在这种情况下,就可以用left on和 right on参数来指定列名: 获取的结果中会有一个多余的列,可以通过 Dataframe的drop()方法将这列去掉。 left index与right index参数除了合并列之外,你可能还需要合并索引。 设置数据连接的集合操作规则通过前面的示例,我们总结出数据连接的一个重要条件:集合操作规则。当一个值出现在一列,却没有出现在另一列时,就需要考虑集合操作规则了。 可以用how参数设置连接方式，默认值为‘inner’，还有‘outer’、‘left’和‘right’。 重复列名：suffixes参数 由于输出结果中有两个重复的列名,因此pd. merge()函数会自动为它们增加后缀_x或_y,当然也可以通过 suffixes参数自定义后缀名。 suffixes参数同样适用于任何连接方式,即使有三个及三个以上的重复列名时也同样适用。 累计与分组在对较大的数据进行分析时,一项基本的工作就是有效的数据累计( summarization):计算累计( aggregation)指标,如sum()、mean()、 median()、min()和max(),其中每一个指标都呈现了大数据集的特征。 Pandas的简单累计功能 Pandas的 Series和 DataFrame支持所有24节中介绍的常用累计函数。另外,还有一个非常方便的 describe()方法可以计算每一列的若干常用统计值。 DataFrame和 Series对象支持以上所有方法。 GroupBy:分割、应用和组合分割、应用和组合 GroupBy的用处就是将这些步骤进行抽象:用户不需要知道在底层如何计算,只要把操作看成一个整体就够了。 我们可以用 DataFrame的 groupby()方法进行绝大多数常见的分割-应用-组合操作,将需要分组的列名传进去即可。 需要注意的是,这里的返回值不是一个 DataFrame对象,而是个 DataFrame GroupBy对象。这个对象的魔力在于,你可以将它看成是一种特殊形式的 DataFrame,里面隐藏着若干组数据,但是在没有应用累计函数之前不会计算。 sum()只是众多可用方法中的一个。你可以用 Pandas或 NumPy的任意一种累计函数,也可以用任意有效的 DataFrame对象。 GroupBy对象GroupBy对象是一种非常灵活的抽象类型。在大多数场景中,你可以将它看成是 Dataframe的集合,在底层解决所有难题。 按列取值GroupBy对象与 Dataframe一样,也支持按列取值,并返回一个修改过的 GroupBy对象。 这里从原来的 DataFrame中取某个列名作为一个 Series组。与GroupBy对象一样,直到我们运行累计函数,才会开始计算。 按组迭代GroupBy对象支持直接按组进行迭代,返回的每组都是 Series或 Dataframe。 调用方法借助 Python类的魔力(@ classmethod),可以让任何不由 GroupBy对象直接实现的方法直接应用到每一组,无论是 Dataframe还是 Series对象都同样适用。 累计、过滤、转换和应用累计aggregate()可以支持更复杂得操作。比如字符串、函数或者函数列表，并且能一次性计算所有累计值。 另一种用法是通过Python字典指定不同列需要累计的函数。 过滤过滤操作可以让呢按照分组的属性丢弃若干数据。 转换累计操作返回的是对组内全量数据缩减过的结果,而转换操作会返回一个新的全量数据。数据经过转换之后,其形状与原来的输入数据是一样的。 apply()方法apply()方法让你可以在每个组上应用任意方法。这个函数输入一个 DataFrame,返回一个 Pandas对象( Data Frame或 Series)或一个标量( scalar,单个数值)。 设置分割的键将列表、数组、Series或索引作为分组键用字典或Series将索引映射到分组名称任意Python函数多个有效键构成的列表数据透视表向量化字符串操作Pandas字符串操作简介Pandas为包含字符串的 Series和 Index对象提供的str属性堪称两全其美的方法,它既可以满足向量化字符串操作的需求,又可以正确地处理缺失值。例如,我们用前面的数据data创建了一个 Pandas的Series。 可以直接调用转换大写方法capitalize()将所有的字符串变成大写形式，缺失值会被跳过。 Pandas字符串方法列表与Python字符串方法相似的方法 注意，这些方法的返回值不同。有的返回一个字符串Series，有的返回数值，有的返回布尔值，有的返回列表或其他复合值。 使用正则表达式的方法 还可以用正则表达式中的开始符号（\\^）与结尾符号（\\$）来实现。能将正则表达式应用到Series与DataFrame之中的话，就有可能实现更多的数据分析与清洗方法。 其他字符串方法 处理时间序列Pandas最初是为金融模型而创建的，因此它拥有一些功能非常强大的日期、时间、带时间索引数据的处理工具。 时间戳表示某个具体的时间点(例如2015年7月4日上午7点)。 时间间隔与周期表示开始时间点与结束时间点之间的时间长度,例如2015年(指的是2015年1月1日至2015年12月31日这段时间间隔)。周期通常是指一种特殊形式的时间间隔,每个间隔长度相同,彼此之间不会重叠(例如,以24小时为周期构成每天）。 时间增量( time delta)或持续时间( duration)表示精确的时间长度(例如,某程序运行持续时间2256秒)。 Python的日期与时间工具原生Python的日期与时间工具：datetime与dateutildatetime和 dateuti1模块在灵活性与易用性方面都表现出色你可以用这些对象及其相应的方法轻松完成你感兴趣的任意操作但如果你处理的时间数据量比较大,那么速度就会比较慢。就像之前介绍过的 Python的原生列表对象没有 NumPy中已经被编码的数值类型数组的性能好一样, Python的原生日期对象同样也没有NumPy中已经被编码的日期( encoded dates)类型数组的性能好。 时间类型数组：NumPy的datetime64类型Python原生日期格式的性能弱点促使 NumPy团队为 NumPy增加了自己的时间序列类型。 datetime64类型将日期编码为64位整数,这样可以让日期数组非常紧凑(节省内存)。datetime64需要在设置日期时确定具体的输入类型。 只要有了这个日期格式，就可以快速的向量化运算。 虽然 datetime64弥补了 Python原生的datetime类型的不足,但它缺少了许多 datetime(尤其是dateutil)原本具备的便捷方法与函数。 Pandas的日期与时间工具：理想与现实的最佳解决方案Pandas所有关于日期与时间的处理方法全部都是通过 Timestamp对象实现的,它利用 numpy. datetime64的有效存储和向量化接口将 datetime和 dateutil的易用性有机结合起来。 Pandas通过一组 Timestamp对象就可以创建一个可以作为 Series或DataFrame索引的 Datetimelndex。 Pandas时间序列：用时间作索引Pandas时间序列工具非常适合用来处理带时间戳的索引数据。我们可以通过一个时间索引数据创建一个 Series对象。 有了一个带时间索引的Series之后,就能用它来演示之前介绍过的Series取值方法,可以直接用日期进行切片取值。 另外,还有一些仅在此类 Series上可用的取值操作,例如直接通过年份切片获取该年的数据。 Pandas时间序列数据结构 针对时间戳数据, Pandas提供了 Timestamp类型。与前面介绍的一样,它本质上是 Python的原生 datetime类型的替代品,但是在性能更好的 numpy.datetime64类型的基础上创建。对应的索引数据结构是Datetimeindex。 针对时间周期数据, Pandas提供了 Period类型。这是利用numpy. datetime64类型将固定频率的时间间隔进行编码。对应的索引数据结构是 Periodindex。 针对时间增量或持续时间, Pandas提供了 Timedelta类型。Timedelta是一种代替 Python原生 datetime, timedelta类型的高性能数据结构,同样是基于 numpy. timedelta64类型。对应的索引数据结构是 Timedeltaindex。 最基础的日期/时间对象是 Timestamp和 Datetimeindex。这两种对象可以直接使用,最常用的方法是pd.to_datetime()函数,它可以解析许多日期与时间格式。对pd.to_datetime()传递一个日期会返回一个 Timestamp类型,传递一个时间序列会返回一个Datetimelndex类型。 任何Datetimeindex类型都可以通过to_ period()方法和一个频率代码转换成 Periodindex类型。下面用‘D’将数据转换成单日的时间序列。 当用一个日期减去另一个日期时,返回的结果是 Timedeltaindex类型。 有规律的时间序列：pd.date_range()。 为了能更简便地创建有规律的时间序列, Pandas提供了一些方法:pd.daterange()可以处理时间戳、pd. period range()可以处理周期、pd.timedelta range()可以处理时间间隔。我们已经介绍过, Python的 range()和NumPy的 np.arange()可以用起点、终点和步长(可选的)创建一个序列。pd.daterange()与之类似,通过开始日期、结束日期和频率代码(同样是可选的)创建一个有规律的日期序列,默认的频率是天。 此外,日期范围不一定非是开始时间与结束时间,也可以是开始时间与周期数periods。 你可以通过freq参数改变时间间隔,默认值是D。例如,可以创建个按小时变化的时间戳。 如果要创建一个有规律的周期或时间间隔序列,有类似的函数pd.period_range()和pd. timedelta_range()。下面是一个以月为周期的示例。 一个以小时递增的序列。 时间频率与偏移量 可以在频率代码后面加三位月份缩写字母来改变季、年频率的开始时间。 还可以将频率组合起来创建新的周期。 重新取样、迁移和窗口重新取样与频率转换处理时间序列数据时,经常需要按照新的频率(更高频率、更低频率)对数据进行重新取样。你可以通过 resample()方法解决这个问题,或者用更简单的 asfreq()方法。这两个方法的主要差异在于, resample()方法是以数据累计( data aggregation)为基础,而 asfreq()方法是以数据选择( data selection)为基础。 时间迁移一种常用的时间序列操作时对数据按时间进行迁移。Pandas有两种解决这类问题的方法：shift()和tshift()。简单来说，shift（）就是迁移数据，而tshift（）就是迁移索引。两种方法都是按照频率代码进行迁移。 shift（900）将数据向前推进了900天，而tshift(900)将时间索引向前推进了900天。 移动时间窗口高性能 Pandas:eval()与 query()query()与eval()的设计动机:复合代数式NumPy与Pandas都支持快速的向量化运算。 用pandas.eval()实现高性能运算Pandas的eval()函数用字符串代数式实现了 DataFrame的高性能运算。eval()版本的代数式比普通方法快一倍（而且内存消耗更少），结果也是一样的。 pd.eval()支持的运算算术运算符pd.eval()支持所有的算术运算符。 比较运算符pd.eval()支持所有的比较运算符,包括链式代数式。 位运算符 对象属性与索引 其他运算目前pd.eval()还不支持函数调用、条件语句、循环以及更复杂的运算。如果你想要进行这些运算,可以借助 Numexpr来实现。 用 DataFrame.eval()实现列间运算由于 pd. eval()是 Pandas的顶层函数,因此 Dataframe有一个eval()方法可以做类似的运算。使用eval()方法的好处是可以借助列名称进行运算。 Dataframe.eval()方法可以通过列名称实现简洁的代数式。 用 DataFrame. eval()新增列 Dataframe.eval()使用局部变量Dataframe.eval()方法还支持通过@符号使用 Python的局部变量。 @符号表示“这是一个变量名称而不是一个列名称”,从而让你灵活地用两个“命名空间”的资源(列名称的命名空间和 Python对象的命名空间)计算代数式。需要注意的是,@符号只能在Dataframe.eval()方法中使用,而不能在 pandas.eval()函数中使用,因为 pandas. eval()函数只能获取一个( Python)命名空间的内容。 DataFrame.query()方法 除了计算性能更优以外，这种方法的语法也比掩码代数式语法更好理解。需要注意的是，query()方法也支持@符号引用局部变量。 性能决定使用时机在考虑要不要用这两个函数时,需要思考两个方面:计算时间和内存消耗,而内存消耗是更重要的影响因素。就像前面介绍的那样,每个涉及NumPy数组或Pandas的 DataFrame的复合代数式都会产生临时数组。 如果临时 DataFrame的内存需求比你的系统内存还大(通常是几吉字),那么最好还是使用eval()和 query()代数式。 在性能方面，即使没有使用最大的系统内存，eval（）的计算速度也比普通方法快。在实际工作中,我发现普通的计算方法与eval/ query计算方法在计算时间上的差异并非总是那么明显,普通方法在处理较小的数组时反而速度更快!eval/ query方法的优点主要是节省内存,有时语法也更加简洁。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"剑指offer  面试的流程","slug":"剑指offer  面试的流程","date":"2018-10-28T08:16:12.000Z","updated":"2018-10-28T08:17:07.000Z","comments":true,"path":"2018/10/28/剑指offer  面试的流程/","link":"","permalink":"https://github.com/zdkswd/2018/10/28/剑指offer  面试的流程/","excerpt":"","text":"面试的三种形式 电话面试与现场面试最大的区别就是应聘者见不到面试官，双方的沟通只能依靠声音。很多外企在电话面试时都会加上英语面试的环节，甚至有些公司全部面试都会用英语进行。对应聘者的听力提出了更高的要求。如果在面试的时候没有听清楚或听懂面试官的问题，千万不要不懂装懂答非所问，这是面试的大忌。当不确定面试官的问题时，一定要大胆的多提问，直到弄清楚面试官的意图为止。 共享桌面远程面试目前只有为数不多的几家大公司会在邀请应聘者到公司参加现场面试前，先进行一两轮共享桌面的远程面试。面试最关心的是应聘者的编程习惯及调试能力。通常面试官认可的习惯： 思考清楚再开始编程。 良好的代码命名和缩进对齐习惯。 更够单元测试。通常面试官出的题目都是要求写函数解决某一问题,如果应聘者能够在定义函数之后,立即对该函数进行全面的单元测试,那就相当于向面试官证明了自己有着专业的软件开发经验。如果应聘者是先写单元测试用例,再写解决问题的函数,我相信面试官定会对你刮目相看,因为能做到测试在前、开发在后的程序员实在是太稀缺了,他会毫不犹豫地抛出绿色的橄榄枝。 通常我们在写代码的时候都会遇到问题。当应聘者运行代码发现结果不对之后的表现,也是面试官关注的重点,因为应聘者此时的反应、采取的措施都能体现出他的调试功底。如果应聘者能够熟练地设置断点、单步跟踪、查看内存、分析调用栈,能很快发现问题的根源并最终解决问题,那么面试官将会觉得他的开发经验很丰富。调试能力是在书本上学不到的只有通过大量的软件开发实践才能积累出调试技巧。当面试官发现一个应聘者的调试功底很扎实的时候,他在写面试报告的时候是不会吝啬赞美之词的。 现场面试在通过上述两个面试后，就会进行现场面试，应当做好以下准备： 规划好路线并估算出行时间，不迟到。 准备好得体的衣服，没有必要穿正装。 注意面试邀请函的面试流程。如果面试有好几轮，时间也很长，在面试过程中可能会觉得疲劳并思维变得迟钝。比如微软对技术职位通常有五论面试，连续几个小时处在高压的面试中，人难免会变得精疲力尽，因此可以带一些提神的饮料或食品。 准备几个问题。每一轮面试的最后，面试官都会让应聘者问几个问题，应聘者可以提前准备好问题。 现场面试时整个面试流程中的重头戏。由于是坐在面试官的对面，应聘者的一举一动都看在面试官的眼力。面试官通过应聘者的语言和行动，考查他的沟通能力、学习能力、编程能力等综合实力。 现场面试的三个环节 行为面试环节面试开始的5~10分钟通常是行为面试的时间。在行为面试这个环节里,面试官会注意应聘者的性格特点,深入地了解简历中列举的项目经历。由于这一环节一般不会问技术难题,因此也是一个暖场的过程,应聘者可以利用这几分钟时间调整自己的情绪,进入面试的状态。 不少面试官会让应聘者做一个简短的自我介绍。由于面试官手中拿着应聘者的简历,而那里有应聘者的详细信息,因此此时的自我介绍不用花很多时间,用30秒到1分钟的时间介绍自己的主要学习、工作经历就即可如果面试官对你的某一段经历或者参与的某一个项目很感兴趣,他会有针对性地提几个问题详细了解。 简历中应聘者的项目经验 Situation:简短的项目背景，比如项目的规模，开发的软件的功能、目标用户等。 Task：自己完成的任务。这个要写详细，要让面试官对自己的工作一目了然。在用词上要注意区分“参与”和“负责”:如果只是加入某一个开发团队写了几行代码就用“负责”,那就很危险。面试官看到简历上应聘者“负责”了某个项目,他可能就会问项目的总体框架设计、核心算法、团队合作等问题。这些问题对于只是简单参与”的人来说,是很难回答的,会让面试官认为你不诚实,印象分会减去很多。 Action：为了完成任务自己做了哪些工作，是怎么做的。这里可以详细介绍。做系统设计的,可以介绍系统架构的特点;做软件开发的,可以写基于什么工具在哪个平台下应用了哪些技术;做软件测试的,可以写是手工测试还是自动化测试,是白盒测试还是黑盒测试等。 Result：自己的贡献。这些方面信息可以写得具体些，最好能用数字加以说明。如果是参与功能开发,可以说按时完成了多少功能;如果做优化,可以说性能提高的百分比是多少;如果是维护,可以说修改了多少个Bug。 举例： 应聘者掌握的技能，了解，熟悉，精通了解： 熟悉： 精通： 回答“为什么跳槽”面试官只是想通过这个问题来了解应聘者的性格，可以根据自己的真实想法来回答这个问题但也不能想说什么就说什么，回答这个问题时不要抱怨，也不要流露出负面的情绪。应当尽量避免以下4个原因： 老板太苛刻。 同事太难相处。面试官可能会觉得这个人本身就很难相处。 加班太频繁。对于大部分IT企业来说，加班是家常便饭。这么说等于不想进这家公司。 工资太低。不建议在面试的时候对面试官抱怨，等完成技术面试之后谈offer时，再和HR谈工资也不迟。通过面试后我们就掌握主动了，想怎么谈就怎么谈，如果工资真的开高了HR会和你很客气地商量的。 技术面试环节面试官在通过简历及行为面试大致了解应聘者的背景之后，接下来就要开始技术面试了。一轮1小时的面试，通常技术面试会占40-50分钟，这是面试的重头戏，对面试的结果起决定性作用。总体面试官会关注应聘者5种素质：扎实的基础知识、能写高质量的代码、分析问题思路清晰、能优化时间和空间效率，以及学习沟通等各方面的能力。 扎实的基础知识基本功在编程面试环节体现在三个方面：编程语言、数据结构和算法。 高质量的代码只有注重质量的程序员,才能写出鲁棒稳定的大型软件。在面试过程中,面试官总会格外关注边界条件、特殊输入等看似细枝末节但实质至关重要的地方,以考查应聘者是否注重代码质量。很多时候,面试官发现应聘者写出来的代码只能完成最基本的功能,一旦输入特殊的边界条件参数就会错误百出甚至程序崩溃。 总有些应聘者很困惑:面试的时候觉得题目很简单,感觉自己都做出来了,可最后为什么被拒了呢?在技术面试过程中,技术面试的面试官一般都是程序员,他们只认一个理:题目做对、做完整了,就让你通过面试;否则失败。所以遇到简单题目却被拒的情况,应聘者应认真反思在思路或者代码中存在哪些漏洞。 通常越是简单的问题，面试官的期望值就会越高。如果题目很简单，面试官会期待应聘者能够很完整的解决问题。除了完成基本功能以外，还要考虑到边界条件、错误处理等各个方面。还要考虑程序是否足够鲁棒。 要想很好地解决前面的问题,最好的办法是在动手写代码之后想好测试用例。只有把各种可能的输入事先都想好了,才能在写代码的时候把各种情况都做相应的处理。写完代码之后,也不要立刻给面试官检查,而是先在心里默默地运行。当输入之前想好的所有测试用例都能得到合理的输出时,再把代码交给面试官。做到了这一步,offer就很简单了。 清晰的思路对于确实很复杂的问题，面试官甚至不期待应聘者能在面试不到一个小时的时间里给出完整的答案，更看重的可能还是应聘者是否有清晰的思路。面试官通常不喜欢应聘者在没有形成清晰思路之前就草率地开始写代码，这样写出来的代码容易逻辑混乱、错误百出。 应聘者可以用几个简单的方法帮助自己形成清晰的思路。首先是举几个简单的具体例子让自己理解问题。当我们一眼看不出问题中隐藏的规律的时候,可以试着用一两个具体的例子模拟操作的过程,这样说不定就能通过具体的例子找到抽象的规律。其次可以试着用图形表示抽象的数据结构。像分析与链表、二叉树相关的题目,我们都可以画出它们的结构来简化题目。最后可以试着把复杂的问题分解成若干个简单的子问题,再解决。很多基于递归的思路,包括分治法和动态规划,都是把复杂的问题分解成一个或者多个简单的子问题。 优化效率的能力优秀的程序员对时间和内存的消耗锱铢必较,他们很有激情地不断优化自己的代码。当面试官出的题目有多种解法的时候,通常他会期待应聘者最终能够找到最优解。当面试官提示还有更好的解法的时候,应聘者不能放弃思考,而应该努力寻找在时间消耗或者空间消耗上可以优化的地方。 要想优化时间或者空间效率,首先要知道如何分析效率。即使是同一个算法,用不同方法实现的效率可能也会大不相同,我们要能够分析出算法及其代码实现的效率。 要想优化代码的效率,我们还要熟知各种数据结构的优缺点,并能选择合适的数据结构解决问题。 要想优化代码的效率,我们也要熟练掌握常用的算法。面试中最常用的算法是査找和排序。 优秀的综合能力除了展示自己的编程能力和技术功底之外，还需要展示自己的软能力，诸如自己的沟通能力和学习能力。软件开发已经告别了单打独斗的年代，程序员与他人的沟通变得越来越重要。知识迁移能力是一种特殊的学习能力。如果我们能够把已经掌握的知识迁移到其他领域，那么学习新技术或者解决新问题就会变得容易。还有些面试官喜欢考察应聘者的抽象建模能力和发散思维能力。 应聘者提问环节在结束面试前的5-10分钟，面试官会给应聘者机会提几个问题，应聘者的问题质量也会对面试的结果有一定的影响。面试官让应聘者问几个问题，主要是想了解他最关心的问题有哪些，因此应聘者至少要问一两个问题。问得问题合适，是加分项，问的问题不合适，那就是减分项。 有些问题是不适合在技术面试这个环节问的。首先，不要问和自己职位没有关系的问题。比如面试职位是一线的开发问公司五年的发展战略。其次是不要问薪水，技术面试不是谈薪水的时候，要谈工资要等通过面试后和HR谈。再次是不要立即打听面试结果，现在大部分公司面试都有好几轮，最终决定应聘者能不能通过面试，是要把面试官的评价综合起来的，问这个等于白问。还会让人觉得没有自我评价的能力。 推荐问的问题是与招聘的职位或者与项目相关的问题，如果这种类的问题问的很好，就加分。不过要问好这类的问题首先应聘者应对应聘的职位或项目的背景有一定的了解。可以从两方面去了解。一是面试前做足功课，到网上去搜集相关的信息，做到对公司成立时间、主要业务、职位要求都了解。二是在面试过程中留意面试官说过的话。有不少面试官在面试前会简单介绍与招聘职位相关的项目，其中会包含其他渠道无法获得的信息，比如项目的进展情况等，可以从中找出一两个点，然后向面试官提问。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"offer","slug":"offer","permalink":"https://github.com/zdkswd/tags/offer/"}]},{"title":"Python数据科学手册 NumPy入门","slug":"Python数据科学手册","date":"2018-10-28T07:00:56.000Z","updated":"2018-10-28T07:12:24.000Z","comments":true,"path":"2018/10/28/Python数据科学手册/","link":"","permalink":"https://github.com/zdkswd/2018/10/28/Python数据科学手册/","excerpt":"","text":"Python数据科学手册 NumPy入门数据集的来源与格式都十分丰富，比如文档集合、图像集合、声音片段集合、数值数据集合，等等。这些数据虽然存在明显的异构性，但是将所有数据简单地看作数字数组非常有助于我们理解和处理数据。 例如，可以将图像（尤其是数字图像）简单地看作二维数字数组，这些数字数组代表各区域的像素值；声音片段可以看做时间和强度的一维数组；文本也可以通过各种方式转化为数值表示，一种可能的转换时用二进制数表示特定单词或单词对出现的频率。不管数据是何种形式，第一步都是将这些数据转化为数值叔祖形式的可分析数据。 正因如此，有效地存储和操作数值数组是数据科学中绝对的基础过程。NumPy(Numerical Python的简称)提供了高效3存储和操作密集数据缓存的接口。 理解Python中的数据类型Python的类型灵活性指出了一个事实：Python变量不仅是它们的值，还包括了关于值得类型的一些额外信息。 Python整型不仅仅是一个整型标准的Python实现是用C语言编写的。这意味着每一个Python对象都是一聪明的伪C语言结构体，该结构体不仅包含其值，还有其他信息。例如当我们在Python中定义一个整型，x=10000时，x并不是一个‘原生’整型，而是一个指针，指向一个C语言的复合结构体，结构体里包含了一些值。 这意味着与C语言这样的编译语言的整型相比，在python中存储一个整型会有一些开销。 这里PyObject_HEAD是结构体中包含引用计数、类型编码和其他之前提到的内容的部分。 两者的差异在于，C语言整型本质上是对应某个内存位置的标签，里面存储的字节会编码成整型。而Python的整型其实是一个指针，指向包含这个Python对象所有信息的某个内存位置，其中包括可以转换成整型的字节。由于Python的整型结构体中还包含了大量额外的信息，所以Python可以自由、动态地编码，但是Python类型中的这些额外信息也会成为负担，在多个对象组合的结构体中尤其明显。 Python列表不仅仅是一个列表python中的标准可变多元素容器是列表。为了获得这些灵活的类型，列表中每一项必须包含各自的类型信息、引用计数和其他信息。也就是每一项都是一个完整的Python对象。python的列表甚至可以是异构的，即每项的类型可以不同。如果列表中的所有变量都是同一类型的，那么很多信息会显得多余—将数据存储在固定类型的数组应该会更高效。动态类型的列表和固定类型（NumPy式）数组的区别。 在实现层面,数组基本上包含一个指向连续数据块的指针。另一方面,Python列表包含一个指向指针块的指针,这其中的每一个指针对应一个完整的 Python对象(如前面看到的 Python整型)。另外,列表的优势是灵活,因为每个列表元素是一个包含数据和类型信息的完整结构体,而且列表可以用任意类型的数据填充。固定类型的 NumPy式数组缺乏这种灵活性,但是能更有效地存储和操作数据。 Python中固定类型数组Python提供了几种将数据存储在有效的、固定类型的数据缓存中的选项。内置的数组( array)模块(在 Python3.3之后可用)可以用于创建统一类型的密集数组: 从Python列表创建数组 最后，不同于Python列表，NumPy数组可以被指定为多维的。 从头创建数组面对大型数组的时候，用NumPy内置的方法从头创建数组是一种更高效的方法。 NumPy标准数据类型NumPy数组包含同一类型的值，因此详细了解这些数据类型及其限制是非常重要的。因为NumPy是在C语言的基础上开发的，所以c的用户会比较熟悉这些数据类型。 当构建一个数组时，你可以用一个字符串参数来指定数据类型。 还可以进行更高级的数据类型指定，例如指定高位字节数或低位字节数。 NumPy数组基础python中的数据操作几乎等同于NumPy数组操作，甚至新出现的Pandas工具也是构建在NumPy数组基础上的。 NumPy数组的属性我们将用NumPy的随机数生成器设置一组种子值，以确保每次程序执行时都可以生成同样的随机数组。 每个数组有nidm(维度)、shape(数组每个维度的大小)和size(数组的大小)属性： 另一个有用的属性时dtype,它是数组的数据类型。其他的属性包括每个数组元素字节的大小itemsize,以及表示数组总字节大小的属性nbytes。可以认为nbytes跟itemsize和size的乘积大小相等。 数组索引：获取单个元素NumPy中可以通过中括号指定索引获取第i个值（从0开始计数），为了获取数组的末尾索引，可以用负值索引，在多维数组中，可以用逗号分隔的索引元组获取元素。也可以用以上索引方式修改元素值。注意：和Python列表不同，NumPy数组是固定类型的。这意味着当试图将一个浮点值插入一个整型数组时，浮点值会被截断成整型，并且是自动完成的。 数组切片：获取子数组可以用切片（slice）符号获取子数组，切片符号用冒号（：）表示。 多维子数组多维切片也采用同样的方式处理，用冒号分隔。 子数组维度也可以同时被逆序。 获取数组的行和列一种常见的需求是获取数组的单行和单列。你可以将索引与切片组合起来实现这个功能。用一个冒号（：）表示空切片。 在获取行时，出于语法的简介考虑，可以省略空的切片。 非副本视图的子数组关于数组切片有一点很重要也非常有用,那就是数组切片返回的是数组数据的视图,而不是数值数据的副本。这一点也是 NumPy数组切片和 Python列表切片的不同之处:在 Python列表中,切片是值的副本。这种默认的处理方式实际上非常有用：它意味着在处理非常大的数据集时，可以获取或处理这些数据集的片段，而不用复制底层的数据缓存。 创建数组的副本尽管数组视图有一些非常好的特性，但是在有些时候明确地复制数组里的数据或子数组也是非常有用的。可以简单地通过copy（）方法实现。 如果修改这个子数组，原始的数值不会被改变。 数组的变形数组变形最灵活的实现方式是通过reshape()函数来实现。 如果希望该方法可行，那么原始数组的大小必须和变形后数组的大小一致。如果满足条件reshape方法将会用到原始数组的一个非副本视图。但实际是，在非连续的数据缓存下，返回非副本视图往往不可能实现。 一个常见的变形模式是将一个一位数组转变为二维的行或列的矩阵。 数组拼接和分裂数组的拼接拼接或连接NumPy中的两个数组主要由np.concatenate、np.vstack和np.hstack例程实现。 也可以一次拼接两个以上数组。 np.concatentate也可以由于二维数组的拼接。 沿着固定维度处理数组时，使用np.vstack(垂直栈)和np.hstack(水平栈)函数会更简洁。 与之类似，np.dstack将沿着第三个维度拼接数组。 数组的分裂分裂可以通过np.split、np.hsplit和np.vsplit函数来实现。可以转递一个索引列表作为参数，索引列表记录的是分裂点位置。 n分裂点会得到n+1个子数组。np.hsplit和np.vsplit的用法也类似。 同样，np.dspliy将数组沿着第三个维度分裂。 NumPy数组的计算：通用函数缓慢的循环Python的默认实现(被称作 CPython)处理起某些操作时非常慢,一部分原因是该语言的动态性和解释性—数据类型灵活的特性决定了序列操作不能像C语言和 Fortran语言一样被编译成有效的机器码。目前,有一些项目试图解决 Python这一弱点,比较知名的包括:PyPy项目一个实时的 Python编译实现; Cython项目,将 Python代码转换成可编译的C代码;Nuba项目,将 Python代码的片段转换成快速的LLⅴM字节码。以上这些项目都各有其优势和劣势,但是比较保守地说,这些方法中还没有一种能达到或超过标准 CPython引擎的受欢迎程度。 Python的相对缓慢通常出现在很多小操作需要不断重复的时候,比如对数组的每个元素做循环操作时。处理结果所花费的时间是不合时宜的慢，处理瓶颈并不是运算本身，而是CPython在每次循环时必须做数据类型的检查和函数调度。在进行循环中每一轮的运算时，Python首先检查对象的类型，并且动态查找可以使用该数据类型的正确函数。如果我们在编译代码时进行这样的操作，那么就能在代码执行之前知晓类型的声明，结果的计算也会更加有效率。 通用函数介绍NumPy为很多类型的操作提供了非常方便的、静态类型的、可编译程序的接口,也被称作向量操作。你可以通过简单地对数组执行操作来实现,这里对数组的操作将会被用于数组中的每一个元素。这种向量方法被用于将循环推送至 NumPy之下的编译层,这样会取得更快的执行效率。如果计算一个较大数组的运行时间，可以看到它的时间比Python循环花费的时间更短。 探索NumPy的通用函数通用函数有两种存在形式:一元通用函数( unary func)对单个输入操作,二元通用函数( binary ufunc)对两个输入操作。 数组的运算NumPy通用函数的使用方式非常自然,因为它用到了 Python原生的算术运算符,标准的加、减、乘、除都可以使用，还有逻辑非，指数运算符和模运算符的一元通用函数。可以任意将这些算术运算符组合使用，当然得考虑这些运算符的优先级。所有这些算术运算符都是NumPy内置函数的简单封装器，例如+运算符就是一个add函数的封装器。 绝对值正如 NumPy能理解 Python内置的运算操作, NumPy也可以理解Python内置的绝对值函数。对应的 NumPy通用函数是 np. absolute,该函数也可以用别名np. abs来访问。 三角函数NumPy提供了大量好用的通用函数,其中对于数据科学家最有用的就是三角函数。np.sin() np.cos() np.tan()逆三角函数同样可以使用。np.arcsin() np.arccos() np.arctan() 指数和对数np.log np.exp 专用的通用函数除了以上介绍到的, NumPy还提供了很多通用函数,包括双曲三角函数、比特位运算、比较运算符、弧度转化为角度的运算、取整和求余运算,等等。浏览 NumPy的文档将会揭示很多有趣的功能。还有一个更加专用,也更加晦涩的通用函数优异来源是子模块scipy. special。如果你希望对你的数据进行一些更晦涩的数学计算, scipy. special可能包含了你需要的计算函数。 NumPy和 scIpy. specia1中提供了大量的通用函数,这些包的文档在网上就可以查到,搜索“ gamma function python”即可。 高级的通用函数特性指定输出 对于较大的数组，通过慎重使用out参数能有效节约内存。 聚合二元通用函数有些非常有趣的聚合功能,这些聚合可以直接在对象上计算。例如,如果我们希望用一个特定的运算 reduce一个数组,那么可以用任何通用函数的 reduce方法。一个 reduce方法会对给定的元素和操作重复执行,直至得到单个的结果。如果需要存储每次计算的中间结果，可以使用accumulate。 请注意,在一些特殊情况中, NumPy提供了专用的函数(np.sum、np.prod、np. cumsum、np. cumprod),它们也可以实现以上 reduce的功能。 外积最后,任何通用函数都可以用 outer方法获得两个不同输入数组所有元素对的函数运算结果。这意味着你可以用一行代码实现一个乘法表。 通用函数：更多的信息有关通用函数的更多信息(包括可用的通用函数的完整列表)可以在NumPy和SciPy文档的网站找到。 聚合：最小值、最大值和其他值当面对大量的数据时，第一个步骤通常都是计算相关数据的概括统计值。最常用的概括统计值可能是均值和标准差，这两个值能让你分别概括出数据集中的“经典”值，但是其他一些形式的聚合也是非常有用的（如求和、乘积、中位数、最小值和最大值、分位数，等等）。 数组值求和Sum函数和np.sum函数并不等同,这有时会导致混淆。尤其是它们各自的可选参数都有不同的含义,np.sum函数是知道数组的维度的。sum是python求和，当然np.sum更快。 最小值和最大值Python也有内置的min函数和max函数,分别被用于获取给定数组的最小值和最大值，NumPy对应的函数也有类似的语法,并且也执行得更快。 多维度聚合一种常用的聚合操作时沿着一行或一列聚合。默认情况下，每一个NumPy聚合函数将会返回对整个数组的聚合结果，聚合函数还有一个参数，用于指定沿着哪个轴的方向进行聚合。axis关键字指定的是数组将会被折叠的维度，而不是将要返回的维度。因此指定axis=0意味着第一个轴将要被折叠。对于二维数组，这意味着每一列的值都将被聚合。 其他聚合函数大多数的聚合都有对NaN值的安全处理策略，即计算时忽略所有的缺失值。 数组的计算：广播另外一种向量化操作的方法是利用 NumPy的广播功能。广播可以简单理解为用于不同大小数组的二进制通用函数(加、减、乘等)的一组规则。 广播的介绍对于同样大小的数组，二进制操作是对相应元素逐个计算。 广播允许这些二进制操作可以用于不同大小的数组，例如可以将一个标量和一个数组相加。 我们也可以将这个原理扩展到更高维度，将一个一位数组和一个二维数组相加。 浅色的盒子表示广播的值。需要注意的是,这个额外的内存并没有在实际操作中进行分配,但是这样的想象方式更方便我们从概念上理解。 广播的规则 比较、掩码和布尔逻辑这一节将会介绍如何用布尔掩码来查看和操作 NumPy数组中的值。当你想基于某些准则来抽取、修改、计数或对一个数组中的值进行其他操作时,掩码就可以派上用场了。例如你可能希望统计数组中有多少值大于某一个给定值,或者删除所有超出某些门限值的异常点。在NumPy中,布尔掩码通常是完成这类任务的最高效方式。 操作布尔数组统计记录的个数如果需要统计布尔数组中True记录的个数,可以使用np. count_nonzero函数。 如要快速检查任意或者所有的值是否为True，可以用np.any()或np.all()。 布尔运算值同标准的算术运算符一样，NumPy用通用函数重载了这些逻辑运算符，这样可以实现数组的逐位运算（通常是布尔运算）。 将布尔数组作为掩码 花哨的索引花哨的索引和前面那些简单的索引非常类似，但是传递的是索引数组，而不是单个标量。花哨的索引让我们能够快速获得并修改复杂得数组值的字数据集。 探索花哨的索引花哨的索引在概念上非常简单,它意味着传递一个索引数组来一次性获得多个数组元素。 花哨的索引也对多个维度适用。 组合索引花哨的索引可以和其他索引方案结合起来形成更强大的索引操作。 更可以将花哨的索引和掩码组合使用。 数组的排序NumPy中的快速排序：np.sort和np.argsort尽管Python有内置的sort和sorted函数可以对列表进行排序，但是效率并不高，NumPy的np.sort函数实际上效率更高。默认情况下，np.sort的排序算法是快速排序，其算法复杂度O[NlogN]，另外也可以选择归并排序和堆排序。对于大多数应用场景，默认的快速排序已经足够高效了。 NumPy排序算法的一个有用功能是通过axis参数，沿着多维数组的行或列进行排序。 这种处理方式是将行或列当做独立的数组，任何行或列的值之间的关系将会丢失。 部分排序：分隔有时候我们不希望对整个数组进行排序，仅仅希望找到数组中第K小的值，NumPy的np.partition函数提供了该功能，最左边是第K小的值，往右是任意顺序的其他值。 与排序类似，也可以沿着多维数组任意的轴进行分割。正如np.argsort函数计算的是排序的索引值，也有一个np.argpartition函数计算的是分隔的索引值。 结构化数据：NumPy的结构化数组 这里U1表示“长度不超过10的 Unicode字符串”,i4表示“4字节(即32比特)整型”,f8表示“8字节(即64比特)浮点型”。 现在生成了一个空的数组容器，可以将列表数据放入数组中。 正如我们希望的，所有的数据被安排在一个内存块中。 更高级的复合类型NumPy中也可以定义更高级的复合数据类型。例如,你可以创建一种类型,其中每个元素都包含一个数组或矩阵。我们会创建一个数据类型,该数据类型用mat组件包含一个3×3的浮点矩阵。 现在X数组的每个元素都包含一个id和一个3×3的矩阵。为什么我们宁愿用这种方法存储数据,也不用简单的多维数组,或者 Python字典呢?原因是 NumPy的 dtype直接映射到C结构的定义,因此包含数组内容的缓存可以直接在C程序中使用。如果你想写一个 Python接口与一个遗留的C语言或 Fortran库交互,从而操作结构化数据,你将会发现结构化数组非常有用! 记录数组：结构化数组的扭转NumPy还提供了np.recarray类。它和前面介绍的结构化数组几乎相同，但是它有一个独特的特征：域可以像属性一样获取，而不是像字典的键那样获取。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"机器学习数学基础下","slug":"机器学习数学基础下","date":"2018-10-23T13:28:47.000Z","updated":"2018-10-23T13:34:44.000Z","comments":true,"path":"2018/10/23/机器学习数学基础下/","link":"","permalink":"https://github.com/zdkswd/2018/10/23/机器学习数学基础下/","excerpt":"","text":"线性代数进阶 矩阵变换 矩阵的标准型：相似变换（把矩阵看做线性映射） 矩阵的标准型：相合变换（二次型） 主成分分析（PCA）PCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。降维当然意味着信息的丢失，不过鉴于实际数据本身常常存在的相关性，我们可以想办法在降维的同时将信息的损失尽量降低。举个例子，假如某学籍数据有两列M和F，其中M列的取值是如何此学生为男性取值1，为女性取值0；而F列是学生为女性取值1，男性取值0。此时如果我们统计全部学籍数据，会发现对于任何一条记录来说，当M为1时F必定为0，反之当M为0时F必定为1。在这种情况下，我们将M或F去掉实际上没有任何信息的损失，因为只要保留一列就可以完全还原另一列。 选择不同的基可以对同样一组数据给出不同的表示，而且如果基的数量少于向量本身的维数，则可以达到降维的效果。但是我们还没有回答一个最最关键的问题：如何选择基才是最优的。 如图中如果想要将二维转化为一维，若想少丢失信息，则应将投影尽可能的分散。而这种分散程度，可以用数学上的方差来表述。 于是上面的问题被形式化表述为：寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。 考虑三维降到二维问题。与之前相同，首先我们希望找到一个方向使得投影后方差最大，这样就完成了第一个方向的选择，继而我们选择第二个投影方向。直观上说，让两个字段尽可能表示更多的原始信息，我们是不希望它们之间存在（线性）相关性的，因为相关性意味着两个字段不是完全独立，必然存在重复表示的信息。数学上可以用两个字段的协方差表示其相关性。 至此，我们得到了降维问题的优化目标：将一组N维向量降为K维（K大于0，小于N），其目标是选择K个单位（模为1）正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大（在正交的约束下，取最大的K个方差）。 上面我们导出了优化目标，但是这个目标似乎不能直接作为操作指南（或者说算法），因为它只说要什么，但根本没有说怎么做。所以我们要继续在数学上研究计算方案。 根据上述推导，我们发现要达到优化目前，等价于将协方差矩阵对角化：即除对角线外的其它元素化为0，并且在对角线上将元素按大小从上到下排列，这样我们就达到了优化目的。 最后需要说明的是，PCA是一种无参数技术，也就是说面对同样的数据，如果不考虑清洗，谁来做结果都一样，没有主观参数的介入，所以PCA便于通用实现，但是本身无法个性化的优化。 （奇异值分解）SVD SVD与PCA我们讲到要用PCA降维，需要找到样本协方差矩阵的最大的k个特征向量，然后用这最大的k个特征向量张成的矩阵来做低维投影降维。 SVD也可以得到协方差矩阵最大的k个特征向量张成的矩阵。 就是说，PCA算法可以不用做特征分解，而是做SVD来完成。 凸优化 最小二乘法是经常使用的优化算法。 对于目标函数，我们限定是凸函数；对于优化变量的可行域（注意，还要包括目标函数定义域的约束），我们限定它是凸集。同时满足这两个限制条件的最优化问题称为凸优化问题，这类问题有一个非常好性质，那就是局部最优解一定是全局最优解。 凸集： 优化问题举例：EM算法简介与混合高斯模型 第一步（E）:如果这个混合模型中，每一次的输出我们知道它是从哪一个模型里边出来的就好了 第二步（M）：最大化似然函数 逐次逼近最优解。 凸优化进阶机器学习与优化 共轭函数与对偶方法 给定一个优化问题，如果比较复杂，可以转化为优化问题的对偶问题。 勒让德（Legendre）变化的理解：函数上境图的支撑超平面的截距。 对偶（共轭）函数抓住了原来函数的一些性质，没有抓住全部性质，抓住了原来函数凸闭包的性质。非凸函数的凸闭包函数是最接近其性质的凸函数，所以可以拿来做近似。第一个结论告诉我勒让德变换抓的是凸包的性质，第二个性质告诉我们，如果是凸函数了。变成共轭函数了没有丢失信息，再做一次变换还能变回来。 第三点说明对于一般的函数，共轭变换是丢失了一部分信息的。 第二点说的就是几何性质。 对偶问题：拉格朗日对偶问题 对于没有约束条件的问题，可以使用牛顿法。对于有约束条件的问题，最优解可能不在可行域里，这时就不太好解了。 当对一群线性函数取逐点极小值的时候，得到的是一个凹函数。所以g函数是一个凹函数。其中x属于全部定义域，是没有约束条件的，这样再做就比较简单。 我们将一个待求函数比较简单但约束条件比较复杂得问题转换为了一个待求函数比较复杂但约束条件比较简单的问题。把问题的复杂性转化到了函数里面去。待求函数不管凸的凹的可以用牛顿法去做逼近。 那转化后的问题与原问题有什么关系呢？ 用g的上界提供了原问题的下界。 d是g的最大值，p是f的最小值。 强对偶性条件 凸优化问题比较容易去求解，但是为什么还需要求对偶变化呢，是因为约束条件比较复杂。需要简化。 当你是对偶问题时，在凸性上一定是变好的，但是不一定能抓住原来问题的所有性质。 一些概念 琴生不等式： 上确界（Supremum）：一个集合的最小上界， 数学符号sups下确界（greatest lower boundinf）：一个集合的最大下界,数学符号inf上确界与最大值：上确界类似于最大值，但是和最大值不同的是，最大值有时候会遇到无法取到的情况。比如x∈R,x&lt;2这样的情况下就不存在一个确定的最大值。但是可以确定上确界为2。 a,x都是向量，b是常数。 简单来说仿射变换就是线性变换加平移。线性变化中原点还在原点，但仿射变换后，原点就移动了。 如何通俗地讲解「仿射变换」这个概念？ - 马同学的回答 - 知乎https://www.zhihu.com/question/20666664/answer/157400568 将前z维每一项都除以最后一维t,将最后一项t舍弃。 支持向量机（SVM） 分割使用的是n-1维的超平面。 等式条件定义了一个球面，球面不是一个凸集合。 此时把支持向量机问题转化为了一个凸优化问题。 允许c和d有一部分交叉。或者使用核方法，将维度增加，再进行划分。 C抜D抜离得最近的两个点的垂直平分线。 压缩感知与图像处理 算法和理论与数学知识点","categories":[{"name":"听课笔记","slug":"听课笔记","permalink":"https://github.com/zdkswd/categories/听课笔记/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"常见的几种最优化方法","slug":"常见的几种最优化方法","date":"2018-10-22T13:32:51.000Z","updated":"2018-11-06T05:42:13.000Z","comments":true,"path":"2018/10/22/常见的几种最优化方法/","link":"","permalink":"https://github.com/zdkswd/2018/10/22/常见的几种最优化方法/","excerpt":"","text":"Math 常见的几种最优化方法 - Poll的笔记 - 博客园最优化方法与凸优化，我们研究凸优化，是因为凸优化比较好研究，其实正确的叫法应当叫最优化方法。 梯度下降法梯度下降法是最早最简单，也是最为常用的最优化方法。梯度下降法实现简单，当目标函数是凸函数时，梯度下降法的解是全局解。一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。 梯度下降的缺点： 靠近极小值时收敛速度减慢，如下图所示 直线搜索时可能会产生一些问题 可能会“之字形”地下降。 为什么计算函数极值用梯度下降算法而不直接令导数为0求解并不是所有的函数都可以根据导数求出取得0值的点的, 现实的情况可能是:1、可以求出导数在每个点的值, 但是直接解方程解不出来,2、计算机更加适合用循环迭代的方法来求极值。 批量梯度下降法（BGD）最小化所有训练样本的损失函数，使得最终求解的是全局的最优解，即求解的参数是使得风险函数最小，但是对于大规模样本问题效率低下。 随机梯度下降法（SGD）最小化每条样本的损失函数，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近，适用于大规模训练样本情况。 两者的关系可以这样理解：随机梯度下降方法以损失很小的一部分精确度和增加一定数量的迭代次数为代价，换取了总体的优化效率的提升。增加的迭代次数远远小于样本的数量。 牛顿法和拟牛顿法牛顿法如何通俗易懂地讲解牛顿迭代法？五次及以上多项式方程没有根式解（就是没有像二次方程那样的万能公式）。没有根式解不意味着方程解不出来，数学家也提供了很多方法，牛顿迭代法就是其中一种。 代数解法 不总是收敛（不总是能求得足够近似的根）充分条件： 也就是说有很多情况下选择牛顿法，根不收敛。 而且不能完整求出所有的根，只能求到起始点附近的根。 总结应用牛顿法最好： 函数在整个定义域内最好是二阶可导的 起始点对求根计算影响重大，可以增加一些别的手段进行试错。 求解最值问题牛顿法也被用于求函数的最值。由于函数取最值的点处的导数值为零，故可用牛顿法求导函数的零点，其迭代式为 高维情况的牛顿迭代式 高维情况依然可以用牛顿迭代求解，但是问题是Hessian矩阵引入的复杂性，使得牛顿迭代求解的难度大大增加，但是已经有了解决这个问题的办法就是Quasi-Newton methond，不再直接计算hessian矩阵，而是每一步的时候使用梯度向量更新hessian矩阵的近似。 关于牛顿法与梯度下降法效率的对比 从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。） 根据wiki上的解释，从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。 优缺点优点：二阶收敛，收敛速度快；缺点：牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。 拟牛顿法拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。 针对牛顿法中海塞矩阵的计算问题，拟牛顿法主要是使用一个海塞矩阵的近似矩阵来代替原来的还塞矩阵，通过这种方式来减少运算的复杂度。其主要过程是先推导出海塞矩阵需要满足的条件，即拟牛顿条件（也可以称为拟牛顿方程）。然后我们构造一个满足拟牛顿条件的近似矩阵来代替原来的海塞矩阵。 外，在满足拟牛顿条件的基础上如何构造近似的海塞矩阵，这有很多种方法，比如：DFP算法，BFGS算法，L-BFGS算法以及Broyden类算法等。常用前两种。 在牛顿法推导中： 然后对f(x)求偏导： 令x=xk得到： g等于f的一阶导。 简化： 于是： 在满足此条件的基础上如何构造近似海塞矩阵呢？下面介绍两个方法：DFP算法和BFGS算法。 DFP算法 BFGS算法 BFGS算法是用直接逼近海塞矩阵的方式来构造近似海塞矩阵，同样，我们使用迭代的方式来逐步逼近。我们使用B来表示海塞矩阵的近似矩阵，而在DFP算法中我们是直接使用D来构造近似海塞矩阵的逆矩阵。 共轭梯度法共轭梯度法是介于最速下降法与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了最速下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hesse矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一。 在各种优化算法中，共轭梯度法是非常重要的一种。其优点是所需存储量小，具有步收敛性，稳定性高，而且不需要任何外来参数。 注：绿色为梯度下降法，红色代表共轭梯度法 启发式优化方法启发式方法指人在解决问题时所采取的一种根据经验规则进行发现的方法。其特点是在解决问题时,利用过去的经验,选择已经行之有效的方法，而不是系统地、以确定的步骤去寻求答案。启发式优化方法种类繁多，包括经典的模拟退火方法、遗传算法、蚁群算法以及粒子群算法等等。 还有一种特殊的优化算法被称之多目标优化算法，它主要针对同时优化多个目标（两个及两个以上）的优化问题，这方面比较经典的算法有NSGAII算法、MOEA/D算法以及人工免疫算法等。 解决约束优化问题—拉格朗日乘数法拉格朗日乘数法的基本思想 作为一种优化算法，拉格朗日乘子法主要用于解决约束优化问题，它的基本思想就是通过引入拉格朗日乘子来将含有n个变量和k个约束条件的约束优化问题转化为含有（n+k）个变量的无约束优化问题。拉格朗日乘子背后的数学意义是其为约束方程梯度线性组合中每个向量的系数 如何将一个含有n个变量和k个约束条件的约束优化问题转化为含有（n+k）个变量的无约束优化问题？拉格朗日乘数法从数学意义入手，通过引入拉格朗日乘子建立极值条件，对n个变量分别求偏导对应了n个方程，然后加上k个约束条件（对应k个拉格朗日乘子）一起构成包含了（n+k）变量的（n+k）个方程的方程组问题，这样就能根据求方程组的方法对其进行求解。 拉格朗日乘数法的基本形态 拉格朗日乘数法与KKT条件我们上述讨论的问题均为等式约束优化问题，但等式约束并不足以描述人们面临的问题，不等式约束比等式约束更为常见，大部分实际问题的约束都是不超过多少时间，不超过多少人力，不超过多少成本等等。所以有几个科学家拓展了拉格朗日乘数法，增加了KKT条件之后便可以用拉格朗日乘数法来求解不等式约束的优化问题了。 KKT条件是指在满足一些有规则的条件下, 一个非线性规划(Nonlinear Programming)问题能有最优化解法的一个必要和充分条件.","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"JavaScript标准参考教程 DOM 事件模型","slug":"JavaScript标准参考教程 DOM 事件模型","date":"2018-10-21T06:53:56.000Z","updated":"2018-10-21T06:55:42.000Z","comments":true,"path":"2018/10/21/JavaScript标准参考教程 DOM 事件模型/","link":"","permalink":"https://github.com/zdkswd/2018/10/21/JavaScript标准参考教程 DOM 事件模型/","excerpt":"","text":"事件的本质是程序各个组成部分之间的一种通信方式，也是异步编程的一种实现。DOM 支持大量的事件。 EventTarget接口DOM 的事件操作（监听和触发），都定义在EventTarget接口。所有节点对象都部署了这个接口，其他一些需要事件通信的浏览器内置对象（比如，XMLHttpRequest、AudioNode、AudioContext）也部署了这个接口。 该接口主要提供三个实例方法。 EventTarget.addEventListener()EventTarget.addEventListener()用于在当前节点或对象上，定义一个特定事件的监听函数。一旦这个事件发生，就会执行监听函数。该方法没有返回值。 该方法接受三个参数。 例子： 关于参数： 第二个参数除了监听函数，还可以是一个具有handleEvent方法的对象。 第三个参数除了布尔值useCapture，还可以是一个属性配置对象。该对象有以下属性。 addEventListener方法可以为针对当前对象的同一个事件，添加多个不同的监听函数。这些函数按照添加顺序触发，即先添加先触发。如果为同一个事件多次添加同一个监听函数，该函数只会执行一次，多余的添加将自动被去除。 如果希望向监听函数传递参数，可以用匿名函数包装一下监听函数。 监听函数内部的this，指向当前事件所在的那个对象。 EventTarget.removeEventListener()EventTarget.removeEventListener方法用来移除addEventListener方法添加的事件监听函数。该方法没有返回值。 removeEventListener方法的参数，与addEventListener方法完全一致。它的第一个参数“事件类型”，大小写敏感。 注意，removeEventListener方法移除的监听函数，必须是addEventListener方法添加的那个监听函数，而且必须在同一个元素节点，否则无效。 EventTarget.dispatchEvent()EventTarget.dispatchEvent方法在当前节点上触发指定事件，从而触发监听函数的执行。该方法返回一个布尔值，只要有一个监听函数调用了Event.preventDefault()，则返回值为false，否则为true。 dispatchEvent方法的参数是一个Event对象的实例。 如果dispatchEvent方法的参数为空，或者不是一个有效的事件对象，将报错。 监听函数浏览器的事件模型，就是通过监听函数（listener）对事件做出反应。事件发生后，浏览器监听到了这个事件，就会执行对应的监听函数。这是事件驱动编程模式（event-driven）的主要编程方式。 JavaScript有三种方法，可以为事件绑定监听函数。 HTML的on-属性HTML 语言允许在元素的属性中，直接定义某些事件的监听代码。 注意，这些属性的值是将会执行的代码，而不是一个函数。一旦指定的事件发生，on-属性的值是原样传入 JavaScript 引擎执行。因此如果要执行函数，不要忘记加上一对圆括号。 使用这个方法指定的监听代码，只会在冒泡阶段触发。 上面代码中，&lt; button&gt;是&lt; div&gt;的子元素。&lt; button&gt;的click事件，也会触发&lt; div&gt;的click事件。由于on-属性的监听代码，只在冒泡阶段触发，所以点击结果是先输出1，再输出2，即事件从子元素开始冒泡到父元素。 直接设置on-属性，与通过元素节点的setAttribute方法设置on-属性，效果是一样的。 元素节点的事件属性元素节点对象的事件属性，同样可以指定监听函数。 使用这个方法指定的监听函数，也是只会在冒泡阶段触发。 注意，这种方法与 HTML 的on-属性的差异是，它的值是函数名（doSomething），而不像后者，必须给出完整的监听代码（doSomething()）。 EventTarget.addEventListener()所有 DOM 节点实例都有addEventListener方法，用来为该节点定义事件的监听函数。 小结 第一种“HTML 的 on- 属性”，违反了 HTML 与 JavaScript 代码相分离的原则，将两者写在一起，不利于代码分工，因此不推荐使用。 “元素节点的事件属性”的缺点在于，同一个事件只能定义一个监听函数，也就是说，如果定义两次onclick属性，后一次定义会覆盖前一次。因此，也不推荐使用。 EventTarget.addEventListener是推荐的指定监听函数的方法。它有如下优点： this的指向监听函数内部的this指向触发事件的那个元素节点。事件的传播一个事件发生后，会在子元素和父元素之间传播（propagation）。这种传播分成三个阶段。 这种三阶段的传播模型，使得同一个事件会在多个节点上触发。 事件的代理由于事件会在冒泡阶段向上传播到父节点，因此可以把子节点的监听函数定义在父节点上，由父节点的监听函数统一处理多个子元素的事件。这种方法叫做事件的代理（delegation）。 上面代码中，click事件的监听函数定义在&lt; ul&gt;节点，但是实际上，它处理的是子节点&lt; li&gt;的click事件。这样做的好处是，只要定义一个监听函数，就能处理多个子节点的事件，而不用在每个&lt; li&gt;节点上定义监听函数。而且以后再添加子节点，监听函数依然有效。 如果希望事件到某个节点为止，不再传播，可以使用事件对象的stopPropagation方法。 但是，stopPropagation方法只会阻止事件的传播，不会阻止该事件触发&lt; p&gt;节点的其他click事件的监听函数。也就是说，不是彻底取消click事件。 如果想要彻底阻止这个事件的传播，不再触发后面所有click的监听函数，可以使用stopImmediatePropagation方法。 Event对象概述事件发生以后，会产生一个事件对象，作为参数传给监听函数。浏览器原生提供一个Event对象，所有的事件都是这个对象的实例，或者说继承了Event.prototype对象。 Event对象本身就是一个构造函数，可以用来生成新的实例。 Event构造函数接受两个参数。第一个参数type是字符串，表示事件的名称；第二个参数options是一个对象，表示事件对象的配置。该对象主要有下面两个属性。 上面代码新建一个look事件实例，然后使用dispatchEvent方法触发该事件。 注意，如果不是显式指定bubbles属性为true，生成的事件就只能在“捕获阶段”触发监听函数。 Event对象的实例属性Event.bubbles，Event.eventPhaseEvent.bubbles属性返回一个布尔值，表示当前事件是否会冒泡。该属性为只读属性，一般用来了解 Event 实例是否可以冒泡。前面说过，除非显式声明，Event构造函数生成的事件，默认是不冒泡的。 Event.eventPhase属性返回一个整数常量，表示事件目前所处的阶段。该属性只读。 Event.eventPhase的返回值有四种可能。 Event.cancelable，Event.cancelBubble，event.defaultPreventedEvent.cancelable属性返回一个布尔值，表示事件是否可以取消。该属性为只读属性，一般用来了解 Event 实例的特性。 大多数浏览器的原生事件是可以取消的。比如，取消click事件，点击链接将无效。但是除非显式声明，Event构造函数生成的事件，默认是不可以取消的。 当Event.cancelable属性为true时，调用Event.preventDefault()就可以取消这个事件，阻止浏览器对该事件的默认行为。 如果事件不能取消，调用Event.preventDefault()会没有任何效果。所以使用这个方法之前，最好用Event.cancelable属性判断一下是否可以取消。 Event.defaultPrevented属性返回一个布尔值，表示该事件是否调用过Event.preventDefault方法。该属性只读。 Event.currentTarget，Event.targetEvent.currentTarget属性返回事件当前所在的节点，即正在执行的监听函数所绑定的那个节点。 Event.target属性返回原始触发事件的那个节点。 也就是currentTarget—&gt;p节点。&lt; em&gt;子节点上面点击，则e.target指向&lt; em&gt;子节点，导致&lt; em&gt;子节点（即 World 部分）会不可见。如果点击 Hello 部分，则整个para都将不可见。 Event.typeEvent.type属性返回一个字符串，表示事件类型。事件的类型是在生成事件的时候。该属性只读。 Event.timeStampEvent.timeStamp属性返回一个毫秒时间戳，表示事件发生的时间。它是相对于网页加载成功开始计算的。 它的返回值有可能是整数，也有可能是小数（高精度时间戳），取决于浏览器的设置。 Event.isTrustedEvent.isTrusted属性返回一个布尔值，表示该事件是否由真实的用户行为产生。比如，用户点击链接会产生一个click事件，该事件是用户产生的；Event构造函数生成的事件，则是脚本产生的。 Event.detailEvent.detail属性只有浏览器的 UI （用户界面）事件才具有。该属性返回一个数值，表示事件的某种信息。具体含义与事件类型相关。比如，对于click和dbclick事件，Event.detail是鼠标按下的次数（1表示单击，2表示双击，3表示三击）；对于鼠标滚轮事件，Event.detail是滚轮正向滚动的距离，负值就是负向滚动的距离，返回值总是3的倍数。 Event 对象的实例方法Event.preventDefault()Event.preventDefault方法取消浏览器对当前事件的默认行为。比如点击链接后，浏览器默认会跳转到另一个页面，使用这个方法以后，就不会跳转了；再比如，按一下空格键，页面向下滚动一段距离，使用这个方法以后也不会滚动了。该方法生效的前提是，事件对象的cancelable属性为true，如果为false，调用该方法没有任何效果。 注意，该方法只是取消事件对当前元素的默认影响，不会阻止事件的传播。如果要阻止传播，可以使用stopPropagation()或stopImmediatePropagation()方法。 Event.stopPropagation()stopPropagation方法阻止事件在 DOM 中继续传播，防止再触发定义在别的节点上的监听函数，但是不包括在当前节点上其他的事件监听函数。 Event.stopImmediatePropagation()Event.stopImmediatePropagation方法阻止同一个事件的其他监听函数被调用，不管监听函数定义在当前节点还是其他节点。也就是说，该方法阻止事件的传播，比Event.stopPropagation()更彻底。 Event.composedPath()Event.composedPath()返回一个数组，成员是事件的最底层节点和依次冒泡经过的所有上层节点。 CustomEvent 接口CustomEvent 接口用于生成自定义的事件实例。那些浏览器预定义的事件，虽然可以手动生成，但是往往不能在事件上绑定数据。如果需要在触发事件的同时，传入指定的数据，就可以使用 CustomEvent 接口生成的自定义事件对象。浏览器原生提供CustomEvent()构造函数，用来生成 CustomEvent 事件实例。 CustomEvent()构造函数接受两个参数。第一个参数是字符串，表示事件的名字，这是必须的。第二个参数是事件的配置对象，这个参数是可选的。CustomEvent的配置对象除了接受 Event 事件的配置属性，只有一个自己的属性。 上面代码也说明，CustomEvent 的事件实例，除了具有 Event 接口的实例属性，还具有detail属性。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"3Blue1Brown线性代数","slug":"3Blue1Brown线性代数","date":"2018-10-15T10:05:32.000Z","updated":"2018-10-15T10:10:16.000Z","comments":true,"path":"2018/10/15/3Blue1Brown线性代数/","link":"","permalink":"https://github.com/zdkswd/2018/10/15/3Blue1Brown线性代数/","excerpt":"","text":"向量究竟是什么在数学中向量以原点为起点，在空间中是一个有向的箭头，每一个位置上的数值代表在对应轴上的数值。为了与点区分，所以向量竖着写。 向量的加法 向量的乘法 线性代数围绕两种基本运算：向量加法与向量数乘。 线性组合、张成的空间与基 基向量。 当我们用数字描述向量时，都依赖于我们所选择的基。 在二维空间中，如果v,w不共线且不为零向量，那么理论上av+bw就可以表示二维空间中所有的向量。 为什么叫线性组合，如果固定其中一个向量那么只能表示部分向量，这些向量的末端构成一条直线。 两个向量张成的空间实际上是问仅通过向量加法与向量数乘这两种基础运算，你能获得的所有可能向量的集合是什么。 向量VS点：可以用点来代替一个起点为原点，终点在该点上的一个向量。 三维向量： 三个向量的线性组合的张成空间同理。 线性相关：一个向量在其他向量线性组合的张成空间中，即这个向量没有提高所有向量组成的张成空间的维度。 线性无关：每一个向量都起到了提高张成空间维度的作用。 矩阵与线性变换变换只不过是函数的一种花哨说法，它接收输入内容，并输出对应结果。在线性代数中考虑的是向量输入，输出一个向量。那为什么不用函数这个词呢？变换这个词在暗示用运动去思考。 如果一个变换有以下两条性质，我们就称它是线性的：一是直线在变换后仍然保持为直线，不能有所弯曲。二是原点保持固定。 如上不是线性变换。 如上为线性变换 变换后的坐标。 由于线性变换后对于基向量的线性组合的值不变，所以只需要知道基向量的变换就可以算出变换后的任意向量的坐标。 变换后的i,j。一个在标准网格的坐标系中的一个向量(x,y) 一个二维线性变换仅由四个数字完全确定。变换后i帽的两个坐标与变换后j帽的两个坐标（标准网格下的坐标）。 矩阵在这里只是一个记号，它含有描述一个线性变换的信息。 矩阵乘法与线性变换复合两个独立变换可以进行复合变换 先旋转再剪切。 两个矩阵相乘有着几何意义，也就是两个线性变换相继作用 之所以能这么做是因为它们都在同一个坐标系下，即标准网格坐标系。 三维空间中的线性变换同理。 行列式 描述一个线性变换是让面积（对二维来说是面积，三维就是体积）拉伸还是挤压了。 也就是说如果一个行列式为0，那就是变换后成了一条线（对二维俩说）。推广就是计算一个矩阵的行列式，我们就能了解这个矩阵代表的变换是否将空间压缩到更小的维度上。 当空间定向改变的情况发生时，原本j在i的左侧，现在j在i的右侧了，行列式为负。 逆矩阵、列空间与零空间 逆矩阵就是逆变换。只要变换不讲空间压缩到更低维度，就有逆变换。 即使压缩到更低的维度，解依然有可能存在，当x恰好在直线上时，解就存在。 列空间就是矩阵的列所张成的空间。秩的更精确的定义是列空间的维数。满秩是指输入空间的维度等于矩阵的秩。对于一个满秩变换来说，唯一能在变换后落在原点的就是零向量自身。对于非满秩的变换，将维度压缩到更低的维度，也就是说会有一系列的向量会压缩到原点。在变换后落在原点的向量集合，被称为所选矩阵的零空间或核。 非方阵 几何意义是将二维空间映射到三维空间上。矩阵有两列表明输入空间有两个基向量，三维是表明变换到了三维空间坐标系中，张成空间为三维空间的一个过原点的二维平面，矩阵依然是满秩的，因为列空间的维数与输入空间的维数相等。 点积与对偶性 这里可以看做是二维空间压缩到一维的数轴上，由于变换是线性的，所以可以用一个1*2的矩阵来表示变换。 叉乘的标准介绍 顺序不同，正负不同。 这里才是真正的叉乘： 方向右手定则。 以线性变换的眼光看叉乘为什么上述的式子中要用到ijk?下面就来解释。 真正的三维向量的叉乘接收两个向量并输出一个向量。 这个函数的几何意义在于，对于任一输入的向量（x,y,z),你都考虑它和v,w确定的平行六面体得到它的体积，然后根据取向确定符号。这个函数是线性的。 一旦知道它是线性的，就可以知道可以通过矩阵乘法来描述这个函数。具体地说，因为这个函数从三维空间到一维空间，就会存在一个1*3矩阵来代表这个变换。根据对偶性，从多维空间到一维空间的变换的特别之处在于可以将整个变换看做与这个特定向量的点积。 我们要找的就是P，使得p与其他任意向量（x,y,z）的点积等于一个3* 3矩阵的行列式。 从算数角度上来说p就是 （。。。。）i+（。。。。）j+（。。。。）k 从几何的角度： 左边式子，向量p与其他向量的点积的几何解释，是将其他向量投影到p上。 右面式子是(x,y,z)的垂直分量*底部面积。和垂直于v,w且长度等于平行四边形面积的向量与（x,y,z）点乘一样。所以p垂直v,w且长度为平行四边形的面积。 所以 基变换线性变换中一个坐标系中的所有向量都跟着动，变换后的向量仍旧是相同的线性组合，不过使用的是新的基向量。基变换中，一个向量是不动的，动的是坐标系。 詹的坐标系： 一个我们坐标系中的向量： 詹系中对它的描述： 詹的基在我们系中的向量坐标： 詹的基自己的坐标： 不同的坐标系（基）对于空间内同一个向量的描述是不同的，也就是描述的语言不同。 不同的基的坐标原点是重合的。如何在不同的坐标系之间进行转化： 式1 就是将（-1，2）进行线性变换后，可以变为黄色的向量。 可以把这个式子看作是我们把我们对詹的误解（詹的坐标系下的数值直接拿到标准网格坐标系里）转化为真实的詹的所指，都是在标准网格坐标系下。 同理，如果取逆。 这时可以求在标准网格坐标系中的某点，在詹坐标系下的值。可在式一两侧左边同时乘以逆来很好的推出。 如果想要旋转90度，詹的基该如何表示？ 开始是一个詹下的向量： 我们转为我们的语言，在标准网格下的一个向量。 此时再进行旋转操作。 最后左乘一个逆矩阵，将其转换为詹的语言。 这就是詹的语言下旋转的操作。 特征向量与特征值在线性变换中，有的向量并不改变方向，只是拉伸或者缩小。 、 这些向量就叫特征向量，每个特征向量都有一个所属的值，拉伸倍数叫做特征值。 如果在三维变化中找到这个特征向量，那它就是旋转轴 抽象空间本质向量是什么？ 从某种意义上来说函数也是向量。 x,y,z是三个点的纵坐标。 同时也存在另一个函数转换为另一个函数的操作（对应线性变化），例如求导。 可见函数是线性的。 抽象性带来的好处是我们能得到一般性的结论。 所以，什么是向量？数学中有许多类似向量的事物，只要你处理的对象集具有合理的数乘和相加概念，线性代数中所有关于向量、线性变换和其他等产生的概念都应该适用于它。 这些类似向量的事物，比如箭头、一组数、函数等，它们构成的集合被称为“向量空间”。 如果要让所有已经建立好的理论和概念适用于一个向量空间，那么它必须满足八条公理。这些公理是一个接口，一边连着应用线代的人，另一边是数学家。 只要满足八条公理，就可以将线代应用到你的研究对象上，而数学家则是根据这些公理证明了你的结论。 向量可以是任何东西，只要它满足公理。回答向量是什么，就像回答3是什么一样。 普适的代价是抽象。","categories":[{"name":"听课笔记","slug":"听课笔记","permalink":"https://github.com/zdkswd/categories/听课笔记/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"}]},{"title":"机器学习数学基础上","slug":"机器学习数学基础上","date":"2018-10-13T11:08:47.000Z","updated":"2018-11-06T05:38:11.000Z","comments":true,"path":"2018/10/13/机器学习数学基础上/","link":"","permalink":"https://github.com/zdkswd/2018/10/13/机器学习数学基础上/","excerpt":"","text":"机器学习基础见李宏毅第0课。 得分函数 权重需要训练得到。 损失函数最优化 左边是非凸函数，右边是凸函数。通过优化损失函数来调整权值。 凸函数琴生不等式 微积分基础 梯度是一个点上升最快的方向。梯度下降法。 极限通俗语言适合于说给对方听，数学记号适合于写给对方看，精确描述比较啰嗦但是非常精确不会造成误解，主要用于证明。不会出错。 无穷小的阶数。 微分学 求导用链式法则。 积分学 泰勒级数。 牛顿法与梯度下降法 为什么不用牛顿法：原因一：牛顿法需要用到梯度和Hessian矩阵，这两个都难以求解。因为很难写出深度神经网络拟合函数的表达式，遑论直接得到其梯度表达式，更不要说得到基于梯度的Hessian矩阵了。原因二：即使可以得到梯度和Hessian矩阵，当输入向量的维度NNN较大时，Hessian矩阵的大小是N×NN×NN\\times N，所需要的内存非常大。原因三：在高维非凸优化问题中，鞍点相对于局部最小值的数量非常多，而且鞍点处的损失值相对于局部最小值处也比较大。而二阶优化算法是寻找梯度为0的点，所以很容易陷入鞍点。 为什么研究凸函数，凸优化？ 概率与统计基础 统计问题是概率问题的逆向工程。概率问题是已知总体的情况，求一次的概率。统计问题则是根据样本的情况反推总体的情况。 概率统计与机器学习的关系概率统计与机器学习天然相关，训练的过程可以看做是统计过程，预测过程可以看做是概率过程。预测分类就是选择一个概率最大的分类。 可以观察各个特征的分布以及标签的分布，筛选出相关性强的特征。 可基于各个分布的特性来评估模型和样本。 统计估计的是分布，机器学习训练出来的是模型，模型可能包含了很多的分布。 训练与预测过程的一个核心评价指标就是模型的误差 误差本身就可以使概率形式，与概率紧密相关。 对误差的不同定义方式就演化成了不同损失函数的定义方式。 机器学习是概率与统计的进阶版本。（不严谨的说法） 方差 协方差 可评估两个分布之间的关系。定义公式几何意义：协方差可以理解成特征进行预处理之后（去均值化，机器学习里比较重要的一个数据预处理的方法）对应的向量的几何的内积。协方差是评价两个变量的线性关系。如果是非线性关系，评价不出来。 相关系数是研究变量之间线性相关程度地量。 var是方差。 概率论 先验——根据若干年的统计（经验）或者气候（常识），某地方下雨（因）的概率； 似然/类条件概率——在下雨（因）的情况下，观测到了乌云（果）的概率，即原因已知时，结果出现的概率； 后验——根据天上有乌云（果），得到的下雨（因）的概率，即给定结果估计原因的概率； x:观察得到的结果。 θ：决定数据分布的原因。 矩： 其中t是一个实数，i是虚数单位，E表示期望值。此乃原点矩。E(（X-0）^n)中心矩就是-μ。 即大部分都分布在均值周围。 没法研究随机变量就研究其特征函数。 当一个分布不是常见的分布时，根据大数定理，反复做实验就可以得到其期望和方差。 大数定理是告诉我们趋近一个数，中心极限定理是告诉我们以何种方式趋近一个数。一个正态分布。 参数估计（统计学） 点估计利用样本来估计总体分布，总体分布的参数很多情况下是未知的。如均值μ、方差\\sigma ^{2} 、泊松分布的λ、二项分布的比例π，其它分布还会有更多的未知参数，需要通过样本进行相应的估计，这种估计值就是点估计。 矩估计 极大似然估计 可以把概率密度看作是θ和x的联合概率密度，把x固定，那么概率密度最大的地方就是θ最可能的地方。 不是概率是因为相加起来和不等于1，类似于概率是因为数值大小是有意义的，代表了可能性的大小。 如何通俗地理解概率论中的「极大似然估计法」? - 马同学的回答 - 知乎https://www.zhihu.com/question/24124998/answer/242682386 简单来说，极大似然函数就是通过样本来求使得概率（似然）为最大的那个θ值。似然越大，就越有可能是这个θ。所以目的就是让似然函数最大就完事了，然后可以通过对θ的梯度下降法，使得似然函数求最大，也就是损失函数为负的似然函数求最小。 点估计的评判准则 区间估计对于未知参数，点估计值只是一个近似值，会存在或大或小误差，这时给一个范围可能是更合适，也是更可信的。比如从北京到张家界旅游5天，你恐怕不能准确说出要花多少钱，但你可以给出一个范围，比如10000—13000，你会觉得比较可信。如果给的范围太大，比如10000—30000，虽然可信度更高一些，但这么大的范围参考意义不大；如果给的范围很小，如10000——10500，则准确性提高了，但可信度就似乎不会很高。找到一个合适的估值范围，这是置信区间要解决的问题。 线性代数基础 （1）保持加法（2）保持乘法。线性映射是最简单的研究对象，用线性映射去逼近别的东西。 线性变换与矩阵的关系，对任何向量x进行线性变换T的结果向量，是一个对基向量组进行线性变换T之后的新向量组的一个线性组合，系数没变。 只需要知道两个基向量i向量和j向量转换之后的的结果，而不用知道转换本身，我们就能推导出二维空间中所有向量转换之后的结果。 Ax的几何意义矩阵乘向量，列向量的线性组合。 svd的几何意义。一个很重要的降维算法。 矩阵乘法在计算中的优势 将很多for循环写成矩阵或者向量乘法的方式。 矩阵计算模块在底层有优化。 numpy进行矩阵运算很快。","categories":[{"name":"听课笔记","slug":"听课笔记","permalink":"https://github.com/zdkswd/categories/听课笔记/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"JavaScript标准参考教程 DOM 属性的操作 Text节点和DocumentFragment","slug":"JavaScript标准参考教程 DOM 属性的操作 Text节点和DocumentFragment","date":"2018-10-12T13:13:56.000Z","updated":"2018-10-12T13:13:15.000Z","comments":true,"path":"2018/10/12/JavaScript标准参考教程 DOM 属性的操作 Text节点和DocumentFragment/","link":"","permalink":"https://github.com/zdkswd/2018/10/12/JavaScript标准参考教程 DOM 属性的操作 Text节点和DocumentFragment/","excerpt":"","text":"属性的操作HTML 元素包括标签名和若干个键值对，这个键值对就称为“属性”（attribute）。 属性本身是一个对象（Attr对象），但是实际上，这个对象极少使用。一般都是通过元素节点对象（HTMlElement对象）来操作属性。本章介绍如何操作这些属性。 Element.attributes属性元素对象有一个attributes属性，返回一个类似数组的动态对象，成员是该元素标签的所有属性节点对象，属性的实时变化都会反映在这个节点对象上。其他类型的节点对象，虽然也有attributes属性，但返回的都是null，因此可以把这个属性视为元素对象独有的。 单个属性可以通过序号引用，也可以通过属性名引用。 返回的都是属性节点对象，而不是属性值。属性节点对象有name和value属性，对应该属性的属性名和属性值，等同于nodeName属性和nodeValue属性。 元素的标准属性HTML 元素的标准属性（即在标准中定义的属性），会自动成为元素节点对象的属性。 这些属性都是可写的。这种修改属性的方法，常常用于添加表单的属性。 上面代码为表单添加提交网址和提交方法。 注意，这种用法虽然可以读写属性，但是无法删除属性，delete运算符在这里不会生效。 HTML 元素的属性名是大小写不敏感的，但是 JavaScript 对象的属性名是大小写敏感的。转换规则是，转为 JavaScript 属性名时，一律采用小写。如果属性名包括多个单词，则采用骆驼拼写法，即从第二个单词开始，每个单词的首字母采用大写，比如onClick。 有些 HTML 属性名是 JavaScript 的保留字，转为 JavaScript 属性时，必须改名。主要是以下两个。 属性操作的标准方法概述元素节点提供四个方法，用来操作属性。 适用性 这四个方法对所有的属性（包括用户自定义的属性）都适用。 返回值 getAttribute()只返回字符串，不会返回其他类型的值。 属性名 这些方法只接受属性的标准名称，不用改写保留字，比如for和class都可以直接使用。另外，这些方法对于属性名是大小写不敏感的。 Element.getAttribute()lement.getAttribute方法返回当前元素节点的指定属性。如果指定属性不存在，则返回null。 Element.setAttribute()Element.setAttribute方法用于为当前元素节点新增属性。如果同名属性已存在，则相当于编辑已存在的属性。 Element.hasAttribute()Element.hasAttribute方法返回一个布尔值，表示当前元素节点是否包含指定属性。 Element.removeAttribute()Element.removeAttribute方法用于从当前元素节点移除属性。 dataset 属性有时，需要在HTML元素上附加数据，供 JavaScript 脚本使用。一种解决方法是自定义属性。使用标准提供的data-*属性。 然后，使用元素节点对象的dataset属性，它指向一个对象，可以用来操作 HTML 元素标签的data-*属性。 通过dataset.foo读写data-foo属性。删除一个data-*属性，可以直接使用delete命令。 除了dataset属性，也可以用getAttribute(‘data-foo’)、removeAttribute(‘data-foo’)、setAttribute(‘data-foo’)、hasAttribute(‘data-foo’)等方法操作data-*属性。 Text节点和DocumentFragment节点Text节点的概念文本节点（Text）代表元素节点（Element）和属性节点（Attribute）的文本内容。如果一个节点只包含一段文本，那么它就有一个文本子节点，代表该节点的文本内容。 通常我们使用父节点的firstChild、nextSibling等属性获取文本节点，或者使用Document节点的createTextNode方法创造一个文本节点。 浏览器原生提供一个Text构造函数。它返回一个文本节点实例。它的参数就是该文本节点的文本内容。 文本节点继承了Node接口，所以属性和方法都和Node一样。 Text节点的属性datadata属性等同于nodeValue属性，用来设置或读取文本节点的内容。 wholeTextwholeText属性将当前文本节点与毗邻的文本节点，作为一个整体返回。大多数情况下，wholeText属性的返回值，与data属性和textContent属性相同。 lengthlength属性返回当前文本节点的文本长度。 nextElementSibling，previousElementSiblingnextElementSibling属性返回紧跟在当前文本节点后面的那个同级元素节点。如果取不到元素节点，则返回null。 previousElementSibling属性返回当前文本节点前面最近的同级元素节点。如果取不到元素节点，则返回null：。 Text节点的方法appendData()，deleteData()，insertData()，replaceData()，subStringData() remove()remove方法用于移除当前Text节点。 splitText()splitText方法将Text节点一分为二，变成两个毗邻的Text节点。它的参数就是分割位置（从零开始），分割到该位置的字符前结束。如果分割位置不存在，将报错。 分割后，该方法返回分割位置后方的字符串，而原Text节点变成只包含分割位置前方的字符串。 父元素的normalize方法可以实现逆操作，将它们合并。 DocumentFragment节点DocumentFragment节点代表一个文档的片段，本身就是一个完整的 DOM 树形结构。它没有父节点，parentNode返回null，但是可以插入任意数量的子节点。它不属于当前文档，操作DocumentFragment节点，要比直接操作 DOM 树快得多。 它一般用于构建一个 DOM 结构，然后插入当前文档。document.createDocumentFragment方法，以及浏览器原生的DocumentFragment构造函数，可以创建一个空的DocumentFragment节点。然后再使用其他 DOM 方法，向其添加子节点。 上面代码创建了一个DocumentFragment节点，然后将一个li节点添加在它里面，最后将DocumentFragment节点移动到原文档。 注意，DocumentFragment节点本身不能被插入当前文档。当它作为appendChild()、insertBefore()、replaceChild()等方法的参数时，是它的所有子节点插入当前文档，而不是它自身。一旦DocumentFragment节点被添加进当前文档，它自身就变成了空节点（textContent属性为空字符串），可以被再次使用。如果想要保存DocumentFragment节点的内容，可以使用cloneNode方法。 上面这样添加DocumentFragment节点进入当前文档，不会清空DocumentFragment节点。 DocumentFragment节点对象没有自己的属性和方法，全部继承自Node节点和ParentNode接口。也就是说，DocumentFragment节点比Node节点多出以下四个属性。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"关于JavaScript的对象的理解","slug":"关于JavaScript的对象的理解","date":"2018-10-11T11:26:32.000Z","updated":"2018-10-11T11:26:54.000Z","comments":true,"path":"2018/10/11/关于JavaScript的对象的理解/","link":"","permalink":"https://github.com/zdkswd/2018/10/11/关于JavaScript的对象的理解/","excerpt":"","text":"关于JavaScript的对象的理解JavaScript的对象可以分为狭义的和广义的对象。广义的对象由数组，狭义的对象和函数组成。 狭义的对象就是{}，里面是键值对。广义的对象其实本质也是键值对。只不过声明的方式多了一些。比如new Object()。Object就是一个构造函数，既然是函数，本身也就是一个对象，可以对Object中添加方法，和狭义对象的方法一样。比如Object.test=Function (){};这时候在外部可以调用Object.test()方法，即Object对象的静态方法。 这里Object是构造函数名，但是函数也是对象啊，我估计函数本质上也是一个键值对，函数可以是构造函数Function.prototype的实例对象。所以称为Object对象。 既然是构造函数，里面是有语句的，执行完语句得到一个键值对，这又是一个对象，称为Object.prototype。这时就是一个纯粹的键值对。就是原型对象。Object.prototype也有很多方法可以调用。至于原型链，就是对象与对象之间的一条链。对象都是构造函数.prototype。继承是通过构造函数的继承来实现的，一般就是在子类中要实现父类的方法。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"JavaScript标准参考教程 DOM模型 实际使用DOM Element节点","slug":"JavaScript标准参考教程 DOM模型 实际使用DOM Element节点","date":"2018-10-09T11:42:56.000Z","updated":"2018-10-09T13:19:32.000Z","comments":true,"path":"2018/10/09/JavaScript标准参考教程 DOM模型 实际使用DOM Element节点/","link":"","permalink":"https://github.com/zdkswd/2018/10/09/JavaScript标准参考教程 DOM模型 实际使用DOM Element节点/","excerpt":"","text":"实战中的使用DOM 如果加了括号就会直接执行了。 Element对象Element对象对应网页的 HTML 元素。每一个 HTML 元素，在 DOM 树上都会转化成一个Element节点对象（以下简称元素节点）。 元素节点的nodeType属性都是1。 Element对象继承了Node接口，因此Node的属性和方法在Element对象都存在。此外，不同的 HTML 元素对应的元素节点是不一样的，浏览器使用不同的构造函数，生成不同的元素节点，比如&lt; a&gt;元素的节点对象由HTMLAnchorElement构造函数生成，&lt; button&gt;元素的节点对象由HTMLButtonElement构造函数生成。因此，元素节点不是一种对象，而是一组对象，这些对象除了继承Element的属性和方法，还有各自构造函数的属性和方法。 实例属性元素特性的相关属性Element.idElement.id属性返回指定元素的id属性，该属性可读写。 id属性的值是大小写敏感。 Element.tagNameElement.tagName属性返回指定元素的大写标签名，与nodeName属性的值相等。 Element.dirElement.dir属性用于读写当前元素的文字方向，可能是从左到右（”ltr”），也可能是从右到左（”rtl”）。 Element.accessKeyElement.accessKey属性用于读写分配给当前元素的快捷键。 上面代码中，btn元素的快捷键是h，按下Alt + h就能将焦点转移到它上面。 Element.draggableElement.draggable属性返回一个布尔值，表示当前元素是否可拖动。该属性可读写。 Element.langElement.lang属性返回当前元素的语言设置。该属性可读写。 Element.tabIndexElement.tabIndex属性返回一个整数，表示当前元素在 Tab 键遍历时的顺序。该属性可读写。 abIndex属性值如果是负值（通常是-1），则 Tab 键不会遍历到该元素。如果是正整数，则按照顺序，从小到大遍历。如果两个元素的tabIndex属性的正整数值相同，则按照出现的顺序遍历。遍历完所有tabIndex为正整数的元素以后，再遍历所有tabIndex等于0、或者属性值是非法值、或者没有tabIndex属性的元素，顺序为它们在网页中出现的顺序。 Element.titleElement.title属性用来读写当前元素的 HTML 属性title。该属性通常用来指定，鼠标悬浮时弹出的文字提示框。 元素状态的相关属性Element.hiddenElement.hidden属性返回一个布尔值，表示当前元素的hidden属性，用来控制当前元素是否可见。该属性可读写。 注意，该属性与 CSS 设置是互相独立的。CSS 对这个元素可见性的设置，Element.hidden并不能反映出来。也就是说，这个属性并不能用来判断当前元素的实际可见性。 CSS 的设置高于Element.hidden。如果 CSS 指定了该元素不可见（display: none）或可见（display: hidden），那么Element.hidden并不能改变该元素实际的可见性。换言之，这个属性只在 CSS 没有明确设定当前元素的可见性时才有效。 Element.contentEditable，Element.isContentEditableHTML 元素可以设置contentEditable属性，使得元素的内容可以编辑。 Element.contentEditable属性返回一个字符串，表示是否设置了contenteditable属性，有三种可能的值。该属性可写。 Element.isContentEditable属性返回一个布尔值，同样表示是否设置了contenteditable属性。该属性只读。 Element.attributesElement.attributes属性返回一个类似数组的对象，成员是当前元素节点的所有属性节点。 Element.className，Element.classListclassName属性用来读写当前元素节点的class属性。它的值是一个字符串，每个class之间用空格分割 classList属性返回一个类似数组的对象，当前元素节点的每个class就是这个对象的一个成员。 classList对象有下列方法。 toggle方法可以接受一个布尔值，作为第二个参数。如果为true，则添加该属性；如果为false，则去除该属性。 Element.dataset网页元素可以自定义data-属性，用来添加数据。 Element.dataset属性返回一个对象，可以从这个对象读写data-属性。 注意，dataset上面的各个属性返回都是字符串。 HTML 代码中，data-属性的属性名，只能包含英文字母、数字、连词线（-）、点（.）、冒号（:）和下划线（_）。它们转成 JavaScript 对应的dataset属性名，规则如下。 因此，data-abc-def对应dataset.abcDef，data-abc-1对应dataset[“abc-1”]。 除了使用dataset读写data-属性，也可以使用Element.getAttribute()和Element.setAttribute()，通过完整的属性名读写这些属性。 Element.innerHTMLElement.innerHTML属性返回一个字符串，等同于该元素包含的所有 HTML 代码。该属性可读写，常用来设置某个节点的内容。它能改写所有元素节点的内容，包括和元素。 如果将innerHTML属性设为空，等于删除所有它包含的所有节点。 注意，读取属性值的时候，如果文本节点包含 \\&amp;、小于号（ &lt;）和大于号（ &gt;），innerHTML属性会将它们转为实体形式 \\&amp; amp;、\\&amp; lt;、\\&amp; gt;。如果想得到原文，建议使用element.textContent属性。 注意，如果文本之中含有&lt; script&gt;标签，虽然可以生成script节点，但是插入的代码不会执行。 为了安全考虑，如果插入的是文本，最好用textContent属性代替innerHTML。 Element.outerHTMLElement.outerHTML属性返回一个字符串，表示当前元素节点的所有 HTML 代码，包括该元素本身和所有子元素。 outerHTML属性是可读写的，对它进行赋值，等于替换掉当前元素。 注意，如果一个节点没有父节点，设置outerHTML属性会报错。 Element.clientHeight，Element.clientWidthElement.clientHeight属性返回一个整数值，表示元素节点的 CSS 高度（单位像素），只对块级元素生效，对于行内元素返回0。如果块级元素没有设置 CSS 高度，则返回实际高度。 除了元素本身的高度，它还包括padding部分，但是不包括border、margin。如果有水平滚动条，还要减去水平滚动条的高度。注意，这个值始终是整数，如果是小数会被四舍五入。 Element.clientWidth属性返回元素节点的 CSS 宽度，同样只对块级元素有效，也是只包括元素本身的宽度和padding，如果有垂直滚动条，还要减去垂直滚动条的宽度。 document.documentElement的clientHeight属性，返回当前视口的高度（即浏览器窗口的高度），等同于window.innerHeight属性减去水平滚动条的高度（如果有的话）。document.body的高度则是网页的实际高度。一般来说，document.body.clientHeight大于document.documentElement.clientHeight。 Element.clientLeft，Element.clientTopElement.clientLeft属性等于元素节点左边框（left border）的宽度（单位像素），不包括左侧的padding和margin。如果没有设置左边框，或者是行内元素（display: inline），该属性返回0。该属性总是返回整数值，如果是小数，会四舍五入。 Element.clientTop属性等于网页元素顶部边框的宽度（单位像素），其他特点都与clientTop相同。 Element.scrollHeight，Element.scrollWidthElement.scrollHeight属性返回一个整数值（小数会四舍五入），表示当前元素的总高度（单位像素），包括溢出容器、当前不可见的部分。它包括padding，但是不包括border、margin以及水平滚动条的高度（如果有水平滚动条的话），还包括伪元素（::before或::after）的高度。 Element.scrollWidth属性表示当前元素的总宽度（单位像素），其他地方都与scrollHeight属性类似。这两个属性只读。 整张网页的总高度可以从document.documentElement或document.body上读取。 注意，如果元素节点的内容出现溢出，即使溢出的内容是隐藏的，scrollHeight属性仍然返回元素的总高度。 Element.scrollLeft，Element.scrollTopElement.scrollLeft属性表示当前元素的水平滚动条向右侧滚动的像素数量，Element.scrollTop属性表示当前元素的垂直滚动条向下滚动的像素数量。对于那些没有滚动条的网页元素，这两个属性总是等于0。 如果要查看整张网页的水平的和垂直的滚动距离，要从document.documentElement元素上读取。 这两个属性都可读写，设置该属性的值，会导致浏览器将当前元素自动滚动到相应的位置。 Element.offsetParentElement.offsetParent属性返回最靠近当前元素的、并且 CSS 的position属性不等于static的上层元素。 该属性主要用于确定子元素位置偏移的计算基准，Element.offsetTop和Element.offsetLeft就是offsetParent元素计算的。 如果该元素是不可见的（display属性为none），或者位置是固定的（position属性为fixed），则offsetParent属性返回null。 如果某个元素的所有上层节点的position属性都是static，则Element.offsetParent属性指向元素。 Element.offsetHeight，Element.offsetWidthElement.offsetHeight属性返回一个整数，表示元素的 CSS 垂直高度（单位像素），包括元素本身的高度、padding 和 border，以及水平滚动条的高度（如果存在滚动条）。 Element.offsetWidth属性表示元素的 CSS 水平宽度（单位像素），其他都与Element.offsetHeight一致。 这两个属性都是只读属性，只比Element.clientHeight和Element.clientWidth多了边框的高度或宽度。如果元素的 CSS 设为不可见（比如display: none;），则返回0。 Element.offsetLeft，Element.offsetTopElement.offsetLeft返回当前元素左上角相对于Element.offsetParent节点的水平位移，Element.offsetTop返回垂直位移，单位为像素。通常，这两个值是指相对于父节点的位移 Element.style每个元素节点都有style用来读写该元素的行内样式信息。 Element.children，Element.childElementCountElement.children属性返回一个类似数组的对象（HTMLCollection实例），包括当前元素节点的所有子元素。如果当前元素没有子元素，则返回的对象包含零个成员。 这个属性与Node.childNodes属性的区别是，它只包括元素类型的子节点，不包括其他类型的子节点。 Element.childElementCount属性返回当前元素节点包含的子元素节点的个数，与Element.children.length的值相同。 Element.firstElementChild，Element.lastElementChildElement.firstElementChild属性返回当前元素的第一个元素子节点，Element.lastElementChild返回最后一个元素子节点。 如果没有元素子节点，这两个属性返回null。 Element.nextElementSibling，Element.previousElementSiblingElement.nextElementSibling属性返回当前元素节点的后一个同级元素节点，如果没有则返回null。 Element.previousElementSibling属性返回当前元素节点的前一个同级元素节点，如果没有则返回null。 实例方法属性相关方法Element.getAttribute()Element.getAttribute方法接受一个字符串作为参数，返回同名属性的值。如果没有该属性，则返回null。 Element.getAttributeNames()Element.getAttributeNames()返回一个数组，成员是当前元素的所有属性的名字。如果当前元素没有任何属性，则返回一个空数组。使用Element.attributes属性，也可以拿到同样的结果，唯一的区别是它返回的是类似数组的对象。 Element.setAttribute()Element.setAttribute方法用于为当前节点设置属性。如果属性已经存在，将更新属性值，否则将添加该属性。该方法没有返回值。 属性值总是字符串，其他类型的值会自动转成字符串，比如布尔值true就会变成字符串true。 Element.hasAttribute()Element.hasAttribute方法返回一个布尔值，表示当前元素节点是否有指定的属性。 Element.hasAttributes()Element.hasAttributes方法返回一个布尔值，表示当前元素是否有属性，如果没有任何属性，就返回false，否则返回true。 Element.removeAttribute()Element.removeAttribute方法移除指定属性。该方法没有返回值。 Element.querySelector()Element.querySelector方法接受 CSS 选择器作为参数，返回父元素的第一个匹配的子元素。如果没有找到匹配的子元素，就返回null。 注意，这个方法无法选中伪元素。 它可以接受多个选择器，它们之间使用逗号分隔。 Element.querySelectorAll()Element.querySelectorAll方法接受 CSS 选择器作为参数，返回一个NodeList实例，包含所有匹配的子元素。 该方法的执行机制与querySelector方法相同，也是先在全局范围内查找，再过滤出当前元素的子元素。因此，选择器实际上针对整个文档的。 它也可以接受多个 CSS 选择器，它们之间使用逗号分隔。如果选择器里面有伪元素的选择器，则总是返回一个空的NodeList实例。 Element.getElementsByClassName()Element.getElementsByClassName方法返回一个HTMLCollection实例，成员是当前元素节点的所有具有指定 class 的子元素节点。该方法与document.getElementsByClassName方法的用法类似，只是搜索范围不是整个文档，而是当前元素节点。 注意，该方法的参数大小写敏感。 由于HTMLCollection实例是一个活的集合，document对象的任何变化会立刻反应到实例。 上面代码中，matches集合的第一个成员，一旦被拿掉 class 里面的foo，就会立刻从matches里面消失，导致出现上面的结果。 Element.getElementsByTagName()Element.getElementsByTagName方法返回一个HTMLCollection实例，成员是当前节点的所有匹配指定标签名的子元素节点。该方法与document.getElementsByClassName方法的用法类似，只是搜索范围不是整个文档，而是当前元素节点。 注意，该方法的参数是大小写不敏感的。 Element.closest()Element.closest方法接受一个 CSS 选择器作为参数，返回匹配该选择器的、最接近当前节点的一个祖先节点（包括当前节点本身）。如果没有任何节点匹配 CSS 选择器，则返回null。 Element.matches()Element.matches方法返回一个布尔值，表示当前元素是否匹配给定的 CSS 选择器。 事件相关方法以下三个方法与Element节点的事件相关。这些方法都继承自EventTarget接口， Element.scrollIntoView()Element.scrollIntoView方法滚动当前元素，进入浏览器的可见区域，类似于设置window.location.hash的效果。 该方法可以接受一个布尔值作为参数。如果为true，表示元素的顶部与当前区域的可见部分的顶部对齐（前提是当前区域可滚动）；如果为false，表示元素的底部与当前区域的可见部分的尾部对齐（前提是当前区域可滚动）。如果没有提供该参数，默认为true。 Element.getBoundingClientRect()Element.getBoundingClientRect方法返回一个对象，提供当前元素节点的大小、位置等信息，基本上就是 CSS 盒状模型的所有信息。 只读。 注意，getBoundingClientRect方法的所有属性，都把边框（border属性）算作元素的一部分。也就是说，都是从边框外缘的各个点来计算。因此，width和height包括了元素本身 + padding + border。 Element.getClientRects()Element.getClientRects方法返回一个类似数组的对象，里面是当前元素在页面上形成的所有矩形（所以方法名中的Rect用的是复数）。每个矩形都有bottom、height、left、right、top和width六个属性，表示它们相对于视口的四个坐标，以及本身的高度和宽度。 对于盒状元素（比如&lt; div&gt;和&lt; p&gt;），该方法返回的对象中只有该元素一个成员。对于行内元素（比如&lt; span&gt;、&lt; a&gt;、&lt; em&gt;），该方法返回的对象有多少个成员，取决于该元素在页面上占据多少行。这是它和Element.getBoundingClientRect()方法的主要区别，后者对于行内元素总是返回一个矩形。 Element.insertAdjacentElement()Element.insertAdjacentElement方法在相对于当前元素的指定位置，插入一个新的节点。该方法返回被插入的节点，如果插入失败，返回null。 Element.insertAdjacentElement方法一共可以接受两个参数，第一个参数是一个字符串，表示插入的位置，第二个参数是将要插入的节点。第一个参数只可以取如下的值。 注意，beforebegin和afterend这两个值，只在当前节点有父节点时才会生效。如果当前节点是由脚本创建的，没有父节点，那么插入会失败。 Element.insertAdjacentHTML()，Element.insertAdjacentText()Element.insertAdjacentHTML方法用于将一个 HTML 字符串，解析生成 DOM 结构，插入相对于当前节点的指定位置。 该方法接受两个参数，第一个是一个表示指定位置的字符串，第二个是待解析的 HTML 字符串。第一个参数只能设置下面四个值之一。 该方法只是在现有的 DOM 结构里面插入节点，这使得它的执行速度比innerHTML方法快得多。 注意，该方法会使 HTML 字符串显示为网页结构，这导致它不能用来插入用户输入的内容，否则会有安全风险。 Element.focus()，Element.blur()Element.focus方法用于将当前页面的焦点，转移到指定元素上。 该方法可以接受一个对象作为参数。参数对象的preventScroll属性是一个布尔值，指定是否将当前元素停留在原始位置，而不是滚动到可见区域。 Element.blur方法用于将焦点从当前元素移除。 Element.click()Element.click方法用于在当前元素上模拟一次鼠标点击，相当于触发了click事件。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"CSS","slug":"CSS","date":"2018-10-06T13:31:32.000Z","updated":"2018-12-20T08:00:46.000Z","comments":true,"path":"2018/10/06/CSS/","link":"","permalink":"https://github.com/zdkswd/2018/10/06/CSS/","excerpt":"","text":"CSS层叠样式表。 书写位置行内式（内联样式） 语法中style是标签的属性，实际上任何HTML标签都拥有style属性，用来设置行内式，其中属性和值的书写规范与CSS样式规范相同，行内式只对其所在的标签及嵌套在其中的子标签起作用。注意是冒号。 内部样式表内嵌式是将CSS代码集中写在HTML文档的head头部标签中，并且用style标签定义。 语法中，style标签一般位于head标签中title标签之后，也可以把他放在HTML文档的任何地方。 type=“text/CSS”在H5中可以省略，写上也比较符合规范，所以这个地方可以写也可以省略。 外部样式表（外链式） 在外部样式中，不用style标签，直接写就完事了。 CSS样式规则 选择器（重点）CSS基础选择器标签选择器（元素选择器） 类选择器 多类名选择器 id选择器id选择器和类选择器最大的不同在于使用次数。id选择器id只能使用一次。 使用‘#’ 定义，使用 id= 调用 通配符选择器 几乎不用。 CSS字体样式属性font-size：字号大小 统一用px font-family:字体font-family属性用于设置字体。网页中常用的字体有宋体、微软雅黑、黑体等。 如果字体都没有，就使用系统默认的字体。 为了照顾浏览器的兼容性，可以使用Unicode编码。 font-weight:字体粗细 bold字体加粗。使用normal也可以让标题不加粗。 font-style：字体风格 综合设置字体样式（重点） CSS外观属性color:文本颜色 十六进制时 # ff0000由于数值一样，可以简写为 # f00。 line-height:行间距 text-align:水平对齐方式 css中没有垂直对齐的方式。 是让盒子里面的内容居中，而不是让盒子居中。 text-indent:首行缩进 text-decoration文本的装饰 复合选择器后代选择器 用空格隔开。 是选择所有的后代。 子代选择器只选亲儿子。 交集选择器 并集选择器（重点） 伪类选择器伪类选择器用于向某些选择器添加特殊的效果，比如给链接添加特殊效果，比如可以选择第一个，第n个元素。 链接伪类选择器 active是按下鼠标还没弹起的状态。 CSS注释 快捷键 标签的显示（display）块级元素（block-level）每个块元素通常都会独自占据一整行或者多整行，可以对其设置宽度、高度、对齐等属性，常用于网页布局和网页结构的搭建。 行内元素（inline-level）行内元素（内联元素）不占有独立的区域，仅仅靠自身的字体大小和图像尺寸来支撑结构，一般不可以设置宽度、高度、对齐等属性，常用于控制页面中文本的样式。 a里面可以放块级元素。 注意： 行内块元素（inline-block） 显示模式转换 每一个标签都是一个小盒子。 如果是行内元素，行内块元素，我们可以看做文本，可以在块级使用text-align:center进行居中对齐。 使行高等于盒子的高度，可以让单行文本垂直居中。 行高的测量 CSS三大特性CSS层叠性 CSS继承性 CSS优先级 CSS背景CSS可以添加背景颜色和背景图片，以及来进行图片设置。 背景颜色与背景图片同时设置的话背景图片会在背景颜色之上。 backgroud-repeat backgroud-position backgroud-attachment 背景简写 背景透明（CSS3） 盒子模型盒子边框盒子边框即border,有border-width,border-style,border-color.可简写为 border: 1px solid red;其中border-style常用值。 border亦可单边进行设置。border-top;border-bottom;border-left;border-right。 合并相邻边框 内边距(padding)默认贴在左上角。 padding和border会撑开带有width和height的盒子。对于没有给定的就是盒子大小不变，内容进行了移动。 外边距(margin) margin值的个数表达的意思和padding类似。 使盒子水平居中： 上下是0，左右是auto。 使块中的内容居中：text-align=center。 外边距合并 以比较大的为准。 解决方法：避免 垂直外边距嵌套元素合并对于两个嵌套关系的块元素，如果父元素没有上内边距及边框，则父元素的上外边距会与子元素的上外边距发生合并，合并后的外边距为两者中的较大者，即使父元素的上外边距为0，也会发生合并。 只有垂直会发生这种情况。 解决方案： 可以为父元素定义1像素的上外边框或上内边距。 可以为父元素添加overflow:hidden. 盒子布局的稳定性按照优先使用顺序：width&gt;padding&gt;margin 插入图片与背景图片 插入图片 最多比如产品展示类；背景图片我们一般用于小图标背景或者超大背景图片。 圆角边框（CSS3） 也可以是px。值越大越圆。 第一个左上，顺时针。 盒子阴影（CSS3） 浮动（float）普通流（normal flow）也称为标准流，CSS的定位机制有三种：普通流、浮动和定位。 普通流实际就是一个网页内标签元素正常从上到下，从左到右排列顺序的意思。比如块级元素会独占一行，行内元素会按顺序依次前后排列。 浮动浮动让盒子浮起来，盒子的位置就由其他盒子占据。 浮动有个很有意思的事情：就是让任何盒子可以一行排列，我们就慢慢地利用浮动的特性来布局了。 为什么不用inline-block?是有的时候需要右对齐，这时就不好知道具体的位置。需要量出来，不同的屏幕显示的效果不一样。而且块之间有缝隙。这时使用浮动就效果比较好。 只有左右。浮动的和浮动的又符合标准流。 浮动的盒子跨越不了padding值。 一个盒子浮动，会影响后面的位置，影响不了前面的位置，也就是说不会往上面的元素上浮。 浮动有一个隐藏的模式转换，浮动可以让元素默认转换为行内块元素，宽度取决于元素的大小。 如果已经给行内元素添加了浮动，此时不需要转换该元素也可以有宽高。 版心和布局流程为了提高网页制作的效率，布局时通常需要遵守一定的布局流程，具体如下： 确定页面的版心（可视区）。 分析页面中的行模块，以及每个行模块中的列模块。 制作HTML结构。 CSS初始化，然后开始运用盒子模型的原理，通过DIV+CSS布局来控制网页的各个模块。","categories":[{"name":"听课笔记","slug":"听课笔记","permalink":"https://github.com/zdkswd/categories/听课笔记/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"https://github.com/zdkswd/tags/CSS/"}]},{"title":"HTML","slug":"HTML","date":"2018-10-06T13:31:32.000Z","updated":"2018-12-20T08:00:13.000Z","comments":true,"path":"2018/10/06/HTML/","link":"","permalink":"https://github.com/zdkswd/2018/10/06/HTML/","excerpt":"","text":"html+csschrome市场份额多。 常见浏览器内核介绍：浏览器内核又可以分成两个部分：渲染引擎（layout engineer或者Rendering Engine）和JS引擎。 渲染引擎它负责取得网页的内容(HTML、XML、图像等等)、整理讯息(例如加入Css等),以及计算网页的显示方式,然后会输出至显示器或打印机。浏览器的内核的不同对于网页的语法解释会有不同,所以渲染的效果也不相同。 JS引擎则是解析Javascript语言,执行 Javascript语言来实现网页的动态效果。 最开始渲染引擎和J5引擎并没有区分的很明确,后来]S引擎越来越独立,内核就倾向于只指渲染引擎。有一个网页标准计划小组制作了个ACID来测试引擎的兼容性和性能。内核的种类很多,如加上没什么人使用的非商业的免费内核,可能会有10多种,但是常见的浏览器内核可以分这四种: Trident、 Gecko、 Blink、 Webkit。 (1) Trident(IE内核)国内很多的双核浏览器的其中一核便是 Trident,美其名曰”兼容模式”。代表:、傲游、世界之窗浏览器、 Avant、腾讯TT、猎豹安全浏览器、360极速浏览器、百度浏览器等。Window10发布后,正将其内置浏览器命名为Edge,Edge最显著的特点就是新内核 EdgeHTML。 (2)Gecko(firefox)Gecko( Firefox内核): Mozilla fire fox(火狐浏览器)采用该内核, Gecko的特点是代码完全公开,因此,其可开发程度很高,全世界的程序员都可以为其编写代码,增加功能。可惜这几年已经没落了,比如打开速度慢、升级频繁、猪一样的队友flash、神一样的对手 chrome。 (3) webkit(Safari)Safari是苹果公司开发的浏览器,所用浏览器内核的名称是大名鼎鼎的 Webkit.现在很多人错误地把 webkit叫做 chrome内核(即使 chrome内核已经是 blink了),苹果感觉像被别人抢了媳妇,都哭晕再厕所里面了。代表浏览器:傲游浏览器3、 Apple Safari(Win/ Mac_iPhone_iPad)、 Symbian手机浏览器、 Android默认浏览器。 (4) Chromium/Blink(chrome)在 Chromium项目中研发 Blink渲染引擎(即浏览器核心),内置于 Chrome浏览器之中。 Blink其实是 Webkit的分支。大部分国产浏览器最新版都采用Bink内核。 移动端的浏览器内核主要说的是系统内置浏览器的内核。 Android手机而言,使用率最高的就是 Webkit内核,大部分国产浏览器宣称的自己的内核,基本上也是属于 webkit二次开发。 IOS以及WP7平台上,由于系统原因,系统大部分自带浏览器内核,一般是 Safari或者IE内核 Trident的。 Web标准通过Web标准不同的浏览器内核展示统一内容。 Web标准构成主要包括：结构（HTML）（最重要），表现（CSS），和行为（JS）。 HTMl初识超（除了文字之外还有其他的，还可以链接），文本，标签，语言（有规范）。 语法骨架，一万年不变： h4之前标签是不分大小写的，h5之后最好小写。 头部是指标签栏位置。 页面内容基本在body中。 HTML标签分类双标签一对尖括号。 单标签单标签数量非常少，用脚趾能数过来。其中都有’/ ‘,’/‘表示关闭符。 HTML标签关系嵌套关系父子关系 并列关系 倡议：如果两个标签之间的关系是嵌套关系，子元素最好缩进一个Tab的身位。如果是并列关系，最好上下对齐。 HTML开发使用sublime，输入html:5或者！后按下tab键自动生成骨骼框架。 右键在浏览器中打开，快捷键f12。 文档类型&lt;!DOCTYPE&gt; 图中就是h5版本。 字符集 UTF-16固定用2个字节来存储。UTF-8（国际通用）,这里的8非常容易误导人,8不是指一个字节,难道一个字节表示一个字符?实际上不是.当用UTF-8时表示一个字符是可变的,有可能是用一个字节表示一个字符,也可能是两个,三个..反正是根据字符对应的数字大小来确定。 HTML语义化核心：在合适的地方给个合适的标签。 HTMl常用标签排版标签（内容）标题标签（熟记） 段落标签（熟记） 水平线标签（认识） 语义化后的效果： 换行标签（熟记） div span标签（重点） 通常css+divdiv独占一行，span一行可以放多个。 文本格式化标签（熟记） 图像标签img(重点) 单独给宽高会等比缩放。 链接标签（重点） 锚点定位（难点） base标签base可以设置整体链接的打开状态。在head中使用，单标签。 特殊字符标签 注释标签 路径（重点难点）相对路径 绝对路径 列表标签整齐有序。 无序列表ul（重点） 先到先得，先到先显示。 有序列表ol(了解)注意事项和ul类似，使用也类似。 自定义列表（理解） 由三个标签组成。 效果： 表格table（会使用）表格不是用来布局的，常见处理，显示表格式数据。 创建表格 表格属性 三参为0 border cellpadding cellspacing 为0 表头标签 一般第一行或第一列使用。居中且加粗。 表格标题 表格结构（了解） 合并单元格（难点） 在td属性中使用。 表单标签（掌握）收集用户信息。一个完整的表单通常由三部分组成：表单控件（也称为表单元素）、提示信息和表单域。 input控件（重点）单标签。 用name来控制单选组，多选组。 label标签（理解）label标签为input元素定义标注（标签）。作用：用于绑定一个表单元素，当点击label标签时，被绑定的表单元素就会获得输入焦点。 textarea控件（文本域） 表单域","categories":[{"name":"听课笔记","slug":"听课笔记","permalink":"https://github.com/zdkswd/categories/听课笔记/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"https://github.com/zdkswd/tags/HTML/"}]},{"title":"数学之美 第四章 谈谈中文分词","slug":"数学之美 第四章 谈谈中文分词","date":"2018-09-26T10:16:32.000Z","updated":"2018-09-26T10:17:13.000Z","comments":true,"path":"2018/09/26/数学之美 第四章 谈谈中文分词/","link":"","permalink":"https://github.com/zdkswd/2018/09/26/数学之美 第四章 谈谈中文分词/","excerpt":"","text":"中文分词方法的演变对于西方拼音语言来说，词之间有明显的分界符，统计和使用语言模型非常直接。而对于中日韩泰等语言，词之间没有明确的分界符。 最容易想到的分词方法,也是最简单的办法,就是查字典。“查字典”的办法,其实就是把一个句子从左向右扫描一遍,遇到字典里有的词就标识出来,遇到复合词(比如“上海大学”)就找最长的词匹配,遇到不认识的字串就分割成单字词,于是简单的分词就完成了。 这个最简单的方法可以解决七八成以上的分词问题,遇到稍微复杂一点的问题就无能为力了。这种方法的一个明显不足时当遇到有二义性的分割时无能为力，另外并非所有的最长匹配都是一定正确的。 利用统计语言模型分词的方法,可以用几个数学公式简单概括如下:假定一个句子S可以有几种分词方法,为了简单起见,假定有以下三种: 其中,A1,A2…B1,B2…,C1,C2…等等都是汉语的词,那么最好的一种分词方法应该保证分完词后这个句子出现的概率最大。 当然,这里面有一个实现的技巧。如果穷举所有可能的分词方法并计算出每种可能性下句子的概率,那么计算量是相当大的。因此,可以把它看成是一个动态规划( Dynamic Programming)的问题,并利用维特比( Viterbi)算法快速地找到最佳分词。(我们在后面的章节会介绍该算法。) 一般来讲,根据不同应用,汉语分词的颗粒度大小应该不同。 中文分词方法可以帮助判别英语单词的边界。因为手写英文字符时已经不能明显的区分边界了。 最后,需要指出的是任何方法都有它的局限性,虽然利用统计语言模型进行分词,可以取得比人工更好的结果,但是也不可能做到百分之百准确。因为统计语言模型很大程度上是依照“大众的想法”,或者“多数句子的用法”,而在特定情况下可能是错的。 工程上的细节分词的一致性如何衡量分词结果的对与错,好与坏看似容易,其实不是那么简单。说它看似容易,是因为只要对计算机分词的结果和人工分词的结果进行比较就可以了。说它不是那么简单,是因为不同的人对同一个句子可能有不同的分词方法。不同的人对词的切分看法上的差异性远比我们想象的要大得多。当统计语言模型被广泛应用后,不同的分词器产生的结果的差异要远远小于不同人之间看法的差异,这时简单依靠与人工分词的结果比较来衡量分词器的准确性就很难,甚至是毫无意义的了。中文分词现在是一个已经解决了的问题,提高的空间微乎其微了。只要采用统计语言模型,效果都差不到哪里去。 词的颗粒度和层次人工分词产生不一致性的原因主要在于人们对词的颗粒度的认识问题。在这里不去强调谁的观点对,而是要指出在不同的应用中,会有一种颗粒度比另一种更好的情况。比如在机器翻译中,一般来讲,颗粒度大翻译效果好。比如“联想公司”作为一个整体,很容易找到它对应的英语翻译 Lenovo,如果分词时将它们分开,很有可能翻译失败。 虽然可以对不同的应用构造不同的分词器,但是这样做不仅非常浪费,而且也不必要。更好的方法是让一个分词器同时支持不同层次的词的切分。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"}]},{"title":"Python廖雪峰 常用内建库","slug":"Python廖雪峰 常用内建模块 ","date":"2018-09-24T09:05:56.000Z","updated":"2018-09-24T09:07:45.000Z","comments":true,"path":"2018/09/24/Python廖雪峰 常用内建模块 /","link":"","permalink":"https://github.com/zdkswd/2018/09/24/Python廖雪峰 常用内建模块 /","excerpt":"","text":"datetimedatetime是Python处理日期和时间的标准库。 获取当前日期和时间 注意到datetime是模块，datetime模块还包含一个datetime类，通过from datetime import datetime导入的才是datetime这个类。 如果仅导入import datetime，则必须引用全名datetime.datetime。 datetime.now()返回当前日期和时间，其类型是datetime。 获取指定日期和时间直接用参数构造一个datetime。 datetime转换为timestamp在计算机中，时间实际上是用数字表示的。我们把1970年1月1日 00:00:00 UTC+00:00时区的时刻称为epoch time，记为0（1970年以前的时间timestamp为负数），当前时间就是相对于epoch time的秒数，称为timestamp。 timestamp一旦确定，其UTC时间就确定了，转换到任意时区的时间也是完全确定的，这就是为什么计算机存储的当前时间是以timestamp表示的，因为全球各地的计算机在任意时刻的timestamp都是完全相同的（假定时间已校准）。 把一个datetime类型转换为timestamp只需要简单调用timestamp()方法。 注意Python的timestamp是一个浮点数。如果有小数位，小数位表示毫秒数。 某些编程语言（如Java和JavaScript）的timestamp使用整数表示毫秒数，这种情况下只需要把timestamp除以1000就得到Python的浮点表示方法。 timestamp转换为datetime要把timestamp转换为datetime，使用datetime提供的fromtimestamp()方法。 这个得到的时间就是当前操作系统设定的时区，timestamp也可以直接被转换到UTC标准时区的时间。datetime.utcfromtimestamp str转换为datetime很多时候，用户输入的日期和时间是字符串，要处理日期和时间，首先必须把str转换为datetime。转换方法是通过datetime.strptime()实现，需要一个日期和时间的格式化字符串。 datetime转换为str如果已经有了datetime对象，要把它格式化为字符串显示给用户，就需要转换为str，转换方法是通过strftime()实现的，同样需要一个日期和时间的格式化字符串。 datetime加减对日期和时间进行加减实际上就是把datetime往后或往前计算，得到新的datetime。加减可以直接用+和-运算符，不过需要导入timedelta这个类。 本地时间转换为UTC时间本地时间是指系统设定时区的时间，例如北京时间是UTC+8:00时区的时间，而UTC时间指UTC+0:00时区的时间。 时区转换我们可以先通过utcnow()拿到当前的UTC时间，再转换为任意时区的时间。 datetime表示的时间需要时区信息才能确定一个特定的时间，否则只能视为本地时间。 collectionscollections是Python内建的一个集合模块，提供了许多有用的集合类。 namedtuple namedtuple是一个函数，它用来创建一个自定义的tuple对象，并且规定了tuple元素的个数，并可以用属性而不是索引来引用tuple的某个元素。 作用是更直接，像类一样表明这个的用途，但又不是类，没那么重。 deque使用list存储数据时，按索引访问元素很快，但是插入和删除元素就很慢了，因为list是线性存储，数据量大的时候，插入和删除效率很低。 deque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈。 deque除了实现list的append()和pop()外，还支持appendleft()和popleft()，这样就可以非常高效地往头部添加或删除元素。 defaultdict使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict。 注意默认值是调用函数返回的，而函数在创建defaultdict对象时传入。 除了在Key不存在时返回默认值，defaultdict的其他行为跟dict是完全一样的。 OrderedDict使用dict时，Key是无序的。在对dict做迭代时，我们无法确定Key的顺序。 注意，OrderedDict的Key会按照插入的顺序排列，不是Key本身排序。 dict内是无序的。 CounterCounter是一个简单的计数器，例如，统计字符出现的个数。 Counter实际上也是dict的一个子类。 base64Base64是一种用64个字符来表示任意二进制数据的方法。Base64是一种任意二进制到文本字符串的编码方法，常用于在URL、Cookie、网页中传输少量二进制数据。 Base64编码会把3字节的二进制数据编码为4字节的文本数据，长度增加33%。6bit表示一个字符在表中的位置。表中共有64个字符。 Python内置的base64可以直接进行base64的编解码。 由于标准的Base64编码后可能出现字符+和/，在URL中就不能直接作为参数，所以又有一种”url safe”的base64编码，其实就是把字符+和/分别变成-和_ structPython提供了一个struct模块来解决bytes和其他二进制数据类型的转换。 尽管Python不适合编写底层操作字节流的代码，但在对性能要求不高的地方，利用struct就方便多了。 hashlibPython的hashlib提供了常见的摘要算法，如MD5，SHA1等等。 摘要算法又称哈希算法、散列算法。它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示）。 MD5是最常见的摘要算法，速度很快，生成结果是固定的128 bit字节，通常用一个32位的16进制字符串表示。 SHA1的结果是160 bit字节，通常用一个40位的16进制字符串表示。 比SHA1更安全的算法是SHA256和SHA512，不过越安全的算法不仅越慢，而且摘要长度更长。 这个函数是一个单向函数，可以通过对比结果的不同来判断原文是否发生过篡改。当然有可能发生两个不同的数据通过某个摘要算法得到了相同的摘要，这种情况叫做碰撞，非常非常罕见。 可以用来在数据库中存储使用md5加密过后的密码，用户登录时，经过计算再与数据库中的摘要作比较。 hmacHmac算法针对所有哈希算法都通用，无论是MD5还是SHA-1。采用Hmac替代我们自己的salt算法，可以使程序算法更标准化，也更安全。 Python自带的hmac模块实现了标准的Hmac算法。 我们首先需要准备待计算的原始消息message，随机key，哈希算法，这里采用MD5，使用hmac的代码如下： 可见使用hmac和普通hash算法非常类似。hmac输出的长度和原始哈希算法的长度一致。需要注意传入的key和message都是bytes类型，str类型需要首先编码为bytes。 Python内置的hmac模块实现了标准的Hmac算法，它利用一个key对message计算“杂凑”后的hash，使用hmac算法比标准hash算法更安全，因为针对相同的message，不同的key会产生不同的hash。 itertoolsPython的内建模块itertools提供了非常有用的用于操作迭代对象的函数。 chain()chain()可以把一组迭代对象串联起来，形成一个更大的迭代器 groupby()groupby()把迭代器中相邻的重复元素挑出来放在一起。 contextlib实际上，任何对象，只要正确实现了上下文管理，就可以用于with语句。实现上下文管理是通过enter和exit这两个方法实现的。 一个是with触发的时候，一个是退出的时候。编写enter和exit仍然很繁琐，因此Python的标准库contextlib提供了更简单的写法。 contextlib是个比with优美的东西，也是提供上下文机制的模块，它是通过Generator装饰器实现的。不再是采用enter和exit。contextlib中的contextmanager作为装饰器来提供一种针对函数级别的上下文管理机制。 一个上下文管理器通过with声明激活, 而且API包含两个方法。__enter__()方法运行执行流进入到with代码块内。他返回一个对象共上下文使用。当执行流离开with块时，__exit__()方法上下文管理器清除任何资源被使用。 @closing如果一个对象没有实现上下文，我们就不能把它用于with语句。这个时候，可以用closing()来把该对象变为上下文对象。例如，用with语句使用urlopen()。 closing也是一个经过@contextmanager装饰的generator，这个generator编写起来其实非常简单。 它的作用就是把任意对象变为上下文对象，并支持with语句。 urlliburllib提供了一系列用于操作URL的功能。 Geturllib的request模块可以非常方便地抓取URL内容，也就是发送一个GET请求到指定的页面，然后返回HTTP的响应。 PostHandlerurllib提供的功能就是利用程序去执行各种HTTP请求。如果要模拟浏览器完成特定功能，需要把请求伪装成浏览器。伪装的方法是先监控浏览器发出的请求，再根据浏览器的请求头来伪装，User-Agent头就是用来标识浏览器的。 XMLXML虽然比JSON复杂，在Web中应用也不如以前多了，不过仍有很多地方在用，所以，有必要了解如何操作XML。 DOM vs SAX操作XML有两种方法：DOM和SAX。DOM会把整个XML读入内存，解析为树，因此占用内存大，解析慢，优点是可以任意遍历树的节点。SAX是流模式，边读边解析，占用内存小，解析快，缺点是我们需要自己处理事件。 正常情况下，优先考虑SAX，因为DOM实在太占内存。 在Python中使用SAX解析XML非常简洁，通常我们关心的事件是start_element，end_element和char_data，准备好这3个函数，然后就可以解析xml了。 解析XML时，注意找出自己感兴趣的节点，响应事件时，把节点数据保存起来。解析完毕后，就可以处理数据。 HTMLParser如果我们要编写一个搜索引擎，第一步是用爬虫把目标网站的页面抓下来，第二步就是解析该HTML页面，看看里面的内容到底是新闻、图片还是视频。 HTML本质上是XML的子集，但是HTML的语法没有XML那么严格，所以不能用标准的DOM或SAX来解析HTML。 Python提供了HTMLParser来非常方便地解析HTML，只需简单几行代码。 利用HTMLParser，可以把网页中的文本、图像等解析出来。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"数学之美 第三章 统计语言模型","slug":"数学之美 第三章 统计语言模型","date":"2018-09-18T12:25:32.000Z","updated":"2018-09-18T12:40:17.000Z","comments":true,"path":"2018/09/18/数学之美 第三章 统计语言模型/","link":"","permalink":"https://github.com/zdkswd/2018/09/18/数学之美 第三章 统计语言模型/","excerpt":"","text":"自然语言从它产生开始,逐渐演变成一种上下文相关的信息表达和传递的方式,因此让计算机处理自然语言,一个基本的问题就是为自然语言这种上下文相关的特性建立数学模型。这个数学模型就是在自然语言处理中常说的统计语言模型( Statistical Language Model),它是今天所有自然语言处理的基础,并且广泛应用于机器翻译、语音识别、印刷体或手写体识别、拼写纠错、汉字输入和文献查询。 用数学的方法描述语言规律统计语言模型产生的初衷是为了解决语音识别问题。 相比较于传统的基于语法语义的分析。贾里尼克的出发点很简单:一个句子是否合理,就看看它的可能性大小如何。至于可能性就用概率来衡量。第一个句子出现的概率大致是十的负二十次方，第二个句子出现的概率是十的负二十五次方,第三个句子出现的概率是十的负七十次方。因此,第一个最有可能,它的可能是第二个句子的10万倍,是第三个句子的一百亿亿亿亿亿亿倍。这个方法更普通而严格的描述是: 假定S表示某一个有意义的句子，由一连串特定顺序排列的词w1,w2,…,wn组成，这里n是句子的长度。若是想知道S在文本中出现的可能性，即数学上所说的S的概率P（S）。当然可以把世界上所有出现过的话统计一下，便知道这句话出现的概率了。当然这是不可能做到的。因此，需要有个模型来估算它。S=w1,w2,…,wn,那么P(S)=P(w1,w2,…,wn)利用条件概率公式 到了词wn，它的出现概率取决于它前面的所有词，到了最后一个词wn，条件概率P的可能性太多，无法估算。 俄罗斯数学家提出了一个偷懒且颇为有效的方法，即马尔科夫假设。假设任意一个词wi出现的概率只同它前面的词wi-1有关。 公式对应的统计语言模型是二元模型。假设一个词由前面N-1个词决定，对应的模型稍微复杂些，被称为N元模型。 估计联合概率P(wi-1，wi)和边缘概率P(wi-1),现在变得很简单。因为有了大量机读文本,也就是专业人土讲的语料库,只要数一数wi-1,wi这对词在统计的文本中前后相邻出现了多少次#（w-1,w),以及W-1本身在同样的文本中出现了多少次#(wi-1),然后用两个数分别除以语料库的大小#,即可得到这些词或者二元组的相对频度: 根据大数定理，只要统计量足够，相对频度就等于概率。 统计语言模型的工程诀窍高阶语言模型显然一个词只跟前面一个词有关，似乎太简化，因此，更普遍的假设是某个词和前面若干个词有关。 假定文本中的每个词wi和前面N-1个词有关，而与更前面的词无关，这样当前词wi的概率只取决于前面N-1个词P。 这就是N-1阶马尔可夫假设，对应的语言模型称为N元模型。而实际应用中使用最多的是N=3的三元模型，更高阶的模型就很少使用了。 \u0010\u0010主要是因为N元模型的空间复杂度几乎是N的指数函数，即O（|V|^N），这里|V|是一种语言词典的词汇量，一般在几万到几十万个。同样时间复杂度也几乎是一个指数函数O（|V|^（N-1）），因此N不能很大。当N从1到2，再从2到3时，模型的效果上升显著。当模型从3到3时，效果的提升就不是很显著了，而资源的耗费增加却非常快，所以，除非是不惜资源为了做到极致，很少有人使用四元以上的模型。Google的罗塞塔翻译系统和语言搜索系统,使用的是四元模型,该模型存储于500台以上的 Google服务器中。 模型的训练、零概率问题和平滑方法使用语言模型需要知道模型中所有的条件概率,我们称之为模型的参数。通过对语料的统计,得到这些参数的过程称作模型的训练。 在数理统计中,我们之所以敢于用对采样数据的观察结果来预测概率,是因为有大数定理( Law of Large Numbers)在背后做支持,它的要求是有足够的观测值。 一个直接的办法就是增加数据量,但是即使如此,依然会遇到零概率或者统计量不足的问题。假定要训练一个汉语的语言模型,汉语的词汇量大致是20万这个量级,训练一个三元模型就有8*10的15次方个不同的参数。假如从互联网上刨去垃圾数据,有100亿个有意义的中文网页,这已经是相当高估的数据,每个网页平均1000词。那么,即使将互联网上全部的中文内容都用作训练,依然只有10的13次方,因此,如果用直接的比值计算概率,大部分条件概率依然是零,这种模型我们称之为不平滑。在实际应用中,统计语言模型的零概率问题是无法回避的。 古德-图灵估计可以解决这个问题。当一个词出现的频次过小时，统计可能不可靠，计算它们的概率时要使用一个更小一点的次数,是dr(而不直接使用r),古德-图灵估计按照下面的公式计算dr： 在语料库中出现r次的词有Nr个，语料库的大小为N。 一般来说,出现一次的词的数量比出现两次的多,出现两次的比出现三次的多。这种规律称为zipf定律(zipf’s Law)。 r越大词的数量Nr越小。因此一般情况下dr&lt;r,而d0&gt;0。这样就给未出现的词赋予了一个很小的非零值，从而解决了零概率的问题。同时下调了出现频率很低的词的概率。当然,在实际的自然语言处理中,一般对出现次数超过某个阈值的词,频率不下调,只对出现次数低于这个阈值的词,频率才下调,下调得到的频率总和给未出现的词。 这样出现r次的词的概率估计为dr/N。于是,对于频率超过一定阈值的词,它们的概率估计就是它们在语料库中的相对频度,对于频率小于这个阈值的词,它们的概率估计就小于它们的相对频度,出现次数越少的,折扣越多。对于未看见的词,也给予了一个比较小的概率。这样所有词的概率估计都很平滑了。 例如对于三元模型。 函数fgt()表示经过古德-图灵估计后的相对频度。 语料的选取问题训练数据应当相关，训练数据通常是越多越好。虽然介绍了相关的方法去解决缺数据的问题，但是在数据量最多的时候概率模型的参数可以估计得比较准确，高阶的模型因为参数多,需要的训练数据也相应会多很多。遗憾的是,并非所有的应用都能得到足够的训练数据,比如说机器翻译的双语语料就非常少,在这种情况下片面追求高阶的大模型就变得一点意义也没有了。 在训练数据和应用数据一致并且训练量足够大的情况下,训练语料的噪音高低也会对模型的效果产生一定的影响,因此,在训练以前有时需要对训练数据进行预处理。一般情况下,少量的(没有模式的)随机噪音清除起来成本非常髙,通常就不做处理了。但是对于能找到模式( Pattern)的、量比较大的噪音还是需要进行过滤的,而且它们也比较容易处理,比如网页文本中大量的制表符。因此,在成本不高的情况下,过滤训练数据还是需要做的。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"}]},{"title":"数学之美 第二章 自然语言处理--从规则到统计","slug":"数学之美 第二章 自然语言处理--从规则到统计","date":"2018-09-18T01:07:32.000Z","updated":"2018-09-18T01:07:41.000Z","comments":true,"path":"2018/09/18/数学之美 第二章 自然语言处理--从规则到统计/","link":"","permalink":"https://github.com/zdkswd/2018/09/18/数学之美 第二章 自然语言处理--从规则到统计/","excerpt":"","text":"任何语言都是一种编码的方式，而语言的语法规则则是编解码的算法。 在上世纪70年代之前，计算机对自然语言的处理集中在分析语句和获取语义，基于规则的自然语言处理。主要是因为当时的学术界存在误区，即要让计算机完成翻译或者是语音识别这样只有人类能做到的事情，就必须先让计算机理解自然语言。因为从直觉上大家都会这么认为。但是相比于上下文无关文法，自然语言这种上下文有关的文法对于同样长度的句子复杂度是前者的万倍，因为上下文有关，所以需要更多额外的信息来表示现在的上下文，以及将自然语言变成及其复杂得树，在计算能力没法跟上的那个年代根本没有办法商用。 从规则到统计随着保守的教授陆续的退休，慢慢地研究方向从基于规则逐渐转向了基于统计。 15年,对于一个学者来讲是一段非常长的时间,如果哪个人从做博士开始就选错了方向并且坚持错误,到15年后发现时,基本上这一辈子可能就一事无成了。 小结基于统计的自然语言处理方法，在数学模型和通信是相通的，甚至就是相同的。因此，在数学意义上自然语言处理又和语言的初衷–通信联系在一起了。但是，科学家们认识到这个联系却花了几十年的时间。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"}]},{"title":"数学之美 第一章 文字和语言vs数字和信息","slug":"数学之美 第一章 文字和语言vs数字和信息","date":"2018-09-14T12:41:32.000Z","updated":"2018-09-14T12:41:59.000Z","comments":true,"path":"2018/09/14/数学之美 第一章 文字和语言vs数字和信息/","link":"","permalink":"https://github.com/zdkswd/2018/09/14/数学之美 第一章 文字和语言vs数字和信息/","excerpt":"","text":"信息 文字和数字当语言和词汇多到一定程度时，人类仅靠大脑已经记不住所有的词汇了。高效记录信息的需求就产生了，这便是文字。 最早是象形文字，当文字的数量多到一定程度时便不再增加了，于是开始了对概念的概括与归类。比如中文的一字多意。对于概念的聚类在原理上与今天自然语言处理或机器学习的聚类有很大的相似性。 文字按照意思来聚类，最终会带来一些歧义性，解决这个问题的方法过去与现在并没有什么不同，都是依靠上下文。但是还是会有有歧义的情况发生。今天的情况也是这样，对上下文建立的概率模型再好也有失灵的时候。这些事语言从产生开始就固有的特点。 翻译之所以能够进行，仅仅是因为不同的文字系统在记录信息上的能力是等价的（这一点非常重要）。文字只是信息的载体，而非信息本身。即使不用文字使用如数字的载体也可以存储同样意义的信息。这便是现代通信的基础。 当然,不同的文明进行交流时,或许会用不同的文字记载同一件事情。这就有可能为我们破解无人能懂的语言提供一把钥匙。 罗塞塔石碑使用了三种语言记录的同一件事情，罗塞塔石碑的破解有两点指导意义。首先，信息的冗余是信息安全的保障，其次，语言的数据，又称为语料尤其是双语或者多语对照语料对翻译至关重要。 既然文字是出现在远古“信息爆炸”导致人们的头脑装不下这些信息的时候,那么数字的出现则是在人们的财产多到需要数一数才搞清楚有多少的时候。 最开始是掰手指头来计数的，所以自然而然的就是十进制了。当然，也有连脚指头算上去的民族，所以他们是二十进制。当十进制不够用时，我们的祖先很聪明,他们发明了进位制,也就是我们今天说的逢十进一。这是人类在科学上的一大飞跃,因为我们的祖先懂得对数量开始编码了,不同的数字代表不同的量。比如二百，就是编过码的数字，解码的方法是乘法2*100。从编码的有效性来说，中国人的做法比罗马人高明。 阿拉伯人传播的古印度发明的数字123是革命性的，标志着数字和文字的分离。 文字和语言背后的数学但是,任何事物的规律性是内在的,并不随它的载体而改变。自然语言的发展在冥冥之中,都受着信息科学规律的引导。 从象形文字到拼音文字是一个飞跃,因为人类在描述物体的方式上,从物体的外表到抽象的概念,同时不自觉地采用了对信息的编码。不仅如此,我们的祖先对文字的编码还非常合理。常用的较短，不常用的较长。这完全符合信息论中的最短编码原理。 在蔡伦发明纸张以前,书写文字不是一件容易的事情。就以中文为例在东汉以前要将文字刻在其他物件比如龟壳、石碑和竹简上。由于刻个字的时间相当长,因此要惜墨如金。这就使得我们的古文(书面文字)非常简洁,但是非常难懂,而同时期的口语却和今天的白话差别不大,语句较长但是易懂。(岭南客家话基本上保留了古代口语的原貌,写出来和我们清末民初的白话颇为相似。)这种现象非常符合今天信息科学(和工程)的一些基本原理,就是在通信时,如果信道较宽,信息不必压缩就可以直接传递;而如果信道很窄,信息在传递前需要尽可能地压缩,然后在接收端进行解压缩。 犹太人在抄写《圣经》时,抄写错误还是难以避免。于是犹太人发明了一种类似于我们今天计算机和通信中校验码的方法。他们把每一个希伯来字母对应于一个数字,这样每行文字加起来便得到一个特殊的数字,这个数字便成为了这一行的校验码。同样,对于每一列也是这样处理。当犹太学者抄完一页《圣经》时,他们需要把每一行的文字加起来,看看新的校验码是否和原文的相同,然后对每一页进行同样的处理。如果这一页每一行和每一列的校验码和原文完全相同,说明这一页的抄写无误。如果某行的校验码和原文中的对应不上,则说明这行至少有一个抄写错误。当然,错误对应列的校验码也一定和原文对不上,这样可以很快找到出错的地方。 如果说从字母到词的构词法(Morphology)是词的编码规则,那么语法则是语言的编码和解码规则。不过,相比较而言,词可以被认为是有限而且封闭的集合,而语言则是无限和开放的集合。从数学上讲,对于前者可以有完备的编解码规则,而后者则不具备这个特性。因此,任何语言都有语法规则覆盖不到的地方,这些例外或者说不精确性,让我们的语言丰富多彩。 小结这些今天自然语言处理学者们研究的问题,我们的祖先在设计语言的时候其实已经遇到了,并且用类似今天的方法解决了,虽然他们的认识大多是自发的,而不是自觉的。他们过去遵循的法则和我们今天探求的研究方法背后有着共同的东西,这就是数学规律。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://github.com/zdkswd/tags/数学/"}]},{"title":"浪潮之巅读书笔记","slug":"浪潮之巅读书笔记","date":"2018-09-14T11:08:47.000Z","updated":"2018-09-14T11:09:05.000Z","comments":true,"path":"2018/09/14/浪潮之巅读书笔记/","link":"","permalink":"https://github.com/zdkswd/2018/09/14/浪潮之巅读书笔记/","excerpt":"","text":"转载加修改，自用。对书名《浪潮之巅》中“浪潮”的理解书名为“浪潮之巅”。顾名思义，本书就是讲述那些曾经或正站在互联网浪潮的巅峰的企业。书中列举了好多我们耳熟能详的企业名称，例如苹果公司、微软、诺基亚等等，“之巅”大家都能理解，即”巅峰“的意思，这些公司无疑能让大家所知，无疑都是在各自领域中极有成就的，然而成就它们达到巅峰状态的，除了自身的内功之外，无一例外的，就是这些伟大的公司都赶上了IT产业的兴起、发展与升级。因而“浪潮”可以这样理解：科技革命的浪潮，同时也可以专指信息技术革命的浪潮。 那些曾经或正在浪潮之巅的弄潮儿们帝国黄昏之AT&amp;T公司AT&amp;T公司创始人，说起来很有名，即使电话的发明人贝尔，后来AT&amp;T公司旗下有闻名于世的贝尔实验室，该实验室出过十一位诺贝尔奖得主。 AT&amp;T可谓老字号，于1877年成立，一百年来发展的顺风顺水，很长时期内垄断整个北美的通信业务。虽然有美国政府的反垄断调查，但是每次调查都会帮AT&amp;T公司剪除枝叶，让它更加茁壮。例如1913年美国司法部的调查，避免了AT&amp;T公司的大肆扩张，这反而让它顺利度过了大萧条时期。 时间到了1984年，AT&amp;T终于挺不过反垄断调查，公司进行了拆分，由一家分成7家，这次修剪让AT&amp;T公司从以通话业务为主转向了新兴的网络和移动通信方面。 1995年在华尔街逐利的资本驱动下，这一次公司高管自我拆分，而正是这个举动让AT&amp;T伤筋动骨。然而明白人大有人在，但是禁不住股票期权的诱惑，公司的未来在目前金钱的诱惑下一文不值。接下来的2000年公司又被拆分为四家，而此时AT&amp;T公司已经错过了互联网的浪潮。由于AT&amp;T主营业务是固定电话业务，互联网兴起后，人们可以直接用网络通话，再也不想用AT&amp;T那昂贵的通话业务了。曾经最能代表行业发展的AT&amp;T，由于华尔街资本的贪婪和技术浪潮的波动，已经变成了明日黄花。 科技界常青树之IBMIBM公司成立于1924年，由托马斯·华生创立。IBM成立的时间正好是第二次工业革命的末期，它发明一种机器，能够帮助政府和大型企业组织进行统计数据的整理和简单分析，因而早期的IBM，其主要客户就是政府和大型组织。 二战结束后，公司由托马斯·华生的儿子小华生接任，他是一位伟大的领导者，正是在他的带领下，IBM走向辉煌，并引领了第三次科技革命。 “电子计算机和IBM的名字是分不开的，就如同电话和AT&amp;T分不开一样”。吴军博士的这句话充分说明了IBM公司同电子计算机的相互促进作用。 在小华生的带领下，IBM投注计算机行业，在提高研究经费的同时也召来很多优秀工程师，并且参与了计算机行业标准的制定。正是这样的举动，IBM公司在小华生执掌期间，业绩年均增长30%，同时IBM公司很高的薪水也吸引了优秀的年轻人加入计算机行业。 从1950年代到1980年代这时期的IBM公司可以说是独孤求败。而这种垄断地位自然而然遭到了美国政府的反垄断调查。IBM公司不得不进行拆分，并想社会公布自己的一些专利和技术。 然而，由于IBM的业务重心一直在政府和大型企业这边，它就不可能把工作重点放在个人电脑业务上，此时一位天才人物比尔·盖茨看到了个人电脑的伟大前景，伴随着摩尔定律的作用，日渐强大的个人计算机不断蚕食IBM的主营业务，IBM就像一个走向坟墓的巨人。 1993年，郭士纳临危受命，拯救IBM。郭士纳果断出售不赚钱的硬件业务，把个人电脑业务卖给联想，从硬件制造商转型为服务政府和大型企业组织。这次转型是相当成功的，IBM公司成功从坟墓中爬了出来。 目前IBM公司是拥有专利最多的公司，在2001年起市值一度超过了微软。 向死而生之苹果说起苹果公司，就一定要讲到史蒂夫·乔布斯。在吴军博士看来，他可谓是硅谷最具传奇色彩的人物。他是唯一一个大学没有超过一年就获得美国工程院院士的人，而他获选院士的理由是：在个人计算机领域的伟大贡献。 1976年苹果公司成立，当时乔布斯和他的小伙伴们的愿望是把昂贵的计算机商业化，让计算机走进千家万户。当时的计算机很昂贵，价值几万美元。而当苹果电脑一代出来时，只需花费数百美元。 虽然现在看起来苹果一代几乎做不了什么事，但这代表了计算机不再是大型组织的专属用品，它有可能走进千家万户。与此同时，1980年代的IT产业巨人IBM也向个人计算机领域进军，一出售就占据了当时个人电脑市场的75%。针对于此，乔布斯致力于开发苹果二代，终于1984年研制出来，这是真正意义上有交互式图形界面并且有鼠标的个人电脑。而这个产品也广受市场欢迎，同时助推苹果股价攀上高峰然而好景不长，此时的苹果公司邀请了原百事可乐总裁斯库利加盟，一年之后乔布斯出走。而苹果公司在斯库利的带领下，凭借乔布斯留下的财产，还能坚挺一阵子，然而苹果的摊子越铺越大，虽然开展了不少项目，但收效甚微。同时苹果电脑业务在微软的挤压下日薄西山。 1998年的苹果决定请回乔布斯，让他执掌苹果这艘破船，而乔布斯也不愿意看着自己所创立的公司倒闭，在他的带领下，苹果公司逐渐走出低谷，获得新生。 进入21世纪的苹果公司发展了两项业务：一个是iPod，一个是iPhone。 iPod的成功是因为乔布斯利用了音乐的数字化浪潮，而iPhone的成功同样借助3G时代的东风，如果这两件产品提前几年，估计不会有现在的成功，而乔布斯天才的地方在于他牢牢抓住了这两次浪潮，才成就了今天的苹果。 前途未知的微软帝国吴军博士这样形容微软：“微软永远是所有公司最可怕的敌人。微软靠它在操作系统上的垄断地位和无比雄厚的财力，在计算机领域几乎是无往而不胜。 这句话放在《浪潮之巅》成书的那一年2008年——2009年还成立，但是现在由于谷歌和苹果的双重夹击，微软，这个被吴军博士称之为“IT业的罗马帝国”的人，前途还真的堪忧。 此话暂且不表，今日就来说说微软帝国如何成立的。1980年代的微软，在乔布斯眼里还只是个小小的软件公司。然而微软有个天才，就是比尔·盖茨。虽然比尔·盖茨在其他领域可能不如乔布斯，但是他在商业经营上的天赋要高于乔布斯，通过两手抓的方式狙击了苹果。 一方面盖茨对苹果方面要求研发软件采用拖字诀；另一方面联合当时强大的IBM，开发新的、与苹果不同的操作系统。没想到盖茨还有第三部，就是微软的操作系统便宜，他采用薄利多销的态度，因而吸引了大量计算机爱好者和软件研发者，他们在上面开发了各种各样的软件，这样用户就逐渐对微软的系统产生依赖。 就这样微软依靠自己相对廉价的操作系统，以及系统良好的兼容性，加上对手苹果公司存在的战略失误，帝国就这样建立起来。 1997年微软市场首次超过IBM，然而微软还不放心，它继续进行维护自己垄断地位的战争。这次它的手段是通过模仿比竞争对手更加廉价的产品，以及依靠自己的垄断地位来打击对手的。 然而没有永远的帝国，微软帝国在取得操作系统的绝对领先后，想进一步扩大优势，于是把眼光瞄向了互联网领域，这次迎接微软挑战的是新兴的雅虎，它比微软更绝，因为雅虎的服务是免费的。经过这次战役后，加上2000年的互联网泡沫，微软错过了进军互联网的最佳时机。 2015年下半年，微软将发布windows 10,它想实现所有操作平台的一体化，不知微软能否通过这一举动，实现王者归来？ 互联网中的福特——雅虎之所以称呼雅虎为互联网中的福特，是因为吴军博士认为雅虎对互联网的影响是可以同福特对汽车工业的影响相提并论的。 在汽车工业中，尽管汽车不是福特发明的，但是福特的生产模式，重新定义了汽车行业，并让普通工薪阶层买得起汽车。而雅虎对互联网行业的影响，在这一意义上，与福特对汽车产业的影响是相似的。 早期的互联网，其信息提供是面向用户收费的。不仅用户入网要收费，而且浏览信息也要收费，如果这样下去，互联网的发展将会和有线电视一样，几乎没有可能发展成现在的样子，而正是雅虎改变了这种状况，它把互联网办成了开放的、免费的，而且更重要的是，盈利的。 雅虎面向用户提供的服务是免费的，例如雅虎邮箱业务，而雅虎转而面向企业收取广告费，这样就形成了良性循环：免费模式吸引了更多的用户，而更多的用户意味着更多的流量，流量意味着广告商的投入更高效。 1996年雅虎上市，成为当时互联网的第一品牌，而其两位创始人——杨致远和大卫·肥罗——立刻成为了亿万富翁。 然而雅虎面对资本市场的疯狂追逐，它没有进行理性衡量，反而把自己的摊子越铺越大，因为雅虎要回应资本市场对它的期望，以支撑住它的股价。2000年，互联网泡沫崩溃，雅虎的股价下跌了90%。 从这之后，雅虎的股价再也没回到高峰，而更严重的是，雅虎并没有非常雄厚的技术积累，这个曾经的互联网巨头，按照吴军博士的话来说，已经进入了“红巨星”时代——恒星的最后一个阶段。 消失的贵族——摩托罗拉曾经，没落罗拉就是无线通信的代名词，同时它还是品质和技术的保证。而现在它在浪潮的冲击下，从被谷歌收购，到现在转手联想，这其中的曲折让人叹息，然而我们不能忘记摩托罗拉曾经的荣耀，它也引领过浪潮。 摩托罗拉公司创立于1928年，原名加尔文制造公司，由创始人之一的保罗·加尔文的名字命名。最早生产汽车收音机，二战时该公司的一些工程师帮助政府研究无线通信工具，并获得军方的认可，由此开始，可以表现出该公司在无线通讯上的强悍技术。 二战后，由于摩托罗拉的品牌越来越响，加尔文公司干脆就改名为摩托罗拉。 从二战结束到20世纪90年代，可谓是摩托罗拉的黄金时代，摩托罗拉在模拟无线通信方面有任何公司都无法比拟的技术优势。 摩托罗拉最大的贡献是在20世纪80年代发明了“大哥大”，而且其品质受到人们的交口称赞。正是因为摩托罗拉的品质和技术优势，它很自然地垄断了第一代移动通信市场。当时的摩托罗拉手机占据了全球市场的70%。 然而时间进入到九十年代，以GSM为标准的第二代移动通信技术普及开来，由于这一技术标准是由欧洲制定，作为欧洲公司的诺基亚具有很大的地理优势和后发优势。另一方面摩托罗拉公司错误估计了信息技术的更新换代技术，而且摩托罗拉过度注重技术，忽视了消费者的需求，导致它的产品不如诺基亚和三星等亚洲公司的产品畅销。 尽管后来摩托罗拉推出过多款经典机型，例如著名的刀锋系列，但是已经回天乏术，2014年转手一次的摩托罗拉进入了联想。 没落的雷神之锤——诺基亚诺基亚是《浪潮之巅》中介绍的唯一一家欧洲公司，然而现在的命运也是堪称坎坷。从2007年的市占率40%到如今的黯然退出手机市场，诺基亚的名字貌似距离现在越来越远。 曾几何时诺基亚还是芬兰的一家木工厂，曾经它的业务也如摊大饼一般，不断寻找大的发展方向，其中一个尝试很重要，就是它在20世纪60年代为军方和商业用户提供对讲机，从这些业务中诺基亚积累了一定的技术。 1982年诺基亚研制出了一种可以移动的电话，然而此时的它还不能与当时的巨头摩托罗拉相比，直到20世纪80年代末因为项目太多，出现严重的亏损。 直到1992年通信业务才成为诺基亚的核心，这一转型使得诺基亚由一个普通的电子公司成为全球移动通信的领导者，除了正确的转型方向外，还有三点对诺基亚的成功很重要：第一，抓住了移动通信技术的转型浪潮；第二，芬兰政府的大力支持；第三，科技以换壳为本。 诺基亚在2G浪潮中比摩托罗拉更注重外观、用户的便捷程度，而且一直保持产品开发的快速和灵活性，又是换一个外壳就是一部新手机，因此有人戏称诺基亚——”科技以换壳为本“。 然而诺基亚在3G浪潮中没落，最终被迫与微软走到一起，出了几款Windows Phone手机，最近的新闻是诺基亚手机部门被微软收购，而变成了Lumia品牌，诺基亚这个曾经的”雷神之锤“黯然退出手机市场。 奔腾的芯–英特尔时势造英雄英特尔公司由戈登•摩尔(Gordon E. Moore)和罗伯特.诺伊斯(Robert Noyce)于 1968 年 创立于硅谷。此前，摩尔和诺伊斯在 1956 年还和另外六个人一起创办了仙童(Fairchild)半 导体公司。 一开始英特尔生产的是性能低的微处理器，是用来补充大计算机公 司看不上的低端市场。在很长时间里，英特尔的产品被认为 是低性能、低价格。虽然它的性价比很高，但并不是尖端产品。 1981 年，IBM 为了短平快地搞 出 PC，也懒得自己设计处理器，拿来英特尔的 8086 就直接用上了。这一下子，英特尔一举 成名。 为了和 IBM PC 兼容，处理器都得是英特尔公司的。 英特尔的崛起就成为历史的必然。这正是时势造英雄。 八十年代，英特尔果断地停掉了它的内存业务，将这个 市场完全让给了日本人，从此专心做处理器。当时日本半导体公司在全市界挣了很多钱，日 本一片欢呼，认为它们打败了美国人。其实，这不过是英特尔等美国公司弃子求势的一招棋。 到今天， 即使是最早生产工作站的太阳公司和世界上最大的计算机公司 IBM 以及以前从不使用英特 尔处理器的苹果公司，都开始在自己的计算机中使用英特尔的或者和英特尔兼容的处理器了。 现在，英特尔已经垄断了计算机处理器市场。 英特尔与摩托罗拉之战资金密集型的日本半导体公司终究不可能是技术密集型的英特尔公司的对手。英特尔公 司迄今唯一遇到的重量级对手只有八十年代的摩托罗拉。 正如同罗马帝国的崛起是通过在布 匿战争中打败原有的霸主迦太基而完成的，英特尔的崛起是靠击败老牌半导体公司摩托罗拉 而实现的。 英特尔公司从外部得到了强援。由于 IBM PC 兼容机的逐步普及，技术上相对落 后的英特尔反而占了更多的市场份额。 要分析摩托罗拉之败，我们不妨来比较一下英特尔和摩托罗拉这两个公司。首先，这是 两个不同时代的公司。总部在美国中部伊利诺斯州的摩托罗拉虽然也是一个高技术公司，也 经历了八十年代的信息革命，但是它的作态完全还是五六十年代的传统的公司。虽然摩托罗 拉对雇员在工资和福利上待遇不错，但是公司和员工，基本上还是传统的雇佣关系，公司内 部管理层次较多，大部分员工基本上没有多少股票期权。因此，公司的业绩和员工的利益关 系不大。英特尔公司则是一的典型的硅谷公司。每个员工的工作强度比摩托罗拉要大很多， 但是每个人平均的股票期权也多很多。硅谷几个比较好的学区的房子，不少被英特尔公司的 早期员工买走了，而这些房子靠工资是一辈子也买不起的。 几年前，美国历史频道(History Channel)在节目中评论了中日甲午战争。美国的历史学家认为，这是两个不同时代军队之间 的战争，虽然双方武器相差不多，战争的结果不会有任何悬念，因为一个在专制的农业时代 后期的军队很难打赢一个兴起的工业化国家的军队。英特尔和摩托罗拉之间的竞争也是如此。 两个公司的统帅水平相去甚远。英特尔公司八九十年代的 CEO 格罗夫虽然是学 者出身，同时也是微机时代最优秀的领导者和管理者，他几次被评为世界上最好的 CEO。摩 托罗拉公司由加尔文(Galvin)兄弟创办，公司六十年代传到了儿子手里，八九十年代传到了 孙子手里，是个典型的家族公司。俗话说富不过三代，这话果然应验在加尔文家族上，三代 人可以说是一代不如一代。 在业务上，半导体只是摩托罗拉的一个部门，而微机处理器又只是其半导体部门的一项 业务，可是它对于英特尔来讲却是全部。 指令集之争英特尔在微软的帮助下，在商业上打赢了对摩托罗拉一战。在接下来的十年里，它在技术上又和全世界打了一战。如果转到精简指令的道路上，英特尔的市场优势会荡然无存;如果坚持 走复杂指令的道路，它就必须逆着全世界处理器发展潮流前进。 英特尔为了兼容性，一直坚持使用CISC，但是并没有放弃RISC。应该讲英特尔在精简指令处理器的工作没有白花，它在奔腾及以后的处理器设计上吸取 了 RISC 的长处，使得处理器内部流水线的效率提高很多。英特尔通过高强度的投入，保证 了它处理器性能提升得比精简指令还要快。而在精简指令阵营，九十年代五大工作站厂家太 阳、SGI、IBM、DEC 和 HP 各自为战，每家都生产自己的精简指令处理器，加上摩托罗拉 为苹果生产的 PowerPC，六家瓜分一个市场，最后谁也做不大、做不好。 英特尔经过十年努力终于打赢了对精简指令集的处理器之战。需要强调的是，英特尔不 是靠技术，而是靠市场打赢的此战。英特尔的表现在很多地方很值得圈点。首先，英特尔坚持自己系列产品的兼容性，即保证以往的软件程序肯定能在新的处理器上运行。这样时间一 长，用户便积累了很多在英特尔处理器上运行的软件。每次处理器升级，用户原来的软件都 能使，非常方便。因此大家就不愿意轻易更换其它厂家的处理器，即使那些处理器更快。而 其它处理器生产厂家这点做的都没有英特尔好，它们常常每过几年就重起炉灶，害得用户以 前很多软件不能用了，必须花钱买新的。时间一长，用户就换烦了。第二，英特尔利用规模 经济的优势，大强度投入研发，让业界普遍看衰的复杂指令集处理器一代代更新。在九十年 代初，英特尔的 x86 系列和精简指令集的处理器相比在实数运算上要略逊一筹。但是，英特 尔十几年来坚持不懈地努力，后来居上，而其它厂商因为各自市场不够大，每一个单独的处 理器芯片的投入远远不如英特尔，因此反倒落在了后面。 英特尔并没有拒绝新技术，它也曾经研制出两个不错的精简 指令的处理器，只是看到它们前途不好时，立即停掉了它们。 英特尔运气很好，在精简指令处理器阵营中，群龙无首。 英特尔和AMD的关系英特尔和 AMD 的关系基 本上是既联合又斗争。如果不是反垄 断法的约束，英特尔很可能已经把 AMD 击垮或者收购了。另外，英特尔和 AMD 的关系基 本上是既联合又斗争。 英特尔并没有想彻底把 AMD 打死。因为留着 AMD 对它利大于弊。 首先，它避免了反垄断的很多麻烦。今天 AMD 的股值只有英特尔的 5%，后者靠手中的现 金就足以买下前者。但是，英特尔不能这么做，否则会有反垄断的大麻烦。其次，留着 AMD 这个对手对英特尔自身的技术进步有好处。 AMD 不同于英特尔以往的对手，它从来没有另起炉灶做一种和英特尔不同的芯片，而是 不断推出和英特尔兼容的、更便宜的替代品。 填补艰难当一个公司的市场份额超过 50% 以后，就不用再想去将市场份额翻番了。 英特尔虽然雄霸个人电脑处理器市场，但随着个人微机市场的饱和，它远景不容乐观。 从某种程度上讲，它是反摩尔定理最大的受害者，因为处理器的价格在不断下降。同时，它 在新市场的开拓上举步艰难，很难摆脱“诺威格效应”的阴影。好在英特尔同时也是安迪-比尔 定理的直接受益者，在可以预见的将来，它的发展很大程度上必须依赖于微软等公司软件的 更新。 互联网的金门大桥（思科）好风凭借力思科公司的图标正是旧金山的金门大桥，创始人的意思是要建起连接不同网络的桥梁。 由斯坦福大学的一对夫妇创办，这对夫妇恐怕开始也没有想到以后思科能变成世界上最大的设备制造商。 思科早期成功的关键在于它的两个创始人在最合适的时机创办了一个世界上最需要的公司。假如 思科早创立两年，它可能在市场还没有起来时就烧完了它的投资而关门了，反过来也一样， 如果它迟了两年，就可能被别的公司占了先机。在思科还是一个小公司时，各大计算机公司 各自有自己很大的市场，它们首先想的是在网络市场上打败对手们而不是研制包容各公司网 络产品的路由器，因此，没有公司和思科争夺多协议路由器的市场。而等到互联网兴起时， 思科已经占据了路由器市场的领先地位。 思科的幸运正好和以朗讯为代表的传统电信公司的不幸互补，互联网的兴起，使得世界上数据传输量急剧增加，而语音通话量下降。 思科的办法很像在大航海时代西班牙和葡萄牙国王对待探险者的做法。那时，包括哥伦 布和麦哲伦在内的很多航海家都得到了王室的资助。 思科具体的做法是，如果公司里有人愿意自己创业，公司又觉 得他们做的东西是好东西，就让他们留在公司内部创业而不要到外面去折腾，而思科会作为 投资者而不再是管理者来对待这些创业的人。一旦这些小公司成功了，思科有优先权把它们 买回来，思科的地盘就得到扩大。而这些独立的小公司的创办者和员工，又可以得到很高的 回报。这样本来想离开思科出去创业的人也就不用麻烦了，接着上自己的班，只是名以上换 了一家公司。当然，如果这些小公司没办好关门了，那么思科除了赔上一些风险投资的钱， 没有额外的负担。这种做法不仅调动了各种员工尤其是早期员工的积极性，也避免这些员工 将来成为自己的对手或者加入对手的阵营。 思科通过这种做法，基本上垄断了互联网路由器和其它重要设备的技术。因为一旦有更 新更好的技术出现，思科总是能有钱买回来。如果说微软是赤裸裸地直接垄断市场，那么思 科则是通过技术间接垄断了互联网设备的市场。 既然思科这种办法证明有效，为什么别的公司学不来。当然这一方面因 为并非所有公司的领袖都有思科 CEO 钱伯斯(John Chambers)的胸怀和远见卓识，更重要 的是思科的基因使然。思科自己的创建就是用到了两个创始人的职务发明。 另外，思科员工的发明，一般很难单独成为一种产品，而必须应用到现有 网络通信系统或设备中，因此它们最好的出路就是卖给思科。所以，思科倒是不怕这些小公 司将来反了天。 竞争者思科真正的竞争对只有一假一真两个。让我们先来看看假的—Juniper Networks。这个公 司基本上是思科的影子公司，相当于 AMD 对英特尔的地位。Juniper 的产品定位在高端，而 不像思科从小到 IP 电话机，大到高端路由器都做。 思科真正的对手是中国的小弟弟华为。 中国制造”的效应。它基本的影响是，当一个原本只能在美欧生产的产品，经过一段时间则可以过渡到日本和韩国，进而落脚于中国。 美欧公司能赚钱的时间只有从美国到中国这段时间差，以前这段时间可以长达数十年，现在 只有几年。一旦一项产品可以由中国制造，那么它的利润空间就会薄到让美欧公司退出市场。 诺威格定理的宿命谷歌研究院院长彼得.诺威格博士说，当一个公司的市场占有率超过50%以后，就不要再指望在市场占有率上翻番了。 硅谷的见证人（惠普公司）昔日的硅谷之星由两个斯坦福的毕业生创办。 斯坦福工业园(Stanford Industrial Park)，惠普公司成为进驻工业园的第一批公司。惠普公司的从这里起步，生意得到 了长足的发展，很多公司也随着进驻斯坦福工业园。到了计算机时代，由于这些公司大多从 事和半导体有关的技术，从此这里便被称为硅谷。而斯坦福大学，不但度过了难关，而且从六十年代起，一跃成为世界顶尖名校。惠普则成为硅谷神话的典型代表。 几十年来，惠普和斯坦福互相提携，堪称厂校合作的典范。惠普从斯坦福获得了无数优秀毕业生，同时在财政上给予斯坦福极大的支持。就是在很长时间里，惠普是斯坦福最大的 捐助者，包括帕克特捐给斯坦福电子工程系的系馆。 如果在九十年代 初问一问硅谷最有名的公司是哪一家，十个人中有十个会回答惠普。当时，惠普是很多斯坦 福学生首选的工作公司。 九十年代后期，惠普经历了不很成功的转型，这个曾经辉煌的硅谷巨星渐渐黯淡下来了。 有争议的生死抉择惠普衰落的原因大致有两个，领导者的错误和“日本/中国制造”的冲击。 一般来讲，公司会卖出利润率低的、对自己没有用的，前景不好的部门并买进对公司长 远发展有帮助的公司，比如郭士纳领导下的 IBM 就是这样。但是，惠普接下来的发展史上最 大的两次拆分和并购，却是反其道而行之，因此科技界和华尔街至今很有争议。 应该讲，1999 年的惠普虽然大，但是并不强。这有点像中国战国时候的楚国。惠普的董 事会当然希望把惠普搞得强大。它必须决定分出去哪个部门，保留哪个部门。医疗仪器部门 虽然利润率高，但是在 GE 的打压下发展有限，经过长期酝酿，才决定将科学仪器和医疗仪器 部门都分出去，成立一个新的公司安捷伦，然后新的惠普好集中精力于计算机行业。这么大 的公司重组当然要有个有经验的人来执行，惠普公司董事会看中了菲奥莉娜拆分和并购公司 的经验，破例选择了她出任硅谷最老的惠普公司的 CEO ，来实施安捷伦上市的事宜。 亚洲制造的冲击从 2003 、2004 年起，整个硅谷开始复苏，很多公司回到并超过 2000 年的水平。但是， 惠普一点没有好转的迹象。华尔街不断看空惠普的股票，忍无可忍的股东们终于决定赶走毫 无建树的菲奥莉娜。根据美国公司的惯例，惠普提供给她一笔丰厚的退休金，然后由她自己 提出辞职，这样大家面子上都好看。菲奥莉娜临走还从惠普投资者手中拿走了上亿美元的现 金和股票。但是，股东们宁可花钱请她走。菲奥莉娜离职的当天，惠普的股票大涨了 10% 。 这是一次惨痛的教训，它说明如果一个公司不能挑选好掌舵人，以后替换掉他成本也是很高 的。 惠普虽然是一个大公司，但是它从来没有领导过哪次技术浪潮。因此，它开创出一个新 行业的可能性不大。(它不同于苹果，后者从来就有创新的基因，因此可以完成从微机到 iPod 再到 iPhone 的过渡。前者则很难转型。)它是当年以半导体和计算机硬件为核心时代的硅谷 的代表，而今天的硅谷，半导体已经变得越来越不重要了。惠普已经不能代表今天硅谷的潮 流了，这也是我在开始时讲惠普是黯淡了的巨星的原因。 下一个帝国——谷歌公司长期以来，硅谷的公司在对决微软时都会处于下风，不仅在市场上被挤占，而且在人才争夺战中也会被微软挤压。从苹果到网景公司，他们都被微软后来居上，然而最终有一个公司从小发展，直至虎口拔牙，终于这家公司有资本正面对决微软了，那就是谷歌公司。 谷歌公司的成立也离不开20世纪末的互联网泡沫，当时还在学校读博士的拉里·佩奇和谢尔盖·布林面对时代的浪潮，他们觉得自己应该做点什么，他们瞄准了新兴的搜索引擎业务，于是谷歌成立。 谷歌英文名Google，原意为一个非常大的数字Googol，即10的一百次方，“实际上宇宙中都没有任何事物能有这么大，甚至宇宙中全部的基本粒子数目也没有这么多，佩奇和布林用这个数字的用意为，他们的搜索引擎很大。 1997年9月，佩奇和布林注册了google.com的域名，然而此时二人只能靠刷信用卡度日，于是他们去寻找投资人，找到了同为斯坦福大学的校友、太阳公司创始人安迪·贝托谢姆。 贝托谢姆看到二人展示的搜索技术，果断决定给他们10万美元的支票。虽然这笔钱看起来不多，然而这在无形中给新兴的谷歌公司做了一次成功的广告。 同时斯坦福大学也向佩奇和布林伸出了援手，为其提供了专利，同时成为谷歌的股东。而为了更好发展，佩奇和布林休学，去进行光荣的创业之旅了。 他们在进行创业之旅的时候”顺走“了另一个技术大牛——克雷格·希尔福斯坦，”他几乎一个人写出了谷歌的第一个商业版本……而早期佩奇和布林忙于商业筹资，技术上只剩下了这个技术大牛。 随着业务发展，谷歌开始招人了，佩奇等人认为谷歌要坚持宁缺毋滥，每招一个人必须所有人同意才行，而且进去谷歌的人必须以一挡百，正是这一个个精英，谷歌才能成为今天的谷歌。谷歌前工程副总裁毫不讳言：“我们只需要天才。” 另外谷歌坚持精英战略， “杀鸡就是要用牛刀。”因此谷歌称为全世界单位办公面积博士最集中的地方。”谷歌不仅喜欢招博士，而且特别喜欢大学成绩优异的，这表明这个人自制力强，有责任心，而且一般而言学习好的学生更聪明。 另一方面谷歌在“品质”的坚持上类似于日本公司，它认为为了保持搜索品质，就一定要用更优秀的才人，因为即使一项工作本科生能完成，然而用硕士生效率和质量会更高，这样反而能节省更多的时间。 这样子的谷歌朝气蓬勃，同时也坚持自己“不作恶”的态度，赢得了其他公司的善意。 而当互联网从桌面上向移动端转移的时候，谷歌比微软响应的速度要快，它推出了安卓操作系统，同时在微软擅长的操作系统领域推出了Chrome。 谷歌正在进行新的布局，它已然成为一个帝国。 推动浪潮的三大定律有三大定律主宰IT行业尤其是计算机产业的发展，分别是摩尔定律（Moore’s Law），安迪-比尔定律（Andy and Bill‘s Law）以及反摩尔定律（Reverse Mooore’s Law）。 摩尔定律所谓摩尔定律，就是每过18个月，IT产品的性能会翻一番，或者说相同性能的电子产品，每过18个月价格会下降一半。 这一定律是由英特尔公司创始人戈登·摩尔（Gordon Moore）于1965年提出的。而自从摩尔定律提出以来，计算机行业始终按照摩尔定律的速度向前发展。然而摩尔定律为什么会实现呢？这要归功于IT行业的特殊性。 IT行业与其他行业不太一样的一点在于，它的成本大部分都是研发成本，而在硬件制造上的成本相对来说比例不是很高，它的硬件制造成本主要集中在制造设备上。 可以说摩尔定律主导计算机行业的发展：首先，摩尔定律要实现，硬件制造厂商不得不加快研究速度，在上一代商品出来之后就立马着手下一代产品的研发，而这需要大量的研发资金，因而从某种意义上来说，进入计算机行业有一定的资金壁垒。其次，摩尔定律促使计算机性能得以快速提升，而这为软件的升级提供了硬件上的支持，希望未来计算机行业继续发展，嘻嘻，我想体验更高的网速。 安迪-比尔定律这条定律，顾名思义，安迪——英特尔公司CEO安迪·格鲁夫（Andy Grove）；比尔——微软公司创始人比尔·盖茨，（PS，这一条定律就是赤裸裸的暗示微软-英特尔联盟啊！）这一条定律的产生与摩尔定律有关，如果按照摩尔定律的说法，如果消费者暂时不想花或者不能花很多的钱，他可以等18个月之后花一半的钱去买相同的产品。那这样的话厂商怎么挣钱？这个时候安迪-比尔定律就出现了。按照摩尔定律，过去几十年计算机的硬件性能得到了飞速提升，然而似乎以微软为代表的软件性能貌似提升并不如硬件性能那样多，然而软件占据的空间越来越大，这就逼迫消费者在使用一台计算机之后，由于软件性能的限制，不得不重新购买升级。这听起来一个阴谋，本来电子产品，就像白色家电一样，是耐用消费品，而安迪-比尔定律硬生生的让计算机和手机变成了快消品。然而事实并不是那么简单。几十年前，软件开发人员在编写程序时非常注意程序的大小，他们要充分利用计算机的空间，而现在的软件开发人员，似乎越来越浪费了。 这似乎不能怪罪软件开发人员，因为他们也要人性化，以前的编程的客观要求软件开发人员极低，而现在由于摩尔定律生效，软件工程师可以比较自由地利用硬件资源做自己喜欢的工作。而另一方面由于人力成本的提高，为了编程人员的最大利用化和缩短编程时间，因此编程语言越来越易懂、好用，而编程语言越来越臃肿。 反摩尔定律这一定律是由谷歌前CEO埃里克·施密特提出的，“如果你反过来看摩尔定律，一个IT公司如果今天和十八个月前卖掉同样多的、同样的产品，它的营业额就要下降一半”（吴军）。 这样子下去的话IT公司就很惨了，因为他们花了同样的劳动，却只得到十八个月之前营业额的一半。而反摩尔定律就是硬逼着硬件公司跟上摩尔定律的速度。 反摩尔定律也有积极作用，就是促进IT行业不断寻找质变，而非像传统行业更多的是量变，而且反摩尔定律对新兴的小公司也是有极大好处的，因为在新的浪潮到来之时，新兴小公司和大公司站在同一起跑线。 读后感：看过吴军博士对计算机行业三大定律的介绍，解答了以前的一个疑惑：例如为什么计算机和电脑越用越卡，是不是他们的阴谋？这个问题就是第二条定律能解答的。 行业兴衰的推手——资本幕后英雄——风险投资传统上创业时的资金来源为自己财产积累或借贷。然而年轻人一般没有什么钱，此时资金的不足就成了创业的瓶颈。而敢于冒险的美国人发明了一种非常规多投资方式——风险投资，这种投资不需要抵押，也不需要偿还，如果投资成功，资本家将获得几倍、乃至几十倍上百倍多利润，而不成功，就当交学费了。而这对年轻人太具有了吸引力了，他不用因为创业失败而背上债务，这样年轻人就敢于创业，因此风险资本促使美国成为创业的国度。 科技公司兴衰背后的重要角色——投资银行2008年的那场金融危机，深刻表露出华尔街的贪婪所造成的恶果，同时他们也对科技公司施加着影响：一方面，科技公司上市时的吹捧者，是他们；另一方面，打压科技公司的也是他们。 华尔街——美国的金融中心，这里坐落着诸多金融公司，而这些公司大致分为以下几类：商业银行（类似于我国的工商银行）、投资银行（替别人买卖任何有价值的商品，是股市的主力军）、共同基金公司（掌管美国所有的退休账户和世界上的很多财富）以及对冲基金（著名的有金融大鳄索罗斯的量子基金）。 而其中对科技公司影响最大的乃是投资银行。著名的投资公司有高盛公司（投资银行的NO.1)、摩根斯坦利（美国大银行家摩根创立）等。 风投公司要收回投资，科技公司的从业人员要获得回报，只有两条路可选：第一是被收购；第二是上市。而上市就需要高盛等公司当承包商，承包商以上市价格从被承包的公司收购一定数量的股票，并且以同样的价格分配给它们的客户。而承包商从中获得两笔收入：佣金（包销股票总金额）、以后用上市价购买科技公司一定股份的权利（这笔钱只有当科技公司股票上涨时才有意义）。而当投资银行认为一家科技公司有前途时，其股票会上涨，反之则会下降。股票价格下降对科技公司的影响有时是灾难性的。诚可谓“成也萧何，败也萧何。” 硅谷的摇篮——斯坦福大学硅谷的传奇与斯坦福大学多方位的支持是分不开关系的。很多当今时尚著名的科技公司都是由斯坦福大学的教授和学生创立的。它们包括惠普公司、思科公司、太阳公司、雅虎、谷歌以及英特尔。斯坦福在科技业的这种契机是任何大学都无法比拟的。 首先，按照斯坦福人自己的说法，一个斯坦福等于一个哈佛加麻省理工。这句话粗看略显自大，但实际是有道理的。斯坦福大学在专业设置上人文理工兼修，同时比东岸名校更重视实践。 斯坦福的学生，在这里能够体现更加丰富的多样性，在这里培养了他们创业时需要的沟通能力和团队协作能力。其次，斯坦福大学给予新兴的科技公司以专利和土地。斯坦福大学，其面积的相当大部分都租给了企业，这些企业绝大部分都是高科技企业，同时斯坦福大学也给予自己学校的毕业生和在读生创业上的优惠。 斯坦福大学的这一举动无疑是双赢。这些斯坦福的毕业生们成功之后就会投桃报李，他们会给母校丰厚的捐赠。 怎样做到基业长青——硅谷成功的商业模式 印钞机日本经营之神——松下幸之助有句名言:一个企业必须要盈利，否则就是对全人类的犯罪。因为无法盈利的企业是浪费资源，还不如把这些人力物力用在更需要的地方。因此很多大公司的兴起，不是靠技术的革新，还是靠商业模式的转变，这里吴军博士介绍了硅谷那些成功的商业模式。什么是好的商业模式通常，好的商业模式都非常简单，即使是外行人也能看得清楚。AT&amp;T从事固定电话业务时（19世纪末），就懂得只收服务费而不是高的吓人的安装费，这点中国电信到2000年都不明白，而英特尔开发出比IBM以及惠普更便宜的处理器，分别卖给这些公司，这也是双赢。 相反，如果一种商业模式好几个小时都说不清楚，在巴菲特看来要么是骗人、要不根本不存在。而最理想的商业模式就是如同印钞机一样自动挣钱的模式，这里吴军介绍了三种印钞机模式——谷歌的广告系统、eBay的电子商务系统以及戴尔的微机直销系统。 Google的广告系统谷歌的广告系统大大降低了全国性广告乃至全球广告的门槛，深受中小企业欢迎，另一方面谷歌的技术实力强悍，机器会自动学习，强化个性化广告推荐，这样广告效果更好，广告上自然更加喜欢。 ebay和亚马逊的在线市场而eBay的模式类似于阿里巴巴，坐收卖家和卖家之间的佣金和中介费，只要网上有交易，它就永远会有收入，但有个问题没有解决:就是信用问题和付款问题。付款问题靠PalPal（国外的支付宝）解决，但是信用问题是让eBay头疼的。 戴尔的虚拟工厂第三个是戴尔的虚拟工厂。戴尔自己没有工厂，只有一个商标，它的创始人精简了从设计到零售的环节，精简了不少费用，一度戴尔电脑的市占率为美国第一。 下一个浪潮没有不消亡的帝国，同样也没有永不衰退的企业，浪潮不断推动企业兴衰更替，而从投资银行到求职者，都希望找到下一个浪潮，能站在下一个浪潮之巅的必将是下一个谷歌一般的企业。 吴军博士断言：云计算很可能成为下一个科技浪潮，因为它将使用户摆脱桌面，通过浏览器，借助高速网络和云端服务器，随时随地享受上网的乐趣。（画外音：话说这不是谷歌的笔记本Chromebook吗？到底吴军博士是谷歌的人啊！）”科技产业让人振奋的是，有新一代技术的革命同时拌嘴这新一代公司的诞生，这个时间可能会很长，但终究会来到。而代表新的技术公司有时是新生的，有时却是以前的公司进化而来，不论是哪一种都足以让人振奋。寻找下一个这样的机会，永远是和所有现代生活相关的人追求或谈论的主题。 涨姿势有关罗斯柴尔德家族的阴谋论到底是不是真的？吴军博士的回答：罗斯柴尔德家族早已是过眼云烟，在华尔街眼里，这个家族就是二三流的水平，而美国，这个家族被人认知，还是因为葡萄酒。 按照一些中国作家的观点，一两百年前这个家族的财富作为原始资本，以每年6%的速度递增，现在该家族有几万亿美元，至于为何没有人看到，是因为这个家族的财务不向外界公开。 几万亿美元，相当于整个中国的经济规模，然而金钱只有流动才有可能增值，这么一大笔钱在世界上不可能藏得住。另外这些作者的假设也是错误的。这里可以举个反例：春秋时代的陶朱公，留给后人1两银子，现在应该变成10的60次方两银子，这远比现今世界上所有财富的加总还要多。这显然不可能，既然陶朱公不可能，凭什么罗斯柴尔德家族就可能呢？ 罗斯柴尔德家族衰落与几个大事件有关：第一个，错失19世纪末飞速发展的美国；第二，纳粹德国的抢掠。在华尔街看来，罗斯柴尔德家族的投资公司顶多算三流的投资公司。 硅谷的另一面成王败寇在硅谷创业成功的几率比中六合彩大奖的概率大不了多少，就如同好莱坞的明星带给了无数少男少 女的明星梦一样。这正是风险投资资本家和华尔街所希望的。只有越来越多的人加入这种创 业的游戏，投资者才能有好的项目投资。 毕竟，硅谷的 竞争太残酷了，成功的机会太低了。我有时会开玩笑地说“如果你不相信这辈子会被汽车撞死， 为什么相信能中硅谷大奖?后者的可能性更小。”他们会开玩笑地说:“也许是利令智昏吧。” 小公司想要成功，有很多因素必须同时具备。 创始人很重要，所有的成功者都是实干家。成功的创业者必须有一个小而精的好团队，里面每个 人都得不计较个人得失，同甘共苦，否则成则争功，败则互相推诿。在技术上，他们必须有 自己的金刚钻，他们的技术必须是不容易被别人学会和模仿的。 但是光有好的团体和技术又远远不够，他们有商业头脑而且必须找到一个能盈利的商业 模型(Business Model)。 再接下来是判断力和执行力。 外部环境。 运气。 硅谷汇集了美国三、四成的风险投资，每天硅谷都有成百上千的公司成立，但同时又有 成百上千的公司关门。对于那些失败的公司，大家并不关心，甚至无人知道它们的存在。即 使很多曾经辉煌过的公司，像网景公司、SGI 公司，人们很快也就忘却了它们。在这些成千 上万家硅谷的公司中，最终创造出了一些像思科、谷歌那样的传奇故事。仿佛间在硅谷办一 个公司就能成一个。岂不知，一将功成万骨枯，无数失败的公司在为少数几个成功者做分母。 嗜血的地方在硅谷，加班很正常，与国内有过之而无不及。但是薪水却不是线性的增长，所以单位时间的薪水反而少了。 硅谷就是这样一个“嗜血”的地方。坦率地讲，硅谷的生活质量达不到美国的平均水平。 机会均等硅谷能成为科技之都，而且长盛不衰，必有它高明之处。其中最关键的一条是保证机会 均等。任何人、任何国家和制度都无法保证我们的社会绝对公平，(事实上也没有必要追求绝 对公平。)但是，一个好的制度要保证每个人有均等的机会。 硅谷是一个到处可见权威却从不相信权威的地方。 任何人要想在这里获得成功，都得真刀真枪地拿出真本事 干出个样子。在美国很多地方，尤其是传统产业中，普遍看中甚至过于看重个人的经历 (Resume)而不是做事情的本领。 在硅谷谋职，简历固然重要， 但是个人的本事(包括和人打交道的软本领)才是各个公司真正看中的。由于每个公司产品 的压力很大，同行业公司之间的淘汰率很高，硅谷的公司需要的不是指手画脚的权威而是实 实在在干事情的人。 对创业者来讲，资历固然有用，但就重要性而言远排不进前几位。名气大、职位高的创 业者经验丰富、交际广，容易找到钱和市场，但是闯劲远不如初出茅庐的牛犊那么足。在风 险投资家看来，一个人的能力，包括处理人际关系的“软”能力(Soft Skills)是决定创业成败 的关键。一个人的职位只代表过去，而财富和地位有时反而成为创业的负担。这也是为什么 硅谷很多著名的公司如思科、苹果、Yahoo 和谷歌，包括中国人创办的 Netscreen 和 Webex 都 是原来默默无名的年轻人办成的，但是却很少听说那个成功公司是一位原某公司老总办的 。 自古英雄出少年，这是风险投资家们普遍承认的事实。红杉风投的投资家们和我谈过他 们选择投资对象的原则，其中一条就是创业者一定要有饥渴感(Hungry)。很难想象一个腰缠 万贯的富翁能比一个急于脱离贫困现状的缀学生更有把公司办好的可能。因为前者办公司不 过是为了锦上添花而后者则是要置于死地而后生。这就是乔布斯勉励年轻人要保持饥渴感 (Keep Hungry)的原因。关于风险投资家如何选择投资对象我以后还会详述。因此资深创业 者和毫无经验的年轻人各有优势，但是机会均等。硅谷各个层次的成功者几乎无一例外是靠 自己的双手从零干起，获得成功的。 由于有一些淘到金子的“冒险家”—科技新贵，就产生了替他们打理财务的需求，今天旧金 山和硅谷就成为投资银行最集中的地区之一。 硅谷相对于美国其它地方是机会最多也是最均等的。因此虽然这里工作压力大，竞争激 烈，还是不断有人愿意来。全世界很多国家想学习硅谷建立自己的科技园，但是至今没有一 个能像硅谷这么成功的。我想这些科技园的管理者们，也许首先应该问问自己是否为创业者 提供了同等的机会，还是将人按照财富、经历、名气预先分为了三六九等。(我对一些科技园 按照学历、职称引进人才和投资额招商很不以为然。) 自古英雄不问出处，今天落魄的学子可能就是明天业界的领袖。 硅含量不断降低今天知道仙童公司的人已经不多了，但它在半导体历史上占据着独一无二的地位。 硅谷没有了硅，那么留下了什么呢? 亘古而常青半导体并不是硅谷真正的本质。硅谷的灵魂是创新。硅没有了，创新的灵魂留下了，它保证了硅谷的繁荣和发展。 在硅谷的人，不论是投资者还是创业者，已经习惯了这种快速的产业变迁，人们不断在 寻找着下一个思科、下一个 Google 。其实，硅谷的创新并不局限于 IT 领域。生物科技无疑 是硅谷另一个亮点。今天的硅谷，也是世界上新兴生物公司最集中的地方。 创新必须依靠技术实力。和 Google 一样，基因科技也是世界上单位办公面积博士密度最 高的公司。就连它的七名董事中都有五名博士，九名执行官中也有六名博士。基因科技里的 科学家在同行中是佼佼者，在公司内部地位也很高。 美国的专利保护机制，一个药物只有一段时间的专利保护期，这一段时间用于回收成本，过了一段时间就不保护。对于药厂来说，必须不断的推出新药，而不能躺在功劳簿上吃一辈子。 与机会失之交臂的公司太阳公司太阳公司不乏能人，它不仅为 Google 培养了 CEO 埃里克.施密特和首任工程部副总裁韦恩.罗森(Wayne Rosen)，并且在一定程度上奠定了今天 Google 工程部门的基础。 太阳公司从 1982 年成立到 2000 年达到顶峰用了近二十年时间，而走下坡路只用了一年，足以令经营者为戒。 太阳公司名称的由来很多人不知道，它其实是斯坦福大学校园网(Stanford University Network)的首字母缩写。 太阳公司，它的操作系统 Solaris 在技术上比 Windows NT 有明显的优势。 包括 Solaris 在内的 各种 Unix 操作系统比 Windows NT 能更好地利用计算机资源，尤其是当计算机系统庞大、 用户数量巨大增加时。对太阳来讲，取胜的关键在于是否能将它在 Unix 上的技术优势转换为市场优势。 马可尼里等人的“思维”锁定在卖硬件上了。虽然太阳公司的工作站当年每台要上万美元、服务器要十万美元，但是比 DEC 的小型机和 IBM 的大型机便宜多了。在九十年代末由于互联网的兴起，太阳公司的服务器和工作站销路太好了、太挣钱了。虽然太阳公司的中小企业市场份额不断 被微软/英特尔联盟侵蚀，但是它也在不断占领原来 DEC 和 HP 小型机的市场并有足够的处女地可以开发。这很像十六世纪的西班牙王国，虽然它 的无敌舰队已经被英国人打败了，并失去了海上霸主的地位，但是由于世界上可殖民的处女地仍然很多，支撑着这个海上老二繁荣了两个世纪，直到十九世纪全世界再无殖民地可开拓 时，西班牙早期埋下的危机才表现出来。当然，衰落要比繁荣来得快。 Novell公司虽然 Novell 采用的是 DRDOS， 但是用户使用起来和微软的 MSDOS 一模一样，对程序开发者来讲也是一样。Novell 无疑是 在帮助微软和 UNIX 争夺企业级的市场。当时，微软在网络操作系统上毫无可圈点之处，它 甚至临时性地选择了 IBM 的 OS/2 LAN Server 来抵消 Novell 在网络上的优势，但是 OS/2 LAN Server 从来就没有成为过一种主流的网络操作系统。 从 1995 年起，微软和 Novell 之争起了质的变化。微软一年前推出的 Windows NT 对 Novell 的影响开始显现出来了。用户已经从 DOS 转向了 Windows，Novell 的操作系统对微 软的 Windows NT 几乎没有优势可言。很难想象一个局域网在其网络服务器上安装 Novell 的操作系统，同时在联网的微机上使用 Windows 。显然从服务器到微机一律采用微软的 Windows 是更好的办法，这时胜利的天平开始向微软倾斜，并成为不可逆转的趋势。 网景公司其网络浏览器被微软公司通过捆绑ie浏览器给打败了。 real networks播放器同理。 成功的转基因道琼斯的常青树（3M）3M 公司至今发明了六万种大大小小的产品，全世界有一半的人每天直接或者间接地接触 3M 的产品。该公司营业额中有三分之一来自于近五年的发明，其中相当大的一部分是员工利 于工作时间从事非工作的研究搞出来的。3M 允许员工用 15% 的时间干任何自己喜欢做的 事，后来这个做法被 Google 学去了，变成了 Google 的“百分之二十项目”。在最具有创新力 的公司里，3M 的排名更在 Google 和苹果这些以创新而闻名的公司前面。 世界最大的联合体（GE）今 天的 GE 是全球最大的联合体，到 2007 年底，它包括六大部门，每个部门如果独立，在各自的领域都是佼佼者。 信息产业的规律性70 20 10律一般在全球容不下三个以上的主要竞争者。这个行业一定有一 个老大，斯库利把它比喻成一个猴王，它是这个行业的主导者。毫无疑问，它虽然想顺顺当 当地统领好整个行业，就像猴王想让猴子们永远臣服一样，但是，它一定会遇到一两个主要 的挑战者，也就是老二(也许还有一个老三)。剩下来的是一大群小商家，就像一大群猴子。 老大是这个领域的主导者，不仅占据着超过一半，通常是百分之六七十的市场，并且制定了 这个领域的游戏规则。老二有自己稳定的百分之二三十的市场份额，有时也会挑战老大并给 老大一些颜色看看，但是总的来讲是受老大欺负的时间多。剩下的一群小猴子数量虽然多， 但是却只能占到百分之十甚至更少的市场，它们基本上唯老大马首是瞻。老大总是密切注视 着老二，并时不时地打压它，防止它做大。老大和老二通常都不会太在意剩下的小企业，这 样就让这一群小的企业能有挣一些小钱的地方。这里面的百分比数字 70、20 和 10 是我加 的，因为信息产业大公司之间的市场份额大抵如此。 诺维格定理当一个公司的市场占有率超过 50% 后，就无法再使市场占有率翻番了。 基因决定定理一个公司可以不相信基因的决定性，但是最终无法摆脱它的影响。 估值与创始人公司上市估值过高与过低都不好。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"商业","slug":"商业","permalink":"https://github.com/zdkswd/tags/商业/"}]},{"title":"petri网理论及其应用 0 形式化表示","slug":"petri网理论及其应用 0 形式化表示","date":"2018-09-13T11:09:56.000Z","updated":"2018-09-13T11:19:33.000Z","comments":true,"path":"2018/09/13/petri网理论及其应用 0 形式化表示/","link":"","permalink":"https://github.com/zdkswd/2018/09/13/petri网理论及其应用 0 形式化表示/","excerpt":"","text":"petri网理论及其应用 0 形式化表示楔子热点必须要了解，结合趋势。 为什么要形式化方法形式化方法的研究高潮始于 20世纪60年代后期，针对当时所谓“软件危机”,人们提出种种解决方法,归纳起来有两类：一是采用工程方法来组织、管理软件的开发过程；二是深入探讨程 序和程序开发过程的规律，建立严密的理论，以其用来指导软件开发实践。前者导致“软件工程”的出现和发展，后者则推动了形式化方法的深入研究。 形式化方法的基本含义是借助数学的方法来研究CS中的有关问题。目的是为开发过程提供一些技术和工具，用于发现并指出软件实现中潜在的缺陷问题。数学是完美的，无二义性的，可以用在航空航天工程中，当然工业界也在慢慢的从软件测试逐步变为形式化方法。 什么是形式化方法根据表达能力，形式化方法可以分为五类： 基于模型的方法：通过明确定义状态和操作来建立一个系统模型（使系统从一个状态转换到另一个状态）。用这种方法虽可以表示非功能性需求（诸如时间需求），但不能很好地表示并发性。如：Z语言，VDM，B方法等。 基于逻辑的方法：用逻辑描述系统预期的性能，包括底层规约、时序和可能性行为。采用与所选逻辑相关的公理系统证明系统具有预期的性能。用具体的编程构 造扩充逻辑从而得到一种广谱形式化方法，通过保持正确性的细化步骤集来开发系统。如：ITL（区间时序逻辑），区段演算（DC），hoare 逻辑，WP演算，模态逻辑，时序逻辑，TAM（时序代理模型），RTTL（实时时序逻辑）等。 代数方法：通过将未定义状态下不同的操作行为相联系，给出操作的显式定义。与基于模型的方法相同的是，没有给出并发的显式表示。如：OBJ， Larch族代数规约语言等； 进程代数方法：通过限制所有容许的可观察的过程间通信来表示系统行为。此类方法允许并发过程的显式表示。如：通信顺序过程（CSP），通信系统演算 （CCS），通信过程代数（ACP），时序排序规约语言（LOTOS），计时CSP(TCSP），通信系统计时可能性演算（TPCCS）等。 基于网络的方法：由于图形化表示法易于理解，而且非专业人员能够使用，因此是一种通用的系统确定表示法。该方法采用具有形式语义的图形语言，为系统开发和再工程带来特殊的好处。如 Petri图，计时Petri图，状态图等。 形式化语言与自动机以四类形式语言（短语结构语言、上下文有关语言、上下文无关语言、正则语言） 四种自动机（有穷自动机、下推自动机、图灵机、线性有界自动机） 自动机自动机是有限状态机(FSM)的数学模型。 在编译当中有所应用。自动机描述的是顺序的，线性的。 有限自动机是指有限个状态，在语法，词法分析中有用到。编译解决的主要是上下文无关文法，日常生活中所用的语言是上下文有关的文法。科大讯飞在解决日常语言识别时使用到了大数据。 λ-演算与图灵机这两者是等价的，都是回答了计算机可计算的边界这一问题。 不同的是，λ-演算使用的是数学的演算，而图灵机则是具有了一个物理的模型。","categories":[{"name":"课堂笔记","slug":"课堂笔记","permalink":"https://github.com/zdkswd/categories/课堂笔记/"}],"tags":[{"name":"petri网","slug":"petri网","permalink":"https://github.com/zdkswd/tags/petri网/"}]},{"title":"人工智能第一课","slug":"人工智能第一课","date":"2018-09-13T08:49:32.000Z","updated":"2018-09-13T08:54:01.000Z","comments":true,"path":"2018/09/13/人工智能第一课/","link":"","permalink":"https://github.com/zdkswd/2018/09/13/人工智能第一课/","excerpt":"","text":"考核方式 学术组织，会议 刊物 作业","categories":[{"name":"课堂笔记","slug":"课堂笔记","permalink":"https://github.com/zdkswd/categories/课堂笔记/"}],"tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://github.com/zdkswd/tags/人工智能/"}]},{"title":"Python廖雪峰 IO编程 进程和线程 正则表达式","slug":"Python廖雪峰 IO编程 进程和线程 正则表达式","date":"2018-09-13T08:46:56.000Z","updated":"2018-12-12T11:29:26.000Z","comments":true,"path":"2018/09/13/Python廖雪峰 IO编程 进程和线程 正则表达式/","link":"","permalink":"https://github.com/zdkswd/2018/09/13/Python廖雪峰 IO编程 进程和线程 正则表达式/","excerpt":"","text":"已修改 IO编程IO在计算机中指Input/Output，也就是输入和输出。由于程序和运行时数据是在内存中驻留，由CPU这个超快的计算核心来执行，涉及到数据交换的地方，通常是磁盘、网络等，就需要IO接口。 比如你打开浏览器，访问新浪首页，浏览器这个程序就需要通过网络IO获取新浪的网页。浏览器首先会发送数据给新浪服务器，告诉它我想要首页的HTML，这个动作是往外发数据，叫Output，随后新浪服务器把网页发过来，这个动作是从外面接收数据，叫Input。所以，通常，程序完成IO操作会有Input和Output两个数据流。当然也有只用一个的情况，比如，从磁盘读取文件到内存，就只有Input操作，反过来，把数据写到磁盘文件里，就只是一个Output操作。 IO编程中，Stream（流）是一个很重要的概念，可以把流想象成一个水管，数据就是水管里的水，但是只能单向流动。Input Stream就是数据从外面（磁盘、网络）流进内存，Output Stream就是数据从内存流到外面去。对于浏览网页来说，浏览器和新浪服务器之间至少需要建立两根水管，才可以既能发数据，又能收数据。 由于CPU和内存的速度远远高于外设的速度，所以，在IO编程中，就存在速度严重不匹配的问题。举个例子来说，比如要把100M的数据写入磁盘，CPU输出100M的数据只需要0.01秒，可是磁盘要接收这100M数据可能需要10秒，怎么办呢？有两种办法： 第一种是CPU等着，也就是程序暂停执行后续代码，等100M的数据在10秒后写入磁盘，再接着往下执行，这种模式称为同步IO； 另一种方法是CPU不等待，只是告诉磁盘，“您老慢慢写，不着急，我接着干别的事去了”，于是，后续代码可以立刻接着执行，这种模式称为异步IO。 很明显，使用异步IO来编写程序性能会远远高于同步IO，但是异步IO的缺点是编程模型复杂。想想看，你得知道什么时候通知你“汉堡做好了”，而通知你的方法也各不相同。如果是服务员跑过来找到你，这是回调模式，如果服务员发短信通知你，你就得不停地检查手机，这是轮询模式。总之，异步IO的复杂度远远高于同步IO。 操作IO的能力都是由操作系统提供的，每一种编程语言都会把操作系统提供的低级C接口封装起来方便使用，Python也不例外。我们后面会详细讨论Python的IO编程接口。 注意，本章的IO编程都是同步模式，异步IO由于复杂度太高，后续涉及到服务器端程序开发时我们再讨论。 文件读写读写文件是最常见的IO操作。Python内置了读写文件的函数，用法和C是兼容的。 读写文件前，我们先必须了解一下，在磁盘上读写文件的功能都是由操作系统提供的，现代操作系统不允许普通的程序直接操作磁盘，所以，读写文件就是请求操作系统打开一个文件对象（通常称为文件描述符），然后，通过操作系统提供的接口从这个文件对象中读取数据（读文件），或者把数据写入这个文件对象（写文件）。 读文件要以读文件的模式打开一个文件对象，使用Python内置的open()函数，传入文件名和标示符： 1f = open(&apos;/Users/michael/test.txt&apos;, &apos;r&apos;) 标示符’r’表示读，这样，我们就成功地打开了一个文件。 如果文件不存在，open()函数就会抛出一个IOError的错误，并且给出错误码和详细的信息告诉你文件不存在。 如果文件打开成功，接下来，调用read()方法可以一次读取文件的全部内容，Python把内容读到内存，用一个str对象表示。 最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的。 1f.close() 由于文件读写时都有可能产生IOError，一旦出错，后面的f.close()就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用try … finally来实现。 123456try: f = open('/path/to/file', 'r') print(f.read())finally: if f: f.close() 但是每次都这么写实在太繁琐，所以，Python引入了with语句来自动帮我们调用close()方法。 12with open('/path/to/file', 'r') as f: print(f.read()) 这和前面的try … finally是一样的，但是代码更佳简洁，并且不必调用f.close()方法。 调用read()会一次性读取文件的全部内容，如果文件有10G，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。另外，调用readline()可以每次读取一行内容，调用readlines()一次读取所有内容并按行返回list。因此，要根据需要决定怎么调用。 如果文件很小，read()一次性读取最方便；如果不能确定文件大小，反复调用read(size)比较保险；如果是配置文件，调用readlines()最方便。 file-like Object像open()函数返回的这种有个read()方法的对象，在Python中统称为file-like Object。除了file外，还可以是内存的字节流，网络流，自定义流等等。file-like Object不要求从特定类继承，只要写个read()方法就行。 StringIO就是在内存中创建的file-like Object，常用作临时缓冲。 二进制文件前面讲的默认都是读取文本文件，并且是UTF-8编码的文本文件。要读取二进制文件，比如图片、视频等等，用’rb’模式打开文件即可。 123&gt;&gt;&gt; f = open(&apos;/Users/michael/test.jpg&apos;, &apos;rb&apos;)&gt;&gt;&gt; f.read()b&apos;\\xff\\xd8\\xff\\xe1\\x00\\x18Exif\\x00\\x00...&apos; # 十六进制表示的字节 字符编码要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件。123&gt;&gt;&gt; f = open('/Users/michael/gbk.txt', 'r', encoding='gbk')&gt;&gt;&gt; f.read()'测试' 写文件写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符’w’或者’wb’表示写文本文件或写二进制文件。123&gt;&gt;&gt; f = open(&apos;/Users/michael/test.txt&apos;, &apos;w&apos;)&gt;&gt;&gt; f.write(&apos;Hello, world!&apos;)&gt;&gt;&gt; f.close() 你可以反复调用write()来写入文件，但是务必要调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以，还是用with语句来得保险。12with open(&apos;/Users/michael/test.txt&apos;, &apos;w&apos;) as f: f.write(&apos;Hello, world!&apos;) 要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码。 以’w’模式写入文件时，如果文件已存在，会直接覆盖（相当于删掉后新写入一个文件）。如果我们希望追加到文件末尾怎么办？可以传入’a’以追加（append）模式写入。 StringIO和BytesIOStringIO很多时候，数据读写不一定是文件，也可以在内存中读写。 StringIO顾名思义就是在内存中读写str。 要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可。12345678910&gt;&gt;&gt; from io import StringIO&gt;&gt;&gt; f = StringIO()&gt;&gt;&gt; f.write('hello')5&gt;&gt;&gt; f.write(' ')1&gt;&gt;&gt; f.write('world!')6&gt;&gt;&gt; print(f.getvalue())hello world! getvalue()方法用于获得写入后的str。 要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取： 1234567891011&gt;&gt;&gt; from io import StringIO&gt;&gt;&gt; f = StringIO('Hello!\\nHi!\\nGoodbye!')&gt;&gt;&gt; while True:... s = f.readline()... if s == '':... break... print(s.strip())...Hello!Hi!Goodbye! BytesIOStringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO。 BytesIO实现了在内存中读写bytes，我们创建一个BytesIO，然后写入一些bytes。 123456&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; f = BytesIO()&gt;&gt;&gt; f.write('中文'.encode('utf-8'))6&gt;&gt;&gt; print(f.getvalue())b'\\xe4\\xb8\\xad\\xe6\\x96\\x87' 请注意，写入的不是str，而是经过UTF-8编码的bytes。 和StringIO类似，可以用一个bytes初始化BytesIO，然后，像读文件一样读取。 1234&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; f = BytesIO(b'\\xe4\\xb8\\xad\\xe6\\x96\\x87')&gt;&gt;&gt; f.read()b'\\xe4\\xb8\\xad\\xe6\\x96\\x87' StringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。 操作文件和目录操作系统提供的命令只是简单地调用了操作系统提供的接口函数，Python内置的os模块也可以直接调用操作系统提供的接口函数。 打开Python交互式命令行，我们来看看如何使用os模块的基本功能。 123&gt;&gt;&gt; import os&gt;&gt;&gt; os.name # 操作系统类型'posix' 要获取详细的系统信息，可以调用uname()函数。 环境变量在操作系统中定义的环境变量，全部保存在os.environ这个变量中，可以直接查看。 要获取某个环境变量的值，可以调用os.environ.get(‘key’)。 操作文件和目录操作文件和目录的函数一部分放在os模块中，一部分放在os.path模块中，这一点要注意一下。查看、创建和删除目录可以这么调用：12345678910# 查看当前目录的绝对路径:&gt;&gt;&gt; os.path.abspath(&apos;.&apos;)&apos;/Users/michael&apos;# 在某个目录下创建一个新目录，首先把新目录的完整路径表示出来:&gt;&gt;&gt; os.path.join(&apos;/Users/michael&apos;, &apos;testdir&apos;)&apos;/Users/michael/testdir&apos;# 然后创建一个目录:&gt;&gt;&gt; os.mkdir(&apos;/Users/michael/testdir&apos;)# 删掉一个目录:&gt;&gt;&gt; os.rmdir(&apos;/Users/michael/testdir&apos;) 把两个路径合成一个时，不要直接拼字符串，而要通过os.path.join()函数，这样可以正确处理不同操作系统的路径分隔符。 同样的道理，要拆分路径时，也不要直接去拆字符串，而要通过os.path.split()函数，这样可以把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名。 os.path.splitext()可以直接让你得到文件扩展名，很多时候非常方便。 这些合并、拆分路径的函数并不要求目录和文件要真实存在，它们只对字符串进行操作。 文件操作使用下面的函数。假定当前目录下有一个test.txt文件。 1234# 对文件重命名:&gt;&gt;&gt; os.rename(&apos;test.txt&apos;, &apos;test.py&apos;)# 删掉文件:&gt;&gt;&gt; os.remove(&apos;test.py&apos;) 但是复制文件的函数居然在os模块中不存在！原因是复制文件并非由操作系统提供的系统调用。理论上讲，读写文件就可以完成文件复制。 shutil模块提供了copyfile()的函数，你还可以在shutil模块中找到很多实用函数，它们可以看做是os模块的补充。 我们要列出当前目录下的所有目录，只需要一行代码：12&gt;&gt;&gt; [x for x in os.listdir('.') if os.path.isdir(x)]['.lein', '.local', '.m2', '.npm', '.ssh', '.Trash', '.vim', 'Applications', 'Desktop', ...] 要列出所有的.py文件，也只需一行代码：12&gt;&gt;&gt; [x for x in os.listdir('.') if os.path.isfile(x) and os.path.splitext(x)[1]=='.py']['apis.py', 'config.py', 'models.py', 'pymonitor.py', 'test_db.py', 'urls.py', 'wsgiapp.py'] 序列化我们把变量从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等，都是一个意思。 序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。 反过来，把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling。 Python提供了pickle模块来实现序列化。 把一个对象序列化并写入文件：1234&gt;&gt;&gt; import pickle&gt;&gt;&gt; d = dict(name='Bob', age=20, score=88)&gt;&gt;&gt; pickle.dumps(d)b'\\x80\\x03&#125;q\\x00(X\\x03\\x00\\x00\\x00ageq\\x01K\\x14X\\x05\\x00\\x00\\x00scoreq\\x02KXX\\x04\\x00\\x00\\x00nameq\\x03X\\x03\\x00\\x00\\x00Bobq\\x04u.' pickle.dumps()方法把任意对象序列化成一个bytes，然后，就可以把这个bytes写入文件。或者用另一个方法pickle.dump()直接把对象序列化后写入一个file-like Object：123&gt;&gt;&gt; f = open(&apos;dump.txt&apos;, &apos;wb&apos;)&gt;&gt;&gt; pickle.dump(d, f)&gt;&gt;&gt; f.close() 看看写入的dump.txt文件，一堆乱七八糟的内容，这些都是Python保存的对象内部信息。 当我们要把对象从磁盘读到内存时，可以先把内容读到一个bytes，然后用pickle.loads()方法反序列化出对象，也可以直接用pickle.load()方法从一个file-like Object中直接反序列化出对象。 12345&gt;&gt;&gt; f = open(&apos;dump.txt&apos;, &apos;rb&apos;)&gt;&gt;&gt; d = pickle.load(f)&gt;&gt;&gt; f.close()&gt;&gt;&gt; d&#123;&apos;age&apos;: 20, &apos;score&apos;: 88, &apos;name&apos;: &apos;Bob&apos;&#125; 当然，这个变量和原来的变量是完全不相干的对象，它们只是内容相同而已。 Pickle的问题和所有其他编程语言特有的序列化问题一样，就是它只能用于Python，并且可能不同版本的Python彼此都不兼容，因此，只能用Pickle保存那些不重要的数据，不能成功地反序列化也没关系。 由于JSON标准规定JSON编码是UTF-8，所以我们总是能正确地在Python的str与JSON的字符串之间转换。 JSON进阶Python的dict对象可以直接序列化为JSON的{}，不过，很多时候，我们更喜欢用class表示对象，比如定义Student类，然后序列化，但是Student对象不是一个可序列化为JSON的对象。 123456def student2dict(std): return &#123; 'name': std.name, 'age': std.age, 'score': std.score &#125; 这样，Student实例首先被student2dict()函数转换成dict，然后再被顺利序列化为JSON：12&gt;&gt;&gt; print(json.dumps(s, default=student2dict))&#123;\"age\": 20, \"name\": \"Bob\", \"score\": 88&#125; 我们可以偷个懒，把任意class的实例变为dict：1print(json.dumps(s, default=lambda obj: obj.__dict__)) 因为通常class的实例都有一个dict属性，它就是一个dict，用来存储实例变量。也有少数例外，比如定义了slots的class。 同样的道理，如果我们要把JSON反序列化为一个Student对象实例，loads()方法首先转换出一个dict对象，然后，我们传入的object_hook函数负责把dict转换为Student实例。 12def dict2student(d): return Student(d['name'], d['age'], d['score']) 123&gt;&gt;&gt; json_str = '&#123;\"age\": 20, \"score\": 88, \"name\": \"Bob\"&#125;'&gt;&gt;&gt; print(json.loads(json_str, object_hook=dict2student))&lt;__main__.Student object at 0x10cd3c190&gt; 进程和线程对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。 有些进程还不止同时干一件事，比如Word，它可以同时进行打字、拼写检查、打印等事情。在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。 多进程Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。 子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。 Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程。 由于Windows没有fork调用，上面的代码在Windows上无法运行。由于Mac系统是基于BSD（Unix的一种）内核，所以，在Mac下运行是没有问题的，推荐大家用Mac学Python！ 有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。 multiprocessing针对Windows没有fork，由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。 multiprocessing模块提供了一个Process类来代表一个进程对象。 创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。 join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。 Pool如果要启动大量的子进程，可以用进程池的方式批量创建子进程。 对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。 Pool的默认大小是CPU的核数。 子进程subprocess模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。 进程间通信Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。 在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。 多线程多任务可以由多进程完成，也可以由一个进程内的多线程完成。 由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。 Python的标准库提供了两个模块：_thread和threading，_thread是低级模块，threading是高级模块，对_thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。 启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行。 由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2…… Lock多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。 创建一个锁就是通过threading.Lock()来实现。 当多个线程同时执行lock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。 获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try…finally来确保锁一定会被释放。 锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。 多核CPUPython的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。 GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。 所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。 不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。 ThreadLocal在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。 但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦。 一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。 进程 vs 线程要实现多任务，通常我们会设计Master-Worker模式，Master负责分配任务，Worker负责执行任务，因此，多任务环境下，通常是一个Master，多个Worker。 如果用多进程实现Master-Worker，主进程就是Master，其他进程就是Worker。 如果用多线程实现Master-Worker，主线程就是Master，其他线程就是Worker。 多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。 多进程模式的缺点是创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。 多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。在Windows上，如果一个线程执行的代码出了问题，你经常可以看到这样的提示：“该程序执行了非法操作，即将关闭”，其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。 在Windows下，多线程的效率比多进程要高，所以微软的IIS服务器默认采用多线程模式。由于多线程存在稳定性的问题，IIS的稳定性就不如Apache。为了缓解这个问题，IIS和Apache现在又有多进程+多线程的混合模式，真是把问题越搞越复杂。 线程切换无论是多进程还是多线程，只要数量一多，效率肯定上不去。 切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。 计算密集型 vs. IO密集型是否采用多任务的第二个考虑是任务的类型。我们可以把任务分为计算密集型和IO密集型。 计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。 计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。 第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。 IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差。 异步IO考虑到CPU和IO之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待IO操作，单进程单线程模型会导致别的任务无法并行执行，因此，我们才需要多进程模型或者多线程模型来支持多任务并发执行。 现代操作系统对IO操作已经做了巨大的改进，最大的特点就是支持异步IO。如果充分利用操作系统提供的异步IO支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx就是支持异步IO的Web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务。在多核CPU上，可以运行多个进程（数量与CPU核心数相同），充分利用多核CPU。由于系统总的进程数量十分有限，因此操作系统调度非常高效。用异步IO编程模型来实现多任务是一个主要的趋势。 对应到Python语言，单线程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。我们会在后面讨论如何编写协程。 分布式进程在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。 Python的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于managers模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。 举个例子：如果我们已经有一个通过Queue通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？ 原有的Queue可以继续使用，但是，通过managers模块把Queue通过网络暴露出去，就可以让其他机器的进程访问Queue了。 服务进程负责启动Queue，把Queue注册到网络上，然后往Queue里面写入任务。 请注意，当我们在一台机器上写多进程程序时，创建的Queue可以直接拿来用，但是，在分布式多进程环境下，添加任务到Queue不可以直接对原始的task_queue进行操作，那样就绕过了QueueManager的封装，必须通过manager.get_task_queue()获得的Queue接口添加。 这个简单的Master/Worker模型有什么用？其实这就是一个简单但真正的分布式计算，把代码稍加改造，启动多个worker，就可以把任务分布到几台甚至几十台机器上，比如把计算n*n的代码换成发送邮件，就实现了邮件队列的异步发送。 Python的分布式进程接口简单，封装良好，适合需要把繁重任务分布到多台机器的环境下。 注意Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径，由Worker进程再去共享的磁盘上读取文件。 正则表达式规则和javascript一样，实现形式通过re模块来实现。 re模块由于Python的字符串本身也用\\转义，所以要特别注意。 因此我们强烈建议使用Python的r前缀，就不用考虑转义的问题了。 match()方法判断是否匹配，如果匹配成功，返回一个Match对象，否则返回None。 re.match与re.search的区别：re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。返回的都是match对象。 正则 re.findall 返回string中所有与pattern相匹配的全部字串，返回形式为数组。在正则里面 “（）” 代表的是分组的意思，一个括号代表一个分组，你只能匹配到”()”中的内容。多个（）就返回元组。 切分字符串用正则表达式切分字符串比用固定的字符更灵活。在split（）函数中可以使用正则表达式。 分组除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）。 如果正则表达式中定义了组，就可以在Match对象上用group()方法提取出子串来。 注意到group(0)永远是原始字符串，group(1)、group(2)……表示第1、2、……个子串。 贪婪匹配正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。 和javascript一样，加个?就可以让\\d+采用非贪婪匹配。 编译当我们在Python中使用正则表达式时，re模块内部会干两件事情： 编译正则表达式，如果正则表达式的字符串本身不合法，会报错； 用编译后的正则表达式去匹配字符串。 如果一个正则表达式要重复使用几千次，出于效率的考虑，我们可以预编译该正则表达式，接下来重复使用时就不需要编译这个步骤了，直接匹配。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"Python廖雪峰 面向对象 异常处理","slug":"Python廖雪峰 面向对象 异常处理","date":"2018-09-02T07:00:56.000Z","updated":"2018-10-26T01:01:47.000Z","comments":true,"path":"2018/09/02/Python廖雪峰 面向对象 异常处理/","link":"","permalink":"https://github.com/zdkswd/2018/09/02/Python廖雪峰 面向对象 异常处理/","excerpt":"","text":"面向对象编程类和实例在Python中，定义类是通过class关键字。 通常，如果没有合适的继承类，就使用object类，这是所有类最终都会继承的类。 创建实例是通过类名+()实现的。 可以自由地给一个实例变量绑定属性，比如，给实例bart绑定一个name属性。 由于类可以起到模板的作用，因此，可以在创建实例的时候，把一些我们认为必须绑定的属性强制填写进去。通过定义一个特殊的__init__方法，在创建实例的时候，就把name，score等属性绑上去。 注意到__init__方法的第一个参数永远是self，表示创建的实例本身。 有了__init__方法，在创建实例的时候，就不能传入空的参数了，必须传入与__init__方法匹配的参数，但self不需要传，Python解释器自己会把实例变量传进去。 和普通的函数相比，在类中定义的函数只有一点不同，就是第一个参数永远是实例变量self，并且，调用时，不用传递该参数。除此之外，类的方法和普通函数没有什么区别，所以，你仍然可以用默认参数、可变参数、关键字参数和命名关键字参数。 数据封装我们从外部看Student类，就只需要知道，创建实例需要给出name和score，而如何打印，都是在Student类的内部定义的，这些数据和逻辑被“封装”起来了，调用很容易，但却不用知道内部实现的细节。 定义一个方法，除了第一个参数是self外，其他和普通函数一样。要调用一个方法，只需要在实例变量上直接调用，除了self不用传递，其他参数正常传入。 封装的另一个好处是可以给Student类增加新的方法。 访问限制在Class内部，可以有属性和方法，而外部代码可以通过直接调用实例变量的方法来操作数据，这样，就隐藏了内部的复杂逻辑。 从前面Student类的定义来看，外部代码还是可以自由地修改一个实例的name、score属性。 如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线__，在Python中，实例的变量名如果以__开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问。 已经无法从外部访问实例变量.__name和实例变量.__score了 需要注意的是，在Python中，变量名类似__xxx__的，也就是以双下划线开头，并且以双下划线结尾的，是特殊变量，特殊变量是可以直接访问的，不是private变量，所以，不能用__name__、__score__这样的变量名。 有些时候，你会看到以一个下划线开头的实例变量名，比如_name，这样的实例变量外部是可以访问的，但是，按照约定俗成的规定，当你看到这样的变量时，意思就是，“虽然我可以被访问，但是，请把我视为私有变量，不要随意访问”。 双下划线开头的实例变量是不是一定不能从外部访问呢？其实也不是。不能直接访问__name是因为Python解释器对外把__name变量改成了_Student__name，所以，仍然可以通过_Student__name来访问__name变量。 总的来说就是，Python本身没有任何机制阻止你干坏事，一切全靠自觉。 对私有数据操作用getter以及setter啦。 继承和多态继承有什么好处？最大的好处是子类获得了父类的全部功能。 当子类和父类都存在相同的run()方法时，我们说，子类的run()覆盖了父类的run()，在代码运行的时候，总是会调用子类的run()。这样，我们就获得了继承的另一个好处：多态。 多态真正的威力：调用方只管调用，不管细节。 当我们新增一种Animal的子类时，只要确保run()方法编写正确，不用管原来的代码是如何调用的。这就是著名的“开闭”原则。对扩展开放：允许新增Animal子类；对修改封闭：不需要修改依赖Animal类型的run_twice()等函数。 静态语言 vs 动态语言对于静态语言（例如Java）来说，如果需要传入Animal类型，则传入的对象必须是Animal类型或者它的子类，否则，将无法调用run()方法。 对于Python这样的动态语言来说，则不一定需要传入Animal类型。我们只需要保证传入的对象有一个run()方法就可以了。 这就是动态语言的“鸭子类型”，它并不要求严格的继承体系，一个对象只要“看起来像鸭子，走起路来像鸭子”，那它就可以被看做是鸭子。 Python的“file-like object“就是一种鸭子类型。对真正的文件对象，它有一个read()方法，返回其内容。但是，许多对象，只要有read()方法，都被视为“file-like object“。许多函数接收的参数就是“file-like object“，你不一定要传入真正的文件对象，完全可以传入任何实现了read()方法的对象。 12维基百科在程序设计中，鸭子类型（英语：duck typing）是动态类型的一种风格。在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由当前方法和属性的集合决定。 获取对象信息使用type()判断对象类型，使用type()函数。基本类型都可以用type()判断，如果一个变量指向函数或者类，也可以用type()判断。返回对应的Class类型。 判断一个对象是否是函数怎么办？可以使用types模块中定义的常量。 使用isinstance()对于class的继承关系来说，使用type()就很不方便。我们要判断class的类型，可以使用isinstance()函数。 isinstance()判断的是一个对象是否是该类型本身，或者位于该类型的父继承链上。 总是优先使用isinstance()判断类型，可以将指定类型及其子类“一网打尽”。 使用dir()如果要获得一个对象的所有属性和方法，可以使用dir()函数，它返回一个包含字符串的list。 类似__xxx__的属性和方法在Python中都是有特殊用途的，比如__len__方法返回长度。在Python中，如果你调用len()函数试图获取一个对象的长度，实际上，在len()函数内部，它自动去调用该对象的__len__()方法。 仅仅把属性和方法列出来是不够的，配合getattr()、setattr()以及hasattr()，我们可以直接操作一个对象的状态。 实例属性和类属性由于Python是动态语言，根据类创建的实例可以任意绑定属性。 给实例绑定属性的方法是通过实例变量，或者通过self变量。 可以直接在class中定义属性，这种属性是类属性，归Student类所有。 当我们定义了一个类属性后，这个属性虽然归类所有，但类的所有实例都可以访问到。 面向对象高级编程使用__slots__正常情况下，当我们定义了一个class，创建了一个class的实例后，我们可以给该实例绑定任何属性和方法，这就是动态语言的灵活性。 为了给所有实例都绑定方法，可以给class绑定方法。 动态绑定允许我们在程序运行的过程中动态给class加上功能，这在静态语言中很难实现。 Python允许在定义class的时候，定义一个特殊的__slots__变量，来限制该class实例能添加的属性。 使用__slots__要注意，__slots__定义的属性仅对当前类实例起作用，对继承的子类是不起作用的。 使用@property在绑定属性时，如果我们直接把属性暴露出去，虽然写起来很简单，但是，没办法检查参数，导致可以把成绩随便改。 这显然不合逻辑。为了限制score的范围，可以通过一个set_score()方法来设置成绩，再通过一个get_score()来获取成绩，这样，在set_score()方法里，就可以检查参数。 调用方法又略显复杂，没有直接用属性这么直接简单。 对于类的方法，装饰器一样起作用。Python内置的@property装饰器就是负责把一个方法（图中为getter方法）变成属性调用的。 @property的实现比较复杂，我们先考察如何使用。把一个getter方法变成属性，只需要加上@property就可以了，此时，@property本身又创建了另一个装饰器@score.setter，负责把一个setter方法变成属性赋值，于是，我们就拥有一个可控的属性操作。 还可以定义只读属性，只定义getter方法，不定义setter方法就是一个只读属性。 多重继承 MixIn MixIn的目的就是给一个类增加多个功能，这样，在设计类的时候，我们优先考虑通过多重继承来组合多个MixIn的功能，而不是设计多层次的复杂的继承关系。 为了更好地看出继承关系，我们把Runnable和Flyable改为RunnableMixIn和FlyableMixIn。 这样一来，我们不需要复杂而庞大的继承链，只要选择组合不同的类的功能，就可以快速构造出所需的子类。 由于Python允许使用多重继承，因此，MixIn就是一种常见的设计。 只允许单一继承的语言（如Java）不能使用MixIn的设计。 定制类__str__定义好__str__()方法，返回一个好看的字符串就可以了。 这是因为直接显示变量调用的不是__str__()，而是__repr__()，两者的区别是__str__()返回用户看到的字符串，而__repr__()返回程序开发者看到的字符串，也就是说，__repr__()是为调试服务的。 解决办法是再定义一个__repr__()。但是通常__str__()和__repr__()代码都是一样的，所以，有个偷懒的写法。 __iter__ 如果一个类想被用于for … in循环，类似list或tuple那样，就必须实现一个__iter__()方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的__next__()方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环。 __getitem__要表现得像list那样按照下标取出元素，需要实现__getitem__()方法。 但是如果想要正确实现一个__getitem__()还是要有很多工作要做的。 此外，如果把对象看成dict，__getitem__()的参数也可能是一个可以作key的object，例如str。 与之对应的是__setitem、__()方法，把对象视作list或dict来对集合赋值。最后，还有一个__delitem__()方法，用于删除某个元素。 总之，通过上面的方法，我们自己定义的类表现得和Python自带的list、tuple、dict没什么区别，这完全归功于动态语言的“鸭子类型”，不需要强制继承某个接口。 __getattr__正常情况下，当我们调用类的方法或属性时，如果不存在，就会报错。 要避免这个错误，Python还有另一个机制，那就是写一个__getattr__()方法，动态返回一个属性。 当调用不存在的属性时，比如score，Python解释器会试图调用__getattr__(self, ‘score’)来尝试获得属性，这样，我们就有机会返回score的值。 返回函数也是完全可以的。 注意，只有在没有找到属性的情况下，才调用__getattr__，已有的属性，比如name，不会在__getattr__中查找。 此外，注意到任意调用如s.abc都会返回None，这是因为我们定义的__getattr__默认返回就是None。要让class只响应特定的几个属性，我们就要按照约定，抛出AttributeError的错误。 __call__一个对象实例可以有自己的属性和方法，当我们调用实例方法时，我们用instance.method()来调用。 任何类，只需要定义一个__call__()方法，就可以直接对实例进行调用。 __call__()还可以定义参数。对实例进行直接调用就好比对一个函数进行调用一样，所以你完全可以把对象看成函数，把函数看成对象，因为这两者之间本来就没啥根本的区别。 如果你把对象看成函数，那么函数本身其实也可以在运行期动态创建出来，因为类的实例都是运行期创建出来的，这么一来，我们就模糊了对象和函数的界限。 更多的时候，我们需要判断一个对象是否能被调用，能被调用的对象就是一个Callable对象，比如函数和我们上面定义的带有__call__()的类实例。 通过callable()函数，我们就可以判断一个对象是否是“可调用”对象。 使用枚举类Python提供了Enum类。 使用元类type()动态语言和静态语言最大的不同，就是函数和类的定义，不是编译时定义的，而是运行时动态创建的。 我们说class的定义是运行时动态创建的，而创建class的方法就是使用type()函数。 type()函数既可以返回一个对象的类型，又可以创建出新的类型。 要创建一个class对象，type()函数依次传入3个参数。 通过type()函数创建的类和直接写class是完全一样的，因为Python解释器遇到class定义时，仅仅是扫描一下class定义的语法，然后调用type()函数创建出class。 正常情况下，我们都用class Xxx…来定义类，但是，type()函数也允许我们动态创建出类来，也就是说，动态语言本身支持运行期动态创建类，这和静态语言有非常大的不同，要在静态语言运行期创建类，必须构造源代码字符串再调用编译器，或者借助一些工具生成字节码实现，本质上都是动态编译，会非常复杂。 metaclass除了使用type()动态创建类以外，要控制类的创建行为，还可以使用metaclass。 metaclass，直译为元类，简单的解释就是，当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。 先定义metaclass，就可以创建类，最后创建实例。metaclass允许你创建类或者修改类，可以把类看成是metaclass创建出来的“实例”。 按照默认习惯，metaclass的类名总是以Metaclass结尾，以便清楚地表示这是一个metaclass。 metaclass是Python面向对象里最难理解，也是最难使用的魔术代码。 编写ORM会用到。 错误、调试和测试错误处理try 当我们认为某些代码可能会出错时，就可以用try来运行这段代码，如果执行出错，则后续代码不会继续执行，而是直接跳转至错误处理代码，即except语句块，执行完except后，如果有finally语句块，则执行finally语句块，至此，执行完毕。 可以有多个except来捕获不同类型的错误。 可以在except语句块后面加一个else，当没有错误发生时，会自动执行else语句。 Python的错误其实也是class，所有的错误类型都继承自BaseException，所以在使用except时需要注意的是，它不但捕获该类型的错误，还把其子类也“一网打尽”。 调用栈如果错误没有被捕获，它就会一直往上抛，最后被Python解释器捕获，打印一个错误信息，然后程序退出。 出错的时候，一定要分析错误的调用栈信息，才能定位错误的位置。 记录错误Python内置的logging模块可以非常容易地记录错误信息。 同样是出错，但程序打印完错误信息后会继续执行，并正常退出。 通过配置，logging还可以把错误记录到日志文件里，方便事后排查。 抛出错误因为错误是class，捕获一个错误就是捕获到该class的一个实例。因此，错误并不是凭空产生的，而是有意创建并抛出的。Python的内置函数会抛出很多类型的错误，我们自己编写的函数也可以抛出错误。 如果要抛出错误，首先根据需要，可以定义一个错误的class，选择好继承关系，然后，用raise语句抛出一个错误的实例。 只有在必要的时候才定义我们自己的错误类型。如果可以选择Python已有的内置的错误类型（比如ValueError，TypeError），尽量使用Python内置的错误类型。 raise语句如果不带参数，就会把当前错误原样抛出。 捕获错误目的只是记录一下，便于后续追踪。但是，由于当前函数不知道应该怎么处理该错误，所以，最恰当的方式是继续往上抛，让顶层调用者去处理。 调试第一种方法简单直接粗暴有效，就是用print()把可能有问题的变量打印出来看看 用print()最大的坏处是将来还得删掉它，想想程序里到处都是print()，运行结果也会包含很多垃圾信息。所以，我们又有第二种方法。 断言凡是用print()来辅助查看的地方，都可以用断言（assert）来替代。 assert的意思是，表达式n != 0应该是True，否则，根据程序运行的逻辑，后面的代码肯定会出错。 如果断言失败，assert语句本身就会抛出AssertionError。 程序中如果到处充斥着assert，和print()相比也好不到哪去。不过，启动Python解释器时可以用-O参数来关闭assert。 关闭后，你可以把所有的assert语句当成pass来看。 logging把print()替换为logging是第3种方式，和assert比，logging不会抛出错误，而且可以输出到文件。 这就是logging的好处，它允许你指定记录信息的级别，有debug，info，warning，error等几个级别，当我们指定level=INFO时，logging.debug就不起作用了。同理，指定level=WARNING后，debug和info就不起作用了。这样一来，你可以放心地输出不同级别的信息，也不用删除，最后统一控制输出哪个级别的信息。 logging的另一个好处是通过简单的配置，一条语句可以同时输出到不同的地方，比如console和文件。 pdb第4种方式是启动Python的调试器pdb，让程序以单步方式运行，可以随时查看运行状态。 以参数-m pdb启动后，pdb定位到下一步要执行的代码-&gt; s = ‘0’。输入命令l来查看代码。 输入命令n可以单步执行代码。 任何时候都可以输入命令p 变量名来查看变量。 这种通过pdb在命令行调试的方法理论上是万能的，但实在是太麻烦了，如果有一千行代码，要运行到第999行得敲多少命令啊。还好，我们还有另一种调试方法。 pdb.set_trace()这个方法也是用pdb，但是不需要单步执行，我们只需要import pdb，然后，在可能出错的地方放一个pdb.set_trace()，就可以设置一个断点。 运行代码，程序会自动在pdb.set_trace()暂停并进入pdb调试环境，可以用命令p查看变量，或者用命令c继续运行。 IDE如果要比较爽地设置断点、单步执行，就需要一个支持调试功能的IDE。目前比较好的Python IDE有，Visual Studio Code，需要安装Python插件。PyCharm。 单元测试单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。 这种以测试为驱动的开发模式最大的好处就是确保一个程序模块的行为符合我们设计的测试用例。在将来修改的时候，可以极大程度地保证该模块行为仍然是正确的 为了编写单元测试，我们需要引入Python自带的unittest模块。 编写单元测试时，我们需要编写一个测试类，从unittest.TestCase继承。 以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会被执行。 对每一类测试都需要编写一个test_xxx()方法。由于unittest.TestCase提供了很多内置的条件判断，我们只需要调用这些方法就可以断言输出是否是我们所期望的。最常用的断言就是assertEqual()。 运行单元测试 文档测试如果你经常阅读Python的官方文档，可以看到很多文档都有示例代码。 可以把这些示例代码在Python的交互式环境下输入并执行，结果与文档中的示例代码显示的一致。 Python内置的“文档测试”（doctest）模块可以直接提取注释中的代码并执行测试。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"Python廖雪峰 高级特性 函数式编程 模块","slug":"Python廖雪峰 高级特性 函数式编程 模块","date":"2018-08-31T07:00:56.000Z","updated":"2018-10-26T00:28:48.000Z","comments":true,"path":"2018/08/31/Python廖雪峰 高级特性 函数式编程 模块/","link":"","permalink":"https://github.com/zdkswd/2018/08/31/Python廖雪峰 高级特性 函数式编程 模块/","excerpt":"","text":"高级特性切片取数组前3个元素，用一行代码就可以完成切片。 从索引0开始取，直到索引3为止，但不包括索引3。 如果第一个索引是0，还可以省略。 Python支持L[-1]取倒数第一个元素，那么它同样支持倒数切片。 后10个数，L[-10:]。前10个数，每两个取一个，L[:10:2]。甚至什么都不写，只写[:]就可以原样复制一个list。 tuple也是一种list，唯一区别是tuple不可变。因此，tuple也可以用切片操作，只是操作的结果仍是tuple。 字符串’xxx’也可以看成是一种list，每个元素就是一个字符。因此，字符串也可以用切片操作，只是操作结果仍是字符串。 Python没有针对字符串的截取函数，只需要切片一个操作就可以完成，非常简单。 迭代当我们使用for循环时，只要作用于一个可迭代对象，for循环就可以正常运行，而我们不太关心该对象究竟是list还是其他数据类型。 通过collections模块的Iterable类型判断一个对象是可迭代对象。 Python内置的enumerate函数可以把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身。 for循环里，同时引用了两个变量，在Python里是很常见的。 列表生成式列表生成式即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。 要生成list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]可以用list(range(1, 11))。 列表生成式则可以用一行语句代替循环。 for循环后面还可以加上if判断。 还可以使用两层循环，还可以使用两层循环。 for循环其实可以同时使用两个甚至多个变量，比如dict的items()可以同时迭代key和value。 生成器创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 如果列表元素可以按照某种算法推算出来，可以在循环的过程中不断推算出后续的元素，就不必创建完整的list。Python中，这种一边循环一边计算的机制，称为生成器：generator。 把一个列表生成式的[]改成()，就创建了一个generator。 通过next()函数获得generator的下一个返回值。 generator保存的是算法，每次调用next(g)，就计算出g的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。 不断调用next(g)实在是太变态了，正确的方法是使用for循环，因为generator也是可迭代对象。 如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator。 最难理解的就是generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。 调用该generator时，首先要生成一个generator对象，然后用next()函数不断获得下一个返回值。 我们在循环过程中不断调用yield，就会不断中断。当然要给循环设置一个条件来退出循环，不然就会产生一个无限数列出来。把函数改成generator后，我们基本上从来不会用next()来获取下一个返回值，而是直接使用for循环来迭代。 但是用for循环调用generator时，发现拿不到generator的return语句的返回值。如果想要拿到返回值，必须捕获StopIteration错误，返回值包含在StopIteration的value中。 迭代器可以直接作用于for循环的对象统称为可迭代对象：Iterable。如集合数据类型，如list、tuple、dict、set、str等，generator，包括生成器和带yield的generator function。 可以使用isinstance()判断一个对象是否是Iterable对象。 可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。 可以使用isinstance()判断一个对象是否是Iterator对象。 生成器都是Iterator对象，但list、dict、str虽然是Iterable，却不是Iterator。 把list、dict、str等Iterable变成Iterator可以使用iter()函数。 Python的Iterator对象表示的是一个数据流，Iterator对象可以被next()函数调用并不断返回下一个数据，直到没有数据时抛出StopIteration错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过next()函数实现按需计算下一个数据，所以Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。 Iterator甚至可以表示一个无限大的数据流，例如全体自然数。而使用list是永远不可能存储全体自然数的。所以list、dict、str等数据类型不是Iterator。 函数式编程高阶函数map/reducePython内建了map()和reduce()函数。 map()函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回。 由于结果r是一个Iterator，Iterator是惰性序列，因此通过list()函数让它把整个序列都计算出来并返回一个list。 所以，map()作为高阶函数，事实上它把运算规则抽象了，能一眼看明白“把f(x)作用在list的每一个元素并把结果生成一个新的list。 reduce把一个函数作用在一个序列[x1, x2, x3, …]上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算。 假设Python没有提供int()函数，你完全可以自己写一个把字符串转化为整数的函数，而且只需要几行代码！ filterPython内建的filter()函数用于过滤序列。 和map()类似，filter()也接收一个函数和一个序列。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。 注意到filter()函数返回的是一个Iterator，也就是一个惰性序列，所以要强迫filter()完成计算结果，需要用list()函数获得所有结果并返回list。 sorted排序算法Python内置的sorted()函数就可以对list进行排序。 sorted()函数也是一个高阶函数，它还可以接收一个key函数来实现自定义的排序，例如按绝对值大小排序。 key指定的函数将作用于list的每一个元素上，并根据key函数返回的结果进行排序。 从上述例子可以看出，高阶函数的抽象能力是非常强大的，而且，核心代码可以保持得非常简洁。 返回函数函数作为返回值高阶函数除了可以接受函数作为参数外，还可以把函数作为结果值返回。 闭包返回的函数并没有立刻执行，而是直到调用了f()才执行。 返回闭包时牢记一点：返回函数不要引用任何循环变量，或者后续会发生变化的变量。 匿名函数匿名函数lambda x: x * x实际上就是 匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。 用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数。 同样，也可以把匿名函数作为返回值返回，比如。 装饰器由于函数也是一个对象，而且函数对象可以被赋值给变量，所以，通过变量也能调用该函数。 函数对象有一个name属性，可以拿到函数的名字。 在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator）。 本质上，decorator就是一个返回函数的高阶函数。 我们要定义一个能打印日志的decorator，可以定义如下。 我们要借助Python的@语法，把decorator置于函数的定义处。 把@log放到now()函数的定义处，相当于执行了语句。 将原函数now传入log函数之中，返回wrapper函数，包含了原本的now功能以及加上了新的功能。将值赋予now。这样就完成了装饰。 偏函数Python的functools模块提供了很多有用的功能，其中一个就是偏函数（Partial function）。要注意，这里的偏函数和数学意义上的偏函数不一样。 简单总结functools.partial的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。 模块使用模块Python本身就内置了很多非常有用的模块，只要安装完毕，这些模块就可以立刻使用。 作用域在一个模块中，我们可能会定义很多函数和变量，但有的函数和变量我们希望给别人使用，有的函数和变量我们希望仅仅在模块内部使用。在Python中，是通过_前缀来实现的。 正常的函数和变量名是公开的（public），可以被直接引用，比如：abc，x123，PI等； 类似__xxx__这样的变量是特殊变量，可以被直接引用，但是有特殊用途，比如上面的__author__，__name__就是特殊变量，hello模块定义的文档注释也可以用特殊变量__doc__访问，我们自己的变量一般不要用这种变量名； 类似_xxx和__xxx这样的函数或变量就是非公开的（private），不应该被直接引用，比如_abc，__abc等； 之所以我们说，private函数和变量“不应该”被直接引用，而不是“不能”被直接引用，是因为Python并没有一种方法可以完全限制访问private函数或变量，但是，从编程习惯上不应该引用private函数或变量。 外部不需要引用的函数全部定义成private，只有外部需要引用的函数才定义为public，这也是一种非常有用的代码封装和抽象的方法。 安装第三方模块在Python中，安装第三方模块，是通过包管理工具pip完成的。 注意：Mac或Linux上有可能并存Python 3.x和Python 2.x，因此对应的pip命令是pip3。 一般来说，第三方库都会在Python官方的pypi.python.org网站注册，要安装一个第三方库，必须先知道该库的名称，可以在官网或者pypi上搜索，比如Pillow的名称叫Pillow，因此，安装Pillow的命令就是。 安装常用模块我们装上Anaconda，就相当于把数十个第三方模块自动安装好了，非常简单易用。 模块搜索路径当我们试图加载一个模块时，Python会在指定的路径下搜索对应的.py文件，如果找不到，就会报错。 默认情况下，Python解释器会搜索当前目录、所有已安装的内置模块和第三方模块，搜索路径存放在sys模块的path变量中。 如果我们要添加自己的搜索目录，有两种方法一是直接修改sys.path，添加要搜索的目录。第二种方法是设置环境变量PYTHONPATH，该环境变量的内容会被自动添加到模块搜索路径中。设置方式与设置Path环境变量类似。注意只需要添加你自己的搜索路径，Python自己本身的搜索路径不受影响。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"Python廖雪峰 简介，解释器，基础，函数","slug":"Python廖雪峰 简介，解释器，基础，函数","date":"2018-08-27T11:33:56.000Z","updated":"2018-11-13T09:16:40.000Z","comments":true,"path":"2018/08/27/Python廖雪峰 简介，解释器，基础，函数/","link":"","permalink":"https://github.com/zdkswd/2018/08/27/Python廖雪峰 简介，解释器，基础，函数/","excerpt":"","text":"Python简介Python就为我们提供了非常完善的基础代码库，覆盖了网络、文件、GUI、数据库、文本等大量内容，被形象地称作“内置电池（batteries included）”。用Python开发，许多功能不必从零编写，直接使用现成的即可。 除了内置的库外，Python还有大量的第三方库，也就是别人开发的，供你直接使用的东西。当然，如果你开发的代码通过很好的封装，也可以作为第三方库给别人使用。 那Python适合开发哪些类型的应用呢？首选是网络应用，包括网站、后台服务等等； 其次是许多日常需要的小工具，包括系统管理员需要的脚本任务等等； 另外就是把其他语言开发的程序再包装起来，方便使用。 Python的缺点第一个缺点就是运行速度慢，和C程序相比非常慢，因为Python是解释型语言，你的代码在执行时会一行一行地翻译成CPU能理解的机器码，这个翻译过程非常耗时，所以很慢。而C程序是运行前直接编译成CPU能执行的机器码，所以非常快。 第二个缺点就是代码不能加密。如果要发布你的Python程序，实际上就是发布源代码，这一点跟C语言不同，C语言不用发布源代码，只需要把编译后的机器码（也就是你在Windows上常见的xxx.exe文件）发布出去。要从机器码反推出C代码是不可能的，所以，凡是编译型的语言，都没有这个问题，而解释型的语言，则必须把源码发布出去。 Python解释器由于整个Python语言从规范到解释器都是开源的，所以理论上，只要水平够高，任何人都可以编写Python解释器来执行Python代码（当然难度很大）。事实上，确实存在多种Python解释器。 CPython官方版本的解释器：CPython。这个解释器是用C语言开发的。CPython是使用最广的Python解释器。教程的所有代码也都在CPython下执行。 IPythonIPython是基于CPython之上的一个交互式解释器，也就是说，IPython只是在交互方式上有所增强，但是执行Python代码的功能和CPython是完全一样的。 PyPyPyPy是另一个Python解释器，它的目标是执行速度。PyPy采用JIT技术，对Python代码进行动态编译（注意不是解释），所以可以显著提高Python代码的执行速度。绝大部分Python代码都可以在PyPy下运行，但是PyPy和CPython有一些是不同的，这就导致相同的Python代码在两种解释器下执行可能会有不同的结果。 JythonJython是运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码执行。 IronPythonIronPython和Jython类似，只不过IronPython是运行在微软.Net平台上的Python解释器，可以直接把Python代码编译成.Net的字节码。 小结Python的解释器很多，但使用最广泛的还是CPython。如果要和Java或.Net平台交互，最好的办法不是用Jython或IronPython，而是通过网络调用来交互，确保各程序之间的独立性。 Python基础数据类型和变量数据类型在Python中，能够直接处理的数据类型有以下几种： 整数Python可以处理任意大小的整数，当然包括负整数，在程序中的表示方法和数学上的写法一模一样，例如：1，100，-8080，0，等等。 计算机由于使用二进制，所以，有时候用十六进制表示整数比较方便，十六进制用0x前缀和0-9，a-f表示，例如：0xff00，0xa5b4c3d2，等等。 浮点数浮点数也就是小数，之所以称为浮点数，是因为按照科学记数法表示时，一个浮点数的小数点位置是可变的，比如，1.23x109和12.3x108是完全相等的。浮点数可以用数学写法，如1.23，3.14，-9.01，等等。但是对于很大或很小的浮点数，就必须用科学计数法表示，把10用e替代，1.23x109就是1.23e9，或者12.3e8，0.000012可以写成1.2e-5，等等。 整数和浮点数在计算机内部存储的方式是不同的，整数运算永远是精确的（除法难道也是精确的？是的！），而浮点数运算则可能会有四舍五入的误差。 字符串字符串是以单引号’或双引号”括起来的任意文本，比如’abc’，”xyz”等等。请注意，’’或””本身只是一种表示方式，不是字符串的一部分，因此，字符串’abc’只有a，b，c这3个字符。如果’本身也是一个字符，那就可以用””括起来，比如”I’m OK”包含的字符是I，’，m，空格，O，K这6个字符。 如果字符串内部既包含’又包含”怎么办？可以用转义字符\\来标识。 如果字符串里面有很多字符都需要转义，就需要加很多\\，为了简化，Python还允许用r’’表示’’内部的字符串默认不转义。 如果字符串内部有很多换行，用\\n写在一行里不好阅读，为了简化，Python允许用’’’…’’’的格式表示多行内容。用在命令行中，py文件中直接换行也可输出换行后的内容。 布尔值一个布尔值只有True、False两种值，要么是True，要么是False。 布尔值可以用and、or和not运算。 空值空值是Python里一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。 变量变量在程序中就是用一个变量名表示了，变量名必须是大小写英文、数字和_的组合，且不能用数字开头。 在Python中，等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量。 可以看到赋值前不需要声明变量。 这种变量本身类型不固定的语言称之为动态语言。 变量在计算机内存中的表示 Python解释器干了两件事情：在内存中创建了一个’ABC’的字符串；在内存中创建了一个名为a的变量，并把它指向’ABC’。 常量所谓常量就是不能变的变量，比如常用的数学常数π就是一个常量。在Python中，通常用全部大写的变量名表示常量。 但事实上PI仍然是一个变量，Python根本没有任何机制保证PI不会被改变。用全部大写的变量名表示常量只是一个习惯上的用法。 / 除法计算结果是浮点数，即使是两个整数恰好整除，结果也是浮点数： 还有一种除法是//，称为地板除，两个整数的除法仍然是整数。 字符串和编码字符编码计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。 Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。 ASCII编码和Unicode编码的区别：ASCII编码是1个字节，而Unicode编码通常是2个字节。 本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间。 在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。 Python的字符串在最新的Python 3版本中，字符串是以Unicode编码的，也就是说，Python的字符串支持多语言。 由于Python的字符串类型是str，在内存中以Unicode表示，一个字符对应若干个字节。如果要在网络上传输，或者保存到磁盘上，就需要把str变为以字节为单位的bytes。 要注意区分’ABC’和b’ABC’，前者是str，后者虽然内容显示得和前者一样，但bytes的每个字符都只占用一个字节。 以Unicode表示的str通过encode()方法可以编码为指定的bytes。 纯英文的str可以用ASCII编码为bytes，内容是一样的，含有中文的str可以用UTF-8编码为bytes。含有中文的str无法用ASCII编码，因为中文编码的范围超过了ASCII编码的范围，Python会报错。 反过来，如果我们从网络或磁盘上读取了字节流，那么读到的数据就是bytes。要把bytes变为str，就需要用decode()方法。 len()函数计算的是str的字符数，如果换成bytes，len()函数就计算字节数。 1个中文字符经过UTF-8编码后通常会占用3个字节，而1个英文字符只占用1个字节。 在操作字符串时，我们经常遇到str和bytes的互相转换。为了避免乱码问题，应当始终坚持使用UTF-8编码对str和bytes进行转换。 由于Python源代码也是一个文本文件，所以，当你的源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为UTF-8编码。Python当然也支持其他编码方式，比如把Unicode编码成GB2312。但这种方式纯属自找麻烦，如果没有特殊业务要求，请牢记仅使用UTF-8编码。 申明了UTF-8编码并不意味着你的.py文件就是UTF-8编码的，必须并且要确保文本编辑器正在使用UTF-8 without BOM编码。 格式化在Python中，采用的格式化方式和C语言是一致的，用%实现。 常见的占位符有： 如果你不太确定应该用什么，%s永远起作用，它会把任何数据类型转换为字符串。 转义，用%%来表示一个%。 format()另一种格式化字符串的方法是使用字符串的format()方法，它会用传入的参数依次替换字符串内的占位符{0}、{1}……，不过这种方式写起来比%要麻烦得多。 使用list和tuplelistlist是一种有序的集合，可以随时添加和删除其中的元素。 len()函数可以获得list元素的个数。 用索引来访问list中每一个位置的元素，记得索引是从0开始的。 -1做索引，直接获取最后一个元素。 append()可以往list中追加元素到末尾 insert()也可以把元素插入到指定的位置。 pop()方法，删除list末尾的元素。要删除指定位置的元素，用pop(i)方法。 要把某个元素替换成别的元素，可以直接赋值给对应的索引位置。 list里面的元素的数据类型也可以不同。list元素也可以是另一个list。 如果一个list中一个元素也没有，就是一个空的list，它的长度为0。 python列表mask: tuple另一种有序列表叫元组：tuple。tuple和list非常类似，但是tuple一旦初始化就不能修改。 没有append()，insert()这样的方法。其他获取元素的方法和list是一样的，你可以正常地使用classmates[0]，classmates[-1]，但不能赋值成另外的元素。 因为tuple不可变，所以代码更安全。如果可能，能用tuple代替list就尽量用tuple。 tuple的陷阱：只有1个元素的tuple定义时必须加一个逗号“ , ”，来消除歧义。 Python在显示只有1个元素的tuple时，也会加一个逗号“ , ”，以免你误解成数学计算意义上的括号。 tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向’a’，就不能改成指向’b’，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！ 创建一个内容也不变的tuple那就必须保证tuple的每一个元素本身也不能变。 条件判断if语句elif是else if的缩写。 inputinput()读取用户的输入，这样可以自己输入。 循环for…in循环 for x in …循环就是把每个元素代入变量x，然后执行缩进块的语句。 range()函数，可以生成一个整数序列，range(5)生成的序列是从0开始小于5（没有5）的整数。 0-100。 while循环 breakbreak语句可以提前退出循环。 continuecontinue语句，跳过当前的这次循环，直接开始下一次循环。 使用dict和setdictPython内置了字典：dict的支持，dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。 把数据放入dict的方法，除了初始化时指定外，还可以通过key放入。 由于一个key只能对应一个value，所以，多次对一个key放入value，后面的值会把前面的值冲掉。 如果key不存在，dict就会报错，要避免key不存在的错误，有两种办法，一是通过in判断key是否存在，二是通过dict提供的get()方法，如果key不存在，可以返回None，或者自己指定的value。注意：返回None的时候Python的交互环境不显示结果。 要删除一个key，用pop(key)方法，对应的value也会从dict中删除。 请务必注意，dict内部存放的顺序和key放入的顺序是没有关系的。 和list比较，dict有以下几个特点查找和插入的速度极快，不会随着key的增加而变慢需要占用大量的内存，内存浪费多而list相反 dict是用空间来换取时间的一种方法。 正确使用dict非常重要，需要牢记的第一条就是dict的key必须是不可变对象。在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list是可变的，就不能作为key。 setset和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。 要创建一个set，需要提供一个list作为输入集合。 重复元素在set中自动被过滤。 通过add(key)方法可以添加元素到set中，可以重复添加，但不会有效果。 通过remove(key)方法可以删除元素。 set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作。 set和dict的唯一区别仅在于没有存储对应的value，但是，set的原理和dict一样，所以，同样不可以放入可变对象。 不可变对象对于不变对象来说，调用对象自身的任意方法，也不会改变该对象自身的内容。相反，这些方法会创建新的对象并返回，这样，就保证了不可变对象本身永远是不可变的。 函数调用函数要调用一个函数，需要知道函数的名称和参数，比如求绝对值的函数abs，只有一个参数。 调用函数的时候，如果传入的参数数量不对，会报TypeError的错误。如果传入的参数数量是对的，但参数类型不能被函数所接受，也会报TypeError的错误，并且给出错误信息。 数据类型转换Python内置的常用函数还包括数据类型转换函数，比如int()函数可以把其他数据类型转换为整数。 函数名其实就是指向一个函数对象的引用，完全可以把函数名赋给一个变量，相当于给这个函数起了一个“别名”。 定义函数在Python中，定义一个函数要使用def语句，依次写出函数名、括号、括号中的参数和冒号:，然后，在缩进块中编写函数体，函数的返回值用return语句返回。 如果你已经把my_abs()的函数定义保存为abstest.py文件了，那么，可以在该文件的当前目录下启动Python解释器，用from abstest import my_abs来导入my_abs()函数，注意abstest是文件名（不含.py扩展名）。 空函数如果想定义一个什么事也不做的空函数，可以用pass语句。 实际上pass可以用来作为占位符，比如现在还没想好怎么写函数的代码，就可以先放一个pass，让代码能运行起来。 缺少了pass，代码运行就会有语法错误。 参数检查调用函数时，如果参数个数不对，Python解释器会自动检查出来，并抛出TypeError。但是如果参数类型不对，Python解释器就无法帮我们检查。 对参数的限制需要我们手动完成，数据类型检查可以用内置函数isinstance()实现。 返回多个值 但其实这只是一种假象，Python函数返回的仍然是单一值。 原来返回值是一个tuple！但是，在语法上，返回一个tuple可以省略括号，而多个变量可以同时接收一个tuple，按位置赋给对应的值，所以，Python的函数返回多值其实就是返回一个tuple，但写起来更方便。 小结函数体内部可以用return随时返回函数结果；函数执行完毕也没有return语句时，自动return None。 函数的参数Python的函数定义非常简单，但灵活度却非常大。除了正常定义的必选参数外，还可以使用默认参数、可变参数和关键字参数，使得函数定义出来的接口，不但能处理复杂的参数，还可以简化调用者的代码。 位置参数对于power(x)函数，参数x就是一个位置参数。 默认参数 power(x, n=2) 当我们调用power(5)时，相当于调用power(5, 2) 设置默认参数时，有几点要注意一是必选参数在前，默认参数在后，否则Python的解释器会报错。当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。变化小的参数就可以作为默认参数。 默认参数降低了函数调用的难度，而一旦需要更复杂的调用时，又可以传递更多的参数来实现。无论是简单调用还是复杂调用，函数只需要定义一个。 有多个默认参数时，调用的时候，既可以按顺序提供默认参数，比如调用enroll(‘Bob’, ‘M’, 7)，意思是，除了name，gender这两个参数外，最后1个参数应用在参数age上，city参数由于没有提供，仍然使用默认值。 也可以不按顺序提供部分默认参数。当不按顺序提供部分默认参数时，需要把参数名写上。比如调用enroll(‘Adam’, ‘M’, city=’Tianjin’)，意思是，city参数用传进去的值，其他默认参数继续使用默认值。 默认参数很有用，但使用不当，也会掉坑里。默认参数有个最大的坑。定义默认参数要牢记一点：默认参数必须指向不变对象！ 为什么要设计str、None这样的不变对象呢？因为不变对象一旦创建，对象内部的数据就不能修改，这样就减少了由于修改数据导致的错误。此外，由于对象不变，多任务环境下同时读取对象不需要加锁，同时读一点问题都没有。我们在编写程序时，如果可以设计一个不变对象，那就尽量设计成不变对象。 可变参数在Python函数中，还可以定义可变参数。顾名思义，可变参数就是传入的参数个数是可变的。 定义可变参数和定义一个list或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此，函数代码完全不变。但是，调用该函数时，可以传入任意个参数，包括0个参数。 Python允许你在list或tuple前面加一个*号，把list或tuple的元素变成可变参数传进去。 关键字参数可变参数允许你传入0个或任意个参数，这些可变参数在函数调用时自动组装为一个tuple。而关键字参数允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。 它可以扩展函数的功能。比如，在person函数里，我们保证能接收到name和age这两个参数，但是，如果调用者愿意提供更多的参数，我们也能收到。试想你正在做一个用户注册的功能，除了用户名和年龄是必填项外，其他都是可选项，利用关键字参数来定义这个函数就能满足注册的需求。 注意kw获得的dict是extra的一份拷贝，对kw的改动不会影响到函数外的extra。 命名关键字参数如果要限制关键字参数的名字，就可以用命名关键字参数，例如，只接收city和job作为关键字参数。这种方式定义的函数如下 和关键字参数**kw不同，命名关键字参数需要一个特殊分隔符*，*后面的参数被视为命名关键字参数。 调用方式如下 如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了 命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错。 命名关键字参数可以有缺省值，从而简化调用。 参数组合在Python中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。 参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 对于任意函数，都可以通过类似func(*args, **kw)的形式调用它，无论它的参数是如何定义的。 递归函数尾递归是指，在函数返回的时候，调用自身本身，并且，return语句不能包含表达式。这样，编译器或者解释器就可以把尾递归做优化，使递归本身无论调用多少次，都只占用一个栈帧，不会出现栈溢出的情况。 遗憾的是，大多数编程语言没有针对尾递归做优化，Python解释器也没有做优化。 使用递归函数的优点是逻辑简单清晰，缺点是过深的调用会导致栈溢出。 针对尾递归优化的语言可以通过尾递归防止栈溢出。尾递归事实上和循环是等价的，没有循环语句的编程语言只能通过尾递归实现循环。 Python标准的解释器没有针对尾递归做优化，任何递归函数都存在栈溢出的问题。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://github.com/zdkswd/tags/Python/"}]},{"title":"JavaScript标准参考教程 DOM模型 概述 Document节点","slug":"JavaScript标准参考教程 DOM模型 一","date":"2018-08-22T10:33:56.000Z","updated":"2018-10-09T07:11:40.000Z","comments":true,"path":"2018/08/22/JavaScript标准参考教程 DOM模型 一/","link":"","permalink":"https://github.com/zdkswd/2018/08/22/JavaScript标准参考教程 DOM模型 一/","excerpt":"","text":"DOM模型概述基本概念DOMDOM 是 JavaScript 操作网页的接口，全称为“文档对象模型”（Document Object Model）。它的作用是将网页转为一个 JavaScript 对象，从而可以用脚本进行各种操作（比如增删内容）。 浏览器会根据 DOM 模型，将结构化文档（比如 HTML 和 XML）解析成一系列的节点，再由这些节点组成一个树状结构（DOM Tree）。所有的节点和最终的树状结构，都有规范的对外接口。 DOM 只是一个接口规范，可以用各种语言实现。所以严格地说，DOM 不是 JavaScript 语法的一部分，但是 DOM 操作是 JavaScript 最常见的任务，离开了 DOM，JavaScript 就无法控制网页。另一方面，JavaScript 也是最常用于 DOM 操作的语言。 节点DOM 的最小组成单位叫做节点（node）。文档的树形结构（DOM 树），就是由各种不同类型的节点组成。每个节点可以看作是文档树的一片叶子。 节点的类型有七种 浏览器提供一个原生的节点对象Node，上面这七种节点都继承了Node，因此具有一些共同的属性和方法。 节点树一个文档的所有节点，按照所在的层级，可以抽象成一种树状结构。这种树状结构就是 DOM 树。它有一个顶层节点，下一层都是顶层节点的子节点，然后子节点又有自己的子节点，就这样层层衍生出一个金字塔结构，倒过来就像一棵树。 浏览器原生提供document节点，代表整个文档。 文档的第一层只有一个节点，就是 HTML 网页的第一个标签&lt; html&gt;，它构成了树结构的根节点（root node），其他 HTML 标签节点都是它的下级节点。 除了根节点，其他节点都有三种层级关系。 DOM 提供操作接口，用来获取这三种关系的节点。比如，子节点接口包括firstChild（第一个子节点）和lastChild（最后一个子节点）等属性，同级节点接口包括nextSibling（紧邻在后的那个同级节点）和previousSibling（紧邻在前的那个同级节点）属性。 Node 接口的属性所有 DOM 节点都继承了 Node 接口，拥有一些共同的属性和方法。这是 DOM 操作的基础。 Node.nodeTypenodeType属性返回一个整数值，表示节点的类型。 Node 对象定义了几个常量，对应这些类型值。 确定节点类型时，使用nodeType属性是常用方法。 Node.nodeNamenodeName属性返回节点的名称。 不同节点的nodeName属性值如下。 Node.nodeValuenodeValue属性返回一个字符串，表示当前节点本身的文本值，该属性可读写。 只有文本节点（text）和注释节点（comment）有文本值，因此这两类节点的nodeValue可以返回结果，其他类型的节点一律返回null。同样的，也只有这两类节点可以设置nodeValue属性的值，其他类型的节点设置无效。 Node.textContenttextContent属性返回当前节点和它的所有后代节点的文本内容。 textContent属性自动忽略当前节点内部的 HTML 标签，返回所有文本内容。 该属性是可读写的，设置该属性的值，会用一个新的文本节点，替换所有原来的子节点。它还有一个好处，就是自动对 HTML 标签转义。这很适合用于用户提供的内容。 对于文本节点（text）和注释节点（comment），textContent属性的值与nodeValue属性相同。对于其他类型的节点，该属性会将每个子节点的内容连接在一起返回，但是不包括注释节点。如果一个节点没有子节点，则返回空字符串。 文档节点（document）和文档类型节点（doctype）的textContent属性为null。如果要读取整个文档的内容，可以使用document.documentElement.textContent。 Node.baseURIbaseURI属性返回一个字符串，表示当前网页的绝对路径。浏览器根据这个属性，计算网页上的相对路径的 URL。该属性为只读。 如果无法读到网页的 URL，baseURI属性返回null。 该属性的值一般由当前网址的 URL（即window.location属性）决定，但是可以使用 HTML 的&lt; base&gt;标签，改变该属性的值。 设置了以后，baseURI属性就返回标签设置的值。 Node.ownerDocumentNode.ownerDocument属性返回当前节点所在的顶层文档对象，即document对象。 document对象本身的ownerDocument属性，返回null。 Node.nextSiblingNode.nextSibling属性返回紧跟在当前节点后面的第一个同级节点。如果当前节点后面没有同级节点，则返回null。 注意，该属性还包括文本节点和注释节点（）。因此如果当前节点后面有空格，该属性会返回一个文本节点，内容为空格。 nextSibling属性可以用来遍历所有子节点。 Node.previousSiblingpreviousSibling属性返回当前节点前面的、距离最近的一个同级节点。如果当前节点前面没有同级节点，则返回null。 注意，该属性还包括文本节点和注释节点。因此如果当前节点前面有空格，该属性会返回一个文本节点，内容为空格。 Node.parentNodeparentNode属性返回当前节点的父节点。对于一个节点来说，它的父节点只可能是三种类型：元素节点（element）、文档节点（document）和文档片段节点（documentfragment）。 文档节点（document）和文档片段节点（documentfragment）的父节点都是null。另外，对于那些生成后还没插入 DOM 树的节点，父节点也是null。 Node.parentElementparentElement属性返回当前节点的父元素节点。如果当前节点没有父节点，或者父节点类型不是元素节点，则返回null。 由于父节点只可能是三种类型：元素节点、文档节点（document）和文档片段节点（documentfragment）。parentElement属性相当于把后两种父节点都排除了。 Node.firstChild，Node.lastChildfirstChild属性返回当前节点的第一个子节点，如果当前节点没有子节点，则返回null。 注意，firstChild返回的除了元素节点，还可能是文本节点或注释节点。 lastChild属性返回当前节点的最后一个子节点，如果当前节点没有子节点，则返回null。用法与firstChild属性相同。 Node.childNodeschildNodes属性返回一个类似数组的对象（NodeList集合），成员包括当前节点的所有子节点。 使用该属性，可以遍历某个节点的所有子节点。 文档节点（document）就有两个子节点：文档类型节点（docType）和 HTML 根元素节点。 Node.isConnectedisConnected属性返回一个布尔值，表示当前节点是否在文档之中。 Node 接口的方法Node.appendChild()appendChild方法接受一个节点对象作为参数，将其作为最后一个子节点，插入当前节点。该方法的返回值就是插入文档的子节点。 如果参数节点是 DOM 已经存在的节点，appendChild方法会将其从原来的位置，移动到新位置。 如果appendChild方法的参数是DocumentFragment节点，那么插入的是DocumentFragment的所有子节点，而不是DocumentFragment节点本身。返回值是一个空的DocumentFragment节点。 Node.hasChildNodes()hasChildNodes方法返回一个布尔值，表示当前节点是否有子节点。 注意，子节点包括所有节点，哪怕节点只包含一个空格，hasChildNodes方法也会返回true。 判断一个节点有没有子节点，有许多种方法，下面是其中的三种。 Node.cloneNode()cloneNode方法用于克隆一个节点。它接受一个布尔值作为参数，表示是否同时克隆子节点。它的返回值是一个克隆出来的新节点。 该方法有一些使用注意点。 克隆一个节点，会拷贝该节点的所有属性，但是会丧失addEventListener方法和on-属性（即node.onclick = fn），添加在这个节点上的事件回调函数。 该方法返回的节点不在文档之中，即没有任何父节点，必须使用诸如Node.appendChild这样的方法添加到文档之中。 克隆一个节点之后，DOM 有可能出现两个有相同id属性（即id=”xxx”）的网页元素，这时应该修改其中一个元素的id属性。如果原节点有name属性，可能也需要修改。 Node.insertBefore()insertBefore方法用于将某个节点插入父节点内部的指定位置。 insertBefore方法接受两个参数，第一个参数是所要插入的节点newNode，第二个参数是父节点parentNode内部的一个子节点referenceNode。newNode将插在referenceNode这个子节点的前面。返回值是插入的新节点newNode。 如果insertBefore方法的第二个参数为null，则新节点将插在当前节点内部的最后位置，即变成最后一个子节点。 注意，如果所要插入的节点是当前 DOM 现有的节点，则该节点将从原有的位置移除，插入新的位置。 由于不存在insertAfter方法，如果新节点要插在父节点的某个子节点后面，可以用insertBefore方法结合nextSibling属性模拟。 如果要插入的节点是DocumentFragment类型，那么插入的将是DocumentFragment的所有子节点，而不是DocumentFragment节点本身。返回值将是一个空的DocumentFragment节点。 Node.removeChild()removeChild方法接受一个子节点作为参数，用于从当前节点移除该子节点。返回值是移除的子节点。 被移除的节点依然存在于内存之中，但不再是 DOM 的一部分。所以，一个节点移除以后，依然可以使用它，比如插入到另一个节点下面。 如果参数节点不是当前节点的子节点，removeChild方法将报错。 Node.replaceChild()replaceChild方法用于将一个新的节点，替换当前节点的某一个子节点。 replaceChild方法接受两个参数，第一个参数newChild是用来替换的新节点，第二个参数oldChild是将要替换走的子节点。返回值是替换走的那个节点oldChild。 Node.contains()contains方法返回一个布尔值，表示参数节点是否满足以下三个条件之一。 Node.compareDocumentPosition()compareDocumentPosition方法的用法，与contains方法完全一致，返回一个七个比特位的二进制值，表示参数节点与当前节点的关系。 由于compareDocumentPosition返回值的含义，定义在每一个比特位上，所以如果要检查某一种特定的含义，就需要使用比特位运算符。 进行与运算（&amp;）。 Node.isEqualNode()，Node.isSameNode()isEqualNode方法返回一个布尔值，用于检查两个节点是否相等。所谓相等的节点，指的是两个节点的类型相同、属性相同、子节点相同。 isSameNode方法返回一个布尔值，表示两个节点是否为同一个节点。 Node.normalize()normailize方法用于清理当前节点内部的所有文本节点（text）。它会去除空的文本节点，并且将毗邻的文本节点合并成一个，也就是说不存在空的文本节点，以及毗邻的文本节点。 该方法是Text.splitText的逆方法。 Node.getRootNode()getRootNode方法返回当前节点所在文档的根节点。 NodeList 接口节点都是单个对象，有时需要一种数据结构，能够容纳多个节点。DOM 提供两种节点集合，用于容纳多个节点：NodeList和HTMLCollection。 这两种集合都属于接口规范。许多 DOM 属性和方法，返回的结果是NodeList实例或HTMLCollection实例。 概述NodeList实例是一个类似数组的对象，它的成员是节点对象。通过以下方法可以得到NodeList实例。 NodeList实例很像数组，可以使用length属性和forEach方法。但是，它不是数组，不能使用pop或push之类数组特有的方法。 注意，NodeList 实例可能是动态集合，也可能是静态集合。所谓动态集合就是一个活的集合，DOM 删除或新增一个相关节点，都会立刻反映在 NodeList 实例。目前，只有Node.childNodes返回的是一个动态集合，其他的 NodeList 都是静态集合。 NodeList.prototype.lengthlength属性返回 NodeList 实例包含的节点数量。 document.getElementsByTagName返回一个 NodeList 集合。对于那些不存在的 HTML 标签，length属性返回0。 NodeList.prototype.forEach()forEach方法用于遍历 NodeList 的所有成员。它接受一个回调函数作为参数，每一轮遍历就执行一次这个回调函数，用法与数组实例的forEach方法完全一致。 forEach方法的第二个参数，用于绑定回调函数内部的this，该参数可省略。 NodeList.prototype.item()item方法接受一个整数值作为参数，表示成员的位置，返回该位置上的成员。 如果参数值大于实际长度，或者索引不合法（比如负数），item方法返回null。如果省略参数，item方法会报错。 所有类似数组的对象，都可以使用方括号运算符取出成员。一般情况下，都是使用方括号运算符，而不使用item方法。 NodeList.prototype.keys()，NodeList.prototype.values()，NodeList.prototype.entries()这三个方法都返回一个 ES6 的遍历器对象，可以通过for…of循环遍历获取每一个成员的信息。区别在于，keys()返回键名的遍历器，values()返回键值的遍历器，entries()返回的遍历器同时包含键名和键值的信息。 HTMLCollection 接口概述HTMLCollection是一个节点对象的集合，只能包含元素节点（element），不能包含其他类型的节点。它的返回值是一个类似数组的对象，但是与NodeList接口不同，HTMLCollection没有forEach方法，只能使用for循环遍历。 HTMLCollection实例都是动态集合，节点的变化会实时反映在集合中。 如果元素节点有id或name属性，那么HTMLCollection实例上面，可以使用id属性或name属性引用该节点元素。如果没有对应的节点，则返回null。 HTMLCollection.prototype.lengthlength属性返回HTMLCollection实例包含的成员数量。 HTMLCollection.prototype.item()item方法接受一个整数值作为参数，表示成员的位置，返回该位置上的成员。 如果参数值超出成员数量或者不合法（比如小于0），那么item方法返回null。 HTMLCollection.prototype.namedItem()namedItem方法的参数是一个字符串，表示id属性或name属性的值，返回对应的元素节点。如果没有对应的节点，则返回null。 ParentNode 接口节点对象除了继承 Node 接口以外，还会继承其他接口。ParentNode接口表示当前节点是一个父节点，提供一些处理子节点的方法。ChildNode接口表示当前节点是一个子节点，提供一些相关方法。 如果当前节点是父节点，就会继承ParentNode接口。由于只有元素节点（element）、文档节点（document）和文档片段节点（documentFragment）拥有子节点，因此只有这三类节点会继承ParentNode接口。 ParentNode.childrenchildren属性返回一个HTMLCollection实例，成员是当前节点的所有元素子节点。该属性只读。 children属性只包括元素子节点，不包括其他类型的子节点（比如文本子节点）。如果没有元素类型的子节点，返回值HTMLCollection实例的length属性为0。 HTMLCollection是动态集合，会实时反映 DOM 的任何变化。 ParentNode.firstElementChildfirstElementChild属性返回当前节点的第一个元素子节点。如果没有任何元素子节点，则返回null。 ParentNode.lastElementChildlastElementChild属性返回当前节点的最后一个元素子节点，如果不存在任何元素子节点，则返回null。 ParentNode.childElementCountchildElementCount属性返回一个整数，表示当前节点的所有元素子节点的数目。如果不包含任何元素子节点，则返回0。 ParentNode.append()，ParentNode.prepend()append方法为当前节点追加一个或多个子节点，位置是最后一个元素子节点的后面。 该方法不仅可以添加元素子节点，还可以添加文本子节点。 注意，该方法没有返回值。 prepend方法为当前节点追加一个或多个子节点，位置是第一个元素子节点的前面。它的用法与append方法完全一致，也是没有返回值。 ChildNode 接口如果一个节点有父节点，那么该节点就继承了ChildNode接口。 ChildNode.remove()remove方法用于从父节点移除当前节点。 ChildNode.before()，ChildNode.after()before方法用于在当前节点的前面，插入一个或多个同级节点。两者拥有相同的父节点。 注意，该方法不仅可以插入元素节点，还可以插入文本节点。 after方法用于在当前节点的后面，插入一个或多个同级节点，两者拥有相同的父节点。用法与before方法完全相同。 ChildNode.replaceWith()replaceWith方法使用参数节点，替换当前节点。参数可以是元素节点，也可以是文本节点。 document 对象概述document对象是文档的根节点，每张网页都有自己的document对象。window.document属性就指向这个对象。只要浏览器开始载入 HTML 文档，该对象就存在了，可以直接使用。 document对象有不同的办法可以获取。 document对象继承了EventTarget接口、Node接口、ParentNode接口。这意味着，这些接口的方法都可以在document对象上调用。除此之外，document对象还有很多自己的属性和方法。 属性快捷方式属性以下属性是指向文档内部的某个节点的快捷方式。 document.defaultViewdocument.defaultView属性返回document对象所属的window对象。如果当前文档不属于window对象，该属性返回null。 document.doctype对于 HTML 文档来说，document对象一般有两个子节点。第一个子节点是document.doctype，指向&lt; DOCTYPE&gt;节点，即文档类型（Document Type Declaration，简写DTD）节点。HTML 的文档类型节点，一般写成&lt; !DOCTYPE html&gt;。如果网页没有声明 DTD，该属性返回null。 document.firstChild通常就返回这个节点。 document.documentElementdocument.documentElement属性返回当前文档的根节点（root）。它通常是document节点的第二个子节点，紧跟在document.doctype节点后面。HTML网页的该属性，一般是节点。 document.body，document.headdocument.body属性指向&lt; body&gt;节点，document.head属性指向&lt; head&gt;节点。 这两个属性总是存在的，如果网页源码里面省略了&lt; head&gt;或&lt; body&gt;，浏览器会自动创建。另外，这两个属性是可写的，如果改写它们的值，相当于移除所有子节点。 document.scrollingElementdocument.scrollingElement属性返回文档的滚动元素。也就是说，当文档整体滚动时，到底是哪个元素在滚动。 标准模式下，这个属性返回的文档的根元素document.documentElement（即）。兼容（quirk）模式下，返回的是元素，如果该元素不存在，返回null。 document.activeElementdocument.activeElement属性返回获得当前焦点（focus）的 DOM 元素。通常，这个属性返回的是&lt; input&gt;、&lt; textarea&gt;、&lt; select&gt;等表单元素，如果当前没有焦点元素，返回&lt; body&gt;元素或null。 document.fullscreenElementdocument.fullscreenElement属性返回当前以全屏状态展示的 DOM 元素。如果不是全屏状态，该属性返回null。 节点集合属性以下属性返回一个HTMLCollection实例，表示文档内部特定元素的集合。这些集合都是动态的，原节点有任何变化，立刻会反映在集合中。 document.linksdocument.links属性返回当前文档所有设定了href属性的&lt; a&gt;及&lt; area&gt;节点。 document.formsdocument.forms属性返回所有&lt; form&gt;表单节点。 document.imagesdocument.images属性返回页面所有&lt; img&gt;图片节点。 document.embeds，document.pluginsdocument.embeds属性和document.plugins属性，都返回所有&lt; embed&gt;节点。 document.scriptsdocument.scripts属性返回所有&lt; script&gt;节点。 document.styleSheetsdocument.styleSheets属性返回文档内嵌或引入的样式表集合。 小结除了document.styleSheets，以上的集合属性返回的都是HTMLCollection实例。 HTMLCollection实例是类似数组的对象，所以这些属性都有length属性，都可以使用方括号运算符引用成员。如果成员有id或name属性，还可以用这两个属性的值，在HTMLCollection实例上引用到这个成员。 文档静态信息属性以下属性返回文档信息。 document.documentURI，document.URLdocument.documentURI属性和document.URL属性都返回一个字符串，表示当前文档的网址。不同之处是它们继承自不同的接口，documentURI继承自Document接口，可用于所有文档；URL继承自HTMLDocument接口，只能用于 HTML 文档。 如果文档的锚点（#anchor）变化，这两个属性都会跟着变化。 document.domaindocument.domain属性返回当前文档的域名，不包含协议和接口。 比如，网页的网址是http://www.example.com:80/hello.html， 那么domain属性就等于www.example.com。如果无法获取域名，该属性返回null。 document.domain基本上是一个只读属性，只有一种情况除外。次级域名的网页，可以把document.domain设为对应的上级域名。比如，当前域名是a.sub.example.com，则document.domain属性可以设置为sub.example.com，也可以设为example.com。修改后，document.domain相同的两个网页，可以读取对方的资源，比如设置的 Cookie。 另外，设置document.domain会导致端口被改成null。因此，如果通过设置document.domain来进行通信，双方网页都必须设置这个值，才能保证端口相同 document.locationLocation对象是浏览器提供的原生对象，提供 URL 相关的信息和操作方法。通过window.location和document.location属性，可以拿到这个对象。 document.lastModifieddocument.lastModified属性返回一个字符串，表示当前文档最后修改的时间。不同浏览器的返回值，日期格式是不一样的。 注意，document.lastModified属性的值是字符串，所以不能直接用来比较。Date.parse方法将其转为Date实例，才能比较两个网页。 document.titledocument.title属性返回当前文档的标题。默认情况下，返回节点的值。但是该属性是可写的，一旦被修改，就返回修改后的值。 document.characterSetdocument.characterSet属性返回当前文档的编码，比如UTF-8、ISO-8859-1等等。 document.referrerdocument.referrer属性返回一个字符串，表示当前文档的访问者来自哪里。 document.dirdocument.dir返回一个字符串，表示文字方向。它只有两个可能的值：rtl表示文字从右到左，阿拉伯文是这种方式；ltr表示文字从左到右，包括英语和汉语在内的大多数文字采用这种方式。 document.compatModecompatMode属性返回浏览器处理文档的模式，可能的值为BackCompat（向后兼容模式）和CSS1Compat（严格模式）。 一般来说，如果网页代码的第一行设置了明确的DOCTYPE（比如&lt;!doctype html&gt;），document.compatMode的值都为CSS1Compat。 文档状态属性document.hiddendocument.hidden属性返回一个布尔值，表示当前页面是否可见。如果窗口最小化、浏览器切换了 Tab，都会导致导致页面不可见，使得document.hidden返回true。 document.visibilityStatedocument.visibilityState返回文档的可见状态。 这个属性可以用在页面加载时，防止加载某些资源；或者页面不可见时，停掉一些页面功能。 document.readyStatedocument.readyState属性返回当前文档的状态，共有三种可能的值。 这个属性变化的过程如下。 每次状态变化都会触发一个readystatechange事件。 document.cookiedocument.cookie属性用来操作浏览器 Cookie。 document.designModedocument.designMode属性控制当前文档是否可编辑，通常用在所见即所得编辑器。该属性只有两个值on和off，默认值为off。 document.implementationdocument.implementation属性返回一个DOMImplementation对象。该对象有三个方法，主要用于创建独立于当前文档的新的 Document 对象。 方法document.open()，document.close()document.open方法清除当前文档所有内容，使得文档处于可写状态，供document.write方法写入内容。 document.close方法用来关闭document.open()打开的文档。 document.write()，document.writeln()document.write方法用于向当前文档写入内容。 在网页的首次渲染阶段，只要页面没有关闭写入（即没有执行document.close()），document.write写入的内容就会追加在已有内容的后面。 注意，document.write会当作 HTML 代码解析，不会转义。 如果页面已经解析完成（DOMContentLoaded事件发生之后），再调用write方法，它会先调用open方法，擦除当前文档所有内容，然后再写入。 如果在页面渲染过程中调用write方法，并不会自动调用open方法。（可以理解成，open方法已调用，但close方法还未调用。） document.write是JavaScript语言标准化之前就存在的方法，现在完全有更符合标准的方法向文档写入内容（比如对innerHTML属性赋值）。所以，除了某些特殊情况，应该尽量避免使用document.write这个方法。 document.writeln方法与write方法完全一致，除了会在输出内容的尾部添加换行符。 注意，writeln方法添加的是 ASCII 码的换行符，渲染成 HTML 网页时不起作用，即在网页上显示不出换行。网页上的换行，必须显式写入。 document.querySelector()，document.querySelectorAll()document.querySelector方法接受一个 CSS 选择器作为参数，返回匹配该选择器的元素节点。如果有多个节点满足匹配条件，则返回第一个匹配的节点。如果没有发现匹配的节点，则返回null。 document.querySelectorAll方法与querySelector用法类似，区别是返回一个NodeList对象，包含所有匹配给定选择器的节点。 这两个方法的参数，可以是逗号分隔的多个 CSS 选择器，返回匹配其中一个选择器的元素节点，这与 CSS 选择器的规则是一致的。 这两个方法都支持复杂的 CSS 选择器。 但是，它们不支持 CSS 伪元素的选择器（比如:first-line和:first-letter）和伪类的选择器（比如:link和:visited），即无法选中伪元素和伪类。 如果querySelectorAll方法的参数是字符串*，则会返回文档中的所有元素节点。另外，querySelectorAll的返回结果不是动态集合，不会实时反映元素节点的变化。 最后，这两个方法除了定义在document对象上，还定义在元素节点上，即在元素节点上也可以调用。 document.getElementsByTagName()document.getElementsByTagName方法搜索 HTML 标签名，返回符合条件的元素。它的返回值是一个类似数组对象（HTMLCollection实例），可以实时反映 HTML 文档的变化。如果没有任何匹配的元素，就返回一个空集。 HTML 标签名是大小写不敏感的，因此getElementsByTagName方法也是大小写不敏感的。另外，返回结果中，各个成员的顺序就是它们在文档中出现的顺序。 注意，元素节点本身也定义了getElementsByTagName方法，返回该元素的后代元素中符合条件的元素。也就是说，这个方法不仅可以在document对象上调用，也可以在任何元素节点上调用。 document.getElementsByClassName()document.getElementsByClassName方法返回一个类似数组的对象（HTMLCollection实例），包括了所有class名字符合指定条件的元素，元素的变化实时反映在返回结果中。 由于class是保留字，所以 JavaScript 一律使用className表示 CSS 的class。 参数可以是多个class，它们之间使用空格分隔。 注意，正常模式下，CSS 的class是大小写敏感的。（quirks mode下，大小写不敏感。） 与getElementsByTagName方法一样，getElementsByClassName方法不仅可以在document对象上调用，也可以在任何元素节点上调用。 document.getElementsByName()document.getElementsByName方法用于选择拥有name属性的 HTML 元素,返回一个类似数组的的对象（NodeList实例），因为name属性相同的元素可能不止一个。 document.getElementById()document.getElementById方法返回匹配指定id属性的元素节点。如果没有发现匹配的节点，则返回null。 注意，该方法的参数是大小写敏感的。比如，如果某个节点的id属性是main，那么document.getElementById(‘Main’)将返回null。 document.getElementById方法与document.querySelector方法都能获取元素节点，不同之处是document.querySelector方法的参数使用 CSS 选择器语法，document.getElementById方法的参数是元素的id属性。document.getElementById()比document.querySelector()效率高得多。 另外，这个方法只能在document对象上使用，不能在其他元素节点上使用。 document.elementFromPoint()，document.elementsFromPoint()document.elementFromPoint方法返回位于页面指定位置最上层的元素节点。 elementFromPoint方法的两个参数，依次是相对于当前视口左上角的横坐标和纵坐标，单位是像素。如果位于该位置的 HTML 元素不可返回（比如文本框的滚动条），则返回它的父元素（比如文本框）。如果坐标值无意义（比如负值或超过视口大小），则返回null。 document.elementsFromPoint()返回一个数组，成员是位于指定坐标（相对于视口）的所有元素。 document.caretPositionFromPoint()document.caretPositionFromPoint()返回一个 CaretPosition 对象，包含了指定坐标点在节点对象内部的位置信息。CaretPosition 对象就是光标插入点的概念，用于确定光标点在文本对象内部的具体位置。 CaretPosition 对象。该对象有两个属性。 document.createElement()document.createElement方法用来生成元素节点，并返回该节点。 createElement方法的参数为元素的标签名，即元素节点的tagName属性，对于 HTML 网页大小写不敏感，即参数为div或DIV返回的是同一种节点。如果参数里面包含尖括号（即&lt;和&gt;）会报错。 注意，document.createElement的参数可以是自定义的标签名。 document.createTextNode()document.createTextNode方法用来生成文本节点（Text实例），并返回该节点。它的参数是文本节点的内容。 这个方法可以确保返回的节点，被浏览器当作文本渲染，而不是当作 HTML 代码渲染。因此，可以用来展示用户的输入，避免 XSS 攻击。 document.createAttribute()document.createAttribute方法生成一个新的属性节点（Attr实例），并返回它。 document.createAttribute方法的参数name，是属性的名称。 document.createComment()document.createComment方法生成一个新的注释节点，并返回该节点。 document.createComment方法的参数是一个字符串，会成为注释节点的内容。 document.createDocumentFragment()document.createDocumentFragment方法生成一个空的文档片段对象（DocumentFragment实例）。 DocumentFragment是一个存在于内存的 DOM 片段，不属于当前文档，常常用来生成一段较复杂的 DOM 结构，然后再插入当前文档。这样做的好处在于，因为DocumentFragment不属于当前文档，对它的任何改动，都不会引发网页的重新渲染，比直接修改当前文档的 DOM 有更好的性能表现。 document.createEvent()document.createEvent方法生成一个事件对象（Event实例），该对象可以被element.dispatchEvent方法使用，触发指定事件。 document.createEvent方法的参数是事件类型，比如UIEvents、MouseEvents、MutationEvents、HTMLEvents。 document.addEventListener()，document.removeEventListener()，document.dispatchEvent()这三个方法用于处理document节点的事件。它们都继承自EventTarget接口。 document.hasFocus()document.hasFocus方法返回一个布尔值，表示当前文档之中是否有元素被激活或获得焦点。 注意，有焦点的文档必定被激活（active），反之不成立，激活的文档未必有焦点。比如，用户点击按钮，从当前窗口跳出一个新窗口，该新窗口就是激活的，但是不拥有焦点。 document.adoptNode()，document.importNode()document.adoptNode方法将某个节点及其子节点，从原来所在的文档或DocumentFragment里面移除，归属当前document对象，返回插入后的新节点。插入的节点对象的ownerDocument属性，会变成当前的document对象，而parentNode属性是null。 注意，document.adoptNode方法只是改变了节点的归属，并没有将这个节点插入新的文档树。所以，还要再用appendChild方法或insertBefore方法，将新节点插入当前文档树。 document.importNode方法则是从原来所在的文档或DocumentFragment里面，拷贝某个节点及其子节点，让它们归属当前document对象。拷贝的节点对象的ownerDocument属性，会变成当前的document对象，而parentNode属性是null。 document.importNode方法的第一个参数是外部节点，第二个参数是一个布尔值，表示对外部节点是深拷贝还是浅拷贝，默认是浅拷贝（false）。虽然第二个参数是可选的，但是建议总是保留这个参数，并设为true。 注意，document.importNode方法只是拷贝外部节点，这时该节点的父节点是null。下一步还必须将这个节点插入当前文档树。 document.createNodeIterator()document.createNodeIterator方法返回一个子节点遍历器。 document.createNodeIterator方法第一个参数为所要遍历的根节点，第二个参数为所要遍历的节点类型，这里指定为元素节点（NodeFilter.SHOW_ELEMENT）。几种主要的节点类型写法如下。 document.createNodeIterator方法返回一个“遍历器”对象（NodeFilter实例）。该实例的nextNode()方法和previousNode()方法，可以用来遍历所有子节点。 currentNode和previousNode都指向同一个的节点。 注意，遍历器返回的第一个节点，总是根节点。 document.createTreeWalker()document.createTreeWalker方法返回一个 DOM 的子树遍历器。它与document.createNodeIterator方法基本是类似的，区别在于它返回的是TreeWalker实例，后者返回的是NodeIterator实例。另外，它的第一个节点不是根节点。 document.createTreeWalker方法的第一个参数是所要遍历的根节点，第二个参数指定所要遍历的节点类型（与document.createNodeIterator方法的第二个参数相同）。 document.getSelection()这个方法指向window.getSelection()。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"健身","slug":"健身","date":"2018-08-21T01:49:12.000Z","updated":"2018-08-21T01:50:35.000Z","comments":true,"path":"2018/08/21/健身/","link":"","permalink":"https://github.com/zdkswd/2018/08/21/健身/","excerpt":"","text":"健身关注引领性指标 3900大卡差值消耗一斤脂肪。 计算每日消耗总热量。 计算摄入量 如果差值过大，会导致肌肉减少和基础代谢率降低，很容易反弹，难以持续。 随着体重降低，也要不断的调整。 把摄入热量除以3得到每餐要吃的热量。 三餐热量不同也可以，只要一天内摄入不超过即可。 每餐一个拳头的蛋白质，一个拳头的碳水化合物，蔬菜随便吃。 蛋白质的主要来源 精瘦的鸡肉，猪肉，牛肉，海鲜，鱼，鸡蛋，牛奶，豆类。 碳水化合物尽量选择粗粮，比如说玉米，红薯，土豆，糙米，米粉，面条，面包。 追踪自己的减脂进展。 超实用技巧餐前吃半根香蕉或者一粒糖。 第二个，每餐前吃六到七粒坚果。增加饱腹感。英国有研究表明每天吃20粒坚果能降低癌症和心脏病的风险。 第三个，用南瓜代替主食。 第四点，少油盐，外食要过水，油的热量远远大于菜的热量。 图中的食物可以随便吃。无限量吃。 第六个，嚼无糖口香糖，咀嚼感。 瘦了后保持体形保持期可以放宽，不需要赤字了。 总结 早睡11点 吃早饭 冥想拉伸 少盐多蛋白质 跳绳","categories":[{"name":"知乎Live","slug":"知乎Live","permalink":"https://github.com/zdkswd/categories/知乎Live/"}],"tags":[{"name":"健身","slug":"健身","permalink":"https://github.com/zdkswd/tags/健身/"}]},{"title":"JavaScript标准参考教程 语法专题","slug":"JavaScript标准参考教程 语法专题","date":"2018-08-20T11:14:56.000Z","updated":"2018-08-20T11:14:47.000Z","comments":true,"path":"2018/08/20/JavaScript标准参考教程 语法专题/","link":"","permalink":"https://github.com/zdkswd/2018/08/20/JavaScript标准参考教程 语法专题/","excerpt":"","text":"异步操作概述单线程模型单线程模型指的是，JavaScript 只在一个线程上运行。也就是说，JavaScript 同时只能执行一个任务，其他任务都必须在后面排队等待。 注意，JavaScript 只在一个线程上运行，不代表 JavaScript 引擎只有一个线程。事实上，JavaScript 引擎有多个线程，单个脚本只能在一个线程上运行（称为主线程），其他线程都是在后台配合。 JavaScript 之所以采用单线程，而不是多线程，跟历史有关系。为了避免复杂性，JavaScript 一开始就是单线程，这已经成了这门语言的核心特征，将来也不会改变。 这种模式的好处是实现起来比较简单，执行环境相对单纯；坏处是只要有一个任务耗时很长，后面的任务都必须排队等着，会拖延整个程序的执行。常见的浏览器无响应（假死），往往就是因为某一段 JavaScript 代码长时间运行（比如死循环），导致整个页面卡在这个地方，其他任务无法执行。JavaScript 语言本身并不慢，慢的是读写外部数据，比如等待 Ajax 请求返回结果。这个时候，如果对方服务器迟迟没有响应，或者网络不通畅，就会导致脚本的长时间停滞。 如果排队是因为计算量大，CPU 忙不过来，倒也算了，但是很多时候 CPU 是闲着的，因为 IO 操作（输入输出）很慢（比如 Ajax 操作从网络读取数据），不得不等着结果出来，再往下执行。JavaScript 语言的设计者意识到，这时 CPU 完全可以不管 IO 操作，挂起处于等待中的任务，先运行排在后面的任务。等到 IO 操作返回了结果，再回过头，把挂起的任务继续执行下去。这种机制就是 JavaScript 内部采用的“事件循环”机制（Event Loop）。 单线程模型虽然对 JavaScript 构成了很大的限制，但也因此使它具备了其他语言不具备的优势。如果用得好，JavaScript 程序是不会出现堵塞的，这就是为什么 Node 可以用很少的资源，应付大流量访问的原因。 为了利用多核 CPU 的计算能力，HTML5 提出 Web Worker 标准，允许 JavaScript 脚本创建多个线程，但是子线程完全受主线程控制，且不得操作 DOM。所以，这个新标准并没有改变 JavaScript 单线程的本质。 同步任务和异步任务程序里面所有的任务，可以分成两类：同步任务（synchronous）和异步任务（asynchronous）。 同步任务是那些没有被引擎挂起、在主线程上排队执行的任务。只有前一个任务执行完毕，才能执行后一个任务。 异步任务是那些被引擎放在一边，不进入主线程、而进入任务队列的任务。只有引擎认为某个异步任务可以执行了（比如 Ajax 操作从服务器得到了结果），该任务（采用回调函数的形式）才会进入主线程执行。排在异步任务后面的代码，不用等待异步任务结束会马上运行，也就是说，异步任务不具有“堵塞”效应。 举例来说，Ajax 操作可以当作同步任务处理，也可以当作异步任务处理，由开发者决定。如果是同步任务，主线程就等着 Ajax 操作返回结果，再往下执行；如果是异步任务，主线程在发出 Ajax 请求以后，就直接往下执行，等到 Ajax 操作有了结果，主线程再执行对应的回调函数。 任务队列和事件循环JavaScript 运行时，除了一个正在运行的主线程，引擎还提供一个任务队列（task queue），里面是各种需要当前程序处理的异步任务。（实际上，根据异步任务的类型，存在多个任务队列。为了方便理解，这里假设只存在一个队列。） 首先，主线程会去执行所有的同步任务。等到同步任务全部执行完，就会去看任务队列里面的异步任务。如果满足条件，那么异步任务就重新进入主线程开始执行，这时它就变成同步任务了。等到执行完，下一个异步任务再进入主线程开始执行。一旦任务队列清空，程序就结束执行。 异步任务的写法通常是回调函数。一旦异步任务重新进入主线程，就会执行对应的回调函数。如果一个异步任务没有回调函数，就不会进入任务队列，也就是说，不会重新进入主线程，因为没有用回调函数指定下一步的操作。 JavaScript 引擎怎么知道异步任务有没有结果，能不能进入主线程呢？答案就是引擎在不停地检查，一遍又一遍，只要同步任务执行完了，引擎就会去检查那些挂起来的异步任务，是不是可以进入主线程了。这种循环检查的机制，就叫做事件循环（Event Loop）。维基百科的定义是：“事件循环是一个程序结构，用于等待和发送消息和事件。 异步操作的模式下面总结一下异步操作的几种模式。 回调函数回调函数是异步操作最基本的方法。 回调函数的优点是简单、容易理解和实现，缺点是不利于代码的阅读和维护，各个部分之间高度耦合（coupling），使得程序结构混乱、流程难以追踪（尤其是多个回调函数嵌套的情况），而且每个任务只能指定一个回调函数。 事件监听另一种思路是采用事件驱动模式。异步任务的执行不取决于代码的顺序，而取决于某个事件是否发生。 首先，为f1绑定一个事件（这里采用的 jQuery 的写法）。 这种方法的优点是比较容易理解，可以绑定多个事件，每个事件可以指定多个回调函数，而且可以“去耦合”（decoupling），有利于实现模块化。缺点是整个程序都要变成事件驱动型，运行流程会变得很不清晰。阅读代码的时候，很难看出主流程。 发布/订阅事件完全可以理解成“信号”，如果存在一个“信号中心”，某个任务执行完成，就向信号中心“发布”（publish）一个信号，其他任务可以向信号中心“订阅”（subscribe）这个信号，从而知道什么时候自己可以开始执行。这就叫做“发布/订阅模式”（publish-subscribe pattern），又称“观察者模式”（observer pattern）。 这个模式有多种实现，下面采用的是 Ben Alman 的 Tiny Pub/Sub，这是 jQuery 的一个插件。 f2完成执行后，可以取消订阅（unsubscribe）。 这种方法的性质与“事件监听”类似，但是明显优于后者。因为可以通过查看“消息中心”，了解存在多少信号、每个信号有多少订阅者，从而监控程序的运行。 异步操作的流程控制如果有多个异步操作，就存在一个流程控制的问题：如何确定异步操作执行的顺序，以及如何保证遵守这种顺序。 串行执行我们可以编写一个流程控制函数，让它来控制异步任务，一个任务完成以后，再执行另一个。这就叫串行执行。 并行执行流程控制函数也可以是并行执行，即所有异步任务同时执行，等到全部完成以后，才执行final函数。 相比而言，上面的写法只要一秒，就能完成整个脚本。这就是说，并行执行的效率较高，比起串行执行一次只能执行一个任务，较为节约时间。但是问题在于如果并行的任务较多，很容易耗尽系统资源，拖慢运行速度。因此有了第三种流程控制方式。 并行与串行的结合所谓并行与串行的结合，就是设置一个门槛，每次最多只能并行执行n个异步任务，这样就避免了过分占用系统资源。 上面代码中，最多只能同时运行两个异步任务。变量running记录当前正在运行的任务数，只要低于门槛值，就再启动一个新的任务，如果等于0，就表示所有任务都执行完了，这时就执行final函数。 这段代码需要三秒完成整个脚本，处在串行执行和并行执行之间。通过调节limit变量，达到效率和资源的最佳平衡。 定时器JavaScript 提供定时执行代码的功能，叫做定时器（timer），主要由setTimeout()和setInterval()这两个函数来完成。它们向任务队列添加定时任务。 setTimeout()setTimeout函数用来指定某个函数或某段代码，在多少毫秒之后执行。它返回一个整数，表示定时器的编号，以后可以用来取消这个定时器。 setTimeout函数接受两个参数，第一个参数func|code是将要推迟执行的函数名或者一段代码，第二个参数delay是推迟执行的毫秒数。 除了前两个参数，setTimeout还允许更多的参数。它们将依次传入推迟执行的函数（回调函数）。 还有一个需要注意的地方，如果回调函数是对象的方法，那么setTimeout使得方法内部的this关键字指向全局环境，而不是定义时所在的那个对象。 为了防止出现这个问题，一种解决方法是将obj.y放入一个函数。obj.y放在一个匿名函数之中，这使得obj.y在obj的作用域执行，而不是在全局作用域内执行，所以能够显示正确的值。 另一种解决方法是，使用bind方法，将obj.y这个方法绑定在obj上面。 setInterval()setInterval函数的用法与setTimeout完全一致，区别仅仅在于setInterval指定某个任务每隔一段时间就执行一次，也就是无限次的定时执行。 与setTimeout一样，除了前两个参数，setInterval方法还可以接受更多的参数，它们会传入回调函数。 clearTimeout()，clearInterval()setTimeout和setInterval函数，都返回一个整数值，表示计数器编号。将该整数传入clearTimeout和clearInterval函数，就可以取消对应的定时器。 连续调用三次setTimeout，返回值都比上一次大了1。 利用这一点，可以写一个函数，取消当前所有的setTimeout定时器。 实例：debounce 函数有时，我们不希望回调函数被频繁调用。如果用户连续击键，就会连续触发keydown事件，造成大量的 Ajax 通信。这是不必要的，而且很可能产生性能问题。正确的做法应该是，设置一个门槛值，表示两次 Ajax 通信的最小间隔时间。如果在间隔时间内，发生新的keydown事件，则不触发 Ajax 通信，并且重新开始计时。如果过了指定时间，没有发生新的keydown事件，再将数据发送出去。 这种做法叫做 debounce（防抖动）。假定两次 Ajax 通信的间隔不得小于2500毫秒，上面的代码可以改写成下面这样。 运行机制setTimeout和setInterval的运行机制，是将指定的代码移出本轮事件循环，等到下一轮事件循环，再检查是否到了指定时间。如果到了，就执行对应的代码；如果不到，就继续等待。 这意味着，setTimeout和setInterval指定的回调函数，必须等到本轮事件循环的所有同步任务都执行完，才会开始执行。由于前面的任务到底需要多少时间执行完，是不确定的，所以没有办法保证，setTimeout和setInterval指定的任务，一定会按照预定时间执行。 setTimeout(f, 0)含义setTimeout的作用是将代码推迟到指定时间执行，如果指定时间为0，即setTimeout(f, 0)，那么会立刻执行吗？ 答案是不会。因为上一节说过，必须要等到当前脚本的同步任务，全部处理完以后，才会执行setTimeout指定的回调函数f。也就是说，setTimeout(f, 0)会在下一轮事件循环一开始就执行。 setTimeout(f, 0)这种写法的目的是，尽可能早地执行f，但是并不能保证立刻就执行f。 Promise 对象概述Promise 对象是 JavaScript 的异步操作解决方案，为异步操作提供统一接口。它起到代理作用（proxy），充当异步操作与回调函数之间的中介，使得异步操作具备同步操作的接口。Promise 可以让异步操作写起来，就像在写同步操作的流程，而不必一层层地嵌套回调函数。 首先，Promise 是一个对象，也是一个构造函数。 Promise 的设计思想是，所有异步任务都返回一个 Promise 实例。Promise 实例有一个then方法，用来指定下一步的回调函数。 总的来说，传统的回调函数写法使得代码混成一团，变得横向发展而不是向下发展。Promise 就是解决这个问题，使得异步流程可以写成同步流程。 Promise 原本只是社区提出的一个构想，一些函数库率先实现了这个功能。ECMAScript 6 将其写入语言标准，目前 JavaScript 原生支持 Promise 对象。 Promise 对象的状态Promise 对象通过自身的状态，来控制异步操作。Promise 实例具有三种状态。 上面三种状态里面，fulfilled和rejected合在一起称为resolved（已定型）。 这三种的状态的变化途径只有两种。 一旦状态发生变化，就凝固了，不会再有新的状态变化。这也是 Promise 这个名字的由来，它的英语意思是“承诺”，一旦承诺成效，就不得再改变了。这也意味着，Promise 实例的状态变化只可能发生一次。 因此，Promise 的最终结果只有两种。 Promise 构造函数JavaScript 提供原生的Promise构造函数，用来生成 Promise 实例。 Promise构造函数接受一个函数作为参数，该函数的两个参数分别是resolve和reject。它们是两个函数，由 JavaScript 引擎提供，不用自己实现。 Promise.prototype.then()Promise 实例的then方法，用来添加回调函数。 then方法可以接受两个回调函数，第一个是异步操作成功时（变为fulfilled状态）时的回调函数，第二个是异步操作失败（变为rejected）时的回调函数（该参数可以省略）。一旦状态改变，就调用相应的回调函数。 then方法可以链式使用。 p1后面有四个then，意味依次有四个回调函数。只要前一步的状态变为fulfilled，就会依次执行紧跟在后面的回调函数。 最后一个then方法，回调函数是console.log和console.error，用法上有一点重要的区别。console.log只显示step3的返回值，而console.error可以显示p1、step1、step2、step3之中任意一个发生的错误。举例来说，如果step1的状态变为rejected，那么step2和step3都不会执行了（因为它们是resolved的回调函数）。Promise 开始寻找，接下来第一个为rejected的回调函数，在上面代码中是console.error。这就是说，Promise 对象的报错具有传递性。 then() 用法辨析Promise 的用法，简单说就是一句话：使用then方法添加回调函数。 Promise 的实例加载图片 Ajax 操作小结Promise 的优点在于，让回调函数变成了规范的链式写法，程序流程可以看得很清楚。它有一整套接口，可以实现许多强大的功能，比如同时执行多个异步操作，等到它们的状态都改变以后，再执行一个回调函数；再比如，为多个回调函数中抛出的错误，统一指定处理方法等等。 而且，Promise 还有一个传统写法没有的好处：它的状态一旦改变，无论何时查询，都能得到这个状态。这意味着，无论何时为 Promise 实例添加回调函数，该函数都能正确执行。所以，你不用担心是否错过了某个事件或信号。如果是传统写法，通过监听事件来执行回调函数，一旦错过了事件，再添加回调函数是不会执行的 Promise 的缺点是，编写的难度比传统写法高，而且阅读代码也不是一眼可以看懂。你只会看到一堆then，必须自己在then的回调函数里面理清逻辑。 微任务Promise 的回调函数属于异步任务，会在同步任务之后执行。 是，Promise 的回调函数不是正常的异步任务，而是微任务（microtask）。它们的区别在于，正常任务追加到下一轮事件循环，微任务追加到本轮事件循环。这意味着，微任务的执行时间一定早于正常任务。 严格模式除了正常的运行模式，JavaScript 还有第二种运行模式：严格模式（strict mode）。顾名思义，这种模式采用更加严格的 JavaScript 语法。 设计目的早期的 JavaScript 语言有很多设计不合理的地方，但是为了兼容以前的代码，又不能改变老的语法，只能不断添加新的语法，引导程序员使用新语法。 严格模式是从 ES5 进入标准的，主要目的有以下几个。 严格模式体现了 JavaScript 更合理、更安全、更严谨的发展方向。 启用方法进入严格模式的标志，是一行字符串use strict。 老版本的引擎会把它当作一行普通字符串，加以忽略。新版本的引擎就会进入严格模式。 严格模式可以用于整个脚本，也可以只用于单个函数。 整个脚本文件use strict放在脚本文件的第一行，整个脚本都将以严格模式运行。如果这行语句不在第一行就无效，整个脚本会以正常模式运行。 单个函数use strict放在函数体的第一行，则整个函数以严格模式运行。 有时，需要把不同的脚本合并在一个文件里面。如果一个脚本是严格模式，另一个脚本不是，它们的合并就可能出错。严格模式的脚本在前，则合并后的脚本都是严格模式；如果正常模式的脚本在前，则合并后的脚本都是正常模式。这两种情况下，合并后的结果都是不正确的。这时可以考虑把整个脚本文件放在一个立即执行的匿名函数之中。 显式报错严格模式使得 JavaScript 的语法变得更严格，更多的操作会显式报错。其中有些操作，在正常模式下只会默默地失败，不会报错。 只读属性不可写严格模式下，设置字符串的length属性，会报错。正常模式下，改变length属性是无效的，但不会报错。 严格模式下，对只读属性赋值，或者删除不可配置（non-configurable）属性都会报错。 只设置了取值器的属性不可写严格模式下，对一个只有取值器（getter）、没有存值器（setter）的属性赋值，会报错。 禁止扩展的对象不可扩展严格模式下，对禁止扩展的对象添加新属性，会报错。 eval、arguments 不可用作标识名严格模式下，使用eval或者arguments作为标识名，将会报错。下面的语句都会报错。 函数不能有重名的参数正常模式下，如果函数有多个重名的参数，可以用arguments[i]读取。严格模式下，这属于语法错误。 禁止八进制的前缀0表示法正常模式下，整数的第一位如果是0，表示这是八进制数，比如0100等于十进制的64。严格模式禁止这种表示法，整数第一位为0，将报错。 增强的安全措施严格模式增强了安全保护，从语法上防止了一些不小心会出现的错误。 全局变量显式声明正常模式中，如果一个变量没有声明就赋值，默认是全局变量。严格模式禁止这种用法，全局变量必须显式声明。 因此，严格模式下，变量都必须先声明，然后再使用。 禁止 this 关键字指向全局对象正常模式下，函数内部的this可能会指向全局对象，严格模式禁止这种用法，避免无意间创造全局变量。 这种限制对于构造函数尤其有用。使用构造函数时，有时忘了加new，这时this不再指向全局对象，而是报错。 禁止使用 fn.callee、fn.caller函数内部不得使用fn.caller、fn.arguments，否则会报错。这意味着不能在函数内部得到调用栈了。 禁止使用 arguments.callee、arguments.callerarguments.callee和arguments.caller是两个历史遗留的变量，从来没有标准化过，现在已经取消了。正常模式下调用它们没有什么作用，但是不会报错。严格模式明确规定，函数内部使用arguments.callee、arguments.caller将会报错。 禁止删除变量严格模式下无法删除变量，如果使用delete命令删除一个变量，会报错。只有对象的属性，且属性的描述对象的configurable属性设置为true，才能被delete命令删除。 静态绑定JavaScript 语言的一个特点，就是允许“动态绑定”，即某些属性和方法到底属于哪一个对象，不是在编译时确定的，而是在运行时（runtime）确定的。 严格模式对动态绑定做了一些限制。某些情况下，只允许静态绑定。也就是说，属性和方法到底归属哪个对象，必须在编译阶段就确定。这样做有利于编译效率的提高，也使得代码更容易阅读，更少出现意外。 禁止使用 with 语句严格模式下，使用with语句将报错。因为with语句无法在编译时就确定，某个属性到底归属哪个对象，从而影响了编译效果。 创设 eval 作用域正常模式下，JavaScript 语言有两种变量作用域（scope）：全局作用域和函数作用域。严格模式创设了第三种作用域：eval作用域。 正常模式下，eval语句的作用域，取决于它处于全局作用域，还是函数作用域。严格模式下，eval语句本身就是一个作用域，不再能够在其所运行的作用域创设新的变量了，也就是说，eval所生成的变量只能用于eval内部。 arguments 不再追踪参数的变化变量arguments代表函数的参数。严格模式下，函数内部改变参数与arguments的联系被切断了，两者不再存在联动关系。 向下一个版本的 JavaScript 过渡JavaScript语言的下一个版本是 ECMAScript 6，为了平稳过渡，严格模式引入了一些 ES6 语法。 非函数代码块不得声明函数ES6 会引入块级作用域。为了与新版本接轨，ES5 的严格模式只允许在全局作用域或函数作用域声明函数。也就是说，不允许在非函数的代码块内声明函数。 ES6 允许在代码块之中声明函数。 保留字为了向将来 JavaScript 的新版本过渡，严格模式新增了一些保留字（implements、interface、let、package、private、protected、public、static、yield等）。使用这些词作为变量名将会报错。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":" JavaScript标准参考教程 面向对象编程","slug":"JavaScript标准参考教程 面向对象编程","date":"2018-08-19T15:33:56.000Z","updated":"2018-08-19T15:37:10.000Z","comments":true,"path":"2018/08/19/JavaScript标准参考教程 面向对象编程/","link":"","permalink":"https://github.com/zdkswd/2018/08/19/JavaScript标准参考教程 面向对象编程/","excerpt":"","text":"构造函数与 new 命令JavaScript 语言具有很强的面向对象编程能力。 对象是什么构造函数典型的面向对象编程语言（比如 C++ 和 Java），都有“类”（class）这个概念。所谓“类”就是对象的模板，对象就是“类”的实例。但是，JavaScript 语言的对象体系，不是基于“类”的，而是基于构造函数（constructor）和原型链（prototype）。 JavaScript 语言使用构造函数（constructor）作为对象的模板。所谓”构造函数”，就是专门用来生成实例对象的函数。它就是对象的模板，描述实例对象的基本结构。一个构造函数，可以生成多个实例对象，这些实例对象都有相同的结构。 构造函数就是一个普通的函数，但是有自己的特征和用法。 为了与普通函数区别，构造函数名字的第一个字母通常大写。 构造函数的特点有两个。 new 命令基本用法new命令的作用，就是执行构造函数，返回一个实例对象。 使用new命令时，根据需要，构造函数也可以接受参数。 new命令本身就可以执行构造函数，所以后面的构造函数可以带括号，也可以不带括号。下面两行代码是等价的，但是为了表示这里是函数调用，推荐使用括号。 如果忘了使用new命令，构造函数就变成了普通函数，并不会生成实例对象。this这时代表全局对象，将造成一些意想不到的结果。 因此，应该非常小心，避免不使用new命令、直接调用构造函数。 为了保证构造函数必须与new命令一起使用，一个解决办法是，构造函数内部使用严格模式，即第一行加上use strict。这样的话，一旦忘了使用new命令，直接调用构造函数就会报错。 另一个解决办法，构造函数内部判断是否使用new命令，如果发现没有使用，则直接返回一个实例对象。 不管加不加new命令，都会得到同样的结果。 new 命令的原理使用new命令时，它后面的函数依次执行下面的步骤。 也就是说，构造函数内部，this指的是一个新生成的空对象，所有针对this的操作，都会发生在这个空对象上。构造函数之所以叫“构造函数”，就是说这个函数的目的，就是操作一个空对象（即this对象），将其“构造”为需要的样子。 如果构造函数内部有return语句，而且return后面跟着一个对象，new命令会返回return语句指定的对象；否则，就会不管return语句，返回this对象。这一点需要特别引起注意。 另一方面，如果对普通函数（内部没有this关键字的函数）使用new命令，则会返回一个空对象。 new.target函数内部可以使用new.target属性。如果当前函数是new命令调用，new.target指向当前函数，否则为undefined。 使用这个属性，可以判断函数调用的时候，是否使用new命令。 Object.create() 创建实例对象构造函数作为模板，可以生成实例对象。但是，有时拿不到构造函数，只能拿到一个现有的对象。我们希望以这个现有的对象作为模板，生成新的实例对象，这时就可以使用Object.create()方法。 this 关键字涵义this都有一个共同点：它总是返回一个对象。 简单说，this就是属性或方法“当前”所在的对象。 由于对象的属性可以赋给另一个对象，所以属性所在的当前对象是可变的，即this的指向是可变的。 总结一下，JavaScript 语言之中，一切皆对象，运行环境也是对象，所以函数都是在某个对象之中运行，this就是函数运行时所在的对象（环境）。 使用场合全局环境全局环境使用this，它指的就是顶层对象window。 不管是不是在函数内部，只要是在全局环境下运行，this就是指顶层对象window。 构造函数构造函数中的this，指的是实例对象。 对象的方法如果对象的方法里面包含this，this的指向就是方法运行时所在的对象。该方法赋值给另一个对象，就会改变this的指向。 如果this所在的方法不在对象的第一层，这时this只是指向当前一层的对象，而不会继承更上面的层。 上面代码中，a.b.m方法在a对象的第二层，该方法内部的this不是指向a，而是指向a.b。 使用注意点避免多层 this由于this的指向是不确定的，所以切勿在函数中包含多层的this。内层的this直接指向顶层对象 因为实际执行的是下面的代码。 使用一个变量固定this的值，然后内层函数调用这个变量，是非常常见的做法，请务必掌握。 JavaScript 提供了严格模式，也可以硬性避免这种问题。严格模式下，如果函数内部的this指向顶层对象，就会报错。 避免数组处理方法中的 this数组的map和foreach方法，允许提供一个函数作为参数。这个函数内部不应该使用this。 foreach方法的回调函数中的this，其实是指向window对象，因此取不到o.v的值。 1最主要的问题就是函数表达式的出现，此时变成了全局环境。 解决这个问题的一种方法，就是前面提到的，使用中间变量固定this。 另一种方法是将this当作foreach方法的第二个参数，固定它的运行环境。 避免回调函数中的 this回调函数中的this往往会改变指向，最好避免使用。 绑定this的方法this的动态切换，固然为 JavaScript 创造了巨大的灵活性，但也使得编程变得困难和模糊。有时，需要把this固定下来，避免出现意想不到的情况。JavaScript 提供了call、apply、bind这三个方法，来切换/固定this的指向。 Function.prototype.call()函数实例的call方法，可以指定函数内部this的指向（即函数执行时所在的作用域），然后在所指定的作用域中，调用该函数。 call方法的参数，应该是一个对象。如果参数为空、null和undefined，则默认传入全局对象。 如果call方法的参数是一个原始值，那么这个原始值会自动转成对应的包装对象，然后传入call方法。 call方法还可以接受多个参数。 call的第一个参数就是this所要指向的那个对象，后面的参数则是函数调用时所需的参数。 call方法的一个应用是调用对象的原生方法。 继承的方法，如果这个方法一旦被覆盖，就不会得到正确结果。call方法可以解决这个问题，它将方法的原始定义放到obj对象上执行，这样无论obj上有没有同名方法，都不会影响结果。 Function.prototype.apply()apply方法的作用与call方法类似，也是改变this指向，然后再调用该函数。唯一的区别就是，它接收一个数组作为函数执行时的参数，使用格式如下。 apply方法的第一个参数也是this所要指向的那个对象，如果设为null或undefined，则等同于指定全局对象。第二个参数则是一个数组，该数组的所有成员依次作为参数，传入原函数。原函数的参数，在call方法中必须一个个添加，但是在apply方法中，必须以数组形式添加。 利用这一点，可以做一些有趣的应用。 找出数组最大元素JavaScript 不提供找出数组最大元素的函数。结合使用apply方法和Math.max方法，就可以返回数组的最大元素。 将数组的空元素变为undefined通过apply方法，利用Array构造函数将数组的空元素变成undefined。 空元素与undefined的差别在于，数组的forEach方法会跳过空元素，但是不会跳过undefined。因此，遍历内部元素的时候，会得到不同的结果。 转换类似数组的对象另外，利用数组对象的slice方法，可以将一个类似数组的对象（比如arguments对象）转为真正的数组。 绑定回调函数的对象Function.prototype.bind()bind方法用于将函数体内的this绑定到某个对象，然后返回一个新函数。 bind还可以接受更多的参数，将这些参数绑定原函数的参数。 bind还可以接受更多的参数，将这些参数绑定原函数的参数。 bind方法有一些使用注意点。 每一次返回一个新函数bind方法每运行一次，就返回一个新函数，这会产生一些问题。 结合回调函数使用回调函数是 JavaScript 最常用的模式之一，但是一个常见的错误是，将包含this的方法直接当作回调函数。 结合call方法使用prototype 对象面向对象编程很重要的一个方面，就是对象的继承。A 对象通过继承 B 对象，就能直接拥有 B 对象的所有属性和方法。这对于代码的复用是非常有用的。 大部分面向对象的编程语言，都是通过“类”（class）来实现对象的继承。JavaScript 语言的继承则是通过“原型对象”（prototype）。 原型对象概述构造函数的缺点通过构造函数为实例对象定义属性，虽然很方便，但是有一个缺点。同一个构造函数的多个实例之间，无法共享属性，从而造成对系统资源的浪费。 每新建一个实例，就会新建一个meow方法。这既没有必要，又浪费系统资源，因为所有meow方法都是同样的行为，完全应该共享。 这个问题的解决方法，就是 JavaScript 的原型对象（prototype）。 prototype 属性的作用JavaScript 继承机制的设计思想就是，原型对象的所有属性和方法，都能被实例对象共享。也就是说，如果属性和方法定义在原型上，那么所有实例对象就能共享，不仅节省了内存，还体现了实例对象之间的联系。 JavaScript 规定，每个函数都有一个prototype属性，指向一个对象。 对于普通函数来说，该属性基本无用。但是，对于构造函数来说，生成实例的时候，该属性会自动成为类类。1类类是自创的概念，类似于类的东西，即指不管实例对象是否存在，它都客观存在的实例对象的原型。 原型对象的属性不是实例对象自身的属性。只要修改原型对象，变动就立刻会体现在所有实例对象上。 当实例对象本身没有某个属性或方法的时候，它会到原型对象去寻找该属性或方法。这就是原型对象的特殊之处。 如果实例对象自身就有某个属性或方法，它就不会再去原型对象寻找这个属性或方法。 原型对象的作用，就是定义所有实例对象共享的属性和方法。这也是它被称为原型对象的原因，而实例对象可以视作从原型对象衍生出来的子对象。 原型链JavaScript 规定，所有对象都有自己的原型对象（prototype）。一方面，任何一个对象，都可以充当其他对象的原型；另一方面，由于原型对象也是对象，所以它也有自己的原型。因此，就会形成一个“原型链”（prototype chain）：对象到原型，再到原型的原型…… 如果一层层地上溯，所有对象的原型最终都可以上溯到Object.prototype，即Object构造函数的prototype属性。也就是说，所有对象都继承了Object.prototype的属性。这就是所有对象都有valueOf和toString方法的原因，因为这是从Object.prototype继承的。 那么，Object.prototype对象有没有它的原型呢？回答是Object.prototype的原型是null。null没有任何属性和方法，也没有自己的原型。因此，原型链的尽头就是null。 读取对象的某个属性时，JavaScript 引擎先寻找对象本身的属性，如果找不到，就到它的原型去找，如果还是找不到，就到原型的原型去找。如果直到最顶层的Object.prototype还是找不到，则返回undefined。如果对象自身和它的原型，都定义了一个同名属性，那么优先读取对象自身的属性，这叫做“覆盖”（overriding）。 注意，一级级向上，在整个原型链上寻找某个属性，对性能是有影响的。所寻找的属性在越上层的原型对象，对性能的影响越大。如果寻找某个不存在的属性，将会遍历整个原型链。 constructor 属性prototype对象有一个constructor属性，默认指向prototype对象所在的构造函数。 由于constructor属性定义在prototype对象上面，意味着可以被所有实例对象继承。 constructor属性的作用是，可以得知某个实例对象，到底是哪一个构造函数产生的。 constructor属性表示原型对象与构造函数之间的关联关系，如果修改了原型对象，一般会同时修改constructor属性，防止引用的时候出错。 构造函数Person的原型对象改掉了，但是没有修改constructor属性，导致这个属性不再指向Person。由于Person的新原型是一个普通对象，而普通对象的contructor属性指向Object构造函数，导致Person.prototype.constructor变成了Object。 修改原型对象时，一般要同时修改constructor属性的指向。 要么将constructor属性重新指向原来的构造函数，要么只在原型对象上添加方法。 如果不能确定constructor属性是什么函数，还有一个办法：通过name属性，从实例得到构造函数的名称。 instanceof 运算符instanceof运算符返回一个布尔值，表示对象是否为某个构造函数的实例。 instanceof运算符的左边是实例对象，右边是构造函数。它会检查右边构建函数的原型对象（prototype），是否在左边对象的原型链上。 只要一个对象的原型不是null，instanceof运算符的判断就不会失真。 instanceof运算符的一个用处，是判断值的类型。 注意，instanceof运算符只能用于对象，不适用原始类型的值。 对于undefined和null，instanceOf运算符总是返回false。 利用instanceof运算符，还可以巧妙地解决，调用构造函数时，忘了加new命令的问题。 Object 对象的相关方法Object.getPrototypeOf()Object.getPrototypeOf方法返回参数对象的原型。这是获取原型对象的标准方法。 Object.setPrototypeOf()Object.setPrototypeOf方法为参数对象设置原型，返回该参数对象。它接受两个参数，第一个是现有对象，第二个是原型对象。 new命令可以使用Object.setPrototypeOf方法模拟。 new命令新建实例对象，其实可以分成两步。第一步，将一个空对象的原型设为构造函数的prototype属性（上例是F.prototype）；第二步，将构造函数内部的this绑定这个空对象，然后执行构造函数，使得定义在this上面的方法和属性（上例是this.foo），都转移到这个空对象上。 Object.create()JavaScript 提供了Object.create方法，该方法接受一个对象作为参数，然后以它为原型，返回一个实例对象。该实例完全继承原型对象的属性。 下面三种方式生成的新对象是等价的。 如果想要生成一个不继承任何属性（比如没有toString和valueOf方法）的对象，可以将Object.create的参数设为null。 使用Object.create方法的时候，必须提供对象原型，即参数不能为空，或者不是对象，否则会报错。 Object.create方法生成的新对象，动态继承了原型。在原型上添加或修改任何方法，会立刻反映在新对象之上。 除了对象的原型，Object.create方法还可以接受第二个参数。该参数是一个属性描述对象，它所描述的对象属性，会添加到实例对象，作为该对象自身的属性。 Object.create方法生成的对象，继承了它的原型对象的构造函数。 Object.prototype.isPrototypeOf()实例对象的isPrototypeOf方法，用来判断该对象是否为参数对象的原型。 只要实例对象处在参数对象的原型链上，isPrototypeOf方法都返回true。 Object.prototype.proto实例对象的proto属性（前后各两个下划线），返回该对象的原型。该属性可读写。 根据语言标准，proto属性只有浏览器才需要部署，其他环境可以没有这个属性。它前后的两根下划线，表明它本质是一个内部属性，不应该对使用者暴露。因此，应该尽量少用这个属性，而是用Object.getPrototypeof()和Object.setPrototypeOf()，进行原型对象的读写操作。 获取原型对象方法的比较获取实例对象obj的原型对象，有三种方法。 前两种都不是很可靠。proto属性只有浏览器才需要部署，其他环境可以不部署。而obj.constructor.prototype在手动改变原型对象时，可能会失效。 推荐使用第三种Object.getPrototypeOf方法，获取原型对象。 Object.getOwnPropertyNames()Object.getOwnPropertyNames方法返回一个数组，成员是参数对象本身的所有属性的键名，不包含继承的属性键名。 Object.getOwnPropertyNames方法返回所有键名，不管是否可以遍历。只获取那些可以遍历的属性，使用Object.keys方法。 Object.prototype.hasOwnProperty()对象实例的hasOwnProperty方法返回一个布尔值，用于判断某个属性定义在对象自身，还是定义在原型链上。 注意，hasOwnProperty方法是 JavaScript 之中唯一一个处理对象属性时，不会遍历原型链的方法。 in 运算符和 for…in 循环in运算符返回一个布尔值，表示一个对象是否具有某个属性。它不区分该属性是对象自身的属性，还是继承的属性。 in运算符常用于检查一个属性是否存在。 获得对象的所有可遍历属性（不管是自身的还是继承的），可以使用for…in循环。 对象的拷贝如果要拷贝一个对象，需要做到下面两件事情。 面向对象编程的模式构造函数的继承让一个构造函数继承另一个构造函数，是非常常见的需求。 这可以分成两步实现。第一步是在子类的构造函数中，调用父类的构造函数。 第二步，是让子类的原型指向父类的原型，这样子类就可以继承父类原型。 上面代码中，Sub.prototype是子类的原型，要将它赋值为Object.create(Super.prototype)，而不是直接等于Super.prototype。否则后面两行对Sub.prototype的操作，会连父类的原型Super.prototype一起修改掉。 1 JavaScript 中对象的赋值是默认引用赋值的，如果你想要复制赋值，则必须要重新分配对象 另外一种写法是Sub.prototype等于一个父类实例。 上面这种写法也有继承的效果，但是子类会具有父类实例的方法。有时，这可能不是我们需要的，所以不推荐使用这种写法。 有时只需要单个方法的继承，这时可以采用下面的写法。 上面代码中，子类B的print方法先调用父类A的print方法，再部署自己的代码。这就等于继承了父类A的print方法。 多重继承JavaScript 不提供多重继承功能，即不允许一个对象同时继承多个对象。但是，可以通过变通方法，实现这个功能。 这种模式又称为 Mixin（混入）。 模块JavaScript不是一种模块化编程语言，ES5不支持”类”（class），更遑论”模块”（module）了。ES6正式支持”类”和”模块”，但还没有成为主流。 基本的实现方法模块是实现特定功能的一组属性和方法的封装。 只要把不同的函数（以及记录状态的变量）简单地放在一起，就算是一个模块。 这种做法的缺点很明显：”污染”了全局变量，无法保证不与其他模块发生变量名冲突，而且模块成员之间看不出直接关系。 为了解决上面的缺点，可以把模块写成一个对象，所有的模块成员都放到这个对象里面。 上面的函数m1和m2，都封装在module1对象里。使用的时候，就是调用这个对象的属性。 但是，这样的写法会暴露所有模块成员，内部状态可以被外部改写。 封装私有变量：构造函数的写法我们可以利用构造函数，封装私有变量。 这种方法将私有变量封装在构造函数中，违反了构造函数与实例对象相分离的原则。并且，非常耗费内存。 封装私有变量：立即执行函数的写法使用“立即执行函数”（Immediately-Invoked Function Expression，IIFE），将相关的属性和方法封装在一个函数作用域里面，可以达到不暴露私有成员的目的。 上面的module1就是JavaScript模块的基本写法。下面，再对这种写法进行加工。 模块的放大模式如果一个模块很大，必须分成几个部分，或者一个模块需要继承另一个模块，这时就有必要采用“放大模式”（augmentation）。 上面的代码为module1模块添加了一个新方法m3()，然后返回新的module1模块。 在浏览器环境中，模块的各个部分通常都是从网上获取的，有时无法知道哪个部分会先加载。如果采用上面的写法，第一个执行的部分有可能加载一个不存在空对象，这时就要采用”宽放大模式”（Loose augmentation）。 与”放大模式”相比，“宽放大模式”就是“立即执行函数”的参数可以是空对象。 输入全局变量独立性是模块的重要特点，模块内部最好不与程序的其他部分直接交互。为了在模块内部调用全局变量，必须显式地将其他变量输入模块。 上面的module1模块需要使用jQuery库和YUI库，就把这两个库（其实是两个模块）当作参数输入module1。这样做除了保证模块的独立性，还使得模块之间的依赖关系变得明显。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"JavaScript 标准参考教程 标准库 下","slug":"JavaScript 标准参考教程 标准库 下","date":"2018-08-17T04:03:56.000Z","updated":"2018-09-01T03:58:36.000Z","comments":true,"path":"2018/08/17/JavaScript 标准参考教程 标准库 下/","link":"","permalink":"https://github.com/zdkswd/2018/08/17/JavaScript 标准参考教程 标准库 下/","excerpt":"","text":"RegExp对象概述JavaScript 的正则表达式体系是参照 Perl 5 建立的。 新建正则表达式有两种方法。一种是使用字面量，以斜杠表示开始和结束。 另一种是使用RegExp构造函数。 区别是，第一种方法在引擎编译代码时，就会新建正则表达式，第二种方法在运行时新建正则表达式，所以前者的效率较高。而且，前者比较便利和直观，所以实际应用中，基本上都采用字面量定义正则表达式。 RegExp构造函数还可以接受第二个参数，表示修饰符。 实例属性正则对象的实例属性分成两类。 一类是修饰符相关，返回一个布尔值，表示对应的修饰符是否设置。 三个属性都是只读的。 另一类是与修饰符无关的属性，主要是下面两个。 实例方法RegExp.prototype.test()正则实例对象的test方法返回一个布尔值，表示当前模式是否能匹配参数字符串。 如果正则表达式带有g修饰符，则每一次test方法都从上一次结束的位置开始向后匹配。 带有g修饰符时，可以通过正则对象的lastIndex属性指定开始搜索的位置。 lastIndex属性只对同一个正则表达式有效。 如果正则模式是一个空字符串，则匹配所有字符串。 RegExp.prototype.exec()正则实例对象的exec方法，用来返回匹配结果。如果发现匹配，就返回一个数组，成员是匹配成功的子字符串，否则返回null。 exec方法的返回数组还包含以下两个属性： 如果正则表达式加上g修饰符，则可以使用多次exec方法，下一次搜索的位置从上一次匹配成功结束的位置开始。 正则实例对象的lastIndex属性不仅可读，还可写。设置了g修饰符的时候，只要手动设置了lastIndex的值，就会从指定位置开始匹配。 字符串的实例方法 String.prototype.match()字符串实例对象的match方法对字符串进行正则匹配，返回匹配结果。 字符串的match方法与正则对象的exec方法非常类似：匹配成功返回一个数组，匹配失败返回null。 如果正则表达式带有g修饰符，则该方法与正则对象的exec方法行为不同，会一次性返回所有匹配成功的结果。 设置正则表达式的lastIndex属性，对match方法无效，匹配总是从字符串的第一个字符开始。 设置正则对象的lastIndex属性是无效的。 String.prototype.search()字符串对象的search方法，返回第一个满足条件的匹配结果在整个字符串中的位置。如果没有任何匹配，则返回-1。 String.prototype.replace()字符串对象的replace方法可以替换匹配的值。它接受两个参数，第一个是正则表达式，表示搜索模式，第二个是替换的内容。 正则表达式如果不加g修饰符，就替换第一个匹配成功的值，否则替换所有匹配成功的值。 replace方法的第二个参数可以使用美元符号$，用来指代所替换的内容。 replace方法的第二个参数还可以是一个函数，将每一个匹配内容替换为函数返回值。 String.prototype.split()字符串对象的split方法按照正则规则分割字符串，返回一个由分割后的各个部分组成的数组。 该方法接受两个参数，第一个参数是正则表达式，表示分隔规则，第二个参数是返回数组的最大成员数。 正则默认是贪婪匹配。 匹配规则字面量字符和元字符如果在正则表达式之中，某个字符只表示它字面的含义（就像前面的a和b），那么它们就叫做“字面量字符”（literal characters）。 除了字面量字符以外，还有一部分字符有特殊含义，不代表字面的意思。它们叫做“元字符”（metacharacters），主要有以下几个。 点字符（.）点字符（.）匹配除回车（\\r）、换行(\\n) 、行分隔符（\\u2028）和段分隔符（\\u2029）以外的所有字符。注意，对于码点大于0xFFFF的 Unicode 字符，点字符不能正确匹配，会认为这是两个字符。 位置字符位置字符用来提示字符所处的位置，主要有两个字符。 选择符（|）竖线符号（|）在正则表达式中表示“或关系”（OR），即cat|dog表示匹配cat或dog。 转义符正则表达式中那些有特殊含义的元字符，如果要匹配它们本身，就需要在它们前面要加上反斜杠。比如要匹配+，就要写成\\ +。 正则表达式中，需要反斜杠转义的，一共有12个字符：^、.、[、$、(、)、|、*、+、?、{和\\。需要特别注意的是，如果使用RegExp方法生成正则对象，转义需要使用两个斜杠，因为字符串内部会先转义一次。 特殊字符正则表达式对一些不能打印的特殊字符，提供了表达方法。 字符类字符类（class）表示有一系列字符可供选择，只要匹配其中一个就可以了。所有可供选择的字符都放在方括号内，比如[xyz] 表示x、y、z之中任选一个匹配。 脱字符（ ^ ）如果方括号内的第一个字符是[^ ]，则表示除了字符类之中的字符，其他字符都可以匹配。比如，[^ xyz]表示除了x、y、z之外都可以匹配。 如果方括号内没有其他字符，即只有[^]，就表示匹配一切字符，其中包括换行符。相比之下，点号作为元字符（.）是不包括换行符的。 注意，脱字符只有在字符类的第一个位置才有特殊含义，否则就是字面含义。 连字符（-）某些情况下，对于连续序列的字符，连字符（-）用来提供简写形式，表示字符的连续范围。比如，[abc]可以写成[a-c]，[0123456789]可以写成[0-9]，同理[A-Z]表示26个大写字母。 [1-31]，不代表1到31，只代表1到3。 连字符还可以用来指定 Unicode 字符的范围。 预定义模式 重复类模式的精确匹配次数，使用大括号（{}）表示。{n}表示恰好重复n次，{n,}表示至少重复n次，{n,m}表示重复不少于n次，不多于m次。 量词符量词符用来设定某个模式出现的次数。 贪婪模式三个量词符，默认情况下都是最大可能匹配，即匹配直到下一个字符不满足匹配规则为止。这被称为贪婪模式。 如果想将贪婪模式改为非贪婪模式，可以在量词符后面加一个问号。 模式结尾添加了一个问号/a+?/，这时就改为非贪婪模式，一旦条件满足，就不再往下匹配。 修饰符修饰符（modifier）表示模式的附加规则，放在正则模式的最尾部。 修饰符可以单个使用，也可以多个一起使用。 g 修饰符默认情况下，第一次匹配成功后，正则对象就停止向下匹配了。g修饰符表示全局匹配（global），加上它以后，正则对象将匹配全部符合条件的结果，主要用于搜索和替换。 i 修饰符默认情况下，正则对象区分字母的大小写，加上i修饰符以后表示忽略大小写（ignorecase）。 m修饰符表示多行模式（multiline），会修改\\^和\\$的行为。默认情况下（即不加m修饰符时），\\^和\\$匹配字符串的开始处和结尾处，加上m修饰符以后，\\^和\\$还会匹配行首和行尾，即\\^和\\$会识别换行符（\\n）。 组匹配概述正则表达式的括号表示分组匹配，括号中的模式可以用来匹配分组的内容。 注意，使用组匹配时，不宜同时使用g修饰符，否则match方法不会捕获分组的内容。 这时必须使用正则表达式的exec方法，配合循环，才能读到每一轮匹配的组捕获。 正则表达式内部，还可以用\\n引用括号匹配的内容，n是从1开始的自然数，表示对应顺序的括号。 非捕获组(?:x)称为非捕获组（Non-capturing group），表示不返回该组匹配的内容，即匹配的结果中不计入这个括号。 先行断言x(?=y)称为先行断言（Positive look-ahead），x只有在y前面才匹配，y不会被计入返回结果。比如，要匹配后面跟着百分号的数字，可以写成/\\d+(?=%)/。 先行否定断言x(?!y)称为先行否定断言（Negative look-ahead），x只有不在y前面才匹配，y不会被计入返回结果。比如，要匹配后面跟的不是百分号的数字，就要写成/\\d+(?!%)/。 JSON对象JSON 格式JSON 格式（JavaScript Object Notation 的缩写）是一种用于数据交换的文本格式。 相比 XML 格式，JSON 格式有两个显著的优点：书写简单，一目了然；符合 JavaScript 原生语法，可以由解释引擎直接处理，不用另外添加解析代码。所以，JSON 迅速被接受，已经成为各大网站交换数据的标准格式，并被写入标准。 每个 JSON 对象就是一个值，可能是一个数组或对象，也可能是一个原始类型的值。总之，只能是一个值，不能是两个或更多的值。 JSON 对值的类型和格式有严格的规定。 JSON 对象JSON对象是 JavaScript 的原生对象，用来处理 JSON 格式数据。它有两个静态方法：JSON.stringify()和JSON.parse()。 JSON.stringify()基本用法JSON.stringify方法用于将一个值转为 JSON 字符串。该字符串符合 JSON 格式，并且可以被JSON.parse方法还原。 注意，对于原始类型的字符串，转换结果会带双引号。 如果对象的属性是undefined、函数或 XML 对象，该属性会被JSON.stringify过滤。 如果数组的成员是undefined、函数或 XML 对象，则这些值被转成null。 正则对象会被转成空对象。 JSON.stringify方法会忽略对象的不可遍历属性。 第二个参数JSON.stringify方法还可以接受一个数组，作为第二个参数，指定需要转成字符串的属性。 这个类似白名单的数组，只对对象的属性有效，对数组无效。 第二个参数还可以是一个函数，用来更改JSON.stringify的返回值。 f函数，接受两个参数，分别是被转换的对象的键名和键值。 这个处理函数是递归处理所有的键。 第三个参数JSON.stringify还可以接受第三个参数，用于增加返回的 JSON 字符串的可读性。如果是数字，表示每个属性前面添加的空格（最多不超过10个）；如果是字符串（不超过10个字符），则该字符串会添加在每行前面。 参数对象的 toJSON 方法如果参数对象有自定义的toJSON方法，那么JSON.stringify会使用这个方法的返回值作为参数，而忽略原对象的其他属性。 JSON.parse()JSON.parse方法用于将 JSON 字符串转换成对应的值。 如果传入的字符串不是有效的 JSON 格式，JSON.parse方法将报错。 单引号字符串不符合 JSON 格式，会报错。 为了处理解析错误，可以将JSON.parse方法放在try…catch代码块中。 JSON.parse方法可以接受一个处理函数，作为第二个参数，用法与JSON.stringify方法类似。 console对象console对象是 JavaScript 的原生对象，它有点像 Unix 系统的标准输出stdout和标准错误stderr，可以输出各种信息到控制台，并且还提供了很多有用的辅助方法。 console的常见用途有两个。 浏览器实现可以使用下面三种方法的打开它。 面板。 Console面板基本上就是一个命令行窗口，你可以在提示符下，键入各种命令。 console 对象的静态方法console对象提供的各种静态方法，用来与控制台窗口互动。 console.log()，console.info()，console.debug()console.log方法用于在控制台输出信息。它可以接受一个或多个参数，将它们连接起来输出。 console.log方法会自动在每次输出的结尾，添加换行符。 如果第一个参数是格式字符串（使用了格式占位符），console.log方法将依次用后面的参数替换占位符，然后再进行输出。 不同类型的数据必须使用对应的占位符。 console.info是console.log方法的别名，用法完全一样。只不过console.info方法会在输出信息的前面，加上一个蓝色图标。 console.debug方法与console.log方法类似，会在控制台输出调试信息。但是，默认情况下，console.debug输出的信息不会显示，只有在打开显示级别在verbose的情况下，才会显示。 console对象的所有方法，都可以被覆盖。因此，可以按照自己的需要，定义console.log方法。 console.warn()，console.error()warn方法和error方法也是在控制台输出信息，它们与log方法的不同之处在于，warn方法输出信息时，在最前面加一个黄色三角，表示警告；error方法输出信息时，在最前面加一个红色的叉，表示出错。同时，还会高亮显示输出文字和错误发生的堆栈。其他方面都一样。 console.table()对于某些复合类型的数据，console.table方法可以将其转为表格显示。 console.count()count方法用于计数，输出它被调用了多少次。 该方法可以接受一个字符串作为参数，作为标签，对执行次数进行分类。 console.dir()，console.dirxml()dir方法用来对一个对象进行检查（inspect），并以易于阅读和打印的格式显示。 dir方法的输出结果，比log方法更易读，信息也更丰富。 对于输出 DOM 对象非常有用，因为会显示 DOM 对象的所有属性。 Node 环境之中，还可以指定以代码高亮的形式输出。 dirxml方法主要用于以目录树的形式，显示 DOM 节点。 如果参数不是 DOM 节点，而是普通的 JavaScript 对象，console.dirxml等同于console.dir。 console.assert()console.assert方法主要用于程序运行过程中，进行条件判断，如果不满足条件，就显示一个错误，但不会中断程序执行。这样就相当于提示用户，内部状态不正确。 它接受两个参数，第一个参数是表达式，第二个参数是字符串。只有当第一个参数为false，才会提示有错误，在控制台输出第二个参数，否则不会有任何结果。 console.time()，console.timeEnd()这两个方法用于计时，可以算出一个操作所花费的准确时间。 time方法表示计时开始，timeEnd方法表示计时结束。它们的参数是计时器的名称。调用timeEnd方法之后，控制台会显示“计时器名称: 所耗费的时间”。 console.group()，console.groupEnd()，console.groupCollapsed()console.group和console.groupEnd这两个方法用于将显示的信息分组。它只在输出大量信息时有用，分在一组的信息，可以用鼠标折叠/展开。 console.groupCollapsed方法与console.group方法很类似，唯一的区别是该组的内容，在第一次显示时是收起的（collapsed），而不是展开的。 console.trace()，console.clear()console.trace方法显示当前执行的代码在堆栈中的调用路径。 console.clear方法用于清除当前控制台的所有输出，将光标回置到第一行。如果用户选中了控制台的“Preserve log”选项，console.clear方法将不起作用。 命令行API浏览器控制台中，除了使用console对象，还可以使用一些控制台自带的命令行方法。 $_$_属性返回上一个表达式的值。 \\$0 - \\$4控制台保存了最近5个在 Elements 面板选中的 DOM 元素，\\$0代表倒数第一个（最近一个），\\$1代表倒数第二个，以此类推直到\\$4。 $(selector)\\$(selector)返回第一个匹配的元素，等同于document.querySelector()。注意，如果页面脚本对\\$有定义，则会覆盖原始的定义。比如，页面里面有 jQuery，控制台执行\\$(selector)就会采用 jQuery 的实现，返回一个数组。 $$(selector)$$(selector)返回选中的 DOM 对象，等同于document.querySelectorAll。 $x(path)$x(path)方法返回一个数组，包含匹配特定 XPath 表达式的所有 DOM 元素。 inspect(object)inspect(object)方法打开相关面板，并选中相应的元素，显示它的细节。DOM 元素在Elements面板中显示，比如inspect(document)会在 Elements 面板显示document元素。JavaScript 对象在控制台面板Profiles面板中显示，比如inspect(window)。 getEventListeners(object)getEventListeners(object)方法返回一个对象，该对象的成员为object登记了回调函数的各种事件（比如click或keydown），每个事件对应一个数组，数组的成员为该事件的回调函数。 keys(object)，values(object)keys(object)方法返回一个数组，包含object的所有键名。values(object)方法返回一个数组，包含object的所有键值。 monitorEvents(object[, events]) ，unmonitorEvents(object[, events])monitorEvents(object[, events])方法监听特定对象上发生的特定事件。事件发生时，会返回一个Event对象，包含该事件的相关信息。unmonitorEvents方法用于停止监听。 monitorEvents允许监听同一大类的事件。所有事件可以分成四个大类。 其他方法命令行 API 还提供以下方法。 debugger 语句debugger语句主要用于除错，作用是设置断点。如果有正在运行的除错工具，程序运行到debugger语句时会自动停下。如果没有除错工具，debugger语句不会产生任何结果，JavaScript 引擎自动跳过这一句。 Chrome 浏览器中，当代码运行到debugger语句时，就会暂停运行，自动打开脚本源码界面。 属性描述对象概述JavaScript 提供了一个内部数据结构，用来描述对象的属性，控制它的行为，比如该属性是否可写、可遍历等等。这个内部数据结构称为“属性描述对象”（attributes object）。每个属性都有自己对应的属性描述对象，保存该属性的一些元信息。 属性描述对象提供6个元属性。 valuevalue是该属性的属性值，默认为undefined。 writablewritable是一个布尔值，表示属性值（value）是否可改变（即是否可写），默认为true。 enumerableenumerable是一个布尔值，表示该属性是否可遍历，默认为true。如果设为false，会使得某些操作（比如for…in循环、Object.keys()，JSON.stringify方法）跳过该属性。 configurableconfigurable是一个布尔值，表示可配置性，默认为true。如果设为false，将阻止某些操作改写该属性，比如无法删除该属性，也不得改变该属性的属性描述对象（value属性除外）。也就是说，configurable属性控制了属性描述对象的可写性。 getget是一个函数，表示该属性的取值函数（getter），默认为undefined。 setset是一个函数，表示该属性的存值函数（setter），默认为undefined。 Object.getOwnPropertyDescriptor()Object.getOwnPropertyDescriptor方法可以获取属性描述对象。它的第一个参数是一个对象，第二个参数是一个字符串，对应该对象的某个属性名。 注意，Object.getOwnPropertyDescriptor方法只能用于对象自身的属性，不能用于继承的属性。 Object.getOwnPropertyNames()Object.getOwnPropertyNames方法返回一个数组，成员是参数对象自身的全部属性的属性名，不管该属性是否可遍历。 这跟Object.keys的行为不同，Object.keys只返回对象自身的可遍历属性的全部属性名。 Object.defineProperty()，Object.defineProperties()Object.defineProperty方法允许通过属性描述对象，定义或修改一个属性，然后返回修改后的对象，它的用法如下。 Object.defineProperty方法接受三个参数，依次如下。 如果一次性定义或修改多个属性，可以使用Object.defineProperties方法。 注意，一旦定义了取值函数get（或存值函数set），就不能将writable属性设为true，或者同时定义value属性，否则会报错。 Object.defineProperty()和Object.defineProperties()的第三个参数，是一个属性对象。它的writable、configurable、enumerable这三个属性的默认值都为false。 Object.prototype.propertyIsEnumerable()实例对象的propertyIsEnumerable方法返回一个布尔值，用来判断某个属性是否可遍历。 元属性属性描述对象的各个属性称为“元属性”，因为它们可以看作是控制属性的属性。 valuevalue属性是目标属性的值。 writableenumerableconfigurable存取器除了直接定义以外，属性还可以用存取器（accessor）定义。其中，存值函数称为setter，使用属性描述对象的set属性；取值函数称为getter，使用属性描述对象的get属性。 一旦对目标属性定义了存取器，那么存取的时候，都将执行对应的函数。利用这个功能，可以实现许多高级特性，比如某个属性禁止赋值。 注意，取值函数get不能接受参数，存值函数set只能接受一个参数（即属性的值）。 存取器往往用于，属性的值依赖对象内部数据的场合。 next属性的存值函数和取值函数，都依赖于内部属性$n。 对象的拷贝有时，我们需要将一个对象的所有属性，拷贝到另一个对象。 可以通过Object.defineProperty方法来拷贝属性。 hasOwnProperty那一行用来过滤掉继承的属性，否则会报错，因为Object.getOwnPropertyDescriptor读不到继承属性的属性描述对象。 控制对象状态有时需要冻结对象的读写状态，防止对象被改变。JavaScript 提供了三种冻结方法，最弱的一种是Object.preventExtensions，其次是Object.seal，最强的是Object.freeze。 Object.preventExtensions()Object.preventExtensions方法可以使得一个对象无法再添加新的属性。 Object.isExtensible()Object.isExtensible方法用于检查一个对象是否使用了Object.preventExtensions方法。也就是说，检查是否可以为一个对象添加属性。 Object.seal()Object.seal方法使得一个对象既无法添加新属性，也无法删除旧属性。 Object.seal实质是把属性描述对象的configurable属性设为false，因此属性描述对象不再能改变了。 Object.seal只是禁止新增或删除属性，并不影响修改某个属性的值。 Object.isSealed()Object.isSealed方法用于检查一个对象是否使用了Object.seal方法。 这时，Object.isExtensible方法也返回false。 Object.freeze()Object.freeze方法可以使得一个对象无法添加新属性、无法删除旧属性、也无法改变属性的值，使得这个对象实际上变成了常量。 这些操作并不报错，只是默默地失败。如果在严格模式下，则会报错。 Object.isFrozen()Object.isFrozen方法用于检查一个对象是否使用了Object.freeze方法。 使用Object.freeze方法以后，Object.isSealed将会返回true，Object.isExtensible返回false。 局限性上面的三个方法锁定对象的可写性有一个漏洞：可以通过改变原型对象，来为对象增加属性。 一种解决方案是，把obj的原型也冻结住。 另外一个局限是，如果属性值是对象，上面这些方法只能冻结属性指向的对象，而不能冻结对象本身的内容。 obj.bar属性指向一个数组，obj对象被冻结以后，这个指向无法改变，即无法指向其他值，但是所指向的数组是可以改变的。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"JavaScript 标准参考教程 标准库 上","slug":"JavaScript 标准参考教程 标准库 上","date":"2018-08-17T04:02:56.000Z","updated":"2018-11-08T07:56:14.000Z","comments":true,"path":"2018/08/17/JavaScript 标准参考教程 标准库 上/","link":"","permalink":"https://github.com/zdkswd/2018/08/17/JavaScript 标准参考教程 标准库 上/","excerpt":"","text":"Object对象概述JavaScript 原生提供Object对象（注意起首的O是大写）。 JavaScript 的所有其他对象都继承自Object对象，即那些对象都是Object的实例。 Object对象的原生方法分成两类：Object本身的方法与Object的实例方法。 Object对象本身的方法Object的实例方法Object（）Object本身是一个函数，可以当作工具方法使用，将任意值转为对象。这个方法常用于保证某个值一定是对象。 如果参数为空（或者为undefined和null），Object()返回一个空对象。 instanceof运算符用来验证，一个对象是否为指定的构造函数的实例。obj instanceof Object返回true，就表示obj对象是Object的实例。 如果参数是原始类型的值，Object方法将其转为对应的包装对象的实例。 如果Object方法的参数是一个对象，它总是返回该对象，即不用转换。 利用这一点，可以写一个判断变量是否为对象的函数。 Object构造函数Object不仅可以当作工具函数使用，还可以当作构造函数使用，即前面可以使用new命令。 Object构造函数的首要用途，是直接通过它来生成新对象。 注意，通过var obj = new Object()的写法生成新对象，与字面量的写法var obj = {}是等价的。或者说，后者只是前者的一种简便写法。 Object的静态方法所谓“静态方法”，是指部署在Object对象自身的方法。 Object.keys()，Object.getOwnPropertyNames()Object.keys方法和Object.getOwnPropertyNames方法都用来遍历对象的属性。 Object.keys方法的参数是一个对象，返回一个数组。该数组的成员都是该对象自身的（而不是继承的）所有属性名。 对于一般的对象来说，Object.keys()和Object.getOwnPropertyNames()返回的结果是一样的。只有涉及不可枚举属性时，才会有不一样的结果。Object.keys方法只返回可枚举的属性，Object.getOwnPropertyNames方法还返回不可枚举的属性名。 由于 JavaScript 没有提供计算对象属性个数的方法，所以可以用这两个方法代替。 其他方法对象属性模型的相关方法 控制对象状态的方法 原型链相关方法 Object的实例方法除了静态方法，还有不少方法定义在Object.prototype对象。它们称为实例方法，所有Object的实例对象都继承了这些方法。 Object实例对象的方法，主要有以下六个。 Object.prototype.valueOf()valueOf方法的作用是返回一个对象的“值”，默认情况下返回对象本身。 valueOf方法的主要用途是，JavaScript 自动类型转换时会默认调用这个方法。 Object.prototype.toString()toString方法的作用是返回一个对象的字符串形式，默认情况下返回类型字符串。 通过自定义toString方法，可以让对象在自动类型转换时，得到想要的字符串形式。 数组、字符串、函数、Date 对象都分别部署了自定义的toString方法，覆盖了Object.prototype.toString方法。覆盖原始方法。 toString() 的应用：判断数据类型Object.prototype.toString方法返回对象的类型字符串，因此可以用来判断一个值的类型。 由于实例对象可能会自定义toString方法，覆盖掉Object.prototype.toString方法，所以为了得到类型字符串，最好直接使用Object.prototype.toString方法。通过函数的call方法，可以在任意值上调用这个方法，帮助我们判断这个值的类型。 不同数据类型的Object.prototype.toString方法返回值如下。 利用这个特性，可以写出一个比typeof运算符更准确的类型判断函数。 Object.prototype.toLocaleString()Object.prototype.toLocaleString方法与toString的返回结果相同，也是返回一个值的字符串形式。 这个方法的主要作用是留出一个接口，让各种不同的对象实现自己版本的toLocaleString，用来返回针对某些地域的特定的值。目前，主要有三个对象自定义了toLocaleString方法。 举例来说，日期的实例对象的toString和toLocaleString返回值就不一样，而且toLocaleString的返回值跟用户设定的所在地域相关。 Object.prototype.hasOwnProperty()Object.prototype.hasOwnProperty方法接受一个字符串作为参数，返回一个布尔值，表示该实例对象自身是否具有该属性。而不显示继承而来的属性。 Array对象构造函数Array是 JavaScript 的原生对象，同时也是一个构造函数，可以用它生成新的数组。 Array构造函数的参数2，表示生成一个两个成员的数组，每个位置都是空值。 如果没有使用new，运行结果也是一样的。 Array构造函数有一个很大的缺陷，就是不同的参数，会导致它的行为不一致。 Array作为构造函数，行为很不一致。因此，不建议使用它生成新数组，直接使用数组字面量是更好的做法。 注意，如果参数是一个正整数，返回数组的成员都是空位。虽然读取的时候返回undefined，但实际上该位置没有任何值。虽然可以取到length属性，但是取不到键名。 静态方法Array.isArray()Array.isArray方法返回一个布尔值，表示参数是否为数组。它可以弥补typeof运算符的不足。 typeof运算符只能显示数组的类型是Object，而Array.isArray方法可以识别数组。 实例方法valueOf()，toString()valueOf方法是一个所有对象都拥有的方法，表示对该对象求值。不同对象的valueOf方法不尽一致，数组的valueOf方法返回数组本身。 toString方法也是对象的通用方法，数组的toString方法返回数组的字符串形式。 push()，pop()push方法用于在数组的末端添加一个或多个元素，并返回添加新元素后的数组长度。注意，该方法会改变原数组。 pop方法用于删除数组的最后一个元素，并返回该元素。注意，该方法会改变原数组。 对空数组使用pop方法，不会报错，而是返回undefined。 shift()，unshift()shift方法用于删除数组的第一个元素，并返回该元素。注意，该方法会改变原数组。 shift方法可以遍历并清空一个数组。 push和shift结合使用，就构成了“先进先出”的队列结构（queue）。 unshift方法用于在数组的第一个位置添加元素，并返回添加新元素后的数组长度。注意，该方法会改变原数组。 unshift方法可以接受多个参数，这些参数都会添加到目标数组头部。 join（）join方法以指定参数作为分隔符，将所有数组成员连接为一个字符串返回。如果不提供参数，默认用逗号分隔。 如果数组成员是undefined或null或空位，会被转成空字符串。 通过call方法，这个方法也可以用于字符串或类似数组的对象。 concat()concat方法用于多个数组的合并。它将新数组的成员，添加到原数组成员的后部，然后返回一个新数组，原数组不变。 除了数组作为参数，concat也接受其他类型的值作为参数，添加到目标数组尾部。 如果数组成员包括对象，concat方法返回当前数组的一个浅拷贝。所谓“浅拷贝”，指的是新数组拷贝的是对象的引用。 reverse()reverse方法用于颠倒排列数组元素，返回改变后的数组。注意，该方法将改变原数组。 slice()slice方法用于提取目标数组的一部分，返回一个新数组，原数组不变。 它的第一个参数为起始位置（从0开始），第二个参数为终止位置（但该位置的元素本身不包括在内）。如果省略第二个参数，则一直返回到原数组的最后一个成员。 如果slice方法的参数是负数，则表示倒数计算的位置。 slice没有参数，实际上等于返回一个原数组的拷贝。 如果第一个参数大于等于数组长度，或者第二个参数小于第一个参数，则返回空数组。 slice方法的一个重要应用，是将类似数组的对象转为真正的数组。 splice()splice方法用于删除原数组的一部分成员，并可以在删除的位置添加新的数组成员，返回值是被删除的元素。注意，该方法会改变原数组。 起始位置如果是负数，就表示从倒数位置开始删除。 如果只是单纯地插入元素，splice方法的第二个参数可以设为0。 sort()sort方法对数组成员进行排序，默认是按照字典顺序排序。排序后，原数组将被改变。 sort方法不是按照大小排序，而是按照字典顺序。也就是说，数值会被先转成字符串，再按照字典顺序进行比较，所以101排在11的前面。 如果想让sort方法按照自定义方式排序，可以传入一个函数作为参数。 sort的参数函数本身接受两个参数，表示进行比较的两个数组成员。如果该函数的返回值大于0，表示第一个成员排在第二个成员后面；其他情况下，都是第一个元素排在第二个元素前面。 map()map方法将数组的所有成员依次传入参数函数，然后把每一次的执行结果组成一个新数组返回。 map方法接受一个函数作为参数。该函数调用时，map方法向它传入三个参数：当前成员、当前位置和数组本身。 map方法还可以接受第二个参数，用来绑定回调函数内部的this变量。 如果数组有空位，map方法的回调函数在这个位置不会执行，会跳过数组的空位。 map方法不会跳过undefined和null，但是会跳过空位。 forEach()forEach方法与map方法很相似，也是对数组的所有成员依次执行参数函数。但是，forEach方法不返回值，只用来操作数据。这就是说，如果数组遍历的目的是为了得到返回值，那么使用map方法，否则使用forEach方法。 forEach的用法与map方法一致，参数是一个函数，该函数同样接受三个参数：当前值、当前位置、整个数组。 forEach方法也可以接受第二个参数，绑定参数函数的this变量。 forEach方法无法中断执行，总是会将所有成员遍历完。如果希望符合某种条件时，就中断遍历，要使用for循环。 forEach方法也会跳过数组的空位。 filter()filter方法用于过滤数组成员，满足条件的成员组成一个新数组返回。 它的参数是一个函数，所有数组成员依次执行该函数，返回结果为true的成员组成一个新数组返回。该方法不会改变原数组。 filter方法的参数函数可以接受三个参数：当前成员，当前位置和整个数组。 filter方法还可以接受第二个参数，用来绑定参数函数内部的this变量。 some()，every()这两个方法类似“断言”（assert），返回一个布尔值，表示判断数组成员是否符合某种条件。 它们接受一个函数作为参数，所有数组成员依次执行该函数。该函数接受三个参数：当前成员、当前位置和整个数组，然后返回一个布尔值。 some方法是只要一个成员的返回值是true，则整个some方法的返回值就是true，否则返回false。 every方法是所有成员的返回值都是true，整个every方法才返回true，否则返回false。 注意，对于空数组，some方法返回false，every方法返回true，回调函数都不会执行。 some和every方法还可以接受第二个参数，用来绑定参数函数内部的this变量。 reduce()，reduceRight()reduce方法和reduceRight方法依次处理数组的每个成员，最终累计为一个值。它们的差别是，reduce是从左到右处理（从第一个成员到最后一个成员），reduceRight则是从右到左（从最后一个成员到第一个成员），其他完全一样。 reduce方法和reduceRight方法的第一个参数都是一个函数。该函数接受以下四个参数。 这四个参数之中，只有前两个是必须的，后两个则是可选的。 如果要对累积变量指定初值，可以把它放在reduce方法和reduceRight方法的第二个参数。 由于这两个方法会遍历数组，所以实际上还可以用来做一些遍历相关的操作。 indexOf()，lastIndexOf()indexOf方法返回给定元素在数组中第一次出现的位置，如果没有出现则返回-1。 indexOf方法还可以接受第二个参数，表示搜索的开始位置。 lastIndexOf方法返回给定元素在数组中最后一次出现的位置，如果没有出现则返回-1。 注意，这两个方法不能用来搜索NaN的位置，即它们无法确定数组成员是否包含NaN。 这是因为这两个方法内部，使用严格相等运算符（===）进行比较，而NaN是唯一一个不等于自身的值。 链式使用包装对象定义对象是 JavaScript 语言最主要的数据类型，三种原始类型的值——数值、字符串、布尔值——在一定条件下，也会自动转为对象，也就是原始类型的“包装对象”。 所谓“包装对象”，就是分别与数值、字符串、布尔值相对应的Number、String、Boolean三个原生对象。这三个原生对象可以把原始类型的值变成（包装成）对象。 包装对象的最大目的，首先是使得 JavaScript 的对象涵盖所有的值，其次使得原始类型的值可以方便地调用某些方法。 Number、String和Boolean如果不作为构造函数调用（即调用时不加new），常常用于将任意类型的值转为数值、字符串和布尔值。 即，这三个对象作为构造函数使用（带有new）时，可以将原始类型的值转为对象；作为普通函数使用时（不带有new），可以将任意类型的值，转为原始类型的值。 实例方法包装对象的实例可以使用Object对象提供的原生方法，主要是valueOf方法和toString方法。 valueOf()valueOf方法返回包装对象实例对应的原始类型的值。 toString()toString方法返回对应的字符串形式。 原始类型与实例对象的自动转换原始类型的值，可以自动当作包装对象调用，即调用各种包装对象的属性和方法。这时，JavaScript 引擎会自动将原始类型的值转为包装对象实例，在使用后立刻销毁实例。 比如，字符串可以调用length属性，返回字符串的长度。 abc是一个字符串，本身不是对象，不能调用length属性。JavaScript 引擎自动将其转为包装对象，在这个对象上调用length属性。调用结束后，这个临时对象就会被销毁。这就叫原始类型与实例对象的自动转换。 自动转换生成的包装对象是只读的，无法修改。所以，字符串无法添加新属性。 调用结束后，包装对象实例会自动销毁。这意味着，下一次调用字符串的属性时，实际是调用一个新生成的对象，而不是上一次调用时生成的那个对象，所以取不到赋值在上一个对象的属性。如果要为字符串添加属性，只有在它的原型对象String.prototype上定义。 自定义方法三种包装对象除了提供很多原生的实例方法，还可以在原型上添加自定义方法和属性，供原始类型的值直接调用。 这种自定义方法和属性的机制，只能定义在包装对象的原型上，如果直接对原始类型的变量添加属性，则无效。 Boolean 对象概述Boolean对象是 JavaScript 的三个包装对象之一。作为构造函数，它主要用于生成布尔值的包装对象实例。 Boolean 函数的类型转换作用Boolean对象除了可以作为构造函数，还可以单独使用，将任意值转为布尔值。这时Boolean就是一个单纯的工具方法。 Number对象概述Number对象是数值对应的包装对象，可以作为构造函数使用，也可以作为工具函数使用。 作为构造函数时，它用于生成值为数值的对象。 属性 实例方法Number对象有4个实例方法，都跟将数值转换成指定格式有关。 Number.prototype.toString()Number对象部署了自己的toString方法，用来将一个数值转为字符串形式。 toString方法可以接受一个参数，表示输出的进制。如果省略这个参数，默认将数值先转为十进制，再输出字符串；否则，就根据参数指定的进制，将一个数字转化成某个进制的字符串。 10一定要放在括号里，这样表明后面的点表示调用对象属性。如果不加括号，这个点会被 JavaScript 引擎解释成小数点，从而报错。 除了为10加上括号，还可以在10后面加两个点，JavaScript 会把第一个点理解成小数点（即10.0），把第二个点理解成调用对象属性，从而得到正确结果。 意味着，可以直接对一个小数使用toString方法。 通过方括号运算符也可以调用toString方法。 toString方法只能将十进制的数，转为其他进制的字符串。如果要将其他进制的数，转回十进制，需要使用parseInt方法。 Number.prototype.toFixed()toFixed方法先将一个数转为指定位数的小数，然后返回这个小数对应的字符串。 Number.prototype.toExponential()toExponential方法用于将一个数转为科学计数法形式。 toExponential方法的参数是小数点后有效数字的位数，范围为0到20，超出这个范围，会抛出一个 RangeError 错误。 Number.prototype.toPrecision()toPrecision方法用于将一个数转为指定位数的有效数字。 toPrecision方法的参数为有效数字的位数，范围是1到21，超出这个范围会抛出 RangeError 错误。 toPrecision方法用于四舍五入时不太可靠，跟浮点数不是精确储存有关。 自定义方法与其他对象一样，Number.prototype对象上面可以自定义方法，被Number的实例继承。 注意，数值的自定义方法，只能定义在它的原型对象Number.prototype上面，数值本身是无法自定义属性的。 String对象概述String对象是 JavaScript 原生提供的三个包装对象之一，用来生成字符串对象。 字符串对象是一个类似数组的对象（很像数组，但不是数组）。 String对象还可以当作工具方法使用，将任意类型的值转为字符串。 静态方法String.fromCharCode()该方法的参数是一个或多个数值，代表 Unicode 码点，返回值是这些码点组成的字符串。 String.fromCharCode方法的参数为空，就返回空字符串；否则，返回参数对应的 Unicode 字符串。 注意，该方法不支持 Unicode 码点大于0xFFFF的字符，即传入的参数不能大于0xFFFF（即十进制的 65535）。 String.fromCharCode发现参数值大于0xFFFF，就会忽略多出的位（即忽略0x20BB7里面的2）。 码点大于0xFFFF的字符占用四个字节，而 JavaScript 默认支持两个字节的字符。这种情况下，必须把0x20BB7拆成两个字符表示。 码点大于0xFFFF的字符的四字节表示法，由 UTF-16 编码方法决定。 实例属性String.prototype.length字符串实例的length属性返回字符串的长度。 实例方法String.prototype.charAt()charAt方法返回指定位置的字符，参数是从0开始编号的位置。 如果参数为负数，或大于等于字符串的长度，charAt返回空字符串。 String.prototype.charCodeAt()charCodeAt方法返回字符串指定位置的 Unicode 码点（十进制表示），相当于String.fromCharCode()的逆操作。 如果没有任何参数，charCodeAt返回首字符的 Unicode 码点。 如果参数为负数，或大于等于字符串的长度，charCodeAt返回NaN。 charCodeAt方法返回的 Unicode 码点不会大于65536（0xFFFF），也就是说，只返回两个字节的字符的码点。如果遇到码点大于 65536 的字符（四个字节的字符），必需连续使用两次charCodeAt，不仅读入charCodeAt(i)，还要读入charCodeAt(i+1)，将两个值放在一起，才能得到准确的字符。 String.prototype.concat()concat方法用于连接两个字符串，返回一个新字符串，不改变原字符串。 如果参数不是字符串，concat方法会将其先转为字符串，然后再连接。 String.prototype.slice()slice方法用于从原字符串取出子字符串并返回，不改变原字符串。它的第一个参数是子字符串的开始位置，第二个参数是子字符串的结束位置（不含该位置）。 如果省略第二个参数，则表示子字符串一直到原字符串结束。 如果参数是负值，表示从结尾开始倒数计算的位置。 如果第一个参数大于第二个参数，slice方法返回一个空字符串。 String.prototype.substring()substring方法用于从原字符串取出子字符串并返回，不改变原字符串，跟slice方法很相像。它的第一个参数表示子字符串的开始位置，第二个位置表示结束位置（返回结果不含该位置）。 如果省略第二个参数，则表示子字符串一直到原字符串的结束。 如果第一个参数大于第二个参数，substring方法会自动更换两个参数的位置。 如果参数是负数，substring方法会自动将负数转为0。 由于这些规则违反直觉，因此不建议使用substring方法，应该优先使用slice。 String.prototype.substr()substr方法用于从原字符串取出子字符串并返回，不改变原字符串，跟slice和substring方法的作用相同。 substr方法的第一个参数是子字符串的开始位置（从0开始计算），第二个参数是子字符串的长度。 如果省略第二个参数，则表示子字符串一直到原字符串的结束。 如果第一个参数是负数，表示倒数计算的字符位置。如果第二个参数是负数，将被自动转为0，因此会返回空字符串。 String.prototype.indexOf()，String.prototype.lastIndexOf()indexOf方法用于确定一个字符串在另一个字符串中第一次出现的位置，返回结果是匹配开始的位置。如果返回-1，就表示不匹配。 indexOf方法还可以接受第二个参数，表示从该位置开始向后匹配。 lastIndexOf方法的用法跟indexOf方法一致，主要的区别是lastIndexOf从尾部开始匹配，indexOf则是从头部开始匹配。 lastIndexOf的第二个参数表示从该位置起向前匹配。 String.prototype.trim()trim方法用于去除字符串两端的空格，返回一个新字符串，不改变原字符串。 该方法去除的不仅是空格，还包括制表符（\\t、\\v）、换行符（\\n）和回车符（\\r）。 String.prototype.toLowerCase()，String.prototype.toUpperCase()toLowerCase方法用于将一个字符串全部转为小写，toUpperCase则是全部转为大写。它们都返回一个新字符串，不改变原字符串。 String.prototype.match()match方法用于确定原字符串是否匹配某个子字符串，返回一个数组，成员为匹配的第一个字符串。如果没有找到匹配，则返回null。 match方法还可以使用正则表达式作为参数。 String.prototype.search()，String.prototype.replace()search方法的用法基本等同于match，但是返回值为匹配的第一个位置。如果没有找到匹配，则返回-1。 search方法还可以使用正则表达式作为参数。 replace方法用于替换匹配的子字符串，一般情况下只替换第一个匹配。 replace方法还可以使用正则表达式作为参数。 String.prototype.split()split方法按照给定规则分割字符串，返回一个由分割出来的子字符串组成的数组。 如果分割规则为空字符串，则返回数组的成员是原字符串的每一个字符。 如果省略参数，则返回数组的唯一成员就是原字符串。 如果满足分割规则的两个部分紧邻着（即两个分割符中间没有其他字符），则返回数组之中会有一个空字符串。 如果满足分割规则的部分处于字符串的开头或结尾（即它的前面或后面没有其他字符），则返回数组的第一个或最后一个成员是一个空字符串。 split方法还可以接受第二个参数，限定返回数组的最大成员数。 split方法还可以使用正则表达式作为参数。 String.prototype.localeCompare()localeCompare方法用于比较两个字符串。它返回一个整数，如果小于0，表示第一个字符串小于第二个字符串；如果等于0，表示两者相等；如果大于0，表示第一个字符串大于第二个字符串。 该方法的最大特点，就是会考虑自然语言的顺序。举例来说，正常情况下，大写的英文字母小于小写字母。 JavaScript 采用的是 Unicode 码点比较但是，localeCompare方法会考虑自然语言的排序情况，大写字母比小写字母大。 localeCompare还可以有第二个参数，指定所使用的语言（默认是英语），然后根据该语言的规则进行比较。 Math对象Math是 JavaScript 的原生对象，提供各种数学功能。该对象不是构造函数，不能生成实例，所有的属性和方法都必须在Math对象上调用。 静态属性 这些属性都是只读的，不能修改。 静态方法 Math.max方法返回参数之中最大的那个值，Math.min返回最小的那个值。如果参数为空, Math.min返回Infinity, Math.max返回-Infinity。 Math.floor方法返回小于参数值的最大整数（地板值）。 Math.ceil方法返回大于参数值的最小整数（天花板值）。 Math.pow方法返回以第一个参数为底数、第二个参数为幂的指数值。 Math.sqrt方法返回参数值的平方根。如果参数是一个负值，则返回NaN。 如果要计算以10为底的对数，可以先用Math.log求出自然对数，然后除以Math.LN10；求以2为底的对数，可以除以Math.LN2。 Math.random()返回0到1之间的一个伪随机数，可能等于0，但是一定小于1。 三角函数方法 Date对象Date对象是 JavaScript 原生的时间库。它以1970年1月1日00:00:00作为时间的零点，可以表示的时间范围是前后各1亿天（单位为毫秒）。 普通函数的用法Date对象可以作为普通函数直接调用，返回一个代表当前时间的字符串。 即使带有参数，Date作为普通函数使用时，返回的还是当前时间。 无论有没有参数，直接调用Date总是返回当前时间。 构造函数的用法Date还可以当作构造函数使用。对它使用new命令，会返回一个Date对象的实例。如果不加参数，实例代表的就是当前时间。 Date实例有一个独特的地方。其他对象求值的时候，都是默认调用.valueOf()方法，但是Date实例求值的时候，默认调用的是toString()方法。这导致对Date实例求值，返回的是一个字符串，代表该实例对应的时间。 作为构造函数时，Date对象可以接受多种格式的参数，返回一个该参数对应的时间实例。 关于Date构造函数的参数， 第一点，参数可以是负整数，代表1970年元旦之前的时间。 第二点，只要是能被Date.parse()方法解析的字符串，都可以当作参数。 第三，参数为年、月、日等多个整数时，年和月是不能省略的，其他参数都可以省略的。也就是说，这时至少需要两个参数，因为如果只使用“年”这一个参数，Date会将其解释为毫秒数。 各个参数的取值范围如下。 注意，月份从0开始计算，但是，天数从1开始计算。另外，除了日期的默认值为1，小时、分钟、秒钟和毫秒的默认值都是0。 这些参数如果超出了正常范围，会被自动折算。比如，如果月设为15，就折算为下一年的4月。 日期设为0，就代表上个月的最后一天。 参数还可以使用负数，表示扣去的时间。 日期的运算类型自动转换时，Date实例如果转为数值，则等于对应的毫秒数；如果转为字符串，则等于对应的日期字符串。所以，两个日期实例对象进行减法运算时，返回的是它们间隔的毫秒数；进行加法运算时，返回的是两个字符串连接而成的新字符串。 静态方法Date.now()Date.now方法返回当前时间距离时间零点（1970年1月1日 00:00:00 UTC）的毫秒数，相当于 Unix 时间戳乘以1000。 Date.parse()Date.parse方法用来解析日期字符串，返回该时间距离时间零点（1970年1月1日 00:00:00）的毫秒数。 日期字符串应该符合 RFC 2822 和 ISO 8061 这两个标准，即YYYY-MM-DDTHH:mm:ss.sssZ格式，其中最后的Z表示时区 如果解析失败，返回NaN。 Date.UTC()Date.UTC方法接受年、月、日等变量作为参数，返回该时间距离时间零点（1970年1月1日 00:00:00 UTC）的毫秒数。 该方法的参数用法与Date构造函数完全一致，比如月从0开始计算，日期从1开始计算。区别在于Date.UTC方法的参数，会被解释为 UTC 时间（世界标准时间），Date构造函数的参数会被解释为当前时区的时间。 实例方法Date的实例对象，有几十个自己的方法，除了valueOf和toString，可以分为以下三类。 Date.prototype.valueOf()valueOf方法返回实例对象距离时间零点（1970年1月1日00:00:00 UTC）对应的毫秒数，该方法等同于getTime方法。 to 类方法Date.prototype.toString()toString方法返回一个完整的日期字符串。 Date.prototype.toUTCString()toUTCString方法返回对应的 UTC 时间，也就是比北京时间晚8个小时。 Date.prototype.toISOString()toISOString方法返回对应时间的 ISO8601 写法。 toISOString方法返回的总是 UTC 时区的时间。 Date.prototype.toJSON()toJSON方法返回一个符合 JSON 格式的 ISO 日期字符串，与toISOString方法的返回结果完全相同。 Date.prototype.toDateString()toDateString方法返回日期字符串（不含小时、分和秒）。 Date.prototype.toTimeString()toTimeString方法返回时间字符串（不含年月日）。 Date.prototype.toLocaleDateString()toLocaleDateString方法返回一个字符串，代表日期的当地写法（不含小时、分和秒）。 get类方法Date对象提供了一系列get*方法，用来获取实例对象某个方面的值。 所有这些get*方法返回的都是整数，不同方法返回值的范围不一样。 上面这些get*方法返回的都是当前时区的时间，Date对象还提供了这些方法对应的 UTC 版本，用来返回 UTC 时间。 set 类方法Date对象提供了一系列set*方法，用来设置实例对象的各个方面。 set*方法的参数都会自动折算。以setDate为例，如果参数超过当月的最大天数，则向下一个月顺延，如果参数是负数，表示从上个月的最后一天开始减去的天数。 set*系列方法除了setTime()和setYear()，都有对应的 UTC 版本，即设置 UTC 时区的时间。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"JavaScript标准参考教程 语法 一","slug":"JavaScript标准参考教程 语法 一","date":"2018-08-14T02:36:56.000Z","updated":"2018-09-01T05:53:32.000Z","comments":true,"path":"2018/08/14/JavaScript标准参考教程 语法 一/","link":"","permalink":"https://github.com/zdkswd/2018/08/14/JavaScript标准参考教程 语法 一/","excerpt":"","text":"基本语法语句 var a=1+3; 分号语句结束。 变量JavaScript 是一种动态类型语言，也就是说，变量的类型没有限制，变量可以随时更改类型。 var a = 1;a = ‘hello’; 变量提升JavaScript 引擎的工作方式是，先解析代码，获取所有被声明的变量，然后再一行一行地运行。这造成的结果，就是所有的变量的声明语句，都会被提升到代码的头部，这就叫做变量提升（hoisting）。 标识符中文是合法的标识符，可以用作变量名。第一个字符，可以是任意 Unicode 字母（包括英文字母和其他语言的字母），以及美元符号（$）和下划线（_）。 注释//单行/*多行*/由于历史上 JavaScript 可以兼容 HTML 代码的注释，所以也被视为合法的单行注释。 区块JavaScript 使用大括号，将多个相关的语句组合在一起，称为“区块”（block）。对于var命令来说，JavaScript 的区块不构成单独的作用域（scope）。 条件语句if和switch 还有三元运算符if switch与c一样。 循环语句while \\for\\ do..whilewhile for do..while语法与c一样。break退出循环，continue退出本轮循环。 JavaScript 语言允许，语句的前面有标签（label），相当于定位符，用于跳转到程序的任意位置。与汇编语言类似。标签:标签通常与break语句和continue语句配合使用，跳出特定的循环. 数据类型概述JavaScript 语言的每一个值，都属于某一种数据类型。JavaScript 的数据类型，共有六种。（ES6 又新增了第七种 Symbol 类型的值，本教程不涉及。） JavaScript中的值分为2大类：基本类型和引用类型。基本类型：数字类型：Number；字符串类型：String；布尔类型：Boolean(true和false)；Undefined；Null。 引用类型：对象。 对象是最复杂的数据类型，又可以分成三个子类型。 狭义的对象和数组是两种不同的数据组合方式，除非特别声明，本教程的”对象“都特指狭义的对象。函数其实是处理数据的方法，JavaScript 把它当成一种数据类型，可以赋值给变量，这为编程带来了很大的灵活性，也为 JavaScript 的“函数式编程”奠定了基础。 在将一个值赋给变量时，解析器必须确定这个值是基本类型值还是引用类型值。 对基本类型，是按值访问的，即通过值复制的方式来赋值和传递。对引用类型，是按引用访问的，即通过引用复制的方式赋值和传递。 当一个变量进行赋值操作时，就是在重新将变量进行指向。 typeof 运算符JavaScript 有三种方法，可以确定一个值到底是什么类型。 typeof可以用来检查一个没有声明的变量，而不报错。 instanceof运算符可以区分数组和对象。 typeof null的类型是object，这是由于历史原因造成的。 null 和 undefinednull与undefined都可以表示“没有”，含义非常相似。将一个变量赋值为undefined或null，老实说，语法效果几乎没区别。 在if语句中，它们都会被自动转为false，相等运算符（==）甚至直接报告两者相等。 区别是这样的：null是一个表示“空”的对象，转为数值时为0；undefined是一个表示”此处无定义”的原始值，转为数值时为NaN。 布尔值 如果 JavaScript 预期某个位置应该是布尔值，会将该位置上现有的值自动转为布尔值。转换规则是除了下面六个值被转为false，其他值都视为true。 空数组（[]）和空对象（{}）对应的布尔值，都是true。 数值概述JavaScript 内部，所有数字都是以64位浮点数形式储存，即使整数也是如此。所以，1与1.0是相同的，是同一个数。这就是说，JavaScript 语言的底层根本没有整数，所有数字都是小数（64位浮点数）。某些运算只有整数才能完成，此时 JavaScript 会自动把64位浮点数，转成32位整数，然后再进行运算。由于浮点数不是精确的值，所以涉及小数的比较和运算要特别小心。 数值精度根据国际标准 IEEE 754，JavaScript 浮点数的64个二进制位，从最左边开始，是这样组成的。 有效数字的第一位默认总是1。 数值范围 如果一个数小于等于2的-1075次方（指数部分最小值-1023，再加上小数部分的52位），那么就会发生为“负向溢出”，即 JavaScript 无法表示这么小的数，这时会直接返回0。 数值的表示法JavaScript 的数值有多种表示方法，可以用字面形式直接表示，比如35（十进制）和0xFF（十六进制）。数值也可以采用科学计数法表示。 科学计数法允许字母e或E的后面，跟着一个整数，表示这个数值的指数部分。 以下两种情况，JavaScript 会自动将数值转为科学计数法表示，其他情况都采用字面形式直接表示。（1）小数点前的数字多于21位。（2）小数点后的零多于5个。 数值的进制JavaScript 对整数提供四种进制的表示方法：十进制、十六进制、八进制、二进制。 默认情况下，JavaScript 内部会自动将八进制、十六进制、二进制转为十进制。 如果八进制、十六进制、二进制的数值里面，出现不属于该进制的数字，就会报错。 有前导0的数值会被视为八进制，但是如果前导0后面有数字8和9，则该数值被视为十进制。 特殊数值正零和负零JavaScript 内部实际上存在2个0：一个是+0，一个是-0，区别就是64位浮点数表示法的符号位不同。它们是等价的。几乎所有场合，正零和负零都会被当作正常的0。唯一有区别的场合是，+0或-0当作分母，返回的值是不相等的。上面的代码之所以出现这样结果，是因为除以正零得到+Infinity，除以负零得到-Infinity，这两者是不相等的。NaNNaN是 JavaScript 的特殊值，表示“非数字”（Not a Number），主要出现在将字符串解析成数字出错的场合。 0除以0也会得到NaN。 NaN不是独立的数据类型，而是一个特殊数值，它的数据类型依然属于Number，使用typeof运算符可以看得很清楚。 NaN不等于任何值，包括它本身。 数组的indexOf方法内部使用的是严格相等运算符，所以该方法对NaN不成立。 NaN在布尔运算时被当作false。 NaN与任何数（包括它自己）的运算，得到的都是NaN。InfinityInfinity表示“无穷”，用来表示两种场景。一种是一个正的数值太大，或一个负的数值太小，无法表示；另一种是非0数值除以0，得到Infinity。 Infinity有正负之分，Infinity表示正的无穷，-Infinity表示负的无穷。 由于数值正向溢出（overflow）、负向溢出（underflow）和被0除，JavaScript 都不报错，而是返回Infinity，所以单纯的数学运算几乎没有可能抛出错误。 Infinity大于一切数值（除了NaN），-Infinity小于一切数值（除了NaN）。 Infinity与NaN比较，总是返回false。 Infinity的四则运算，符合无穷的数学计算规则。 0乘以Infinity，返回NaN；0除以Infinity，返回0；Infinity除以0，返回Infinity。 Infinity减去或除以Infinity，得到NaN。 Infinity与null计算时，null会转成0，等同于与0的计算。 Infinity与undefined计算，返回的都是NaN。 与数值相关的全局方法parseInt方法用于将字符串转为整数。如果字符串头部有空格，空格会被自动去除。如果parseInt的参数不是字符串，则会先转为字符串再转换。 字符串转为整数的时候，是一个个字符依次转换，如果遇到不能转为数字的字符，就不再进行下去，返回已经转好的部分。如果字符串的第一个字符不能转化为数字（后面跟着数字的正负号除外），返回NaN。 所以，parseInt的返回值只有两种可能，要么是一个十进制整数，要么是NaN。 如果字符串以0x或0X开头，parseInt会将其按照十六进制数解析。 如果字符串以0开头，将其按照10进制解析。 对于那些会自动转为科学计数法的数字，parseInt会将科学计数法的表示方法视为字符串，因此导致一些奇怪的结果。 进制转换parseInt方法还可以接受第二个参数（2到36之间），表示被解析的值的进制，返回该值对应的十进制数。 如果第二个参数不是数值，会被自动转为一个整数。这个整数只有在2到36之间，才能得到有意义的结果，超出这个范围，则返回NaN。如果第二个参数是0、undefined和null，则直接忽略。 如果字符串包含对于指定进制无意义的字符，则从最高位开始，只返回可以转换的数值。如果最高位无法转换，则直接返回NaN。 前面说过，如果parseInt的第一个参数不是字符串，会被先转为字符串。这会导致一些令人意外的结果。 JavaScript 不再允许将带有前缀0的数字视为八进制数，而是要求忽略这个0。但是，为了保证兼容性，大部分浏览器并没有部署这一条规定。 parseFloat()parseFloat方法用于将一个字符串转为浮点数。 如果字符串符合科学计数法，则会进行相应的转换。 如果字符串包含不能转为浮点数的字符，则不再进行往后转换，返回已经转好的部分。 parseFloat方法会自动过滤字符串前导的空格。 如果参数不是字符串，或者字符串的第一个字符不能转化为浮点数，则返回NaN。 上面代码中，尤其值得注意，parseFloat会将空字符串转为NaN。这些特点使得parseFloat的转换结果不同于Number函数。 isNaNisNaN方法可以用来判断一个值是否为NaN。 但是，isNaN只对数值有效，如果传入其他值，会被先转成数值。比如，传入字符串的时候，字符串会被先转成NaN，所以最后返回true，这一点要特别引起注意。也就是说，isNaN为true的值，有可能不是NaN，而是一个字符串。 出于同样的原因，对于对象和数组，isNaN也返回true。 但是，对于空数组和只有一个数值成员的数组，isNaN返回false。 上面代码之所以返回false，原因是这些数组能被Number函数转成数值。 因此，使用isNaN之前，最好判断一下数据类型。 判断NaN更可靠的方法是，利用NaN为唯一不等于自身的值的这个特点，进行判断。 isFinite（）isFinite方法返回一个布尔值，表示某个值是否为正常的数值。 除了Infinity、-Infinity、NaN和undefined这几个值会返回false，isFinite对于其他的数值都会返回true。 字符串概述字符串就是零个或多个排在一起的字符，放在单引号或双引号之中。 单引号字符串的内部，可以使用双引号。双引号字符串的内部，可以使用单引号。 如果要在单引号字符串的内部，使用单引号，就必须在内部的单引号前面加上反斜杠，用来转义。双引号字符串内部使用双引号，也是如此。 字符串默认只能写在一行内，分成多行将会报错。 如果长字符串必须分成多行，可以在每一行的尾部使用反斜杠。注意，反斜杠的后面必须是换行符，而不能有其他字符（比如空格），否则会报错。 连接运算符（+）可以连接多个单行字符串，将长字符串拆成多行书写，输出的时候也是单行。 转义 反斜杠还有三种特殊用法。 如果在非特殊字符前面使用反斜杠，则反斜杠会被省略。如果字符串的正常内容之中，需要包含反斜杠，则反斜杠前面需要再加一个反斜杠，用来对自身转义。 字符串与数组字符串可以被视为字符数组，因此可以使用数组的方括号运算符，用来返回某个位置的字符（位置编号从0开始）。 但是，字符串与数组的相似性仅此而已。实际上，无法改变字符串之中的单个字符。 字符串内部的单个字符无法改变和增删，这些操作会默默地失败。 length 属性length属性返回字符串的长度，该属性也是无法改变的。但是不会报错。 字符集JavaScript 使用 Unicode 字符集。JavaScript 引擎内部，所有字符都用 Unicode 表示。 JavaScript 不仅以 Unicode 储存字符，还允许直接在程序中使用 Unicode 码点表示字符，即将字符写成\\uxxxx的形式，其中xxxx代表该字符的 Unicode 码点。比如，\\u00A9代表版权符号。 解析代码的时候，JavaScript 会自动识别一个字符是字面形式表示，还是 Unicode 形式表示。输出给用户的时候，所有字符都会转成字面形式。 每个字符在 JavaScript 内部都是以16位（即2个字节）的 UTF-16 格式储存。也就是说，JavaScript 的单位字符长度固定为16位长度，即2个字节。 但是，UTF-16 有两种长度。对于码点在U+0000到U+FFFF之间的字符，长度为16位（即2个字节）；对于码点在U+10000到U+10FFFF之间的字符，长度为32位（即4个字节），而且前两个字节在0xD800到0xDBFF之间，后两个字节在0xDC00到0xDFFF之间。 JavaScript 对 UTF-16 的支持是不完整的，由于历史原因，只支持两字节的字符，不支持四字节的字符。 总结一下，对于码点在U+10000到U+10FFFF之间的字符，JavaScript 总是认为它们是两个字符（length属性为2）。所以处理的时候，必须把这一点考虑在内，也就是说，JavaScript 返回的字符串长度可能是不正确的。 Base64 转码有时，文本里面包含一些不可打印的符号，比如 ASCII 码0到31的符号都无法打印出来，这时可以使用 Base64 编码，将它们转成可以打印的字符。另一个场景是，有时需要以文本格式传递二进制数据，那么也可以使用 Base64 编码。 所谓 Base64 就是一种编码方法，可以将任意值转成 0～9、A～Z、a-z、+和/这64个字符组成的可打印字符。使用它的主要目的，不是为了加密，而是为了不出现特殊字符，简化程序的处理。 JavaScript 原生提供两个 Base64 相关的方法。 两个方法不适合非 ASCII 码的字符，会报错。 要将非 ASCII 码字符转为 Base64 编码，必须中间插入一个转码环节，再使用这两个方法。 对象概述简单说，对象就是一组“键值对”（key-value）的集合，是一种无序的复合数据集合。 键名对象的所有键名都是字符串（ES6 又引入了 Symbol 值也可以作为键名），所以加不加引号都可以。 如果键名是数值，会被自动转为字符串。 如果键名不符合标识名的条件（比如第一个字符为数字，或者含有空格或运算符），且也不是数字，则必须加上引号，否则会报错。 对象的每一个键名又称为“属性”（property），它的“键值”可以是任何数据类型。如果一个属性的值为函数，通常把这个属性称为“方法”，它可以像函数那样调用。 如果属性的值还是一个对象，就形成了链式引用。 对象的属性之间用逗号分隔，最后一个属性后面可以加逗号（trailing comma），也可以不加。 属性可以动态创建，不必在对象声明时就指定。 对象的引用如果不同的变量名指向同一个对象，那么它们都是这个对象的引用，也就是说指向同一个内存地址。修改其中一个变量，会影响到其他所有变量。 其中任何一个变量添加属性，另一个变量都可以读写该属性。 如果取消某一个变量对于原对象的引用，不会影响到另一个变量。 这种引用只局限于对象，如果两个变量指向同一个原始类型的值。那么，变量这时都是值的拷贝。 表达式还是语句对象采用大括号表示，这导致了一个问题：如果行首是一个大括号，它到底是表达式还是语句？ V8 引擎规定，如果行首是大括号，一律解释为对象。不过，为了避免歧义，最好还是在大括号前加上圆括号。 属性的操作读取对象的属性，有两种方法，一种是使用点运算符，还有一种是使用方括号运算符。 注意，如果使用方括号运算符，键名必须放在引号里面，否则会被当作变量处理。 数字键可以不加引号，因为会自动转成字符串。 注意，数值键名不能使用点运算符（因为会被当成小数点），只能使用方括号运算符。 属性的赋值点运算符和方括号运算符，不仅可以用来读取值，还可以用来赋值。 JavaScript 允许属性的“后绑定”，也就是说，你可以在任意时刻新增属性，没必要在定义对象的时候，就定义好属性。 查看所有属性查看一个对象本身的所有属性，可以使用Object.keys方法。 delete 命令delete命令用于删除对象的属性，删除成功后返回true。delete A[属性名]；。 注意，删除一个不存在的属性，delete不报错，而且返回true。因此，不能根据delete命令的结果，认定某个属性是存在的。 只有一种情况，delete命令会返回false，那就是该属性存在，且不得删除。 注意，delete命令只能删除对象本身的属性，无法删除继承的属性。即为即使delete返回true，该属性依然可能读取到值。 in 运算符in运算符用于检查对象是否包含某个属性（注意，检查的是键名，不是键值），如果包含就返回true，否则返回false。 in运算符的一个问题是，它不能识别哪些属性是对象自身的，哪些属性是继承的。 for…in 循环for…in循环有两个使用注意点。 如果继承的属性是可遍历的，那么就会被for…in循环遍历到。但是，一般情况下，都是只想遍历对象自身的属性，所以使用for…in的时候，应该结合使用hasOwnProperty方法，在循环内部判断一下，某个属性是否为对象自身的属性。 with 语句 它的作用是操作同一个对象的多个属性时，提供一些书写的方便。 注意，如果with区块内部有变量的赋值操作，必须是当前对象已经存在的属性，否则会创造一个当前作用域的全局变量。 因为with区块没有改变作用域，它的内部依然是当前作用域。这造成了with语句的一个很大的弊病，就是绑定对象不明确。 因此，建议不要使用with语句，可以考虑用一个临时变量代替with。 数组定义数组用方括号表示。任何类型的数据，都可以放入数组。 数组本质本质上，数组属于一种特殊的对象。数组的特殊性体现在，它的键名是按次序排列的一组整数（0，1，2…）。JavaScript 语言规定，对象的键名一律为字符串，所以，数组的键名其实也是字符串。之所以可以用数值读取，是因为非字符串的键名会被转为字符串。 length属性清空数组的一个有效方法，就是将length属性设为0。如果人为设置length大于当前元素个数，则数组的成员数量会增加到这个值，新增的位置都是空位。 in运算符检查某个键名是否存在的运算符in，适用于对象，也适用于数组。 for…in 循环和数组的遍历for…in循环不仅可以遍历对象，也可以遍历数组，毕竟数组只是一种特殊对象。 但是，for…in不仅会遍历数组所有的数字键，还会遍历非数字键。所以，不推荐使用for…in遍历数组。数组的遍历可以考虑使用for循环或while循环。 数组的forEach方法，也可以用来遍历数组。 数组的空位当数组的某个位置是空元素，即两个逗号之间没有任何值，我们称该数组存在空位（hole）。数组的空位不影响length属性。数组最后一个成员后面有一个逗号，这不影响length属性的值。数组的空位是可以读取的，返回undefined。使用delete命令删除一个数组成员，会形成空位，并且不会影响length属性。 类似数组的对象如果一个对象的所有键名都是正整数或零，并且有length属性，那么这个对象就很像数组，语法上称为“类似数组的对象”（array-like object）。 “类似数组的对象”并不是数组，因为它们不具备数组特有的方法。对象obj没有数组的push方法，使用该方法就会报错。 “类似数组的对象”的根本特征，就是具有length属性。只要有length属性，就可以认为这个对象类似于数组。但是有一个问题，这种length属性不是动态值，不会随着成员的变化而变化。 典型的“类似数组的对象”是函数的arguments对象，以及大多数 DOM 元素集，还有字符串。 数组的slice方法可以将“类似数组的对象”变成真正的数组。 除了转为真正的数组，“类似数组的对象”还有一个办法可以使用数组的方法，就是通过call()把数组的方法放到对象上面。 字符串也是类似数组的对象，所以也可以用Array.prototype.forEach.call遍历。 注意，这种方法比直接使用数组原生的forEach要慢，所以最好还是先将“类似数组的对象”转为真正的数组，然后再直接调用数组的forEach方法。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"JavaScript标准参考教程 语法 二","slug":"JavaScript标准参考教程 语法 二","date":"2018-08-14T02:36:56.000Z","updated":"2018-09-01T05:56:42.000Z","comments":true,"path":"2018/08/14/JavaScript标准参考教程 语法 二/","link":"","permalink":"https://github.com/zdkswd/2018/08/14/JavaScript标准参考教程 语法 二/","excerpt":"","text":"函数概述JavaScript 有三种声明函数的方法。 function 命令function命令声明的代码区块，就是一个函数。function命令后面是函数名，函数名后面是一对圆括号，里面是传入函数的参数。函数体放在大括号里面。 函数表达式除了用function命令声明函数，还可以采用变量赋值的写法。 这种写法将一个匿名函数赋值给变量。 采用函数表达式声明函数时，function命令后面不带有函数名。如果加上函数名，该函数名只在函数体内部有效，在函数体外部无效。 这种写法的用处有两个，一是可以在函数体内部调用自身，二是方便除错（除错工具显示函数调用栈时，将显示函数名，而不再显示这里是一个匿名函数）。因此，下面的形式声明函数也非常常见。 注意，函数的表达式需要在语句的结尾加上分号，表示语句结束。而函数的声明在结尾的大括号后面不用加分号。 Function 构造函数 你可以传递任意数量的参数给Function构造函数，只有最后一个参数会被当做函数体，如果只有一个参数，该参数就是函数体。 这种声明函数的方式非常不直观，几乎无人使用。 函数的重复声明如果同一个函数被多次声明，后面的声明就会覆盖前面的声明。 圆括号运算符，return 语句和递归第一等公民JavaScript 语言将函数看作一种值，与其它值（数值、字符串、布尔值等等）地位相同。凡是可以使用值的地方，就能使用函数。比如，可以把函数赋值给变量和对象的属性，也可以当作参数传入其他函数，或者作为函数的结果返回。函数只是一个可以执行的值，此外并无特殊之处。 由于函数与其他数据类型地位平等，所以在 JavaScript 语言中又称函数为第一等公民。 函数名的提升JavaScript 引擎将函数名视同变量名，所以采用function命令声明函数时，整个函数会像变量声明一样，被提升到代码头部。 由于“变量提升”，函数f被提升到了代码头部，也就是在调用之前已经声明了。但是，如果采用赋值语句定义函数，JavaScript 就会报错。 不能在条件语句中声明函数根据 ES5 的规范，不得在非函数的代码块中声明函数，最常见的情况就是if和try语句。 但是，实际情况是各家浏览器往往并不报错，能够运行。 但是由于存在函数名的提升，所以在条件语句中声明函数，可能是无效的，这是非常容易出错的地方。 要达到在条件语句中定义函数的目的，只有使用函数表达式。 函数的属性和方法name属性函数的name属性返回函数的名字。 如果是通过变量赋值定义的函数，那么name属性返回变量名。 只有在变量的值是一个匿名函数时才是如此。如果变量的值是一个具名函数，那么name属性返回function关键字之后的那个函数名。 name属性的一个用处，就是获取参数函数的名字。 length属性函数的length属性返回函数预期传入的参数个数，即函数定义之中的参数个数。 length属性提供了一种机制，判断定义时和调用时参数的差异，以便实现面向对象编程的”方法重载“（overload）。 toString()函数的toString方法返回一个字符串，内容是函数的源码。 函数内部的注释也可以返回。 函数作用域定义函数外部声明的变量就是全局变量（global variable），它可以在函数内部读取。 在函数内部定义的变量，外部无法读取，称为“局部变量”（local variable）。 函数内部定义的变量，会在该作用域内覆盖同名全局变量。 函数内部的变量提升与全局作用域一样，函数作用域内部也会产生“变量提升”现象。var命令声明的变量，不管在什么位置，变量声明都会被提升到函数体的头部。 函数本身的作用域函数本身也是一个值，也有自己的作用域。它的作用域与变量一样，就是其声明时所在的作用域，与其运行时所在的作用域无关。 参数概述函数运行的时候，有时需要提供外部数据，不同的外部数据会得到不同的结果，这种外部数据就叫参数。 参数的省略函数参数不是必需的，Javascript 允许省略参数。 运行时无论提供多少个参数（或者不提供参数），JavaScript 都不会报错。省略的参数的值就变为undefined。 注意，函数的length属性与实际传入的参数个数无关，只反映函数预期传入的参数个数。 传递方式函数参数如果是原始类型的值（数值、字符串、布尔值），传递方式是传值传递（passes by value）。这意味着，在函数体内修改参数值，不会影响到函数外部。 如果函数参数是复合类型的值（数组、对象、其他函数），传递方式是传址传递（pass by reference）。也就是说，传入函数的原始值的地址，因此在函数内部修改参数，将会影响到原始值。 注意，如果函数内部修改的，不是参数对象的某个属性，而是替换掉整个参数，这时不会影响到原始值。 重新对o赋值导致o指向另一个地址，保存在原地址上的值当然不受影响。 同名参数如果有同名的参数，则取最后出现的那个值。 arguments 对象由于 JavaScript 允许函数有不定数目的参数，所以需要一种机制，可以在函数体内部读取所有参数。这就是arguments对象的由来。 rguments对象包含了函数运行时的所有参数，arguments[0]就是第一个参数，arguments[1]就是第二个参数，以此类推。这个对象只有在函数体内部，才可以使用。 正常模式下，arguments对象可以在运行时修改。 严格模式下，arguments对象是一个只读对象，修改它是无效的，但不会报错。 通过arguments对象的length属性，可以判断函数调用时到底带几个参数。 与数组的关系需要注意的是，虽然arguments很像数组，但它是一个对象。数组专有的方法（比如slice和forEach），不能在arguments对象上直接使用。 callee属性arguments对象带有一个callee属性，返回它所对应的原函数。 可以通过arguments.callee，达到调用函数自身的目的。这个属性在严格模式里面是禁用的，因此不建议使用。 函数的其他知识点闭包闭包（closure）是 Javascript 语言的一个难点，也是它的特色，很多高级应用都要依靠闭包实现。 出于种种原因，需要得到函数内的局部变量。正常情况下，这是办不到的，只有通过变通方法才能实现。那就是在函数的内部，再定义一个函数。 闭包就是函数f2，即能够读取其他函数内部变量的函数。由于在 JavaScript 语言中，只有函数内部的子函数才能读取内部变量，因此可以把闭包简单理解成“定义在一个函数内部的函数”。 闭包最大的特点，就是它可以“记住”诞生的环境，比如f2记住了它诞生的环境f1，所以从f2可以得到f1的内部变量。在本质上，闭包就是将函数内部和函数外部连接起来的一座桥梁。 闭包的最大用处有两个，一个是可以读取函数内部的变量，另一个就是让这些变量始终保持在内存中，即闭包可以使得它诞生环境一直存在。 原因就在于inc始终在内存中，而inc的存在依赖于createIncrementor，因此也始终在内存中，不会在调用结束后，被垃圾回收机制回收。 闭包的另一个用处，是封装对象的私有属性和私有方法。 注意，外层函数每次运行，都会生成一个新的闭包，而这个闭包又会保留外层函数的内部变量，所以内存消耗很大。因此不能滥用闭包，否则会造成网页的性能问题。 立即调用的函数表达式（IIFE） 通常情况下，只对匿名函数使用这种“立即执行的函数表达式”。它的目的有两个：一是不必为函数命名，避免了污染全局变量；二是 IIFE 内部形成了一个单独的作用域，可以封装一些外部无法读取的私有变量。 eval 命令eval命令的作用是，将字符串当作语句执行。 eval的命令字符串不会得到 JavaScript 引擎的优化，运行速度较慢。这也是一个不应该使用它的理由。 运算符加法运算符JavaScript 允许非数值的相加。如果是两个字符串相加，这时加法运算符会变成连接运算符，返回一个新的字符串，将两个原字符串连接在一起。如果一个运算子是字符串，另一个运算子是非字符串，这时非字符串会转成字符串，再连接在一起。 除了加法运算符，其他算术运算符（比如减法、除法和乘法）都不会发生重载。它们的规则是：所有运算子一律转为数值，再进行相应的数学运算。 对象的相加如果运算子是对象，必须先转成原始类型的值，然后再相加。 算数运算符 余数运算符运算结果的正负号由第一个运算子的正负号决定。 余数运算符还可以用于浮点数的运算。但是，由于浮点数不是精确的值，无法得到完全准确的结果。 赋值运算符比较运算符 相等比较和非相等比较。两者的规则是不一样的，对于非相等的比较，算法是先看两个运算子是否都是字符串，如果是的，就按照字典顺序比较（实际上是比较 Unicode 码点）；否则，将两个运算子都转成数值，再比较数值的大小。 字符串的比较字符串按照字典顺序进行比较。 JavaScript 引擎内部首先比较首字符的 Unicode 码点。如果相等，再比较第二个字符的 Unicode 码点，以此类推。 非字符串的比较两个原始类型的值的比较，除了相等运算符（==）和严格相等运算符（===），其他比较运算符都是先转成数值再比较。 字符串和布尔值都会先转成数值，再进行比较。 特殊情况，即任何值（包括NaN本身）与NaN比较，返回的都是false。 对象 严格相等运算符JavaScript 提供两种相等运算符：==和===。 简单说，它们的区别是相等运算符（==）比较两个值是否相等，严格相等运算符（===）比较它们是否为“同一个值”。如果两个值不是同一类型，严格相等运算符（===）直接返回false，而相等运算符（==）会将它们转换成同一个类型，再用严格相等运算符进行比较。 需要注意的是，NaN与任何值都不相等（包括自身）。另外，正0等于负0。 两个复合类型（对象、数组、函数）的数据比较时，不是比较它们的值是否相等，而是比较它们是否指向同一个地址。使用=== 空对象、空数组、空函数的值，都存放在不同的内存地址。 注意，对于两个对象的比较，严格相等运算符比较的是地址，而大于或小于运算符比较的是值。 undefined和nullundefined和null与自身严格相等。 由于变量声明后默认值是undefined，因此两个只声明未赋值的变量是相等的。 严格不相等运算符严格相等运算符有一个对应的“严格不相等运算符”（!==），它的算法就是先求严格相等运算符的结果，然后返回相反值。 相等运算符对象（这里指广义的对象，包括数组和函数）与原始类型的值比较时，对象转化成原始类型的值，再进行比较。 undefined和null与其他类型的值比较时，结果都为false，它们互相比较时结果为true。 相等运算符隐藏的类型转换，会带来一些违反直觉的结果。 因此不要使用相等运算符（==），最好只使用严格相等运算符（===）。 不相等运算符相等运算符有一个对应的“不相等运算符”（!=），两者的运算结果正好相反。 布尔运算符 ！对于非布尔值，取反运算符会将其转为布尔值。可以这样记忆，以下六个值取反后为true，其他值都为false。 如果对一个值连续做两次取反运算，等于将其转为对应的布尔值，与Boolean函数的作用相同。这是一种常用的类型转换的写法。 &amp;&amp;||（?:）位运算符 位运算符只对整数起作用，如果一个运算子不是整数，会自动转为整数后再执行。另外，虽然在 JavaScript 内部，数值都是以64位浮点数的形式储存，但是做位运算的时候，是以32位带符号的整数进行运算的，并且返回值也是一个32位带符号的整数。 左移运算符（&lt;&lt;）表示将一个数的二进制值向左移动指定的位数，尾部补0，即乘以2的指定次方（最高位即符号位不参与移动）。 右移运算符（&gt;&gt;）表示将一个数的二进制值向右移动指定的位数，头部补0，即除以2的指定次方（最高位即符号位不参与移动）。 带符号位的右移运算符（&gt;&gt;&gt;）表示将一个数的二进制形式向右移动，包括符号位也参与移动，头部补0。所以，该运算总是得到正值。对于正数，该运算的结果与右移运算符（&gt;&gt;）完全一致，区别主要在于负数。 开关作用掩码 其他运算符void运算符void运算符的作用是执行一个表达式，然后不返回任何值，或者说返回undefined。 这个运算符的主要用途是浏览器的书签工具（bookmarklet），以及在超级链接中插入代码防止网页跳转。 逗号运算符逗号运算符用于对两个表达式求值，并返回后一个表达式的值。 运算顺序优先级五个运算符的优先级从高到低依次为：小于等于（&lt;=)、严格相等（===）、或（||）、三元（?:）、等号（=）。 记住所有运算符的优先级，是非常难的，也是没有必要的。 数据类型转换JavaScript 是一种动态类型语言，变量没有类型限制，可以随时赋予任意值。 虽然变量的数据类型是不确定的，但是各种运算符对数据类型是有要求的。如果运算符发现，运算子的类型与预期不符，就会自动转换类型。比如，减法运算符预期左右两侧的运算子应该是数值，如果不是，就会自动将它们转为数值。 强制转换强制转换主要指使用Number、String和Boolean三个函数，手动将各种类型的值，分布转换成数字、字符串或者布尔值。 Number()使用Number函数，可以将任意类型的值转化成数值。 Number函数将字符串转为数值，要比parseInt函数严格很多。基本上，只要有一个字符无法转成数值，整个字符串就会被转为NaN。 parseInt和Number函数都会自动过滤一个字符串前导和后缀的空格。 Number方法的参数是对象时，将返回NaN，除非是包含单个数值的数组。 第一步，调用对象自身的valueOf方法。如果返回原始类型的值，则直接对该值使用Number函数，不再进行后续步骤。第二步，如果valueOf方法返回的还是对象，则改为调用对象自身的toString方法。如果toString方法返回原始类型的值，则对该值使用Number函数，不再进行后续步骤。第三步，如果toString方法返回的是对象，就报错。 String()String函数可以将任意类型的值转化成字符串，转换规则如下。 String方法的参数如果是对象，返回一个类型字符串；如果是数组，返回该数组的字符串形式。 String方法背后的转换规则，与Number方法基本相同，只是互换了valueOf方法和toString方法的执行顺序。 Boolean()Boolean函数可以将任意类型的值转为布尔值。 它的转换规则相对简单：除了以下五个值的转换结果为false，其他的值全部为true。 所有对象（包括空对象）的转换结果都是true，甚至连false对应的布尔对象new Boolean(false)也是true。 自动转换自动转换是以强制转换为基础的。 以下三种情况时，JavaScript 会自动转换数据类型，即转换是自动完成的，用户不可见。 第一种情况，不同类型的数据互相运算。 第二种情况，对非布尔值类型的数据求布尔值。 第三种情况，对非数值类型的值使用一元运算符（即+和-）。 自动转换的规则是这样的：预期什么类型的值，就调用该类型的转换函数。比如，某个位置预期为字符串，就调用String函数进行转换。 由于自动转换具有不确定性，而且不易除错，建议在预期为布尔值、数值、字符串的地方，全部使用Boolean、Number和String函数进行显式转换。 自动转换为布尔值自动转换为字符串字符串的自动转换，主要发生在字符串的加法运算时。当一个值为字符串，另一个值为非字符串，则后者转为字符串。 这种自动转换很容易出错。期望求导个整数值结果得到个字符串。 自动转换为数值除了加法运算符（+）有可能把运算子转为字符串，其他运算符都会把运算子自动转成数值。 注意：null转为数值时为0，而undefined转为数值时为NaN。 一元运算符也会把运算子转成数值。 错误处理机制Error 实例对象JavaScript 解析或运行时，一旦发生错误，引擎就会抛出一个错误对象。JavaScript 原生提供Error构造函数，所有抛出的错误都是这个构造函数的实例。 原生错误类型Error实例对象是最一般的错误类型，在它的基础上，JavaScript 还定义了其他6种错误对象。也就是说，存在Error的6个派生对象。 SyntaxError 对象SyntaxError对象是解析代码时发生的语法错误。 ReferenceError 对象ReferenceError对象是引用一个不存在的变量时发生的错误。 另一种触发场景是，将一个值分配给无法分配的对象，比如对函数的运行结果或者this赋值。 RangeError 对象RangeError对象是一个值超出有效范围时发生的错误。主要有几种情况，一是数组长度为负数，二是Number对象的方法参数超出范围，以及函数堆栈超过最大值。 TypeError 对象TypeError对象是变量或参数不是预期类型时发生的错误。比如，对字符串、布尔值、数值等原始类型的值使用new命令，就会抛出这种错误，因为new命令的参数应该是一个构造函数。 URIError 对象URIError对象是 URI 相关函数的参数不正确时抛出的错误，主要涉及encodeURI()、decodeURI()、encodeURIComponent()、decodeURIComponent()、escape()和unescape()这六个函数。 EvalError 对象eval函数没有被正确执行时，会抛出EvalError错误。该错误类型已经不再使用了，只是为了保证与以前代码兼容，才继续保留。 自定义错误throw语句throw语句的作用是手动中断程序执行，抛出一个错误。 实际上，throw可以抛出任何类型的值。也就是说，它的参数可以是任何值。 对于 JavaScript 引擎来说，遇到throw语句，程序就中止了。引擎会接收到throw抛出的信息，可能是一个错误实例，也可能是其他类型的值。 try…catch 结构一旦发生错误，程序就中止执行了。JavaScript 提供了try…catch结构，允许对错误进行处理，选择是否往下执行。 如果你不确定某些代码是否会报错，就可以把它们放在try…catch代码块之中，便于进一步对错误进行处理。 catch代码块之中，还可以再抛出错误，甚至使用嵌套的try…catch结构。 为了捕捉不同类型的错误，catch代码块之中可以加入判断语句。 finally 代码块try…catch结构允许在最后添加一个finally代码块，表示不管是否出现错误，都必需在最后运行的语句。 return语句的执行是排在finally代码之前，只是等finally代码执行完毕后才返回。 由于没有catch语句块，所以错误没有捕获。执行finally代码块以后，程序就中断在错误抛出的地方。 try…catch…finally这三者之间的执行顺序。 尽量不要在finally中使用return语句，如果使用的话，会忽略try、catch中的返回语句，也会忽略try、catch中的异常，屏蔽了错误的发生 finally中避免再次抛出异常，一旦finally中发生异常，代码执行将会抛出finally中的异常信息，try、catch中的异常将被忽略 所以在实际项目中，finally常常是用来关闭流或者数据库资源的，并不额外做其他操作。 编程风格概述编程风格的选择不应该基于个人爱好、熟悉程度、打字量等因素，而要考虑如何尽量使代码清晰易读、减少出错。你选择的，不是你喜欢的风格，而是一种能够清晰表达你的意图的风格。这一点，对于 JavaScript 这种语法自由度很高的语言尤其重要。 缩进行首的空格和 Tab 键，都可以产生代码缩进效果（indent）。 Tab 键可以节省击键次数，但不同的文本编辑器对 Tab 的显示不尽相同，有的显示四个空格，有的显示两个空格，所以有人觉得，空格键可以使得显示效果更统一。 区块如果循环和判断的代码体只有一行，JavaScript 允许该区块（block）省略大括号。 建议总是使用大括号表示区块。 JavaScript 要使用起首的大括号跟在关键字的后面，因为 JavaScript 会自动添加句末的分号，导致一些难以察觉的错误。 因此，表示区块起首的大括号，不要另起一行。 圆括号圆括号（parentheses）在 JavaScript 中有两种作用，一种表示函数的调用，另一种表示表达式的组合（grouping）。 建议可以用空格，区分这两种不同的括号。 行尾的分号不使用分号的情况for和while循环 注意，do…while循环是有分号的。 分支语句：if，switch，try 函数的声明语句 注意，函数表达式仍然要使用分号。 以上三种情况，如果使用了分号，并不会出错。因为，解释引擎会把这个分号解释为空语句。 分号的自动添加所有语句都应该使用分号。但是，如果没有使用分号，大多数情况下，JavaScript 会自动添加。 麻烦的是，如果下一行的开始可以与本行的结尾连在一起解释，JavaScript 就不会自动添加分号。 如果continue、break、return和throw这四个语句后面，直接跟换行符，则会自动添加分号。这意味着，如果return语句返回的是一个对象的字面量，起首的大括号一定要写在同一行，否则得不到预期结果。 由于解释引擎自动添加分号的行为难以预测，因此编写代码的时候不应该省略行尾的分号。 不应该省略结尾的分号，还有一个原因。有些 JavaScript 代码压缩器（uglifier）不会自动添加分号，因此遇到没有分号的结尾，就会让代码保持原状，而不是压缩成一行，使得压缩无法得到最优的结果。 另外，不写结尾的分号，可能会导致脚本合并出错。所以，有的代码库在第一行语句开始前，会加上一个分号。 上面这种写法就可以避免与其他脚本合并时，排在前面的脚本最后一行语句没有分号，导致运行出错的问题。 全局变量JavaScript 最大的语法缺点，可能就是全局变量对于任何一个代码块，都是可读可写。这对代码的模块化和重复使用，非常不利。 因此，建议避免使用全局变量。如果不得不使用，可以考虑用大写字母表示变量名，这样更容易看出这是全局变量，比如UPPER_CASE。 变量声明JavaScript 会自动将变量声明”提升“（hoist）到代码块（block）的头部。 为了避免可能出现的问题，最好把变量声明都放在代码块的头部。 所有函数都应该在使用之前定义。函数内部的变量声明，都应该放在函数的头部。 with语句with可以减少代码的书写，但是会造成混淆。 因此，不要使用with语句。 相等和严格相等相等运算符会自动转换变量类型，造成很多意想不到的情况。 建议不要使用相等运算符（==），只使用严格相等运算符（===）。 语句的合并建议不要将不同目的的语句，合并成一行。 自增和自减运算符自增（++）和自减（–）运算符，放在变量的前面或后面，返回的值不一样，很容易发生错误。事实上，所有的++运算符都可以用+= 1代替。 建议自增（++）和自减（–）运算符尽量使用+=和-=代替。 switch…case结构switch…case结构要求，在每一个case的最后一行必须是break语句，否则会接着运行下一个case。这样不仅容易忘记，还会造成代码的冗长。 建议switch…case结构可以用对象结构代替。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"JavaScript标准参考教程 1 导论","slug":"JavaScript标准参考教程 导论","date":"2018-08-11T08:58:56.000Z","updated":"2018-10-09T03:11:45.000Z","comments":true,"path":"2018/08/11/JavaScript标准参考教程 导论/","link":"","permalink":"https://github.com/zdkswd/2018/08/11/JavaScript标准参考教程 导论/","excerpt":"","text":"JS标准参考教程 1 导论什么是JSJavaScript 是一种嵌入式（embedded）语言。它本身提供的核心语法不算很多，只能用来做一些数学和逻辑运算。JavaScript 本身不提供任何与 I/O（输入/输出）相关的 API，都要靠宿主环境（host）提供，所以 JavaScript 只合适嵌入更大型的应用程序环境，去调用宿主环境提供的底层 API。 目前，已经嵌入 JavaScript 的宿主环境有多种，最常见的环境就是浏览器，另外还有服务器环境，也就是 Node 项目。 JavaScript 的核心语法部分相当精简，只包括两个部分：基本的语法构造（比如操作符、控制结构、语句）和标准库（就是一系列具有各种功能的对象比如Array、Date、Math等）。除此之外，各种宿主环境提供额外的 API（即只能在该环境使用的接口），以便 JavaScript 调用。以浏览器为例，它提供的额外 API 可以分成三大类。 • 浏览器控制类：操作浏览器 • DOM 类：操作网页的各种元素 • Web 类：实现互联网的各种功能 JavaScript 语言本身，虽然是一种解释型语言，但是在现代浏览器中，JavaScript 都是编译后运行。程序会被高度优化，运行效率接近二进制程序。而且，JavaScript 引擎正在快速发展，性能将越来越好。 此书是针对浏览器的js JS代码的注意问题","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://github.com/zdkswd/tags/JavaScript/"}]},{"title":"微信小程序剖析 运行机制","slug":"微信小程序剖析-运行机制","date":"2018-08-11T02:02:43.000Z","updated":"2018-08-11T03:34:11.000Z","comments":true,"path":"2018/08/11/微信小程序剖析-运行机制/","link":"","permalink":"https://github.com/zdkswd/2018/08/11/微信小程序剖析-运行机制/","excerpt":"","text":"解压应用简单的说明一下： app 目录下放置了app的代码 modified_modules 即一些修改后的模块 node_modules 地球人都知道 package.json 配置了NW相关的内容 在modified_modules目录下有两个子模块： anyproxy，从名字就可以看起来这是一个代理模块 weinre，远程调试工具 IDE这是一个NodeWebkit封装的Web应用。 1234node-webkit能做什么？用Web技术（Node.JS，JavaScript，HTML5）开发桌面应用程序。Node.js是一个Javascript运行环境(runtime environment)。实质是对Chrome V8引擎进行了封装。Node.js使用Module模块去划分不同的功能，以简化应用的开发。Modules模块有点像C++语言中的类库。每一个Node.js的类库都包含了十分丰富的各类函数，比如http模块就包含了和http功能相关的很多函数，可以帮助开发者很容易地对比如http,tcp/udp等进行操作，还可以很容易的创建http和tcp/udp的服务器。 在package.json中的”main”: “app/html/index.html”,即定义了这个APP的入口是这个index.html，而不是别的文件。 这是一个React应用。 1React 起源于 Facebook 的内部项目，因为该公司对市场上所有 JavaScript MVC 框架，都不满意，就决定自己写一套。 其中的编辑环境是基于Monaco。1monaco editor是微软开源的一款web版代码编辑器。它支持智能提示，代码高亮，代码格式化。 WeAPP运行机制wxml： html，wxss ： css。对应的有几个不同的transform: transWxmlToJs transWxssToCss transConfigToPf transWxmlToHtml transManager PF指代的是PageFrame的意思，pageFrame有一个对应的模板文件。 名为wcc以及一个名为wcsc的工具。wcc用于转换wxml中的自定义tag为virtual_dom。wcsc转换wxss为css 可以理解为微信小应用有点类似于 Virtual Dom + WebView，毕竟上面有个WAWebView文件 ，还有一个webviewSDK文件 。 当然无论是React + WebView，或者Vue + WebView都不重要，现在有了 WA + WebView 在本地写的WeApp都会被提交到微信服务器，然后打包，上传到服务器，交给CDN。 1CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。 上传的过程大致如下： APP会被打包成以日期命名 + .wx文件。 IDE会检测包的大小，并提示：代码包大小为 xx kb，超过限制 xx kb，请删除文件后重试。这个xx好像是1024，所以APP的大小是1M。 APP将会上传。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"https://github.com/zdkswd/tags/微信小程序/"}]},{"title":"微信应用号开发基础教程","slug":"微信应用号开发基础教程","date":"2018-08-10T03:14:13.000Z","updated":"2018-08-10T03:19:22.000Z","comments":true,"path":"2018/08/10/微信应用号开发基础教程/","link":"","permalink":"https://github.com/zdkswd/2018/08/10/微信应用号开发基础教程/","excerpt":"","text":"前言获取微信小程序的AppID创建项目编写代码app.js、app.json、app.wxss 这三个。其中，.js 后缀的是脚本文件，.json 后缀的文件是配置文件，.wxss 后缀的是样式表文件。微信小程序会读取这些文件，并生成小程序实例。 app.js 是小程序的脚本代码。我们可以在这个文件中监听并处理小程序的生命周期函数、声明全局变量。调用 MINA 提供的丰富的 API app.json 是对整个小程序的全局配置。我们可以在这个文件中配置小程序是由哪些页面组成，配置小程序的窗口 背景色，配置导航条样式，配置默认标题。注意该文件不可添加任何注释。 app.wxss 是整个小程序的公共样式表。我们可以在页面组件的 class 属性上直接使用 app.wxss 中声明的样式规则。 创建页面微信小程序中的每一个页面的【路径 + 页面名】都需要写在 app.json 的 pages 中，且 pages 中的第一个页面是小程序的首页。 每一个小程序页面是由同路径下同名的四个不同后缀文件的组成，如：index.js、index.wxml、index.wxss、index.json。.js 后缀的文件是脚本文件，.json 后缀的文件是配置文件，.wxss 后缀的是样式表文件，.wxml 后缀的文件是页面结构文件。 index.wxml 是页面的结构文件。 index.js 是页面的脚本文件，在这个文件中我们可以监听并处理页面的生命周期函数、获取小程序实例，声明并处理数据，响应页面交互事件等。 index.wxss 是页面的样式表。页面的样式表是非必要的。当有页面样式表时，页面的样式表中的样式规则会层叠覆盖 app.wxss 中的样式规则。如果不指定页面的样式表，也可以在页面的结构文件中直接使用 app.wxss 中指定的样式规则。 index.json 是页面的配置文件。页面的配置文件是非必要的。当有页面的配置文件时，配置项在该页面会覆盖 app.json 的 window 中相同的配置项。如果没有指定的页面配置文件，则在该页面直接使用 app.json 中的默认配置。 手机预览第一章 准备工作第二章 项目架构从操作 DOM 转为操作数据，基于微信提供的一个过桥工具实现很多 h5 在公众号很难实现的功能，有点类似于 hybrid 开发，不同于 hybrid 开发的方式是：微信开放的接口更为严谨，结构必须采用他提供给我们的组件，外部的框架和插件都不能在这里使用上，让开发者完全脱离操作 DOM，开发思想转变很大。 生命周期：顺序是 App Launch–&gt;App Show–&gt;onload–&gt;onShow–&gt;onReady。 首先是整个 app 的启动与显示，app 的启动在 app.js 里面可以配置，其次再进入到各个页面的加载显示等等。可以想象到这里可以处理很多东西了，如加载框之类的都可以实现等等。 路由：微信在路由方面经过很好的封装，也提供三个跳转方法。 wx.navigateTo(OBJECT)：保留当前页面，跳转到应用内的某个页面，使用wx.navigateBack可以返回到原页面。 wx.redirectTo(OBJECT)：关闭当前页面，跳转到应用内的某个页面。 wx.navigateBack()：关闭当前页面，回退前一页面。 组件：微信在组件提供方面也是非常全面，基本上满足项目需求，故而开发速度非常快，开发前可以认真浏览几次，开发效率会很好。 其它：任何外部框架以及插件基本上无法使用，就算原生的 js 插件也很难使用，因为以前我们的 js 插件也基本上全部是操作 dom 的形式存在，而微信应用号此次的架构是不允许操作任何 dom，就连以前我们习惯使用的动态设置的rem.js也是不支持的。 此次微信还提供了 WebSocket，就可以直接利用它做聊天，可以开发的空间非常大。 注意：微信的底部菜单最多支持五栏（五个 icons），所以在你设计微信应用的 UI 和基本架构时就要预先考虑好菜单栏的排布。 建议你新建一个「wxml」文件的同时，把对应的「js」和「wxss」文件一起新建好，因为微信应用号的配置特点就是解析到一个「wxml」文件时，会同时在同级目录下找到同文件名的「js」和「wxss」文件，所以「js」文件需及时在「app.json」里预先配置好。 编写「wxml」时，根据微信应用号提供的接口编码即可，大部分就是以前的「div」，而我们现在就用「view」即可。需要用其它子集时，可以根据微信提供的接口酌情选择。 使用「class」名来设置样式，「id」名在这里基本没有什么用处。主要操作数据，不操作「dom」。 「Wxss」文件是引入的样式文件，你也可以直接在里面写样式，示例中采用的是引入方式： @import “wxss/index.CSS“ 注意：修改「wxml」和「wxss」下的内容后，直接 F5 刷新就能直接看到效果，修改「js」则需点击重启按钮才能看到效果。 「Js」文件需要在「app.json」文件的「”page”」里预先配置好。","categories":[{"name":"教程","slug":"教程","permalink":"https://github.com/zdkswd/categories/教程/"}],"tags":[{"name":"微信小程序","slug":"微信小程序","permalink":"https://github.com/zdkswd/tags/微信小程序/"}]},{"title":"《深度学习》4 数值计算","slug":"《深度学习》4 数值计算","date":"2018-08-03T01:47:12.000Z","updated":"2018-08-10T03:22:24.000Z","comments":true,"path":"2018/08/03/《深度学习》4 数值计算/","link":"","permalink":"https://github.com/zdkswd/2018/08/03/《深度学习》4 数值计算/","excerpt":"","text":"上溢和下溢连续数学在数字计算机上的根本困难是,我们需要通过有限数量的位模式来表示无限多的实数。这意味着我们在计算机中表示实数时,几乎总会引入一些近似误差。 种极具毁灭性的舍人误差是下溢( underflow)。当接近零的数被四舍五入为零时发生下溢。 另一个极具破坏力的数值错误形式是上溢( overfow)。当大量级的数被近似为+∞或-∞时发生上溢。进一步的运算通常会导致这些无限值变为非数字。 必须对上溢和下溢进行数值稳定的一个例子是softmax函数。 病态条件 这是最大和最小特征值的模之比1 。当该数很大时，矩阵求逆对输入的误差特别敏感。 这种敏感性是矩阵本身的固有特性，而不是矩阵求逆期间舍入误差的结果。 基于梯度的优化方法大多数深度学习算法都涉及某种形式的优化。优化指的是改变 x 以最小化或最 大化某个函数 f(x) 的任务。我们通常以最小化 f(x) 指代大多数最优化问题。最大化可经由最小化算法最小化−f(x) 来实现。 我们把要最小化或最大化的函数称为 目标函数(objective function)或 准则 (criterion)。当我们对其进行最小化时，我们也把它称为 代价函数(cost function)、 损失函数(loss function)或 误差函数(error function)。 有些临界点既不是最小点也不是最大点。这些点被称为 鞍点(saddle point)。 最速下降法(method of steepest descent) 或 梯度下降(gradient descent)。 其中 ε 为 学习率(learning rate)。 梯度之上:Jacobian 和 Hessian 矩阵有时我们需要计算输入和输出都为向量的函数的所有偏导数。包含所有这样的偏导数的矩阵被称为 Jacobian 矩阵。 雅可比矩阵。 当我们的函数具有多维输入时，二阶导数也有很多。我们可以将这些导数合并 成一个矩阵，称为 Hessian 矩阵。 黑塞矩阵。 Hessian 等价于梯度的 Jacobian 矩阵。 当 Hessian 的条件数很差时，梯度下降法也会表现得很差。 病态条件也导致很难选择合适的步长。步长必须足够小，以免冲过最小而向具有较强正曲率的方向上升。这通常意味着步长太小，以致于在其他较小曲率的方向上进展不明显。 牛顿法， 仅使用梯度信息的优化算法被称为一阶优化算法(first-order optimization al- gorithms)，如梯度下降。使用 Hessian 矩阵的优化算法被称为二阶最优化算法(second-order optimization algorithms)(Nocedal and Wright, 2006)，如牛顿法。 在深度学习的背景下，限制函数满足Lipschitz 连续(Lipschitz continuous)或 其导数Lipschitz连续可以获得一些保证。直觉上，利普希茨连续函数限制了函数改变的速度，符合利普希茨条件的函数的斜率，必小于一个称为利普希茨常数的实数（该常数依函数而定）。 最成功的特定优化领域或许是 凸优化(Convex optimization)。凸优化通过更强 的限制提供更多的保证。凸优化算法只对凸函数适用，即 Hessian 处处半正定的函 数。因为这些函数没有鞍点而且其所有局部极小点必然是全局最小点，所以表现很 好。然而，深度学习中的大多数问题都难以表示成凸优化的形式。凸优化仅用作一 些深度学习算法的子程序。凸优化中的分析思路对证明深度学习算法的收敛性非常 有用，然而一般来说，深度学习背景下凸优化的重要性大大减少。 约束优化在 x 的某些集合 S 中找 f(x) 的最大值或最小值。这被称 为 约束优化(constrained optimization)。在约束优化术语中，集合 S 内的点 x 被称为可行(feasible)点。 我们常常希望找到在某种意义上小的解。针对这种情况下的常见方法是强加一 个范数约束，如 ||x|| ≤ 1。 Karush–Kuhn–Tucker(KKT)方法是针对约束优化非常通用的解决方案。KKT 方法是 Lagrange 乘子法(只允许等式约束)的推广。 我们可以使用一组简单的性质来描述约束优化问题的最优点。这些性质称 为 Karush–Kuhn–Tucker(KKT)条件 (Karush, 1939; Kuhn and Tucker, 1951)。 这些是确定一个点是最优点的必要条件，但不一定是充分条件。这些条件是: 广义 Lagrangian 的梯度为零。 所有关于 x 和 KKT 乘子的约束都满足。 不等式约束显示的 ‘‘互补松弛性’’.","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"https://github.com/zdkswd/tags/深度学习/"}]},{"title":"《深度学习》3 概率与信息论","slug":"《深度学习》3 概率与信息论","date":"2018-08-01T09:20:12.000Z","updated":"2018-08-10T03:22:18.000Z","comments":true,"path":"2018/08/01/《深度学习》3 概率与信息论/","link":"","permalink":"https://github.com/zdkswd/2018/08/01/《深度学习》3 概率与信息论/","excerpt":"","text":"为什么要使用概率在医生诊断病人的例子中,我们用概率来表示一种信任度( degree of belief),其中1表示非常肯定病人患有流感,而0表示非常肯定病人没有流感。前面那种概率,直接与事件发生的频率相联系,被称为频率派概率( frequentist probability);而后者,涉及到确定性水平,被称为贝叶斯概率( Bayesian probability)。 随机变量随机变量( random variable)是可以随机地取不同值的变量。 随机变量可以是离散的或者连续的。离散随机变量拥有有限或者可数无限多的状态。注意这些状态不一定非要是整数;它们也可能只是一些被命名的状态而没有数值。连续随机变量伴随着实数值。 概率分布离散型变量和概率质量函数 1也有翻译成概率分布律的 连续型变量和概率密度函数 边缘概率 条件概率 条件概率的链式法则 独立性和条件独立性 如果关于x和y的条件概率分布对于z的每一个值都可以写成乘积的形式那么这两个随机变量x和y在给定随机变量z时是条件独立的。 期望、方差和协方差 协方差的绝对值如果很大则意味着变量值变化很大并且它们同时距离各自的均值很远。如果协方差是正的,那么两个变量都倾向于同时取得相对较大的值。如果协方差是负的,那么其中一个变量倾向于取得相对较大的值的同时,另一个变量倾向于取得相对较小的值,反之亦然。其他的衡量指标如相关系数( correlation)将每个变量的贡献归一化,为了只衡量变量的相关性而不受各个变量尺度大小的影响。 协方差和相关性是有联系的,但实际上是不同的概念。它们是有联系的,因为两个变量如果相互独立那么它们的协方差为零,如果两个变量的协方差不为零那么它们一定是相关的。然而,独立性又是和协方差完全不同的性质。两个变量如果协方差为零,它们之间一定没有线性关系。独立性比零协方差的要求更强,因为独立性还排除了非线性的关系。两个变量相互依赖但具有零协方差是可能的。 常用概率分布Bernoulli分布（01分布） Multinoulli分布就是多项分布。 高斯分布即为正态分布。 指数分布和 Laplace分布指数分布 拉普拉斯分布 Dirac分布和经验分布Dirac分布狄拉克δ函数是一个广义函数，在物理学中常用其表示质点、点电荷等理想模型的密度分布，该函数在除了零以外的点取值都等于零，而其在整个定义域上的积分等于1。 狄拉克δ函数在概念上，它是这么一个“函数”：在除了零以外的点函数值都等于零，而其在整个定义域上的积分等于1。 经验分布 分布的混合通过组合一些简单的概率分布来定义新的概率分布也是很常见的。一种通用的组合方法是构造混合分布( mixture distribution)。混合分布由一些组件( component)分布构成。 混合模型是组合简单概率分布来生成更丰富的分布的一种简单策略。 混合模型使我们能够一瞥以后会用到的一个非常重要的概念—潜变量。 常用函数的有用性质logistic sigmoid函数 softplus函数 贝叶斯规则 连续型变量的技术细节连续型随机变量和概率密度函数的深入理解需要用到数学分支测度论(Ineasure heory)的相关内容来扩展概率论。 信息论信息论是应用数学的一个分支,主要研究的是对一个信号包含信息的多少进行量化。在机器学习中,我们也可以把信息论应用于连续型变量。 信息论的基本想法是一个不太可能的事件居然发生了,要比一个非常可能的事件发生,能提供更多的信息。 也记作H(P)。换言之,一个分布的香农熵是指遵循这个分布的事件所产生的期望信息总量。当x是连续的,香农熵被称为微分熵( differential entropy)。 又称为相对熵，是用来度量使用基于Q的编码来编码来自P的样本平均所需的额外的比特个数。典型情况下，P表示数据的真实分布，Q表示数据的理论分布，模型分布，或P的近似分布。 是描述两个概率分布P和Q差异的一种方法。它是非对称的，这意味着D(P||Q) ≠ D(Q||P)。特别的，在信息论中，D(P||Q)表示当用概率分布Q来拟合真实分布P时，产生的信息损耗，其中P表示真实分布，Q表示P的拟合分布。 有人将KL散度称为KL距离，但事实上，KL散度并不满足距离的概念，因为：(1)KL散度不是对称的；(2)KL散度不满足三角不等式。 结构化概率模型机器学习的算法经常会涉及到在非常多的随机变量上的概率分布。通常，这些概率分布涉及到的直接相互作用都是介于非常少的变量之间的。使用单个函数来描述整个联合概率分布是非常低效的 (无论是计算上还是统计上)。 我们可以把概率分布分解成许多因子的乘积形式，而不是使用单一的函数来表 示概率分布。例如，假设我们有三个随机变量 a, b 和 c，并且a影响b的取值，b影响c的取值，但是 a 和 c 在给定 b 时是条件独立的。我们可以把全部三个变量的概 率分布重新表示为两个变量的概率分布的连乘形式: 这种分解可以极大地减少用来描述一个分布的参数数量。每个因子使用的参数 数目是它的变量数目的指数倍。 我们可以用图来描述这种分解。把它称为结构化概率模型(structured probabilistic model)或者图模型(graphical model)。 有两种主要的结构化概率模型:有向的和无向的。两种图模型都使用图 G，其中 图的每个节点对应着一个随机变量，连接两个随机变量的边意味着概率分布可以表 示成这两个随机变量之间的直接作用。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"https://github.com/zdkswd/tags/深度学习/"}]},{"title":"《深度学习》2 线性代数","slug":"《深度学习》2 线性代数","date":"2018-07-31T09:41:12.000Z","updated":"2018-08-10T03:22:13.000Z","comments":true,"path":"2018/07/31/《深度学习》2 线性代数/","link":"","permalink":"https://github.com/zdkswd/2018/07/31/《深度学习》2 线性代数/","excerpt":"","text":"标量、向量、矩阵和张量 标量( scalar)一个标量就是一个单独的数,它不同于线性代数中研究的其他大部分对象(通常是多个数的数组)。我们用斜体表示标量。标量通常被赋予小写的变量名称。当我们介绍标量时,会明确它们是哪种类型的数。比如,在定义实数标量时,我们可能会说“令s∈R表示一条线的斜率”;在定义自然数标量时,我们可能会说“令n∈N表示元素的数目”。 向量( vector):一个向量是一列数。这些数是有序排列的。通过次序中的索引,我们可以确定每个单独的数。通常我们赋予向量粗体的小写变量名称,比如x。向量中的元素可以通过带脚标的斜体表示。向量x的第一个元素是x1,第二个元素是x2,等等。我们也会注明存储在向量中的元素是什么类型的。如果每个元素都属于R,并且该向量有n个元素,那么该向量属于实数集R的n次笛卡尔乘积构成的集合,记为 。当需要明确表示向量中的元素时,我们会将元素排列成一个方括号包围的纵列: 我们可以把向量看作空间中的点,每个元素是不同坐标轴上的坐标。有时我们需要索引向量中的一些元素。在这种情况下,我们定义一个包含这些元素索引的集合,然后将该集合写在脚标处。比如,指定x1,和,我们定义集合S={1,3,6},然后写作xs。我们用符号一表示集合的补集中的索引。比如x-1表示x中除x1外的所有元素,x-s表示x中除x1,x3,x6外所有元素构成的向量。 矩阵( matrix):矩阵是一个二维数组,其中的每一个元素被两个索引(而非一个)所确定。我们通常会赋予矩阵粗体的大写变量名称,比如A（斜体）。如果一个实数矩阵高度为m,宽度为n,那么我们说 。我们在表示矩阵中的元素时,通常以不加粗的斜体形式使用其名称,索引用逗号间隔。比如,A1，1表示A左上的元素,Am，n表示A右下的元素。我们通过用“：”表示水平坐标,以表示垂直坐标i中的所有元素。比如,Ai,:表示A中垂直坐标i上的一横排元素。这也被称为A的第i行(row)。同样地,A:,i表示A的第i列column)。当我们需要明确表示矩阵中的元素时,我们将它们写在用方括号括起来的数组中: 有时我们需要矩阵值表达式的索引,而不是单个元素。在这种情况下,我们在表达式后面接下标,但不必将矩阵的变量名称小写化。比如 表示函数f作用在A上输出的矩阵的第i行第j列元素。 张量( tensor):在某些情况下,我们会讨论坐标超过两维的数组。一般地个数组中的元素分布在若干维坐标的规则网格中,我们称之为张量。我们使用字体A（不是斜体）来表示张量“A”。张量A中坐标为(i,j,k)的元素记作Ai,j,k。 转置( transpose)是矩阵的重要操作之一。矩阵的转置是以对角线为轴的镜像这条从左上角到右下角的对角线被称为主对角线( main diagonal)。我们将矩阵A的转置表示为AT,定义如下 向量可以看作只有一列的矩阵。对应地,向量的转置可以看作是只有一行的矩阵。 。标量可以看作是只有一个元素的矩阵。因此,标量的转置等于它本身,a=aT。转置的运算性质 1【】只是记法 在深度学习中,我们也使用一些不那么常规的符号。我们允许矩阵和向量相加,产生另一个矩阵:C=A+b,其中 。换言之,向量b和矩阵A的每一行相加。这个简写方法使我们无需在加法操作前定义一个将向量b复制到每一行而生成的矩阵。这种隐式地复制向量b到很多位置的方式,被称为广播( broadcasting )。 矩阵和向量相乘 单位矩阵和逆矩阵 线性相关和生成子空间 1还有一种看法是以列向量为新的参考系，看在参考系下要表示的向量的坐标。 不等式n≥m仅是方程对每一点都有解的必要条件。这不是一个充分条件。 1奇异值行列式为0 范数有时我们需要衡量一个向量的大小。在机器学习中,我们经常使用被称为范数（norm)的函数衡量向量大小。形式上, 范数定义如下： 范数(包括 范数)是将向量映射到非负值的函数。直观上来说,向量x的范数衡量从原点到点x的距离。更严格地说,范数是满足下列性质的任意函数： 当p=2时, 范数被称为欧几里得范数( Euclidean norm)。它表示从原点出发到向量c确定的点的欧几里得距离。L2范数在机器学习中出现地十分频繁,经常简化表示为 ,略去了下标2。平方L2范数也经常用来衡量向量的大小,可以简单地通过点积 计算。 另外一个经常在机器学习中出现的范数是L∞范数,也被称为最大范数（max norm)这个范数表示向量中具有最大幅值的元素的绝对值: 1弗罗贝尼乌斯范数 特殊类型的矩阵和向量对角矩阵 对称 单位向量 正交矩阵 特征分解特征分解( eigendecomposition)是使用最广的矩阵分解之一,即我们将矩阵分解成一组特征向量和特征值。 1矩阵A乘以x表示，对向量x进行一次转换（旋转或拉伸)（是一种线性转换），而该转换的效果为常数c乘以向量x（即只进行拉伸）。 奇异值分解我们探讨了如何将矩阵分解成特征向量和特征值。还有另一种分解矩阵的方法,被称为奇异值分解( singular value decomposition,SVD),将矩阵分解为奇异向量( singular vector)和奇异值( singular value)。通过奇异值分解,我们会得到一些与特征分解相同类型的信息。然而,奇异值分解有更广泛的应用。每个实数矩阵都有一个奇异值分解,但不一定都有特征分解。例如,非方阵的矩阵没有特征分解,这时我们只能使用奇异值分解。 Moore-Penrose伪逆 迹运算 另一个有用的事实是标量在迹运算后仍然是它自己:a=Tr(a)。 行列式行列式,记作det(A),是一个将方阵A映射到实数的函数。行列式等于矩阵特征值的乘积。行列式的绝对值可以用来衡量矩阵参与矩阵乘法后空间扩大或者缩了多少。如果行列式是0,那么空间至少沿着某一维完全收缩了,使其失去了所有的体积。如果行列式是1,那么这个转换保持空间体积不变。 实例:主成分分析主成分分析( principal components analysis,PCA)是一个简单的机器学习算法,可以通过基础的线性代数知识推导。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"https://github.com/zdkswd/tags/深度学习/"}]},{"title":"《深度学习》 1 引言","slug":"《深度学习》 1 引言","date":"2018-07-29T10:55:12.000Z","updated":"2018-08-10T03:22:06.000Z","comments":true,"path":"2018/07/29/《深度学习》 1 引言/","link":"","permalink":"https://github.com/zdkswd/2018/07/29/《深度学习》 1 引言/","excerpt":"","text":"引言讽刺的是,抽象和形式化的任务对人类而言是最困难的脑力任务之一,但对计算机而言却属于最容易的。计算机早就能够打败人类最好的象棋选手,但直到最近计算机才在识别对象或语音任务中达到人类平均水平。一个人的日常生活需要关于世界的巨量知识。很多这方面的知识是主观的、直观的,因此很难通过形式化的方式表达清楚。计算机需要获取同样的知识才能表现出智能。人工智能的一个关键挑战就是如何将这些非形式化的知识传达给计算机。 些人工智能项目力求将关于世界的知识用形式化的语言进行硬编码(hard code)。计算机可以使用逻辑推理规则来自动地理解这些形式化语言中的声明。这就是众所周知的人工智能的知识库( knowledge base)方法。然而,这些项目最终都没有取得重大的成功。其中最著名的项目是 Cyc(Lenat and Guha,1989)Cyc包括一个推断引擎和一个使用CycL语言描述的声明数据库。这些声明是由人类监督者输入的。这是一个笨拙的过程。人们设法设计出足够复杂的形式化规则来精确地描述世界。例如,Cyc不能理解一个关于名为rred的人在早上剃须的故事( Linde,1992)。它的推理引擎检测到故事中的不一致性:它知道人体的构成不包含电气零件,但由于Fred正拿着一个电动剃须刀,它认为实体“正在剃须的Fred”(“ Fred While Shaving”)含有电气部件。因此它产生了这样的疑问—Fred在刮胡子的时候是否仍然是一个人。；） 依靠硬编码的知识体系面对的困难表明,AI系统需要具备自己获取知识的能力即从原始数据中提取模式的能力。这种能力被称为机器学习( machine learning)引入机器学习使计算机能够解决涉及现实世界知识的问题，并能作出看似主观的决策。比如,一个被称为逻辑回归( logistic regression)的简单机器学习算法可以决定是否建议剖腹产(Mor- Yosef et al,1990)。而同样是简单机器学习算法的朴素贝叶斯( naive Bayes)则可以区分垃圾电子邮件和合法电子邮件 这些简单的机器学习算法的性能在很大程度上依赖于给定数据的表示( repre-sentation)。 许多人工智能任务都可以通过以下方式解决:先提取一个合适的特征集,然后将这些特征提供给简单的机器学习算法。例如,对于通过声音鉴别说话者的任务来说,一个有用的特征是对其声道大小的估计。这个特征为判断说话者是男性、女性还是儿童提供了有力线索。 然而,对于许多任务来说,我们很难知道应该提取哪些特征。例如,假设我们想编写一个程序来检测照片中的车。我们知道,汽车有轮子,所以我们可能会想用车轮的存在与否作为特征。不幸的是,我们难以准确地根据像素值来描述车轮看上去像什么。虽然车轮具有简单的几何形状,但它的图像可能会因场景而异,如落在车轮上的阴影、太阳照亮的车轮的金属零件、汽车的挡泥板或者遮挡的车轮一部分的前景物体等等。 解决这个问题的途径之一是使用机器学习来发掘表示本身,而不仅仅把表示映射到输出。这种方法我们称之为表示学习( representation learning)。学习到的表示往往比手动设计的表示表现得更好。并且它们只需最少的人工干预,就能让AI系统迅速适应新的任务。表示学习算法只需几分钟就可以为简单的任务发现一个很好的特征集,对于复杂任务则需要几小时到几个月。手动为一个复杂的任务设计特征需要耗费大量的人工时间和精力;甚至需要花费整个社群研究人员几十年的时间。 表示学习算法的典型例子是自编码器( autoencoder)。自编码器由一个编码器( encoder)函数和一个解码器( decoder)函数组合而成。编码器函数将输入数据转换为一种不同的表示,而解码器函数则将这个新的表示转换到原来的形式。我们期望当输人数据经过编码器和解码器之后尽可能多地保留信息,同时希望新的表示有各种好的特性,这也是自编码器的训练目标。为了实现不同的特性,我们可以设计不同形式的自编码器。 当设计特征或设计用于学习特征的算法时,我们的目标通常是分离出能解释观察数据的变差因素( factors of variation)。在此背景下,“因素”这个词仅指代影响的不同来源;因素通常不是乘性组合。这些因素通常是不能被直接观察到的量。相反,它们可能是现实世界中观察不到的物体或者不可观测的力,但会影响可观测的量。为了对观察到的数据提供有用的简化解释或推断其原因,它们还可能以概念的形式存在于人类的思维中。它们可以被看作数据的概念或者抽象,帮助我们了解这些数据的丰富多样性。当分析语音记录时,变差因素包括说话者的年龄、性别、他们的口音和他们正在说的词语。当分析汽车的图像时,变差因素包括汽车的位置、它的颜色、太阳的角度和亮度。 显然,从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话口音这样的变差因素,只能通过对数据进行复杂的、接近人类水平的理解来辨识。这几乎与获得原问题的表示一样困难,因此,乍一看,表示学习似乎并不能帮助我们。 深度学习( deep learning)通过其他较简单的表示来表达复杂表示,解决了表示学习中的核心问题。 屏幕快照 2018-07-29 下午5.55.44 如何通过组合较简单的概念(例如转角和轮廓,它们转而由边线定义)来表示图像中人的概念。深度学习模型的典型例子是前馈深度网络或多层感知机( multilayer perceptron,MLP)。多层感知机仅仅是一个将一组输人值映射到输出值的数学函数该函数由许多较简单的函数复合而成。我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。 学习数据的正确表示的想法是解释深度学习的一个视角。另一个视角是深度促使计算机学习一个多步骤的计算机程序。每一层表示都可以被认为是并行执行另组指令之后计算机的存储器状态。更深的网络可以按顺序执行更多的指令。顺序指令提供了极大的能力,因为后面的指令可以参考早期指令的结果。从这个角度上看在某层激活函数里,并非所有信息都蕴涵着解释输入的变差因素。表示还存储着状态信息,用于帮助程序理解输人。这里的状态信息类似于传统计算机程序中的计数器或指针。它与具体的输人内容无关,但有助于模型组织其处理过程。 屏幕快照 2018-07-29 下午6.03.19 由于不同的人选择不同的最小元素集来构建相应的图,因此就像计算机程序的长度不存在单一的正确值一样,架构的深度也不存在单一的正确值。另外,也不存在模型多么深才能被修饰为“深”的共识。但相比传统机器学习,深度学习研究的模型涉及更多学到功能或学到概念的组合,这点毋庸置疑。 屏幕快照 2018-07-29 下午6.07.58 本书面向的读者 屏幕快照 2018-07-29 下午6.09.31 深度学习的历史趋势神经网络的众多名称和命运变迁20世纪40年代到60年代深度学习的雏形出现在控制论( cybernetics)中。 尽管有些机器学习的神经网络有时被用来理解大脑功能( Hinton and shallice,1991),但它们一般都没有被设计成生物功能的真实模型。 现在,神经科学被视为深度学习研究的一个重要灵感来源,但它已不再是该领域的主要指导。 媒体报道经常强调深度学习与大脑的相似性。的确,深度学习研究者比其他器学习领域(如核方法或贝叶斯统计)的研究者更可能地引用大脑作为影响,但是大家不应该认为深度学习在尝试模拟大脑。 深度学习领域主要关注如何构建计算机系统,从而成功解决需要智能才能解决的任务,而计算神经科学领域主要关注构建大脑如何进行真实工作的比较精确的模型。 在20世纪80年代,神经网络研究的第二次浪潮在很大程度上是伴随一个被称为联结主义( connectionism)或并行分布处理( parallel distributed processing)潮流而出现的( Rumelhart et al,1986d; McClelland et al,1995)。 联结主义的中心思想是,当网络将大量简单的计算单元连接在一起时可以实现智能行为。这种见解同样适用于生物神经系统中的神经元,因为它和计算模型中隐藏单元起着类似的作用。 其中一个概念是分布式表示( distributed representation)( Hinton et al,1986)其思想是:系统的每一个输入都应该由多个特征表示,并且每一个特征都应该参与到多个可能输人的表示。例如,假设我们有一个能够识别红色、绿色、或蓝色的汽车、卡车和鸟类的视觉系统,表示这些输人的其中一个方法是将九个可能的组合:红卡车,红汽车,红鸟,绿卡车等等使用单独的神经元或隐藏单元激活。这需要九个不同的神经元,并且每个神经必须独立地学习颜色和对象身份的概念。改善这种情况的方法之一是使用分布式表示,即用三个神经元描述颜色,三个神经元描述对象身份。这仅仅需要6个神经元而不是9个,并且描述红色的神经元能够从汽车、卡车和鸟类的图像中学习红色,而不仅仅是从一个特定类别的图像中学习。分布式表示的概念是本书的核心。 联结主义潮流的另一个重要成就是反向传播在训练具有内部表示的深度神经网络中的成功使用以及反向传播算法的普及( Rumelhart et al,1986c; LeCun,1987)。这个算法虽然曾黯然失色不再流行,但截至写书之时,它仍是训练深度模型的主导方法。 在20世纪90年代,研究人员在使用神经网络进行序列建模的方面取得了重要进展。 Hochreiter(191b)和 Bengio et al.(1994a)指出了对长序列进行建模的些根本性数学难题, Hochreiter and schmidhuber(1997)引入长短期记忆( long short-term memory,LSTM)网络来解决这些难题。如今,LSTM在许多序列建模任务中广泛应用,包括 Google的许多自然语言处理任务。 神经网络研究的第三次浪潮始于2006年的突破。Geoffrey Hinton表明名为深度信念网络的神经网络可以使用一种称为贪婪逐层预训练的策略来有效地训练。 神经网络研究的这一次浪潮普及了“深度学习”这一术语的使用,强调研究者现在有能力训练以前不可能训练的比较深的神经网络,并着力于深度的理论重要。此时,深度神经网络已经优于与之竞争的基于其他机器学习技术以及手工设计功能的AI系统。 尽管深度学习的研究重点在这一段时间内发生了巨大变化。第三次浪潮已开始着眼于新的无监督学习技术和深度模型在小数据集的泛化能力,但目前更多的兴趣点仍是比较传统的监督学习算法和深度模型充分利用大型标注数据集的能力。 与日俱增的数据量“大数据”时代使机器学习更加容易。截至2016年,一个粗略的经验法则是,监督深度学习算法在每类给定约5000个标注样本情况下一般将达到可以接受的性能,当至少有1000万个标注样本的数据集用于训练时,它将达到或超过人类表现。此外,在更小的数据集上获得成功是一个重要的研究领域,为此我们应特别侧重于如何通过无监督或半监督学习充分利用大量的未标注样本。 与日俱增的模型规模20世纪80年代,神经网络只能取得相对较小的成功,而现在神经网络非常成功的另一个重要原因是我们现在拥有的计算资源可以运行更大的模型。联结主义的主要见解之一是,当动物的许多神经元一起工作时会变得聪明。单独神经元或小集合的神经元不是特别有用。 就神经元的总数目而言,直到最近神经网络都是惊人的小。自从隐藏单元引人以来,人工神经网络的规模大约每2.4年扩大一倍。这种增长是由更大内存、更快的计算机和更大的可用数据集驱动的。更大的网络能够在更复杂的任务中实现更高的精度。这种趋势看起来将持续数十年。除非有能力迅速扩展的新技术,否则至少要到21世纪50年代,人工神经网络将才能具备与人脑相同数量级的神经元。生物神经元表示的功能可能比目前的人工神经元所表示的更复杂。 屏幕快照 2018-07-29 下午6.47.54 现在看来,其神经元比一个水蛭还少的神经网络不能解决复杂的人工智能问题是不足为奇的。即使现在的网络,从计算系统角度来看它可能相当大的,但实际上它比相对原始的脊椎动物如青蛙的神经系统还要小。 由于更快的CPU、通用GPU的出现更快的网络连接和更好的分布式计算的软件基础设施,模型规模随着时间的推移不断增加是深度学习历史中最重要的趋势之一。人们普遍预计这种趋势将很好地持续到未来。 与日俱增的精度、复杂度和对现实世界的冲击 屏幕快照 2018-07-29 下午6.51.21 深度学习的另一个最大的成就是其在强化学习( reinforcement learning)领域的扩展。在强化学习中,一个自主的智能体必须在没有人类操作者指导的情况下,通过试错来学习执行任务。 DeepMind表明,基于深度学习的强化学习系统能够学会玩并在多种任务中可与人类匹敌Mnih et al.,2015)。深度学习也显著改善了机器人强化学习的性能。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"https://github.com/zdkswd/tags/深度学习/"}]},{"title":"松本行弘的程序世界 14 函数式编程","slug":"松本行弘的程序世界 14 函数式编程","date":"2018-07-26T13:00:32.000Z","updated":"2018-07-27T03:20:34.000Z","comments":true,"path":"2018/07/26/松本行弘的程序世界 14 函数式编程/","link":"","permalink":"https://github.com/zdkswd/2018/07/26/松本行弘的程序世界 14 函数式编程/","excerpt":"","text":"松本行弘的程序世界 14 函数式编程新范型–函数式编程函数式编程是全部使用函数来编写程序代码的编程方法。这是可以与一般的结构化编程及面向对象编程相提并论的编程方法。 以函数为中心的函数式编程具有特征： 函数本身也作为数据来处理（第一级函数） 以函数为参数的高阶函数 参数相同即可保证结果相同的引用透明性。 为实现引用透明性，禁止产生副作用的处理。 函数式编程的最大优点在于，程序可以按照数学的形式以及声明的形式来编写。 结构式编程是在改变变量值的同时进行计算，所以一直注意着，这个变量的值是什么，并据此来预想计算过程。 采用函数式编程方式并不改变变量的值。并不包含状态或者动作等信息，仅仅是对想要做什么加以描述，这样不容易出错。 这种不是描述动作而是描述性质的编程方式称为声明式编程。声明式描述是函数式编程的一大优点。 具有多种函数式性质的Lisp之前，Lisp被认为是函数式编程的代表。Lisp具备函数式语言的很多性质。 Lisp最大的特征是S式记法。S式是括号很多的Lisp的记法。S式无与伦比的优点是它彻底的统一性。对Lisp而言，不管什么都可以同一成单一形式。 第二个重要之处在于链这种数据结构。Lisp语言本名是List Processor（链表处理器），从侧面说明了链的重要性。链是一种构成树结构数据的通用数据结构，构成数据结构的节点分别包含两个引用。 屏幕快照 2018-07-25 上午10.02.29 总之，Lisp具备了函数编程语言的基本特征。但是Lisp不直接支持多数纯粹的函数式编程语言所拥有的副作用如回避以及延迟计算等功能。对变量的赋值没有任何限制。且编程风格为很多很多括号。比较难适应。 近年来，由于像Haskell这样的彻底的函数式编程语言的兴起，Lisp作为函数式编程语言在人们心中的印象越来越淡薄。 彻底的函数式编程语言HaskellHaskell可以说是纯粹的函数式编程语言。Haskell语言特征： 没有副作用 高阶函数 函数部分应用 延迟计算(非正式) 静态多态类型系统 型推论 链内包表达式 用对齐来表示块 没有副作用Haskell程序基本没有副作用，不但不能改变变量的值，就连链的元素也是不能改变的。因此，只要参数不变，函数的返回值也就总是一样的。相同输入总能返回相同结果，这种可重复性对测试程序非常有利。这种重复性也称为引用透明性。 高阶函数Haskell高阶函数把函数本身作为数据来处理。比如，Haskell中没有循环控制结构，循环都是用递归调用或者高阶函数来实现的。 延迟计算：不必要的处理就不做必要时才进行处理。 灵活的“静态多态性”类型系统与没有类型的Ruby不同，Haskell是在编译时确定所有变量类型的静态类型语言。但实际上Haskell程序基本上没有必要给出变量的类型。这是因为聪明的Haskell语言处理系统会推测变量的类型。 Haskell利用多态性的类型系统和系统推测，在维持着接近于duck typing灵活性的同时，也使编译时的完全类型检查成为可能。 近代函数式语言之父OCamlOCaml也是具有代表性的函数式编程语言之一。它比Haskell还古老，说它是近代函数式语言之父也毫不为过。 与Haskell相比，OCaml具有如下不同： 没有副作用 没有延迟计算 具有强力的模块系统 虽然不像Haskell那样自然地做到延迟计算，但换来的好处是，程序内容与实际处理关系接近，使人容易理解程序的执行过程。 强于并行计算的Erlang作为函数式编程语言，二郎的特点 受Prolog影响 专用于并行计算 用Ruby进行函数式编程Ruby中有几个能进行函数式编程的工具 Proc对象（lambda）Ruby中唯一与函数直接对应的是Proc对象。 程序块以程序块为参数的方法等价于函数型语言的高阶函数。灵活运用以程序块为参数的方法，就可以实现函数式编程的高阶函数的技巧。 枚举器Ruby中没有延迟计算，但用枚举器对数组和列表进行循环，可以实现类似于延迟计算的处理。 避免副作用所谓避免副作用，就是对生成的对象，尽量少去改变其状态。 用枚举器来实现延迟计算从Ruby1.8.7开始，很多以块为参数的方法在参数不是块的时候，就会返回枚举器。 枚举器就是把循环用对象来表达的一种方法。 使用这样的枚举器可以实现与Haskell类似的延迟计算。 自动生成代码在商业中利用Ruby使用Ruby自动生成代码编程中的代码重复是非常恶劣的。发现了代码重复，就应该考虑在合理的代价范围内避免代码重复的方法。 消除重复代码为了在构建程序的时候，自动生成省略部分，我们只需要定义make的规则、在构建程序的过程中调用代码生成工具。 代码生成的应用数据库访问从数据结构定义自动生成数据库的访问例程（包括SQL）。 用户接口大多数依赖于数据库的Web应用程序，常常需要对表的各项目进行增删改查操作。 单元测试代码生成对单元测试也很有效果。只要有数据和测试条件，就可以开始单元测试。 客户界面文档化代码生成也适合与文档化。对于自动生成的类，由人工记入档案是纯粹的浪费。按照JavaDoc的形式，在生成代码的程序里写好相应的文档，应该是个聪明的办法。 代码生成的效果代码生成有如下好处： 改进质量。 确保一致性 集中知识。 增加用于设计的时间。 独立于程序实现的设计判断 编写代码生成器对代码生成最有帮助的工具要数eRuby。Ruby本身也拥有优越的文本处理功能。使用eRuby以比较自然地形式编写模板的同时，还可以灵活运用Ruby的处理能力。 也可以使用XML幸运的是，Ruby拥有解释XML的标准库REXML。REXML提供操作XML的功能。 在EJB中使用代码生成1EJB (Enterprise JavaBean)是J2EE(javaEE)的一部分 内存管理与垃圾收集垃圾收集（GC）是一种管理程序使用的内存区域的方法。使用具有垃圾收集功能的编程语言或处理程序的话，程序中不需要编写内存管理的代码，即不用编写代码来释放使用过的内存区域。 内存管理的困难在垃圾收集普及之前，内存区域的取得和释放完全是程序员的责任。随着程序的执行，会使用一些内存区域作为作业区。为记忆对象、字符串和数组等个别信息，都需要使用内存区域。没有垃圾收集的语言一般都提供有API，利用这些API，可以再需要时向操作系统申请并取得内存，使用过之后再把内存区域返回给操作系统。 悬挂指针如果把还在使用中的内存区域错误调用free予以释放的话，就会发生悬挂指针的现象。程序再去访问该区域时就可能会出错。在引用该区域内容时，多数场合会读取到被破坏的数据，或是在更新该领域数据的时候，会置换成预想之外的数据。 内存泄漏另一方面，如果忘记了把申请的内存区域返还给操作系统的话，就会发生内存泄漏。这时候因为使用过的内存区域越来越多，程序占有的内存就会逐渐增加。特别是长时间启动，连续提供服务的常驻内存型程序，容易发生内存泄漏，导致系统停止等重大问题。 二重释放对已经释放过的内存区域再次调用free的情况也时有发生。这称为二重释放。这会带来malloc和free内部使用的数据区域不一致的问题。 内存泄漏问题只有在内存占用量超过预想的时候才会显露，而悬挂指针问题不会发生在释放使用内存的时刻，而是要到访问释放过的内存区域才会出现。程序员往往会在看起来完全没有问题的地方突然遭遇意想不到的错误。 垃圾收集亮相之前应该管理的内存区域越来越多，内存释放时刻的管理也就越来越难，这是产生内存问题的原因。 关于垃圾收集，有以下这些先入为主的观念。 垃圾收集慢有研究表明，在某些条件下，垃圾收集比手工管理内存还更快。 垃圾收集可靠性低在Java之后诞生的编程语言，不管是否受到Lisp的影响，几乎都毫无例外的拥有垃圾收集的功能。垃圾收集从诞生之日起，经历了40多年的发展，终于成为大家认可的一项特性了。 评价垃圾收集的两个指标假如存在无线内存的计算机的话，就没有必要进行垃圾收集。 垃圾收集的性能可以由两个指标来测定： 吞吐量吞吐量是垃圾收集处理在程序全部执行时间中所占的比例。比例越小越好，比例大的话，程序整体的性能就会低下。 暂停时间暂停时间是一次垃圾收集处理所中断的时间。暂停时间过长的话，处理的中断时间就会变得很显眼，程序反应就会变慢。 垃圾收集每次所花的时间会因垃圾收集执行时对象的总数而变化，暂停时间有两种，一是把垃圾收集时间求平均值得到平均暂停时间，二是程序执行中最长的垃圾收集时间所代表的最大暂停时间。 那些实时性要求高的程序，就很重视最大暂停时间。像批处理这样非对话的处理强调吞吐量要高，而重视反应速度的嵌入式或者GUI程序就强调暂停时间要短。 Java运行环境中实现由多种垃圾收集算法，可以根据程序的性质来切换合适的垃圾收集算法。 垃圾收集算法基本上是以下4类，还有几种变形： 引用计数方式 标记和扫除方式 标记和紧缩方式 复制方式 引用计数方式引用计数方式在垃圾收集算法中具有最简单最容易实现的特征。 屏幕快照 2018-07-25 下午5.25.46 引用计数器最大的优点就是容易实现。这种方式得到广泛的使用。暂停时间短也是它的优点。 最大的缺点是不能释放有循环引用关系的对象群。 屏幕快照 2018-07-25 下午5.28.21 与生俱来的缺点，因为在引用增减的时候有必要同时正确维护引用计数器的增减，忘了这一点就会带来悬挂指针或内存泄露问题。 最后一个缺点是，引用计数器的管理与并行处理不相容。如果多个进程同时增减一个引用计数器的话，就会发生引用计数器的值不一致的现象。为避免这一个问题，需要在操作引用计数器的时候进行排他处理，但在频繁发生引用操作的同时进行排他处理的话，会带来巨大的时间开销。 总之，这种原理简单实现也简单的引用计数器方式，缺点很多，最近已经不怎么用了。 采用引用计数器方式的主要语言处理系统有Perl和Python。为了回避循环引用的问题，它们都组合了其他垃圾收集方式。这些语言基本上以引用计数器方式来进行垃圾收集，只有在极个别的情况下，才通过别的垃圾收集算法来处理引用计数器不能回收的对象。 标记和扫除方式标记和扫除方式也是古老的垃圾收集算法。标记和扫除方式从有可能成为对象引用元的变数（根）开始，给被引用的对象加上标记，表明其“活着”。然后再给标记对象所引用的对象还有其再引用的对象，也都递归地加上引用标记。 这样从根开始不管是直接还是间接，只要把所有引用的对象都加上标记的话，那么没有标记的对象就是没有被引用的，也就是“已经死了”。然后在所有的对象中找出没有标记的对象，把它们作为垃圾扫除出去。 屏幕快照 2018-07-25 下午5.50.20 此法虽然古老，但是非常优秀，现在也还被多种处理系统所采用。 但是当对象数目较多时，性能容易恶化。在标记的时候要访问生存的所有对象，在回收时按顺序访问所有的对象，找出”已经死了“的对象。在寻找垃圾和扫除过程中，基本不能进行其他处理，垃圾收集时间长的话，会影响到本来的处理工作。 标记和紧缩方式标记和紧缩方式是标记和扫除的变形。标记处理是一样的，后阶段有所不同。 屏幕快照 2018-07-26 下午12.01.29 标记和紧缩方式最大的特征也是他的优越之处，是把空间集中起来（紧缩）。紧缩的结果是把没有释放而活下来的对象都集中到一个地方。这样，内存访问就集中到一个局部区域，这可以提高缓存功能的效率。对象的分配也只是把指针移动一下就完成了，降低了对象分配的开销。 缺点是，把生存着的对象全部复制的紧缩开销，容易比标记和扫除方式中执行的开销还要大。因为对象被移动位置了。 一部分Lisp处理系统采用的是标记和紧缩方式，Java处理系统（作为多个垃圾收集算法中的一个）也有标记和紧缩方式。 复制方式像标记和扫除方式、标记和紧缩方式这样“标记之后释放死了的对象”的算法，标记时间与活着的对象数成比例，扫除时间与总对象数成比例。所以在分配有很多的对象，其中几乎所有对象都要被释放的场合，扫除的开销会变高，在性能方面很不利。 复制方式与标记和扫除方式一样，从根开始扫描所有的对象，但他不仅仅是加标记，还执行复制。 屏幕快照 2018-07-26 下午12.11.58 复制方式把内存空间分成旧空间和新空间两大块，总是在旧空间中分配对象。旧空间爆满时，从根开始扫描对象，把对象复制到新空间。这时，复制后的引用也要随之更新。 递归的执行从旧空间到新空间的复制，结束时就会把所有活着的对象都移动到新空间。不再被引用的对象都遗留到旧空间，旧空间就可以整个弃之不用，就避免了扫除的开销，从此再把新空间作为旧空间再进行同样的处理。 最大的优点是，垃圾回收的开销只和活着的对象数成比例。对象分配的开销也低。还有“局部性”的优点。复制方式按顺序把引用的对象复制到新空间，关系近的对象会被分配到相近的内存空间，称为局部性。关系近的对象被访问的可能性也高。计算机因为有缓存，内存空间相接近的访问可能具有较好的性能，局部性高的程序具有提高性能的优势。 缺点：复制方式要复制所有活着的对象，几乎具有和标记和紧缩方式一样的缺点。 多种多样的垃圾收集算法把基本算法组合起来的技术，几个具有代表性的： 分代垃圾收集 保守垃圾收集 增量垃圾收集 并行垃圾收集 位图标志 这些技术的组合也是有可能的。 分代垃圾收集分代垃圾收集的基本思想是利用程序和对象的性质。一般程序都有这样一个性质，几乎所有的对象都在比较短的时间里变成垃圾，存活时间超过一定程度的对象总是拥有更长的寿命。 因为这一性质，就可以重点对分配之后的年轻对象进行扫描，这样就不用扫描全部对象就可能高效率地回收垃圾。 分代垃圾收集把对象的内存空间分成两个，新代和旧代，也有分成3个的。 只扫描新代区域的回收称为轻垃圾收集，但没有检查旧代区域对新代的引用，被引用的对象可能误判死亡，就会带来内存问题。 解决这一问题的方法是，监视对象的更新。在旧代区域引用新代区域的同时，就把这一引用的记录例程以及对象的更新场所全都记录下来，这个检查例程叫做写屏障，记录旧代区域对新代区域的引用叫记录集。 以所有区域对象的垃圾收集称为全垃圾收集或重垃圾收集。 屏幕快照 2018-07-26 下午12.33.58 分代垃圾收集减少了扫描对象的个数，有缩短平均暂停时间的效果。但是，因为要执行全垃圾收集，最大暂停时间不会得到明显的改善。 最近几乎所有的Java都实现有分代垃圾收集。另外，函数型语言OCaml也采用了分代垃圾收集。 保守垃圾收集像C这种本来没有垃圾收集的语言，编译之后没有保留区别整数和指针的信息，因为CPU对两者不加区分，所以也就没这个必要。通常，垃圾收集的实现需要明确区分引用（指针），而C和C++没有这样的功能，在这样的环境下实现垃圾收集的技巧之一称为保守垃圾收集。 其基本思想就是如果碰巧有整数的值与引用相同的话，该对象就有可能被引用，就当它是活着的。保守就是倾向于安全的意思。与此相对，能够明确区别所用的环境下的垃圾收集称为精确垃圾收集。 因为倾向于安全一面，保守垃圾收集在C或者C++这样没有垃圾收集功能的语言中也可以得到实现，这是它的优点。但是，本来应该回收的对象却在意料之外保留下来不能回收，这是它的缺点。以及，它不能喝复制垃圾收集这样需要移动的垃圾收集算法组合使用。 Ruby采用的是保守垃圾收集。局部变量可以按照通常语言的访问路径来处理，系统堆栈部分是当做指针数组来扫描的。Ruby大部分是用C编写的，因为有了保守垃圾收集，C库的实现变得非常简单。实际上，Python和Perl因为采用的是引用计数器，C例程内部的引用数管理非常复杂，偶然忘记增减就会发生内存问题。但是，用C编写Ruby扩展库时，基本上不用操心内存管理，好处十分明显。 Boehm GC为C和C++增加了垃圾收集功能。Boehm GC也同时实现了分代垃圾收集。Boehm GC不仅用于C和C++，在Scheme处理系统Gauche等多种语言处理系统中，也作为垃圾收集功能得到广泛的应用。 增量垃圾收集在实时性要求高的程序中，垃圾收集带来的中断时间必须是可预测的。为保证实时性，不需要等垃圾收集完全执行结束，而是要把垃圾收集细分正许多细小的片段，每次执行一点，这叫增量垃圾收集。 增量垃圾收集在垃圾收集处理过程中程序也在同时执行，引用有可能会改变。结果是垃圾收集的一致性不能得到保证。增量垃圾收集为避免这样的问题，采用了与保守垃圾收集相同的写屏蔽操作。 嵌入式处理系统采用的是增量垃圾收集。有名的Io和Lua都实现了增量垃圾收集。 并行垃圾收集在多核环境下，灵活运用线程可以最大限度地发挥多个CPU的能力。并行垃圾收集就是要最大限度利用多个CPU的能力。 并行垃圾收集基本原理与增量垃圾收集大致是一样的，都是利用写屏蔽来维护当前状态的信息。有的并行垃圾收集的实现生成垃圾收集专用线程，把垃圾收集设计成总是与普通处理并行执行。 位图标记以Linux为首的UNIX系列操作系统在使用fork系统调用复制过程时，内存空间并不进行复制而是直接共享。通过写时复制来提高性能。 垃圾收集与这一功能兼容性不好，给引用对象那个设置标记的方式会因设置标记而复制包含该对象的内存页。复制方式也同样会产生大量写内存操作。 位图标记是在利用标记的垃圾收集中消减操作系统内存页复制的方法。它不在对象里设置被引用的标记，而是利用外部位图区域（管理用内存区域）来保存引用标记。 只有标记用的位图部分会发生内存页复制，从而避免了复制没有实际更新的对象所在的内存页。 Ruby的垃圾收集也有了实现位图标记的补丁。 用C语言来扩展RubyRuby是解释型语言，即Ruby程序是由Ruby解释器的程序来解释执行的。 提起解释器，大家会觉得它是逐行读取程序并执行，实际上Ruby解释器是把要执行的程序全部读进来，首先变换成更有效率的内部表现形式。解释器对其内部表现加以分析来执行程序。 解释型语言的特点，马上可以执行，开发周期非常快。至于C、C++、Java这样的编译语言，首先要把程序变换成计算机可以直接执行的形式再从头执行。 在执行程序过程中，编译型语言不再需要对原来程序进行解释和变换，速度很快。但是开发周期较长。 开发与执行速度的取舍这两种类型的语言要做取舍。Ruby的设计方针是开发效率优于执行效率，选择解释型的实现也是必然。 Ruby解释器是由C语言开发的，采用C语言开发理由： C语言作者拿手 C语言运行系统调用，速度高 用面向对象语言来实现别的面向对象语言的话，容易混淆对象的概念。 屏幕快照 2018-07-26 下午5.36.05 引擎是解释内部表现，并实际上执行程序的部分。1.9版本的引擎解释的字节码，可以说是近似于虚拟计算机的机器语言。所以1.9版本的引擎也可以成为VM。 引擎在解释内部表现是，需要其他组件的帮助。内存和对象的管理，变量访问和方法调用的实现等，都要依靠底层称为运行库的组件来完成。运行库提供底层强有力的支持，是程序执行时不可或缺的部分。 Ruby利用的各种类是类库提供的。Ruby的这一部分也是用C编写的。像Ruby这样的解释型语言，因为是经过C编写的引擎来间接执行程序，与一般的编译语言相比，执行速度明显慢得多（100 倍或者 1000 倍）。但是，实际上程序的执行时间大部分都花在 C 編写的类库方法内部，因此在执行速度上很少会产生那么巨大的差距。 扩展库扩展库是指利用Ruby运行库的API,用C定义的类库。Ruby的API使用C几乎可以实现Ruby所有的功能。使用这些API可以很简单地实现如下的功能： 定义类 定义方法 访问实例变量 调用方法 调用块 特意花时间用C来实现扩展库的理由主要有以下两点。 想要比Ruby执行速度快 想使用C可以利用的库。 前面已经说过,Ruby是解释型语言,它的执行速度不如像C这样的编译型语言。如果是绝对需要改善速度的程序,用C扩展库来实现其中成为瓶颈的部分的话,有可能显著改善程序的执行速度。 UNX系列操作系统的大多数功能都是通过C可以访问的库来提供的。Ruby要想利用这些功能的话,就需要有一种从Ruby调用C的API的方法,这最简单的方法就是利用扩展库。 扩展库的编译首先按照以上的顺序编写源代码。若C程序的文件名后约定为c的话,后续步骤会自动识别出来C程序文件。 为生成编译所需要的文件,需要准备必要的Ruby文件。这个文件通常命名为 extconf.rbminitab的 extconf.rb的内容如图所示 屏幕快照 2018-07-26 下午7.09.31 extons,xb是由以下几个部分构成的: 调用 require’mkmf’; 用have_1 ibrary和 hava header检查必要的库和头文件是否存在； 用 create makefile来生成必要的Makefile. create makefile的参数是库的名字。 照图14-34执行 extconfrb,就可以生成Makefi1e。 屏幕快照 2018-07-26 下午7.13.48 用make命令来编译,尔后可以用 make insta11命令来安装编译后的库。 扩展库之外的工具RubyInlineRubylnline可以在Ruby的源代码中直接嵌入C的程序。不用每次准备 exton,rb文件,也不需要明确的编译步骤,非常便利,但它也有不少约束,比如在执行环境中需要有编译器,与外部库的链接也有些麻烦等。 dl有了d1,仅用Ruby也能实现与 minitab同样动作的库。把图1435的程序保存成 inial,rb文件,没有扩展库也可以使用 minitab。al的优点是在没有安装编译器和头文件的环境下也可以运行。 ffi关于Ruby的扩展,ffi库受到关注。ffi是 foreign function interface的缩写,它也提供在Ruby水平上的与外部函数的直接接口,这个目的与d1几乎是一样的。ffi可以从 Ruby Gems得到。ffi的特征是使用lb更有效率地调用外部函数,Ruby、 Rubinius和 GRubby都可以使用同样的API。 为什么要开源自由软件的思想为保证执行的自由,必须能够将软件免费拿到手。出于学习和研究的目的,也必须能够自由地得到源代码。还有,为了修改程序错误,或者为适合自己的目的而进行改造,那就不单单是阅读源代码,还要允许改变源代码。把自己认为好的软件推荐给别人,或者把自己进行的修改或改善与他人共享的话,就需要有再发布的自由。 自由软件的历史曾几何时,在计算机的黎明期,软件完全是硬件的附属物。买了计算机,附带操作系统等源代码,根本就不是什么稀罕的事。那时,或者在更早一些的时候,甚至有这样的情况,从生产厂家买来的计算机连操作系统也没有,需要用户自己来开发各种软件。买了同样计算机的用户互相交换自己开发的软件,互助合作。虽然不够精致,但与如今开源软件的情况很有些相似之处。 Emacs事件的发生但是,戈斯林把 Gosmacs的专利卖给了 Unipress公司,斯托曼就不能够在 Gosmacs的基础上开发新的 Emacs了。结果,斯托曼从零开始开发了自己的UNIX版的Emacs。 他们的最终目标是，创造一个从上到下完全自由的操作系统环境。 开源的诞生 屏幕快照 2018-07-26 下午8.52.32 OSS许可证GPLGPL( GNU General Public license)应该可以说是自由软件许可证的鼻祖,它具有如下特征: 没有保证; 表示版权; 保持同样的许可证 GPL特征中最重要的是保持同样的许可证,也就是说,在对GPL许可证的软件进行修改或复制的情况下,必须保持其原来的GPL许可证。这意味着再利用GPL软件的源代码而开发的软件的许可证也必须是GPL。批判GPL的人把这称为感染性。赞同GPL的人们称之为版权保留,因为这一性质意味着版权的保留。 LGPLBSD许可证APL和CPL开源的背景在科学领域,共享知识和信息本来是非常普通的事情。即使不用看站在巨人的肩膀上的牛顿的例子,把知识作为论文(免费)公开,利用前人的成绩进行新的研究是再理所当然不过的。 软件,特别是商业软件,一旦作为商品来经营的话,就容易忘记这样一点,与论文的内容一样,软件也不过是信息的一种,也应该适用同样的原则。科学家致力于研究,大学或研究机构对科学家给予支持,这种体制对软件也有可能成立。实际上,大学或研究机构支援软件开发的例子相当多。 但是,谈到近年来开源的普及和发展,计算机的普及和因特网的发展则功不可没。过去如果要想开发髙质量软件的话,需要购买价格髙昂的计算机,召集大量的技术人员。现在一般家庭里的计算机都完全能够开发软件,通过网络进行合作开发的事情也屡见不鲜。个人出于兴趣而编程也已经能够达到相当高的水平了。 软件的复杂化和商品化也是开源的背景之一,不容忽视。软件所覆盖的领域越来越广,软件也越来越复杂。过去1万行左右的程序就实现了的操作系统,如今变成了超过600万行的巨大软件。 企业关注开源的理由从1998年以来,开始出现了盈利企业为自己的利益而开发开源软件的事例。一旦认识到无法自己来开发所有软件之后,企业只自己开发最具竞争力的小部分核心软件,而让大家共同来开发其他软件,结果对大家都有好处,企业关注开源正是这种冷静的分析考量的结果。 参与开源的人们也各有各的想法。有因经营考虑而参加的企业,有为软件自由而参加的程序员,有因上级命令而参加的公司职员,各种各样,千差万别。但是,开源有可能为个人和全人类带来幸福,如果能继续下去形成良性循环的话,那真是再好不过了。 Ruby与开源Ruby从一开始就是开源软件。Ruby在1995年初次公开的时候,开源这个单词还没有诞生,也许应该称为自由软件。 选择许可证的方法许可证与技术无关,而是有关法律和合同的工作,这不是技术人员的工作,而是属于律师的工作范围。对于软件开发人员来说,这决不是一件令人感兴趣的工作,有人甚至会想:“哪用得着这些东西呢?” 如果使用你的许可证的软件的所有代码都完全是由你自己写出来的话,这几乎不成为什么问题。只要发布新的许可证版本,问题就解决了但是,如果其中包含了其他人写的补丁的话,软件就不再是你一个人的了,在法律上写补丁的人是共同拥有版权的。 FSF作为软件自由的拥护者,强烈推行版权保留。另一方面,不怎么在乎版权保留的开发人员好像更多一些。如果你希望版权保留的话,几乎就只能选择GPL。 如果你的软件是作为库来使用的话,那么LGPL则是个不错的选择。如果对库适用GPL许可证的话,那事实上就只能为GPL软件所用,采用限制较为宽松的LGPL的话,有可能使你的软件得到更为广泛的使用。但是,LGPL有不方便、难于理解以及没有得到充分考察等缺点,在不太强烈希望版权保留的时候,最好不要选择它。 对于不太在乎版权保留的人来说,可以选择GPL以外的许可证。这里的要点是,该软件是否需要与其他软件进行链接。如果预想到将来可能以某种方式与GPL许可证的软件链接在一起的话,那么与GPL的互换性就变得很重要。拥有插件功能的软件或库特别要注意这一点。作为与GPL不相矛盾的许可证,有修正BSD许可证和MIT许可证等。 另一个应该考虑的要点是,与相关软件和许可证是否一致。比如 Eclipse插件就应该选择Eclipse许可证(即使不与GPL互换)。另外,PHP关联软件选择与PHP一致的许可证也是安全的。用Ruby编写的软件与Ruby本身的许可证本来是相互独立的,但好像也大都选择Rby许可证。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 13 关于数据的持久化","slug":"松本行弘的程序世界 13 关于数据的持久化","date":"2018-07-24T02:00:32.000Z","updated":"2018-08-10T16:09:13.000Z","comments":true,"path":"2018/07/24/松本行弘的程序世界 13 关于数据的持久化/","link":"","permalink":"https://github.com/zdkswd/2018/07/24/松本行弘的程序世界 13 关于数据的持久化/","excerpt":"","text":"松本行弘的程序世界 13 关于数据的持久化持久化数据的方法保存文本变换成文本的Marshal将对象按一定的方式变换成文本，就可以保存到文件中去。这样的对象文本化就称为serialize(序列化)，或是marshal(封送处理)。 使用Marshal模块标准Ruby中，嵌入了marshal功能，这就是Marshal模块。Marshal模块中提供了几乎能将全部Ruby对象变为字节串的方法dump，以及将字节串恢复成原对象（的复制）的load方法。对象可以简单地保存到文件里。 复制有两种方式使用Marshal可以完成对象的深复制。复制对象的时候，通常使用clone方法。这种情况下，只复制直接对象，引用的对象不复制。称为浅复制。深复制连同引用对象也一起进行递归复制。 仔细看Marshal的格式Marshal用二进制形式将对象文本化。 屏幕快照 2018-07-23 上午11.07.00 屏幕快照 2018-07-23 上午11.09.40 不能保存的3类对象Marshal在实现上有限制。以下3类对象不能保存： 定义了特异方法的对象。 输入、输出或是套接字等不能超越进程保存的对象。 在扩充库中定义，Ruby不知道保存方法的对象。 但是即使不能封送处理，若不是像输入输出那种从原理上不可能的情况，单纯是不知道封送处理方法的话，重新教一遍也就行了。 制作面向对象数据库使用Marshal保存对象，使对象具有了持久性。所以，Marshal也可应用于面向对象数据库。PStore库是Marshal的一个用例。Marshal虽然只是将数据变换成字符串，PStore却利用了这一点，简单地实现了面向对象数据库。PStore有三个特征：使用Marshal，可以原封不动地保存任意的Ruby对象；具有容易使用的接口；有事务处理（transaction）。PStore也有缺点，它不适合一下子将数据全部读入内存的大规模数据库。但几百字节的小规模数据库，应该没问题。 试用PStore打开数据库开始事务处理对象的登录和取得事务处理的终止简单说明一下事务处理的步骤： 用flock将数据文件加锁。 用Marshal从数据文件中读取数据 执行（事务处理）块 块的执行成功，Marshal将数据写入数据文件 块的执行失败，什么也不做。 变换为文本的YAMLMarshal的变换结果是二进制文件，内容不容易看懂。有些场合及时效率低一些，也需要能够以更容易看懂的形式输出。能够满足要求的是YAML。使用文本形式，不依赖平台的体系结构，是一种对人而言易读易编辑的序列化格式。 有以下几个特征：记述简洁；结果容易读懂；使用缩进的层次表现；数据表现是专用的，不必烦恼标签的名称问题。 YMAL可以活用在Ruby on Rails的配置文件等各种各样的领域。YMAL是在Perl中开发的，但正式的支持，Ruby是第一个。 用YAML制作数据库类似于PStore的东西，YAML：：Store，其与PStore的互换性非常高，只要把名字换一换，面向PStore的程序在YAML：：Store也能运行。 他俩的区别： 数据格式很显然，一个YAML，一个Marshal。 数据量Marshal比YAML紧凑的多，Marshal牺牲了易读性而实现了良好性能。 执行速度性能优良不光是容量的问题。使用Marshal的PStore比YAML：：Store速度高，在这一点上，也是数据量越大，两者的差异就越显著。 对象的保存对象持久化库Madeleine，利用直接持久化对象的设计模式Object Prevalence。 Madeleine是Object Prevalence在Ruby中的实现，应称为PStore的发展形式。 PStore只是对象单纯由Marshal输出而来，Madeleine则与应用程序相协调，实现了高可靠性和高性能的持久化。 高速的Object Prevalence所谓Prevalence，是一种实现应用程序持久化和进程间共享数据的设计模式。高性能的秘密在于直接访问内存中的数据。Object Prevalence将处理的数据保存在正在执行的应用程序的内存中，检索等操作不通过SQL而是直接进行，节省了与数据库副武器的通信成本，引用当然就会很高速。 但是，只有是同一进程，才能引用内存中的数据，进程一结束，数据马上消失。从持久化角度有必要解决这一问题。 Object Prevalence用日志记录（journaling）和快照（snapshot）来解决这一问题。Object Prevalence中，数据更新时不是直接更新对象，而是创建称为command的对象，采用的是一种非常间接的方法，在用command更新对象时，内存中的对象更新的同时，所有的更新内容也会写到称为日志（journal log）的外部文件中。 长此下去日志越来越大，所以要将现在数据状态写到称为快照的文件中。有了快照，老日志就不需要了，可在适当的时机删除。 有了最新的快照和最新的日志，可以完全恢复现在对象的状态。程序启动，按三步骤恢复内存的数据。及时有多个进程，只要写入日志的信息是完整的，就可以共享对象的状态。 如果不存在快照，就初始化应用程序数据。 如果存在快照，就读入其中最新的一个。 如果还存在日志，也将其读入，并用其中最新的一个更新应用程序数据。 Object Prevalence的问题点Object Prevalence通过使用日志记录和快照实现了对象的持久化和进程间共享。Object Prevalence将所有数据都保存到内存中，随着数据量的增大，内存的消耗也在增大。 关系数据库中，不引用的数据放在文件中，必要的内存量就不用那么多了。 Object Prevalence有为了数据更新而具有的特殊结构，更新持久化数据时需要经由command对象。 使用Madeleine访问时刻信息让Madeleine更容易使用Madeleine既保持简洁性，又能让对象持久化，但是最大的缺点是在每次更新应用程序时必须生成command对象。 Madeleine的实用例InstikiMadeleine没有得到广泛应用，除了知道的人少，还因为数据全保存在内存中，就必须十分留意数据的大小。 Madeleine有一个很大的缺点，就是没有考虑多个进程同时更新数据的情况。 关于XML的考察XML的祖先是SGMLSGML是将文档电子化的一种格式。由三部分组成：表示数据本身的Instance，表示数据结构的DTD，以及SGML声明。 由于SGML太复杂，处理成本太高，为了表现网页，将SGML特化为HTML，随之诞生的是XML。 XML不像HTML那样是为了特定目的的标记语言，它一开始就是为了通用目的而设计的。为了让XML在没有DTD来定义语法或提供schema信息的情况下，也能够解析，人们对其语法进行了简化。 XML是树结构的数据表现XML基本上是纯文本，以类似于HTML的标签嵌套方式实现树结构。XML是继承了SGML的通用标记语言，其与SGML最大的区别是其基本语法固定，不依赖于DTD那样的外部信息也能解析。 即使没有标签的概要信息也能解析的语法称为良构的（well-formed）,这是XML的一大特征。 优点在于纯文本最大的优点在于XML基本上是纯文本的，表示结构的信息附加在标签里。 第二个优点是不易发生字符编码的问题。XML规定，在没有明确指定的情况下，字符编码均使用Unicode。 第三个优点是得益于良构的性质，在没有数据结构的情况下也能解析XML数据。这样就可以不考虑目的，而用共同的工具来处理XML数据。 第四个优点在于，XML与其解析工具不依赖于特定的语言，比如Java生成的XML数据在Ruby中的解析也很简单。解析XML的API，像DOM和SAX都超越语言提供了几乎共通的性质，所以不同语言也可以进行同样的操作。 最后一个有点是，人们也很容易理解。 总之，XML作为各种数据交换格式的框架，具有优良的性质。作为格式的格式，也就是元格式，是很优秀的。 缺点在于冗长最大的缺点是效率低下。XML是以纯文本出现的，标签信息反复出现，显得冗长。与表示相同信息的二进制数据相比，XML数据的容量要大得多，与其他文本表现方式相比（YAML，JSON）也显得冗长。 效率低下不光体现在数据大小上，解析XML的效率也不怎么高。与二进制文件相比，XML文件的解析因为含有大量字符串处理，而容易变得很慢。 作为文本的标记语言而诞生的XML，用其表现有一定结构的数据到底好不好还是个疑问。如果只是用于表现构造数据，比XML更有效率的格式还有很多。而且XML原则上只能表现树结构的数据。 总结，XML作为出于通用目的的数据格式，效率很低，所谓很多优点，如果场合不对，也没多大意义。适才适用，XML也要分情况适当使用。 不适合重视效率的处理对于重视通信量和速度的情况都不适合，此时应使用专用的协议或是效率更高的格式。 像配置文件那样靠人直接编辑的数据也不推荐XML。配置文件中，需要用到XML的树结构数据地方很少，随着要素数增加，就会很难读，用YMAL和JSON才更合适。 XML适合的场合： 人一般不直接接触 复杂性不成问题 效率不成为问题 跨平台 适合于信息交换的格式利用XML的元格式性质，以XML为基础的格式的例子。 RSS。Web网站更新信息。 Atom。RSS的代替。 ebXML。电子商务数据交换。 SVG。向量-图像表示。 SMIL。 多媒体及内容控制。 以上这些都具有XML的性质，可以用XML处理工具简单地解析。制作数据格式时，最麻烦的就是制作处理这种格式的软件。所以，XML与XML处理库的存在是很可贵的。 另外，XML数据库中，问题不在于数据是不是实际以纯文本XML来表现，而在于XML能够表现的树结构能够自由自在地操作。即，不是带标签的纯文本，而是由带属性、带内容的节点所构成的树结构本身才是最重要的。关系数据库的表只能表示间接数据，如果是树结构，可以直接操作直接表现的数据。 XML的解析XML的解析方法有好几种。 DOMDOM是文档对象模型的缩写，是对读取了XML数据的树结构进行操作的库。 SAXSimple API for XML,与将数据全部读入内存的DOM不同，通常，SAX以数据流的形式读入XML，以事件驱动进行处理。SAX中，没必要将数据全部读入，这样往往处理效率更高，所以适合于将XML变换为其他形式的处理，反过来说，不适合于对树结构进行随机访问等用途。 XPathXPath是用于指定XML树的一部分的书写格式。使用XPath，可以用节点名、属性名或是属性值等来选择特定的节点（群）。 XML处理库REXMLREXML是Ruby标准附属的XML处理库。REXML是具有DOM、SAX、SAX2以及XML Pull Parser等多照片那个功能的库。全部用Ruby实现，所以速度表现不怎么优秀。在特别重视效率的情况下，有必要用libxml等别的XML处理库。 XML的代替JSON（JavaScript Object Notation）JSON是把JavaScript的对象记法作为表现格式来使用。 将JSON数据原封不动地作为JavaScript去执行，就可以得到数据表现所对应的对象。但是JSON数据从外部读取的情况较多，实际上作为JavaScript直接执行容易引起安全上的问题，即使效率稍稍低一些，也应当使用解析JSON的库。 Ruby支持JSON。 YAML（YMAL ain’t Markup Language）YAML是作为XML的对立面而诞生的，具有以下特征。完全放弃标记性记述，专注于数据表现；以缩进为基础表现数据结构；不要标签；可以对应各种语言。文件后缀为.yml 在用作数据表现及配置文件时，具有易读和不易变复杂等优点。实际上，YAML在Ruby on Rails中广泛用于配置文件。 另一方面，YAML到底是数据表现语言，没有相当于schema的东西，不适合于带结构的文本表现及元数据格式。 活用记号和缩进的YMAL比JSON更简洁，正如其名，YMAL不是标记语言，需要使用标记语言时还是XML合适。1YAML是JSON的超集，采用空格来作为结构，JSON则是括号，一般YAML解析速度高于JSON，但对于某些东西定义的复杂性高于JSON，速度差别不大时可考虑用JSON。 Binary XML与通常的XML有等价意义，但效率更高，采用二进制表现的是Binary XML。但现在还没有Binary XML的标准规格。 Protocol BufferProtocol Buffer使用一种“数据描述语言”来定义数据结构，然后从这个定义生成一个库，将原始数据变为二进制表现（序列化）。 12持久数据的重要性如果不是有了像纸和刻了文字的石头等经久不烂而且可以读出的媒介，将来人类文明说不定会遇到失去重要信息的危险。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 12 关于时间的处理","slug":"松本行弘的程序世界 12 关于时间的处理","date":"2018-07-23T13:53:32.000Z","updated":"2018-07-23T13:53:46.000Z","comments":true,"path":"2018/07/23/松本行弘的程序世界 12 关于时间的处理/","link":"","permalink":"https://github.com/zdkswd/2018/07/23/松本行弘的程序世界 12 关于时间的处理/","excerpt":"","text":"松本行弘的程序世界 12 关于时间的处理用程序处理时刻与时间时差与时区世界协调时间夏令时一定时期内时钟拨快一小时。 改历日期与时间的类Time类表示日常所用时间的类。 Date类表示不含时刻的日期的类。 DateTime类Date类附加上时间信息的类。能表示时间，而且没有范围限制，功能上最强。 2038年问题不仅限UNIX，很多操作系统都是以过去某个时点开始所经过的时间来表示时刻的。在UNIX中，过去某个时点指1970年1月1日零点。问题是计算机能够处理的整数大小有限，界限是2038年1月19日3时14分7秒。 DateTime类相对于epoch（某个时点）开始的秒数来管理Time类，DateTime类是以日期为基础计算的Date类，附加上时刻信息而生成的。 Time与DateTime的相互变换","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 11 程序安全性","slug":"松本行弘的程序世界 11 程序安全性","date":"2018-07-21T13:28:32.000Z","updated":"2018-07-21T13:29:05.000Z","comments":true,"path":"2018/07/21/松本行弘的程序世界 11 程序安全性/","link":"","permalink":"https://github.com/zdkswd/2018/07/21/松本行弘的程序世界 11 程序安全性/","excerpt":"","text":"松本行弘的程序世界 11 程序安全性程序的漏洞与攻击方法四种软件漏洞 dos攻击 信息泄露 权限夺取 权限升格 DOS攻击，即拒绝服务攻击，指妨碍软件正常运行（服务的执行）的网络攻击手段。能够引起软件异常终止的程序错误，全部都是引发DOS攻击的安全性程序错误。分为软件漏洞与外部DOS攻击。信息泄露指不愿公开的信息被公开了。 因权限被窃取而成为重大问题安全问题的根源在于运行软件的人（权限所有者）和利用软件的人是不同的。安全问题有三种 恶意软件指在程序本身植入了恶意代码。 setuid/setgid指执行的程序以所有者权限进行动作。setuid的缺点已经变得比优点更突出，现在几乎不用了。 服务器 “守护神”引起的问题服务这里指的是为了提供服务而常驻型的软件，又为后台服务(daemon),即守护神的意思。后台服务基本上都是受理经由socket而来的请求。执行它所提供的服务，将结果经socket返回。几乎所有的情况，发出请求者和执行权限者都是不同的。这种软件若有了漏洞，会引起DOS问题和权限夺取问题。 多样化的攻击手段代表性的有： 缓冲区溢出 整数溢出 跨站点脚本攻击（XSS） SQL注入 跨站点伪造请求（CSRF） 缓冲区溢出指向固定的缓冲区输入了比假定长度要长很多的数据，使程序异常终止。或者是更改堆栈的跳转地址劫持程序。使用C那种连数组长度都不检查的语言，可以说肯定会产生问题。幸亏，像Ruby这样的高级语言，语言处理系统自动分配内存，可以不使用固定长的缓冲区。使用更高级的语言，可以从缓冲区溢出问题中解放出来。但由于速度上的考虑，还会开发C语言的CGI及Daemon程序，应多加注意。 整数溢出整数溢出与缓冲区溢出相似，但它是更难被发现的问题。c等很多语言，整数只能表示一定范围的数，超过范围，就会发生溢出，也不发出警告就将数值舍入。这个问题通过使用Ruby这样的高级语言可以解决，内存分配不是由用户直接进行，内部分配都要经过严格检查。所以，只要使用Ruby，与整数溢出就不沾边。 SQL注入SQL注入是对外部的输入检查不充分时所产生的典型问题。从外部的输入不能原封不动填到SQL语句中去，因为填入的文字可能含有对SQL语句有某种意义的文字。 Shell注入Shell注入与SQL注入原理相同。从外部的输入，如果不进行检查就不能传递给system等危险的函数。为了从一定程度上检查出这类问题，Ruby和Perl中有“污染检查”功能。给外部输入的数据加上“污染记号”，禁止对字符串进行危险操作。 跨站点脚本攻击跨站点脚本攻击与SQL注入和Shell注入一样，也是因为将输入值原封不动地放在输出值内而引起的问题。如用户输入中含有HTML标签。而且HTML可能夹杂JavaScript。 跨站点伪造请求跨站点伪造请求（CSRF）是Web应用程序固有的攻击手段。构成Web应用程序的每一页由两部分构成，一个来自网路浏览器的HTTP请求，一个是HTTP服务器的响应。 屏幕快照 2018-07-21 下午7.11.22 社会工程用异常进行错误处理异常的历史Java的受控异常采用受控异常的，Java是第一个。 Icon的面向目标判断Ruby在设计之初，也曾认真考虑过采用像Icon式的真伪值判断，结果还是采用了nil和false以外的值全是真值的这种正统方式。 Ruby的异常 屏幕快照 2018-07-21 下午7.30.12 异常发生 屏幕快照 2018-07-21 下午7.33.32 异常处理的设计方针方法的执行应当“异常安全”，即执行时及时发生了异常也不会发生异常情况： 因为发生了异常，留下了不完全的数据结构 因为发生了异常，数据库里进了垃圾 因为发生了异常，程序异常终止 异常发生的设计原则假设发生的情况与既有的异常类明显不同，需要制作一个新的异常。此时考虑： 名称：应该给新的类起一个什么样的名字 父类：新的类应该属于哪一个异常类的子类 生成方法：应该如何初始化新的类实例 产生异常的两个原则：1异步异常，基本原则是不要使用异步异常。2.文档化，有必要清楚详细的写成文档。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 10 高速执行和并行处理","slug":"松本行弘的程序世界 10 高速执行和并行处理","date":"2018-07-20T09:58:32.000Z","updated":"2018-07-20T10:20:12.000Z","comments":true,"path":"2018/07/20/松本行弘的程序世界 10 高速执行和并行处理/","link":"","permalink":"https://github.com/zdkswd/2018/07/20/松本行弘的程序世界 10 高速执行和并行处理/","excerpt":"","text":"松本行弘的程序世界 10 高速执行和并行处理让程序高速执行（前篇）是不是越快越好并不是视速度最优先就一定好。预算、开发效率和开发周期等制约因素也在性能权衡范围之内。 高速执行的乐趣与效率在进行性能优化之前，必须确认是否真有必要提高速度。速度提高到什么程度也要事先估算。 以数据为基础做出判断改善系统调用排序处理任务重时，典型的对策是使用施瓦茨变换。 数据可靠吗误差 只需改善瓶颈性能优化中，“因为是排序，所以就用施瓦茨变换”这种条件反射式的对策并非总管用。为了合理提高速度，确立恰当的策略是很必要的。帕累托法则又称80/20法则，即80%的数值是由20%的构成要素产生的。由帕累托法则可知，有20%的努力可以达到巨大回报，而有80%的努力得不到多少回报。在得不到回报的地方，不管怎么努力都是徒劳的。Donald Knuth也提到，通常一半以上的执行时间都耗费在程序中不到4%的部分。这些耗费了大半以上执行时间的部分称为瓶颈。判定瓶颈，可以用profiler这一工具。 profiler本身成了累赘不确定性原理是指测定行为本身对被测对象产生了影响，从原理上可以说不可能正确知道对象的状态。但是知道实际状态的大体倾向。 算法与数据结构选择合适的算法，这是性能改善的第一考虑因素，要记住这条铁则。 理解O记法如何从效率方面判定一个算法的好坏呢。一个方法就是O记法，表示某种算法对于变量（比如使用的元素个数）如何变化。 屏幕快照 2018-07-20 上午11.05.39 选择算法调查算法的性能Ruby提供进行算法性能比较时用的benchmark程序。 高速执行的悲哀徒劳无益的努力很容易在瓶颈无关的地方花费太多徒劳无益的努力。 改良绊住了手脚sort_by所依据的施瓦茨变换，是用时间和空间的交换来消减计算量的方法。sort_by方法与sort方法相比，占用了多达三倍以上的内存。所以，模块内的处理本来不是很重，如果一味地占用内存反而可能会变慢。性能优化，光有理论还不行，如果不实际做的话就不知道到底什么是正确的。 算法选择的圈套在进行性能优化时，不改变原来程序的执行时一个大原则。 性能优化的格言过早的优化是万恶之源。 优化有两条准则。1.别做优化2.（仅适用于专家）先不要做优化 过早的优化是万恶之源代码优化的好处多多，但是这并不意味着所有的代码都需要进行优化，有时过度的优化反而适得其反——费时、费力、不讨好。“现代计算机科学的鼻祖”Donald Knuth曾说过“过早的优化是万恶之源”，因为：让正确的程序更快，要比让快速的程序正确容易得多。在项目开发中，总是有程序员浪费宝贵的时间去改进那些不需要改进的代码，而没有通过所做的改进增加价值。在对项目进行优化时，究竟哪些地方应该优化，应该如何优化，哪些不应该优化呢？你需要先来了解一下本文所说的这7件事。1.究竟要优化什么？在优化工作开始的时候，你还尚未明确优化内容和目的，那么你很容易陷入误区。在一开始，你就应该清楚地了解你要达到的效果，以及其他优化相关的各种问题。这些目标需要明确指出（至少精通技术的项目经理可以理解和表达它），接下来，在整个优化过程中，你需要坚持这些目标。在实际的项目开发中，经常会存在各种各样的变数。可能一开始时要优化这一方面，随后你可能会发现需要优化另一方面。这种情况下，你需要清晰地了解这些变化，并确保团队中的每个人都明白目标已经发生了变化。2.选择一个正确的优化指标选择正确的指标，是优化的一个重要组成部分，你需要按照这些指标来测量优化工作的进展情况。如果指标选择不恰当，或者完全错误，你所做的努力有可能白费了。即使指标正确，也必须有一些辨别。在某些情况下，将最多的努力投入到运行消耗时间最多的那部分代码中，这是实用的策略。但也要记住，Unix/Linux内核的大部分时间花费在了空循环上。需要注意的是，如果你轻易选择了一个很容易达到的指标，这作用不大，因为没有真正解决问题。你有必要选择一个更复杂的、更接近你的目标的指标。3.优化在刀刃上这是有效优化的关键。找到项目中与你的目标（性能、资源或其他）相背的地方，并将你的努力和时间用在那里。举一个典型的例子，一个Web项目速度比较慢，开发者在优化时将大部分精力放在了数据库优化上，最终发现真正的问题是网络连接慢。另外，不要分心于容易实现的问题。这些问题尽管很容易解决，但可能不是必要的，或与你的目标不相符。容易优化并不意味着值得你花费工夫。4.优化层次越高越好在一般情况下，优化的层次越高，就会越有效。根据这个标准，最好的优化是找到一个更有效的算法。举个例子，在一个软件开发项目中，有一个重要的应用程序性能较差，于是开发团队开始着手优化，但性能并没有提升太多，之后，项目人员交替，新的开发人员在检查代码时发现，性能问题的核心是由于在表中使用了冒泡排序算法，导致成千上万项的增加。尽管如此，高层次的优化也不是“银弹”。一些基本技术，如将所有东西移到循环语句外，也可以产生一些优化的效果。通常情况下，大量低层次的优化可以产生等同于一个高层次优化的效果。还需要注意的是，高层次优化，会减少一些代码块，那么你之前对这些代码块所做的优化就没有任何意义了，因此，刚开始就应该考虑高层次的优化。5.不要过早优化在项目早期就进行优化，会导致你的代码难以阅读，或者会影响运行。另一方面，在项目后期，你可能会发现之前所做的优化没有起到任何作用，白白浪费了时间和精力。正确的方式是，你应该将项目开发和优化当作两个独立的步骤来做。6.依赖性能分析，而不是直觉你往往会认为你已经知道哪里需要优化，这是不可取的，尤其是在复杂的软件系统中，性能分析数据应该是第一位的，最后才是直觉。优化的一个有效的策略是，你要根据所做工作对优化效果的影响来进行排序。在开始工作之前找到影响最大的“路障”，然后再处理小的“路障”。7.优化不是万金油优化最重要的规则之一是，你无法优化一切，甚至无法同时优化两个问题。比如，优化了速度，可能会增加资源利用；优化了存储的利用率，可能会使其他地方放慢。你需要权衡一下，哪个更符合你的优化目标。 让程序高速执行（后篇）例题是曼德勃罗集合的计算程序，指复平面上满足以下条件的复素数的集合：经过某种反复迭代运算以后，其值不会发散到无限大。 确认程序概要发现瓶颈使用profiler 使用更好地profilerruby-prof程序通过使用扩展库可以实现高速profile 高速优化之一：消减对象Ruby高速优化的规则。 减少对象高级面向对象语言中对象的生成要花费一定的时间，减少对象，除了会降低生成成本外，还有别的好处。Ruby中不在使用的对象，由被称作垃圾收集的处理自动进行回收。垃圾收集处理需要检查对象的引用关系，任何地方都不再引用的对象会被判定为已经不再使用了。当对象的数量很多时，判断成本就要增大。 减少方法调用方法调用中，存在多态性这一面向对象的本质特征，先要评价参数，判定对象种类，然后选出一个合适的方法，再讲控制交给该方法，这是一个缓慢的处理过程。为了避开方法调用，尽可能不用Ruby中实现的方法。Ruby中实现的方法，几乎所有的情况都是调用其他方法来实现的。也就是说，只要使用了一次Ruby中实现的方法，就会有多余的方法调用发生。 高速优化之二：利用立即值Ruby中有几类对象并不实际分配内存，而是用引用本身来表示，这种值称为立即值。现在的Ruby中，小的整数（±2 ^30以内）、真假值、nil和符号名等都是立即值。立即值既然不生成对象，就不用担心对象的生成成本，而且也不用垃圾收集处理，所以它具有特别理想的特性。 高速优化之三：利用C语言Ruby是解释性语言，单纯计算的循环不是很快。如果将处理交给编译器，就可以变得很快。 高速优化之四：采用合适的数据结构全部以C语言计算还存在其他技巧还有以空间换时间。 并行编程使用线程的理由与进程不同，同一进程的线程可以共享内存空间，所以，不同的线程能够引用同一对象。不需要经过将数据变为字节流再进行通信这样麻烦的处理，就能交换信息。 生成线程线程的执行状态Ruby的线程有四种状态。run：执行中stop：停止中to_kill:终止处理中killed:终止 屏幕快照 2018-07-20 下午1.55.11 传递值给线程的方法信息共享所产生的问题 数据完整性丧失 死锁 与其说是线程的问题，不如说是并行处理本身的问题。 数据完整性的丧失原子操作 死锁哲学家进餐问题 用锁来实现对资源的独占Ruby Mutex类，互斥锁。Java中，方法定义声明为synchronize,该方法被调用时自动加锁。 二级互斥很遗憾，锁的问题并不全是Mutex所能覆盖的单纯事例。如数据库中，对数据的访问需要以下多种互斥控制。 可以同时引用 禁止同时更新 禁止更新中引用 禁止引用中更新 引用与更新这种两个层次的互斥（二级互斥），在文件读取时也经常会发生。 数据库锁总结 数据库锁出现的原因是为了处理并发问题，因为数据库是一个多用户共享的资源，当出现并发的时候，就会导致出现各种各样奇怪的问题，就像程序代码一样，出现多线程并发的时候，如果不做特殊控制的话，就会出现意外的事情，比如“脏“数据、修改丢失等问题。所以数据库并发需要使用事务来控制，事务并发问题需要数据库锁来控制，所以数据库锁是跟并发控制和事务联系在一起的。 平时会经常看到或者听到数据库锁有“共享锁”，“排它锁”，“互斥锁”，“写锁”，“读锁”，“悲观锁”，“乐观锁”，“行级锁”，“表级锁”，“页级锁”等，同时我们还会常看到“丢失修改“，”不可重复读“，”读脏数据“这三个术语，他们究竟是什么关系以及怎么理解呢，下面就来介绍一下他们。 先说事务的特性，要想成为事务，必须满足：ACID（原子性，一致性，隔离性，持久性）四特性，事务是恢复和并发控制的基本单位。原子性指的是事务是数据库的逻辑工作单位，事务中操作要么都做，要么都不做；一致性指的是事务的执行结果必须是使数据库从一个一致性状态变大另一个一致性状态，一致性和原子性是密切相关的；隔离性指的是一个事务执行不能被其他事务干扰；持久性指的是一个事务一旦提交，他对数据库中数据的改变就是永久性的。 先说悲观锁和乐观锁吧。并发控制一般采用三种方法，分别是乐观锁和悲观锁以及时间戳。乐观锁认为一个用户读数据的时候，别人不会去写自己所读的数据；悲观锁就刚好相反，觉得自己读数据库的时候，别人可能刚好在写自己刚读的数据，其实就是持一种比较保守的态度；时间戳就是不加锁，通过时间戳来控制并发出现的问题。悲观锁就是在读取数据的时候，为了不让别人修改自己读取的数据，就会先对自己读取的数据加锁，只有自己把数据读完了，才允许别人修改那部分数据，或者反过来说，就是自己修改某条数据的时候，不允许别人读取该数据，只有等自己的整个事务提交了，才释放自己加上的锁，才允许其他用户访问那部分数据。乐观锁就比较简单了，就是不做控制，这只是一部分人对于并发所持有的一种态度而已。时间戳就是在数据库表中单独加一列时间戳，比如“TimeStamp”，每次读出来的时候，把该字段也读出来，当写回去的时候，把该字段加1，提交之前 ，跟数据库的该字段比较一次，如果比数据库的值大的话，就允许保存，否则不允许保存，这种处理方法虽然不使用数据库系统提供的锁机制，但是这种方法可以大大提高数据库处理的并发量，因为这种方法可以避免了长事务中的数据库加锁开销（操作员A 和操作员B操作过程中，都没有对数据库数据加锁），大大提升了大并发量下的系 统整体性能表现。 需要注意的是，乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局 限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户 余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。在 系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如 将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途 径，而不是将数据库表直接对外公开）。以上悲观锁所说的加“锁”，其实分为几种锁，分别是：排它锁和共享锁，其中排它锁又称为写锁，共享锁又称为读锁。 共享锁和排它锁是具体的锁，是数据库机制上的锁，存在以下关系： 屏幕快照 2018-07-20 下午2.17.40 (x表示是排它锁(Exclusive)，s表示共享锁(Share)，Y表示yes，N表示no） 上图表示可以共存的锁，如，第二行表示，一个事务T1给某数据加了X锁，则事务T2就不能再给那数据加X锁了，同时也不能再加S锁了，只有到T1事务提交完成之后，才可以。默认来说，当sql脚本修改更新某条记录的时候，会给该条记录加X锁，读的话加的是S锁。另外，并发操作会导致数据的不一致性，主要包括“丢失数据”，“不可重复读”，“读脏数据等。还有就是，并发控制会造成活锁和死锁，就像操作系统那样，会因为互相等待而导致。活锁指的是T1封锁了数据R，T2同时也请求封锁数据R，T3也请求封锁数据R，当T1释放了锁之后，T3会锁住R，T4也请求封锁R，则T2就会一直等待下去，这种处理方法就是采用“先来先服务”策略；死锁就是我等你，你又等我，双方就会一直等待下去，比如：T1封锁了数据R1，正请求对R2封锁，而T2封住了R2,正请求封锁R1，这样就会导致死锁，死锁这种没有完全解决的方法，只能尽量预防，预防的方法有：1一次封锁发，指的是一次性把所需要的数据全部封锁住，但是这样会扩大了封锁的范围，降低系统的并发度；2顺序封锁发，指的是事先对数据对象指定一个封锁顺序，要对数据进行封锁，只能按照规定的顺序来封锁，但是这个一般不大可能的。另外，系统如何判断出现死锁呢，毕竟出现死锁不能一直干等下去，要及时发现死锁同时尽快解决出现的死锁，诊断和判断死锁有两种方法，一是超时法，二是等待图法。超时法就是如果某个事物的等待时间超过指定时限，则判定为出现死锁；等待图法指的是如果事务等待图中出现了回路，则判断出现了死锁。对于解决死锁的方法，只能是撤销一个处理死锁代价最小的事务，释放此事务持有的所有锁，同时对撤销的事务所执行的数据修改操作必须加以恢复。 最后，说下行级锁和表级锁。锁包括行级锁和表级锁行级锁是一种排他锁，防止其他事务修改此行。 用队列协调线程使用锁对资源进行互斥控制，是线程间保证协调的一种机制。除了锁以外，为了保证协调，还有别的方法。问题的根源在于多个进程访问同一资源，为了实现无共享，给每个资源准备一个管理用的线程，各线程间只能交换某些限定的信息。线程间信息交换的方法有代表性的有信息存储，信道及队列。 屏幕快照 2018-07-20 下午3.05.36 1这里的生产者消费者问题并不是典型的生成者消费者问题，而是做出了一定的限制，即生产速度小于消费速度。不锁buffer,仅做信息传递的通道来进行说明。 队列也可以用于解决资源的竞争。 屏幕快照 2018-07-20 下午3.08.13 锁模型与队列模型的比较锁模型如果竞争足够少，多数情况下能保持较高性能，对于资源的竞争，不能忘记加锁，要做到完美无缺较难。 队列模型在竞争少的时候，其性能比不上锁模型，比锁模型更容易贯彻，会因线程增多而带来性能低下的恶果。 前景可期的并行编程技术，Actor并行编程，要求有更高的抽象度和对人类而言更简单的编程模型。Actor（参与者模式）或许就是答案。 何谓Actor所谓Actor，是（仅）通过消息（message）进行通信的实体。与面向对象语言中对象的区别。向对象发送消息（方法调用），调用开始后，会一直等到返回结果，是一种同步方式。面向Actor发送消息，仅仅是发送消息而不返回结果，是一种异步方式。123同步(Synchronous)和异步(Asynchronous)1.同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。2.异步方法调用更像一个消息传递，一旦开始，方法调用就会立即返回，调用者就可以继续后续的操作。而，异步方法通常会在另外一个线程中，“真实”地执行着。整个过程，不会阻碍调用者的工作。 Actor由于仅仅通过消息进行信息交换，所以不能直接共享同一个值，信息传达要多花些代价。Actor由于没有消息以外的信息传递手段，所以不用担心Actor之间的资源竞争。发送给Actor的消息都配送到各个Actor所拥有的邮箱里。多个消息同时到达时竞争由内嵌到系统中的排除机制来处理。Actor的一大优点是安全，更大的优点是易懂。Actor根据消息进行处理，必要的化会向其他Actor传递消息，或向Actor返回消息。这与现实世界中人与人之间相处没有多大的差别。现实世界中，别人在想什么你不知道，想要求什么时，需要通过某种手段传递“消息”。理论上要到达最高性能，一般认为线程更优秀。但如果不注意使用线程的话，会出现与时机相关的很麻烦的问题。在计算机性能日益提高的今天，与理论上最高性能的可能性相比，Actor的安全性和易懂性更引人注目。 操作Actor的三种处理系统Actor Model的函数型语言Erlang。Erlang是只允许单一赋值的函数型语言，即一旦赋值，变量的值就不再改变。 Erlang的程序pingpong处理的开始启动pingpong程序Erlang的错误处理Erlang中通过发送消息来通知异常终止。收到消息的process（actor）料理死去的process后事。有了这种机制，使得Erlang适合构造抗障碍性强的系统。 Erlang的使用场所Erlang在通常的文本处理汇总并不怎么快。Erlang的好处在于其扩展性。对于多个处理并列执行的情况，分割成合适的Erlang process，能够发挥多CPU的威力。同样的多任务分割虽然用操作系统的进程或线程也能实现，但Erlang的process与操作系统的进程或线程相比，能够轻量实现（1个process最小只耗费300字节），即使有大量process也不必顾虑、更进一步说，Erlang设计思想不用process连基本处理都不能实现，process分割在某种意义上可以说是强制的。 适合现代服务器端程序。 面向Ruby的库“Revactor”Revactor的目的是为Ruby提供Erlang式的编程。其优点是可以同时体验Ruby和Erlang的好处。但是Revactor中Actor的实现不是靠线程而是靠Fiber。Erlang的目的在于最大限度地利用多核CPU，而Revactor并不适合这种目的。Revactor的最大优点，是能够在等待文件输入输出时，将程序的停止控制在最小程度。 另一个库DramatisDramatis是Ruby中另一个Actor库。函数型语言Erlang不支持面向对象功能。用Ruby这样的面向对象语言来实现Actor的时候，即使用普通对象来实现Actor，也不可避免地会出现把方法调用和发送消息这两种类似概念混在一起的情况。Dramatis库就是解答这种“概念混淆”。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"Android群英传 3 Android控件架构与自定义控件详解","slug":"Android群英传 3 Android控件架构与自定义控件详解","date":"2018-07-18T07:27:32.000Z","updated":"2018-07-18T09:58:53.000Z","comments":true,"path":"2018/07/18/Android群英传 3 Android控件架构与自定义控件详解/","link":"","permalink":"https://github.com/zdkswd/2018/07/18/Android群英传 3 Android控件架构与自定义控件详解/","excerpt":"","text":"Android群英传 3 Android控件架构与自定义控件详解Android控件架构控件大致被分为两类，即ViewGroup控件与View控件。通过ViewGroup，整个界面的控件形成了一个树形结构控件树。上层控件负责下层子控件的测量与绘制，并传递交互事件。findViewById（）方法，就是在控件树以数深度优先来遍历查找对应的元素。每颗控件树的顶部，都有一个ViewParent对象，为整棵树的控制核心，所有的交互管理事件都由它统一调度和分配，从而可以对整个视图进行整体控制。 屏幕快照 2018-07-17 下午2.31.03 通常，在Activity中使用setContentView（）方法来设置一个布局，在调用该方法后，布局内容才真正的显示出来。 屏幕快照 2018-07-17 下午2.36.21 每个Activity都包含一个Window对象，由PhoneWindow来实现。PhoneWindow将一个DecorView设置为整个应用窗口的根View。DecorView作为窗口界面的顶层视图，封装了一些窗口操作的通用方法。DecorView将要显示的具体方法呈现在PhoneWindow上，这里面的所有View的监听事件通过WindowManageService来进行验收，并通过Activity对象来回调相应的onClickListener。在显示上，它将屏幕分为两部分，TitleView和ContentView。 屏幕快照 2018-07-17 下午2.45.14 其中ViewGroup会根据对应参数设置不同的布局，如最常用的布局。而如果用户通过设置requestWindowFeature(Window.FEATURE_NO_TITLE)来设置全屏显示，视图树中的布局就只有Content了，这就解释了为什么调用requestWindowFeature()方法一定要在调用setContentView()方法之前才能生效的原因。在代码中，当程序在onCreate（）方法中调用setContentView（）方法后，ActivityManagerService会回调onResume（）方法，此时系统才会把整个DecorView添加到PhoneWindow中，并让其显示出来，从而最终完成界面的绘制。 View的测量系统在绘制View前，必须对View进行测量，即告诉系统该画一个多大的View，在onMeasure（）方法中进行。通过系统提供的设计精悍功能强大的类MeasureSpec类来测量View。MeasureSpec为32位int值，高2位位测量的模式，低30位为测量的大小，在计算中使用位运算是为了提高并优化效率。测量模式为3种： EXACTLY即精确值模式，当我们将控件的layout_width或layout_height属性指定为具体数值时，或指定为match_parent属性时（占据父View的大小），系统使用的是EXACTLY模式。 AT_MOST即最大值模式，当控件的layout_width或layout_height属性指定为wrap_content时，控件大小一般岁总监的子控件或内容的变化而变化，此时控件的尺寸只要不超过父控件允许的最大尺寸即可。 UNSPECIFID不指定大小测量模式，View想多大就多大，通常情况下在绘制自定义View时才会使用。 View类默认的onMeasure（）方法只支持EXACTLY模式，所以如果自定义控件时不重写onMeasure方法的话，就只能使用EXACTLY模式。控件可以响应你指定的具体宽高值或是match_parent属性。而如果要让自定义View支持wrap_content属性，那么就必须重写onMeasure（）方法来指定wrap_content时的大小，如果不重写，就不知道该使用默认多大的尺寸，因此，就会默认填充整个父布局，所以重写onMeasure（）方法的目的，就是为了能够给View一个wrap_content属性下的默认大小。 View的绘制测量好一个View后，我们就可以重写onDraw（）方法，在Canvas对象上来绘制所需要的图形。当创建一个Canvas对象时，需要传进去一个bitmap对象。这个bitmap用来存储所有绘制在Canvas上的像素信息。调用所有的Canvas.drawXXX方法都发生在这个bitmap上。 ##ViewGroup的测量ViewGroup会去管理子View，就有负责子View的显示大小。当ViewGroup大小为wrap_content时，就需要对子View进行遍历，以获得所有子View的大小，从而决定自己的大小。其他模式则会通过具体的指定值来设置自身的大小。ViewGroup在测量时通过遍历所有的子View，从而调用View的Measure方法来获得每一个子View的测量结果。当子View测量完毕时，就需要将子View放到合适的位置，这个过程就是View的Layout过程。ViewGroup在执行Layout过程时，同样是使用遍历来调用子View的Layout方法，并制定其具体显示的位置从而来决定其布局位置。在定义ViewGroup时，通常会重写onLayout方法来控制其子View显示位置的逻辑。同样，如果要支持wrap_content属性，必须重写onMeasure。 ViewGroup的绘制ViewGroup通常不需要绘制，如果不是指定了ViewGroup的背景颜色，ViewGroup的onDraw方法都不会被调用，但是，ViewGroup会使用dispatchDraw()方法来绘制其子View，其过程同样是通过遍历所有的子View，并调用子View绘制方法来完成绘制。 自定义View在自定义View时，我们通常会去重写onDraw()来绘制View的显示内容，如果该View还需要使用wrap_content属性，那么还必须重写onMeasure()方法。另外，通过自定义attrs属性，还可以设置新的属性配置值。在View中通常有以下一些比较重要的回调方法。 onFinishInflate():从XML加载组件后回调。 onSizeChanged():组件大小改变时回调。 onMeasure():回调该方法来进行测量。 onLayout():回调该方法来确定显示的位置。 onTouchEvent():监听到触摸事件时回调。 通常有以下方法来实现自定义的控件。 对现有控件进行扩展。 通过组合来实现新的控件。 重写View来实现全新的控件。 对现有控件进行扩展可以再onDraw()方法中对原生控件行为进行扩展。程序调用super.onDraw(canvas)方法来实现原生控件的功能。 创建复合控件创建复合控件可以很好地创建出具有重用功能的控件集合。这种方式通常需要继承一个合适的ViewGroup，再给它添加指定功能的控件，再给它添加指定功能的控件，从而组合成新的复合控件。通过这种方式创建的控件，我们一般会给它指定一些可配置的属性，让它具有更强的扩展性。 定义属性为一个View提供可自定义的属性非常简单，只需要在res资源目录的values目录下创建一个attrs.xml的属性定义文件，并在该文件中通过代码定义相应的属性即可。 屏幕快照 2018-07-17 下午5.04.48 在代码中通过&lt; declare-styleable&gt;标签声明了使用自定义属性，通过name属性来确定引用的名称。通过&lt; attr&gt;标签来声明具体的自定义属性。通过format属性来指定属性的类型。在确定好属性后，就可以创建一个自定义控件，让它继承自ViewGroup，从而组合一些需要的控件。在构造方法中，通过TypedArray对象的getString()和getColor()等方法，就可以获取这些定义的属性值。 屏幕快照 2018-07-17 下午5.11.26 屏幕快照 2018-07-17 下午5.12.42 屏幕快照 2018-07-17 下午5.13.03 当获取完所有的属性值后，需要调用TypedArray的recyle方法来完成资源的回收。 组合控件通过动态添加控件的方式，使用addView（）方法将控件加入到模板中，并给它们设置前面所获取到的具体的属性值，如文字颜色、大小等。 屏幕快照 2018-07-17 下午5.16.29 定义接口 屏幕快照 2018-07-17 下午5.21.03 暴露接口给调用者 屏幕快照 2018-07-17 下午5.25.21 屏幕快照 2018-07-17 下午5.25.46 实现接口回调在调用者的代码中，调用者需要实现这样一个接口，并完成接口中的方法。 屏幕快照 2018-07-17 下午5.28.58 除了通过接口回调的方式来动态的控制UI模板，同样可以使用公共方法来动态地修改UI模板中的UI。这样可以进一步提高模板的可定制性。 屏幕快照 2018-07-17 下午5.31.54 引用UI模板在需要使用的地方引用UI模板，在引用前，需要指定第三方控件的命名空间。 屏幕快照 2018-07-17 下午5.33.56 这行代码就是在指定引用的命名空间xmlns，即xml namespace。这里指定了名字空间为“android”，因此在接下来使用系统属性时，才可以使用“android:”来引用Android的系统属性。如果要使用自定义的属性，就需要创建自己的名字空间。在Android Studio中，第三方的控件都使用如下代码来引入名字空间。 屏幕快照 2018-07-17 下午5.39.45 这里我们将引入的第三方控件的名字空间取名为custom，之后再xml文件中使用自定义的属性时，就可以通过这个名字空间来引用。 屏幕快照 2018-07-17 下午5.41.56 使用自定义的View与系统原生的View的最大区别就是在申明控件时，需要指定完整的包名，而在引用自定义的属性时，需要使用自定义的xmls名字。再更进一步，将这个UI模板写到一个布局文件中，在其他的布局文中，直接通过&lt; include&gt;标签来引用这个UI模板的View。 重写View来实现全新的控件当Android系统原生的控件无法满足我们的需求时，我们就可以完全创建一个新的自定义View来实现需要的功能。通常需要继承View类，重写onDraw，onMeasure来实现绘制逻辑，同时重写onTouchEvent等触控时间来实现交互逻辑。还可以像实现组合控件那样，通过引入自定义属性，丰富自定义View的可定制性。 弧线展示图音频条形图自定义ViewGroup重写onMeasure来对子View进行测量，重写onLayout确定子View的位置，重写onTouchEvent增加响应事件。 事件拦截机制分析Android为触摸事件封装了一个类MotionEvent，里面封装了触摸点的坐标，点击事件的类型。 屏幕快照 2018-07-18 下午3.08.26 对于ViewGroup重写了三个方法：dispatchTouchEventonInterceptTouchEventonTouchEvent对于View来说，重写了两个方法：onTouchEventdispatchTouchEvent 屏幕快照 2018-07-18 下午3.12.38 屏幕快照 2018-07-18 下午3.12.47 dispatchTouchEvent基本不用动。事件拦截的核心方法是onInterceptTouchEvent返回值：True，拦截，不继续；False，不拦截，继续流程。事件处理onTouchEvent返回值：True，处理了，不用给上级汇报了，上级不会继续处理了；False，给上级处理。 屏幕快照 2018-07-18 下午3.20.48","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"},{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"}]},{"title":"Android群英传 2 Android开发工具新接触","slug":"Android群英传 2 Android开发工具新接触","date":"2018-07-14T04:18:32.000Z","updated":"2018-07-14T04:19:03.000Z","comments":true,"path":"2018/07/14/Android群英传 2 Android开发工具新接触/","link":"","permalink":"https://github.com/zdkswd/2018/07/14/Android群英传 2 Android开发工具新接触/","excerpt":"","text":"Android群英传 2 Android开发工具新接触Android开发IDE介绍ADB命令使用技巧ADB–Android Debug Bridge，借助此工具，我们可以用电脑来操作手机。 ADB基础ADB工具位于SDK的platform-tools目录下。手机助手也是使用ADB来实现它的功能。手机端需要开发者模式，USB Debug。 adb shell可以使用Linux Shell命令。 android list targets显示系统中全部Android平台 adb install -r 程序.apk安装apk程序之install abd push &lt; local&gt; &lt; remote&gt;安装apk程序之push两者都可以安装上APK，但是install是安装到data/data目录中，作为普通的用户应用程序。push则不是安装命令，是将文件写入手机的存储系统，所以，只要拥有相应的权限，就可以把任何Apk放到任何目录中，甚至是System目录下成为一个系统应用程序。 abd push &lt; local&gt; &lt; remote&gt;向手机写入文件 abd pull &lt; local&gt; &lt; remote&gt;从手机获取文件。这些东西在Android Device Monitor工具都可以直接使用。 通过Logcat来查看Log删除应用查看系统盘符输出所有已经安装的应用模拟按键输入模拟滑动输入查看运行状态Package管理信息AM管理信息录制屏幕重新启动ADB命令来源模拟器使用与配置","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"},{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"}]},{"title":"Android群英传 1 Android体系与系统架构","slug":"Android群英传 1 Android体系与系统架构","date":"2018-07-14T03:01:32.000Z","updated":"2018-07-14T03:02:20.000Z","comments":true,"path":"2018/07/14/Android群英传 1 Android体系与系统架构/","link":"","permalink":"https://github.com/zdkswd/2018/07/14/Android群英传 1 Android体系与系统架构/","excerpt":"","text":"Android群英传 1 Android体系与系统架构Google生态系统Android系统架构 2fdda3cc7cd98d10ac7dfab52b3fb80e7aec908d 这些层次结构即是相互独立的，又是相互关联的。 LinuxLinux层(仅为Linux内核)，Android最底层最核心的部分。显示内核版本，就是显示所用的Linux内核的版本。Linux层包含了Android系统的核心服务，包括硬件驱动，进程管理，安全系统等等。 Dalvik与ARTDalvik包含了一整套Android运行环境虚拟机，每个App都会分配Dalvik虚拟机来保证互相之间不受干扰，并保持独立，特点是在运行时编译。在Android 5.x开始，ART模式已经取代了Dalvik，ART是安装时进行编译，在运行时就不用编译了。 Framework见上图 Standard libraries见上图 Application不管是使用NDK开发还是Java开发的App，都有Android Manifest文件、Dalvik Classes、Resource Bundle这些东西。 Android App组件架构即四大组件：Activity、BroadCastReciever、ContentProvider和Service。它们是组成一个Android App的最基本元素。 Android四大组件如何协同工作Activity作为人机交互的第一界面，负责向用户展示和处理结果，信息的来源可以是通过资源获取，也可以是通过Content Provider来获取其他应用的信息，或是Service从后台计算，下载，处理后的结果，也可以是通过BroadCast Reciever获取到广播信息。同时，Android系统还提供了一个信使Intent，作为信息传递的载体。组件与组件之间通过Intent来通信、传递信息、交换数据，正是通过这样一种方式，四大组件形成了各自独立而又紧密联系的关系。 应用运行上下文对象Android系统上下文对象即Context，Activity、Service、Application都是继承自Context。Android应用程序会在几个时间点创建应用上下文Context。 创建Application 创建Activity 创建Service 创建Context的时机就是在创建Context的实现类时。 Android系统源代码目录与系统目录Android系统源代码目录包含了Android系统所有的源代码，从底层驱动到上层应用，Android系统对所有文件都进行了详细管理。在手机中，Android系统的目录和源代码目录不是一一对应的，与源代码编译后，与打包生成的Image文件的结构相同。 Android系统源代码目录看完Android源代码，要懂C、懂脚本、懂Java。 屏幕快照 2018-07-14 上午10.18.18 应注意，不是所有的源代码结构都是这样。只有AOSP的Android项目才是这样的结构，有些芯片厂家如MTK目录结构就不同。Android源码采用Makefile编译。像Android这样的大型项目，它的源代码不计其数，不同的功能，模块，按类型分别放置在不同的目录中，这些模块通常会有Makefile文件进行管理。它定义了一系列的规则来指定模块，哪些文件需要编译，以及这些文件该按照怎演的顺序去编译。甚至可以配置更复杂的功能操作，比如定义编译规则，打包规则，Makefile就像一个shell脚本，不仅可以使用自己的语法，也能调用操作系统的命令。Android系统源代码目录每个目录中还会包含更多的目录，而它的每一个最小的功能单位的目录下，都会有一个Makefile文件，这样每一级向上，通过一个个Makefile文件，就把整个源代码有条不紊的联系在一起了。 Android系统目录通过ADB连上手机，通过Linux的ls命令查看Android系统的根目录。其中/system和/data是开发者非常关心的两个目录。 /system/app/这里面放的是一些系统的App /system/bin/这里面主要放的是Linux自带的组件 /system/build.prop这里记录的是系统的属性信息。 /system/fonts/系统字体存放的目录root后可下载TTF格式字体替代原字体。 /system/framework/系统的核心文件，架构层。 /system/lib/存放几乎所有的共享库（.so）文件。 /system/media/该目录用来保存系统提示音、系统铃声。 /system/usr/该目录用来保存用户的配置文件，如键盘布局、共享、时区文件等。 /data/app/data目录包含了用户大部分数据信息。app目录下包含了用户安装的App或者升级的App。 /data/data/这个目录应该是开发者访问最多的目录了，这里包含了App的数据信息，文件信息、数据库信息等，以包名的方式来区分各个应用。 /data/system/这个目录包含了手机的各项系统信息。 /data/misc/这个目录保存了大部分的WiFi、VPN信息。 Android App文件目录","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"},{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"}]},{"title":"松本行弘的程序世界 9 整数和浮点小数","slug":"松本行弘的程序世界 9 整数和浮点小数","date":"2018-07-12T09:41:32.000Z","updated":"2018-07-12T09:39:19.000Z","comments":true,"path":"2018/07/12/松本行弘的程序世界 9 整数和浮点小数/","link":"","permalink":"https://github.com/zdkswd/2018/07/12/松本行弘的程序世界 9 整数和浮点小数/","excerpt":"","text":"松本行弘的程序世界 9 整数和浮点小数深奥的整数世界整数是有范围的 屏幕快照 2018-07-12 下午4.23.38 尝试位运算 屏幕快照 2018-07-12 下午4.24.58 操作特定的位位运算组合起来，可以对存储在计算机中的各位进行自由操作。操作二进制位就等于操作计算机的数据。基本的位处理操作有4种。 取出特定位的状态 特定位置位（设为1） 特定位清零（设为0） 特定位反转 将操作限制在特定位的数为掩码。 表示负数的办法 开头一位做符号位 将整数的各位反转（1的补数） Ruby的整数Ruby的整数有两种，一种是范围有限制的整数Fixnum（32位CPU是31位，64位CPU是63位），另一种是范围没有限制（超过内存容量除外）的整数Bignum，根据计算结果自动变换。 挑战公开密钥方式RSA加密的强度（解读的困难程度），就归因于素因数分解的难度。 扑朔迷离的浮点小数世界计算机对小数的处理固定小数点数不易使用浮点数，就是小数点的位置可以移动。 科学计数法也有问题计算机中广泛使用的小数表示方法是科学计数法。科学计数法是指将有效数字和指数组合起来表示小数（实数）。 屏幕快照 2018-07-12 下午5.01.23 IEEE754规定，尾数部分的首位始终归一化为1，所以首位始终省略，实质有效数字为53位。 小数不能完全表示 计算机中的数的表示有长度（位数）限制。 计算机中数的表示是二进制。 浮点数是有限的浮点数有误差对于浮点小数，结合法不成立有不能比较的时候对于浮点数进行比较运算，只有两个数在内部表示是完全相同的情况下才判定为相等。作为铁则，两个浮点数不能用==进行比较运算。如果有进行比较的必要，判断条件中的两个数的差要足够小。根据操作系统的不同，对于浮点数，足够小的值e有不同的定义。 误差积累减少运算次数。 不是数的特别“数” 屏幕快照 2018-07-12 下午5.13.14 无限大Inf，零0，非数NaN 计算误差有多种舍入误差最大值溢出与最小值溢出信息丢失位数脱落截止误差误差导致的严重问题BigDecimal是什么浮点数运算的陷阱可以归结为：1. 能够表示的精度有限 以二进制来表示 Ruby提供了BigDecimal类，有以下3个特点： 与Bignum一样，有效数字自动扩展 以十进制计算 以C语言记述，比内嵌的浮点数类（Float）要慢 能够表示分数的Rational类","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 8 正则表达式","slug":"松本行弘的程序世界 8 正则表达式","date":"2018-07-12T04:41:32.000Z","updated":"2018-07-12T04:43:36.000Z","comments":true,"path":"2018/07/12/松本行弘的程序世界 8 正则表达式/","link":"","permalink":"https://github.com/zdkswd/2018/07/12/松本行弘的程序世界 8 正则表达式/","excerpt":"","text":"松本行弘的程序世界 8 正则表达式正则表达式基础检索“像那样的东西”正则表达式的语法普通字符除了表中所示的元字符以外的普通字符，都与该字符自身相匹配。 屏幕快照 2018-07-12 上午10.28.08 字符集合用括号（【】）括起来的部分为字符集合。与括号内所含的每一个字符都匹配。比如，【abcde】能与小写字母abcde中的任何一个相匹配。字符集合中，用中划线（-）来指定范围。所以，【abcde】可以用【a-e】来代替。字符集合中，第一个字符是【\\^】时，表示取反。就是说，不与括号（【】）中的字符相匹配。 任意一个字符表示任意一个字符读得模式是“.”。除了匹配换行符。 重复 屏幕快照 2018-07-12 上午10.42.59 贪婪与懒惰贪婪：寻找符合的最长的，遍历完再回溯，懒惰：寻找第一个符合的。 分组将模式绑定起来的功能称为分组。（ma）+ 选择| 锚点指定位置而不是字符来进行匹配。称为锚点（anchor）。 屏幕快照 2018-07-12 上午10.53.24 三个陷阱记号多、密度高的表达式为应对这一问题，出现了扩展正则表达式。 0次以上的重复贪婪型匹配正则表达式对象面向对象语言Ruby中，所有数据都是对象。正则表达式也是对象。Ruby程序中正则表达式对象写成/.*/的样子。正则表达式对象可以用正则表达式类方法生成。程序中由组合字符串生成正则表达式时，使用类方法更自然。 选项Ruby正则表达式末尾斜杠的后面，可以为这个正则表达式添加选项。 屏幕快照 2018-07-12 上午11.34.28 屏幕快照 2018-07-12 上午11.35.23 正则表达式匹配的方法 屏幕快照 2018-07-12 上午11.37.23 特殊变量Ruby中有源于Perl的特殊变量。以$开头的变量。 屏幕快照 2018-07-12 上午11.41.33 字符串与正则表达式 屏幕快照 2018-07-12 上午11.43.29 split的本质分割字符串的方法split,与正则表达式组合起来能实现很多功能。 字符串的扫描置换想要置换与字符串模式匹配的部分，可以用置换方法。 正则表达式的应用实例与“鬼车”正则表达式是表达字符串模式的一种微型语言。正则表达式由字符本身、字符模式、锚点以及重复等组合而成。 解析日志文件的方法避免使用$的方法记号$不美观。Ruby中，以match方法替代=~运算符，就可以在程序中不使用这些记号了。 从邮件中取出日期的方法典型拼写错误的检索方法Ruby1.9的新功能“鬼车”“鬼车”新正则表达式库。123456DSLDomain Specific Language,意为面向特定领域的编程语言。DSL分内部DSL和外部DSL。内部DSL，就是往既有的语言中加入特定领域的词汇，使之DSL化。如软件编译工具Rake中表达依存关系的内部DSL。make是一个同样目的的工具，它使用Makefile来表达依存关系。Rake可以利用Ruby的编程功能、方法定义、条件分歧和循环等，不管关系有多复杂，都可以编程对应。外部DSL，不是扩展现有的语言，而是面向特定目的，如SQL就是DSL的代表性例子。正则表达式也可以称作是以实现模式匹配为目的的外部DSL。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 7 文字编码","slug":"松本行弘的程序世界 7 文字编码","date":"2018-07-12T02:00:32.000Z","updated":"2018-07-12T02:01:00.000Z","comments":true,"path":"2018/07/12/松本行弘的程序世界 7 文字编码/","link":"","permalink":"https://github.com/zdkswd/2018/07/12/松本行弘的程序世界 7 文字编码/","excerpt":"","text":"松本行弘的程序世界 7 文字编码文字编码的种类早期的文字编码纸带与文字的表现文字是什么走向英语以外的语言（欧洲篇）英语以外得到语言（亚洲篇）Unicode的问世统一编码成16位的汉字统合Unicode的两个问题选择16位文字的Unicode有两大副作用。一是字节顺序的问题，一是NUL文字问题。字节顺序就是低八位先放还是高八位先放的问题。传统C语言处理的字符串，一般有一个终端文字NUL（‘\\0’）。但是作为16位文字的字符串，中途会出现NUL文字。所以，C语言中处理字符串的传统函数不能用于16位文字的字符串。像java那样的语言，一开始就是以16位文字为前提而设计的，所以没什么问题。但以C语言处理16位文字的时候，需要全新的api。 Unicode的文字集现在，Unicode放弃了16位方式，而用21位来表示一个文字，现在Unicode能够表示4111个文字，肯定够用了。 文字表示的不确定性Unicode的字符编码方式UTF-8UTF-8以一定式样的字节组合来表示Unicode中的21位文字。对于内部程序处理字符串非常方便，另外没有字节顺序问题，在外部处理时也很有用。缺点：消费过多内存，几乎所有的汉字都要占用3个字节。构成文字的字节数是可变的，随机访问任意文字，代价与字符串长度成正比。但是随着计算机内存的容量和性能提高，这些缺点也无所谓了。 UTF-16Unicode中能以16位表示的空间就以16位表示，超过16位就以两个16位码组合来表示。到现在缺点已经很突出了，从今以后没必要采用这种字符编码方式了。 UTF-32固定长，可以随机访问，但存在字节顺序的问题。因为4字节，没什么人气。 程序中的文字处理文字编码有多个意思只能处理文字集中包含的文字纷繁复杂的文字编码方式影响力渐微的Shift_JIS与EUC-JPUnicode有多种字符编码方式为什么会发生乱码字符编码方式错误没有字体变换为内部码时出错发生不完全变换文字集的不同字节顺序错误像UTF-16，UTF-32这种基本数据单位大于一个字节的编码方式，存放数据时字节该以什么顺序摆放，有两大流派，一个是big endian,一个是little endian。所以同样是UTF-16格式（UTF-32也一样）根据字节顺序不同就会有两种。UTF-8就不会。 从编程语言的角度处理文字编程语言处理文本数据的方法，有UCS方式和CSI方式两种。 以变换为前提的UCS方式UCS（泛用字符集），是指程序中所处理的共同文字集（及字符编码方式）。输入输出时，编程语言将文本数据变成UCS，内部对文本数据进行统一处理。优点： 原理简单，容易实现 除变换外，处理成本低 实际成果多 缺点： 发生不必要的变换 变换存在模糊部分 有外字及机种依存文字的问题 UCS中不包含的文字绝对不能处理 原封不动处理的CSI方式CSI（Character Set Independent，字符集独立），是指不对各种文字集（及编码方式）进行任何变换，原封不动地进行处理。相对于UCS的内部只有一种编码方式的处理方式，CSI中对各种编码方式原封不动地处理。CSI是优点多，自由度高的方式。 不发生不必要的变换 不发生变换所带来的问题 不易发生外字的问题。 理论上不存在不能处理的文字 根据需要，可以处理应用程序独立的文字集 缺点： 字符串的处理容易变得复杂化 预计处理性能会变低 实际成果少 实际上，现在存在的多种编程语言中，采用CSI方式的几乎没有。 使用UTF-16的JavaJava采用UCS方式，内部字符编码选用UTF-16制作Java时，Unicode仅限于16位。java没选择可变长的UTF-8，而选择UTF-16，因而产生了这样的悲剧。说是时机的恶作剧也罢，真是太可惜了。 使用UTF-8的PerlPerl也使用UCS方式，内部编码方式采用UTF-8。 用UTF-16的PythonUCS，UTF-16 采用CSI方式的Ruby1.8强化了功能的Ruby1.9是UCS还是CSI","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 6 Ruby On Rails","slug":"松本行弘的程序世界 6 Ruby On Rails","date":"2018-07-11T04:00:32.000Z","updated":"2018-07-11T03:59:46.000Z","comments":true,"path":"2018/07/11/松本行弘的程序世界 6 Ruby On Rails/","link":"","permalink":"https://github.com/zdkswd/2018/07/11/松本行弘的程序世界 6 Ruby On Rails/","excerpt":"","text":"松本行弘的程序世界 6 Ruby On RailsMVC和Ruby On RailsMVC是设计GUI程序的设计模式之一。大部分设计模式仅决定程序某一部分的构成，而MVC决定了应用程序的整体部分，有时候也被成为架构模式。 模型、视图和控制的作用模型：是表现窗口中表示内容（信息）的对象。模型代表的只是信息（名字、数值等抽象的信息），它不能包含如何来显示这些信息的信息。视图：代表将模型中包含的信息在窗口中进行表示的对象。视图知道要表现的模型的信息，而模型一般不知道要表示自己的视图信息。控制：是从用户端接受输入，对视图和模型进行操作的对象。 屏幕快照 2018-07-11 上午9.26.46 用秒表的例子来学习MVC模式生成视图和控制部分GUI工具箱与MVC同时使用工具箱和MVCMVC的优缺点优点： 可以更换界面一个模型对应多个视图多个视图可以同时响应容易测试缺点： 复杂性强关联性对模型对象进行了功能追加这样的变更后，相应地也必须对视图和控制进行变更。 Web应用中的MVCWeb应用基本是HTTP。HTTP的一次处理经过了一下过程：（1）Web浏览器对应于用户的操作，向Web服务器发出HTTP请求。（2）Web服务器根据请求，准备好发送到Web浏览器的数据。（3）Web服务器把数据以HTTP响应的形式送还Web浏览器。 利用MVC来描述：（1）Web浏览器发送过来的HTTP请求通过Web服务器传给控制部分。Web应用框架的分配器把请求传递给合适的控制部分。（2）控制部分操作的模型和请求的信息相对应，同时制定显示使用的视图。视图从模型启动，一边引用模型一边准备发送给Web浏览器的数据。（3）Web服务器把数据以HTTP响应的形式送还Web浏览器。 屏幕快照 2018-07-11 上午9.54.09 Ruby on Rails上的MVC各部分功能稍有不同。Rails中的模型相当于数据库层，视图指显示用的模板，控制器指控制用的类（包含了应用逻辑）。 屏幕快照 2018-07-11 上午9.56.48 开放类和猴子补丁猴子补丁，即在动态语言中，不改变源代码而对功能进行追加和变更。现在灵活使用开放类，变更和追加方法全部称为猴子补丁。 开放类Ruby的类的特征是所谓的开放类，相对于其他语言，特别容易打猴子补丁。Ruby中，可以把String类、Array类等基本的数据类型及所有的类都作为开放类处理，可以自由地追加功能。 猴子补丁的目的功能追加利用开放类可以给已有的类追加功能。 功能变更修改程序错误因为重新定义了有程序错误或有副作用的方法，不用修改原来那部分的代码就可以解决问题。这也是本来的猴子补丁的目的。 钩子有时间想在每个方法调用的同时增加一些其他处理。这种伴随方法调用而进行的处理称为“钩子”（hook），钩子的追加也可以用猴子补丁来实现。 缓存（cache）猴子补丁的技巧可以吧Ruby提供的对方法、类和模块进行操作的功能运用到打猴子补丁上。最基本的功能就是给已有的方法改名或取消。 屏幕快照 2018-07-11 上午10.58.20 undefundef有把方法取消定义的功能。用undef不仅可以取消本类中的方法，也可以取消父类中定义的方法。 aliasinclude灵活使用开放类的库jcode库可以不使用正则表达式，利用开放类的功能，使得字符串的方法可以处理多字节文字。 猴子补丁的几点问题若要正确使用开放类，安全地打猴子补丁，需遵守： 基本上只是追加功能对类追加新方法不会让已有的程序无法执行。使用开放类时，主要做不容易导致问题的功能追加会更保险。做功能追加时，如果发生名称重复会造成麻烦，在选择追加的方法名时需要慎重。 进行功能变更时要慎重，尽可能小规模 小心相互作用 其他方法猴子补丁能够不改变源代码进行动态修改，这种灵活性是显示动态语言柔软性和扩展性的好例子。实现猴子补丁的Ruby开放类有时功能过强，可能会引起问题。其他语言中用更易控制的形式也能实现猴子补丁。 Ruby on Rails和开放类Rails构成部分之一ActiveSupport库。ActiveSupport利用Ruby的开放类功能，对Ruby标准提供的类大胆地追加了功能。 ActiveSupport带来的扩展 时间 字节单位系列 复数形和序数 大规模开发和Ruby编译时不作类型检查Ruby在执行时作类型检查，大规模程序为了保证可靠性一定会有严格的测试程序，如果作了严格的测试，在编译时作类型检查的优点就不像所说的那么重要了。 没有包Java对于构成库的类和文件有独立的包，要想具备某种功能，必须明确地进行import操作。而Ruby是不具备这种功能的。所以，库定义的类和模块名是全局的，从任何地方都可以引用。因此，可以说名称重复的危险性很大。 存在开放类各自独立的库发生互相矛盾的变更时，问题不能简单解决。这也可能在大规模开发时引发问题。 信赖性模型在某种类型的大规模开发中，Ruby的性质会造成问题，或者说造成问题时解决起来不像其他语言那么容易，这种现象是现实中可能存在的。如果认为这些是问题的话，可能不使用Ruby会更好。但是，到现在为止我们看到的情况表明，会发生那种问题的大规模开发本来就绝不是好的开发状况。首先要做的，是把项目的信赖关系改善到可以使用Ruby的程度。就算是最后也没有使用Ruby，这也是应该先做到的事情。 猴子补丁的未来猴子补丁虽然有一定的危险性，但有利有弊，它也提供了方便性、扩展性和灵活性。开放类和利用它的猴子补丁，将来也可能会被更安全的、由1特定目的而特制的功能群而替代。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 5 Ajax","slug":"松本行弘的程序世界 5 Ajax","date":"2018-07-10T09:25:32.000Z","updated":"2018-07-10T09:26:45.000Z","comments":true,"path":"2018/07/10/松本行弘的程序世界 5 Ajax/","link":"","permalink":"https://github.com/zdkswd/2018/07/10/松本行弘的程序世界 5 Ajax/","excerpt":"","text":"松本行弘的程序世界 5 AjaxAjax和JavaScript（前篇）Ajax（Asynchronous JavaScript and XML）,含义是异步JavaScript及XML。Ajax不算是一个新技术，只是既有技术的组合。 通信及异步页面更新Ajax的最大特点是进行异步操作，异步意味着Web浏览器的通信和页面更新是互相独立的。以前的Web应用程序，每按下一个按钮就开始显示下一个页面，在页面完整呈现之前，用户只能等待，无法进行其他操作，使用Ajax技术的页面是在后台和HTTP服务器进行通信，设计优良的Web应用程序，在客户和服务器通信的过程中也可以让用户进行操作，而不需要等待。Ajax的最大优点是改善了应用程序的操控性。 屏幕快照 2018-07-10 上午8.52.52 Ajax技术中，对于用户进行的操作，基本是由JavaScript在Web浏览器中进行响应。尽在数据必须从服务器获取的情况下，才在后台进行异步通信。在通信过程中，用户也可以继续对Web浏览器进行操作。和服务器通信得到的结果由DHTML对当前的页面进行部分更新而现实出来。 技术要素之一：JavaScript支撑Ajax的三个主要技术：JavaScript、XML及DHTML。JavaScript是几乎所有Web浏览器处理系统都支撑的一种编程语言。因此，它被称为世界上最普及的编程语言。JavaScript可以简单的嵌入到表示网页的HTML中去，利用JavaScript可以做出完全不用和服务器进行通信的网页。 技术要素之二：XMLXML（eXtensible Markup Language）,和SGML、HTML类似，使用标签（tag）对数据进行标识说明的一种语言。XML已经成为了数据表示、配置各种文件及其他多种场合下广泛使用的一种格式。Ajax的名字中部分包括了XML，是因为当初大部分使用Ajax技术的应用程序都使用了XML数据，以及用JavaScript进行异步通信的对象的名字是XMLHTTPRequest。当然不用XML的XMLHTTPRequest的通信也是存在的，使用Ajax技术的Web应用进行通信的数据格式也是多种多样的，比如有普通文本格式以及YAML，JSON。 XML以外的数据表示形式YAML（YAML Ain’t Markup Language）看出它不是标记语言。YAML只是表示数据的语言，目的仅仅是表示数据。特点有： 记述简洁 容易理解 专注于表示数据，不用费心考虑给标签起名字。 屏幕快照 2018-07-10 上午9.30.23 和YMAL相提并论的是JSON（JavaScript Object Notation）意思是JavaScript对象表示法。是直接把JavaScript表示对象的程序拿来记述数据。JSON是合法的JavaScript程序，作为JavaScript实现可以生成对象。JSON可以表现下面6种数据类型：数值（整数及浮点小数）、字符串、布尔值（真、假）、数组、对象（键和值的表）和null。YAML通过扩展可以表示各种形式的数据。相比较，JSON就简单太多了，但也够用了。 技术要素之三：DHTMLDHTML，动态HTML，顾名思义，可以动态地对HTML进行引用、修改和更新。更具体的说，是利用装载在网页中的JavaScript，使用DOM（文档对象模型）对网页数据进行操作。使用DOM可以进行下述处理： 取得页面中特定标签中的数据； 修改标签的数据（文字、属性等） 在页面中添加标签； 设定事件处理程序JavaScript技术基础JavaScript是以对象为基础的语言，所有的数据都可以作为“对象”进行统一处理。不过，它不具备“类”这样的所谓普通面向对象语言所提供的功能，即使去除JavaScript面向对象的编程功能，它也可以作为普通的结构化编程语言来使用。基本语法JavaScript的基本语法和C、Java类似。最大的不同是，JavaScript不指定变量类型。函数定义JavaScript的特点之一是把函数作为对象进行处理。C也是将函数作为对象处理，但JavaScript的不同之处在于函数对象有闭包（closure），可以使用函数外面的局部变量。闭包功能称为了JavaScript面向对象功能的基础。1闭包是Ruby中块变为对象后的结果。它的优点是，只要闭包还存在，就能访问闭包内的变量。 原型模式的面向对象编程语言如果具有原型模式的面向对象功能的话，就可以最大限度地消减语言本身的固有功能。这非常适合于JavaScript这样的语言。以类为中心的传统面向对象编程，是以类为基础生成新对象。类和对象的关系可以类比成铸模和铸件的关系。而原型模式的面向对象编程语言没有类这样一个概念。需要生成新的对象时，只要给对象追加属性。设置函数对象作为属性的话，就成为方法。当访问对象中不存在的属性时，JavaScript会去搜索该对象prototype属性所指向的对象。JavaScript利用这个功能，使用“委派”而非“继承”来实现面向对象编程。1委派是指，把对于某个对象的调用传送到另一个对象上。 JavaScript的方式过于简单反而使记述太过复杂。 使用prototype.js库为了克服JavaScript记述过于繁杂的缺点，JavaScript提供了进行功能扩展的一些库。如prototype.js库prototype.js受到了Ruby的影响，实际上Ruby on Rails中标准地附加了prototype.js库，使用得很广泛。 prototype.js的功能Ajax功能prototype.js支持XMLHttpRequest对象，可以对HTML进行异步更新。实际上不同Web浏览器获取XMLHttpRequest对象的方法也是不同的。Ajax.Request帮我们屏蔽了与代码移植相关的问题。 Enumerable它是Ruby的Enumerable模块在JavaScript中的实现。 其他扩展功能如使用Object.extend()给对象追加功能。 Ajax和JavaScript(后篇)像Ajax有3个特点： 没有Web页面跳转 通过异步通信实现快速反应 实现了动画和拖拽等单独使用HTML格式无法表现的用户界面构成DHTML基础的JavaScript是一个速度不怎么快的语言。某种技术在开发出来之后经过相当长一段时间才得到普及，此类例子并不少见。巧妙使用DHTMLDHTML被称为Ajax的本质技术。顾名思义，可以动态访问、更新HTML。具体就是利用嵌入网页的JavaScript，使用DOM操作页面数据。1DOM是操作HTML和XML的规范。特点是把HTML和XML作为树结构进行处理。 HTML被读取后，生成树结构。 屏幕快照 2018-07-10 下午4.39.14 使用JavaScript对树结构进行操作就是DHTML的本质。因此JavaScript提供的W3C DOM API有如下功能： 获取documnent节点 获取和更新标签数据（包括文字、类型以及属性等） 追加documnent节点 设定时间处理程序（event handler） 获取documnent节点 getElementById(name)getElementsByTagName(name) 获取和更新标签数据获取节点对象后，通过调用对象的方法，读写对象的属性等就能够获取和更新标签数据。 设定事件处理程序两种办法： 指定标签属性。如设置为a标签的onclick属性值来指定事件处理程序。 把方法设为JavaScript对象的属性。如 屏幕快照 2018-07-10 下午4.49.48 追加标签节点用appendChild方法可以为节点对象追加节点，消除节点用removeChild方法。 本地HTML应用和服务器间的通信使用DHTML之后，对于较简单的应用，在客户端就能够实现。但是，客户端无法保存数据，所以保存和获取数据时需要和服务器进行通信。Ajax是利用XMLHTTPRequest对象来进行异步通信，不需要网页跳转，在后台就可以进行通信。 使用Prototype.js的优点不需要麻烦的记述。 在服务器上保存数据Web应用的脆弱性如XSS（跨站点脚本问题） 使用JavaScript的感觉作为动态语言名副其实DHTML比想象的更有趣Prototype.js也不错调试比较麻烦JavaScript理就算有程序错误，Web浏览器也不会显示任何信息。想要确认程序的状态，只能多次使用alert()。Firefox提供了Firebug的扩展功能，对于JavaScript的调试非常有用。 兼容性问题Ajax开发最难的一点就是Web浏览器间JavaScript的兼容性问题。12名字的重要性起了一个合适的名字本身意味着功能设计的正确。反过来，起了不好的名字说明设计者自己也没有完全理解应完成什么样的功能。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 4 设计模式","slug":"松本行弘的程序世界 4 设计模式","date":"2018-07-09T10:21:32.000Z","updated":"2018-07-20T11:02:15.000Z","comments":true,"path":"2018/07/09/松本行弘的程序世界 4 设计模式/","link":"","permalink":"https://github.com/zdkswd/2018/07/09/松本行弘的程序世界 4 设计模式/","excerpt":"","text":"松本行弘的程序世界 4 设计模式设计模式（1）设计模式的价值和意义Gamma他们并没有发现新的模式，总结出来的23种设计模式也是软件开发中早就存在并反复使用的模式，因此并不能说是Gamma他们的首创。但即使是这样，设计模式有了名字，人们就可以认识到它的存在，并对之进行讨论。这种不能用语言表达的知识称为内隐知识。给这些在软件中经常反复出现的模式命名，使得这些本来只有经验丰富的程序员才能认识到的软件设计模式能被广泛认识和讨论。 设计模式是程序抽象化的延伸一旦有了设计模式，只要把过去优秀的人们考虑出来的模式拿来应用一下。 Ruby中的设计模式Singleton模式单件模式。用来保证某个类的实例只有一个。Ruby实现Singleton模式的方法有几个 使用singleton库的方法Ruby以库的形式实现了Singleton模式。使用Singleton库，在任意类中include Singleton模块，那个类就变成Singleton模式的对象。 使用类或模块C++和java是不能把类作为对象使用的，与之不同的是，smalltalk或Ruby能把类也作为对象来处理。因此，在类或模块中定义一个方法就可以实现Singleton模式。 把一般的对象作为Singleton来使用为了把一个类的对象限制为只有一个，并不一定要对对象的一般生产方法进行限制。可以生成一个一般的对象，然后不要在生产更多个对象了。 使用对象和特异方法Ruby可以在对象生成以后再增加新的方法。 Proxy模式Proxy（代理）模式是为某个对象提供代理对象的模式。在不知道是否真正需要一个生成代价很大的对象时可能造成很大浪费，但不生成又什么都做不了。 Iterator模式Iterator（迭代器）模式提供按顺序访问集合对象中各元素的方法。即使不知道对象的内部构造，也可以按顺序访问其中的每个元素。Iterator模式是为集合对象另外准备用来控制循环处理的对象，就像C++或java一样，我们称这个循环控制对象为Iyerator，也称为游标。 外部与内部，哪一个更好它们都有方便的一面，也都有不方便的另一面。 内部迭代器的缺陷内部迭代器不能同时进行多个循环，也就无法实现按顺序比较两个集合元素的处理。 外部迭代器的缺陷外部迭代器的缺陷在于迭代器对象需要引用集合对象的内部信息，为了按顺序访问集合对象的各个元素，迭代器需要访问集合的内部构造，破坏了隐藏集合内部构造的封装性原则。 设计模式（2）模式与动态语言的关系《设计模式》一书中介绍了23个设计模式。这些设计模式可分为3大类：（1）有关生成的模式（5个），有关构造的模式（7个）以及有关行为的模式（11个）。Singleton为（1），Proxy为（2），Iterayor为（3）。 重复使用既存对象的Protoype模式Protoype（原型）模式明确一个实例作为要生成对象的种类原型，通过复制该实例来生成新的对象。在需要新种类对象时，首先复制一个既存的对象，给复制的对象直接增加方法或实例变量等功能，生成最初的第一个新种类对象。最初一个也并不特别，只是偶尔被用来复制而已。相对于类模式编程，原型模式的编程构成元素比较少，具有简单实现面向对象功能设计的倾向，JavaScript的面向对象就是原型模式。io语言也是。 亲身体验IO语言Ruby中的原型基本上讲Ruby是类模式的语言，但也拥有支持原型模式编程功能。 复制对象的clone方法 给个别对象增加方法的特意方法功能 给个别对象增加一组功能的extend方法 静态语言中没有原型编程，因为不可能给复制的对象增加新方法。 编写抽象算法的Template Method模式用Ruby来尝试Template MethodRuby的类库中最大限度灵活运用Template Method模式的部分，应该是Enumerable模块和Comparable模块了。 动态语言与Template Method模式Template Method模式的这种优秀性质与语言是不是静态没有关系。 避免高度依赖性的Observer模式Observer（观察者）模式是当某个对象的状态发生变化时，依存于该状态的全部对象都自动得到通知，而且为了让它们都得到通知，定义了对象间一对多的依存关系。这是控制类与类之间依存关系的一种模式。高度依赖性会导致组成程序的零件过大，避免高度依赖性的Observer模式，构成观察者模式的有两个对象，一个称谓Observer（观察者）接受变更通知；另一个称为Subject（对象）或Observable（被观察者），发出变更通知。被观察者让人得到被动的印象，在实际处理中，被观察者会发出通知“我已经变化了哦”。 Observable模块Ruby中为实现Observer模式提供了名为observer的库。observer库提供observer模块。 Observer模式与动态语言由于Ruby的动态性质，Observer库具有以下几方面的灵活性。 观察者类不必是特定类的子类。 观察者类不必实现特定的接口（本来在Ruby中也没有接口） 观察者类的更新方法名可以自由决定 观察者类更新方法的参数可以自由决定 被观察者类不必是特定类的子类 对被观察者类的要求，只是将Observable模块包括进来。 123说到事件监听模式,很容易将它和观察者模式联系在一起。实质上这两者完成同类型的工作。依个人理解，事件监听模式更像是观察者模式的进阶。事件监听机制就是对观察者模式进行了进一步抽象，节省了代码量。 设计模式（3）软件开发的悲剧 复杂性 变化性 软件的规模越大，各个部分之间的牵连越复杂，更改也就越难。在软件开发过程中，需求变更几乎是不可避免的。 开放-封闭原则对模块扩展必须开放，对修改必须封闭。为了应对将来的需要，扩展必须是开放的，但是即使某一模块的内部结构改变了，对外接口也应当是不变的。简称OCP。 面向对象的情况既要开放，又要封闭，看似互相矛盾，但是面向对象编程语言能够很彻底地消除这个矛盾。 非面向对象的情况非面向对象则很难处理好。面向对象的精髓在于对OCP的实践。至于把对象看做物体理解起来比较容易，能够建立现实世界的模型等，不过是锦上添花。 OCP与Template Method模式虽说使用面向对象语言的功能，可以实现OCP，但是只是说有这种可能性，并不是说什么时候都能实现。当然，虽然使用了面向对象语言，却做成了一个糟糕的设计，这种情况也是屡见不鲜。分类中很多设计模式之所以优秀是因为经得起OCP所要求的变化。Template Method模式，是满足OCP的基本手段。其他的设计模式都是利用多个类的关联来实现的，而Template Method模式则仅仅使用了继承，基本上无非是实现了一个抽象类。 Observer模式Observer模式是满足OCP的。DRY也好，OCP也好，都不过是原则，根据具体情况，要做适当的选择，如果代码没有再利用的打算，也没有扩展功能的打算，也就没有必要生搬硬套设计模式。使用前有必要先做判断。 使用Strategy模式Strategy（策略）模式是定义算法的集合，将各算法封装，使它们能够交换。利用Strategy模式，算法和利用这些算法的客户程序可以分别独立进行修改而不互相影响。Strategy模式就是将容易变化的处理归纳为独立的对象，然后使它们能够互相交换，使用方法与将容易变化的处理交给子类的Template Method模式相类似。两个模式最大的区别在于，Strategy模式是独立的对象，能够动态交换处理逻辑。 Strategy模式与OCPStrategy模式完全满足OCP。世上很多设计模式，为了能应对将来可能的修改，都是按照OCP的要求来设计的。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界 3 程序块","slug":"松本行弘的程序世界 3 程序块","date":"2018-07-09T02:21:32.000Z","updated":"2018-07-11T02:11:19.000Z","comments":true,"path":"2018/07/09/松本行弘的程序世界 3 程序块/","link":"","permalink":"https://github.com/zdkswd/2018/07/09/松本行弘的程序世界 3 程序块/","excerpt":"","text":"松本行弘的程序世界 3 程序块程序块的威力Ruby的特色功能之一——程序块。Ruby的程序块是指在方法调用时可以追加的代码块。 把函数作为参数的高阶函数高阶函数是指以函数作为参数的函数。为了实现高阶函数，编程语言中必须把函数和方法作为数据来处理。 C语言高阶函数的局限在C语言中，实现函数间的信息传递只有两种方法：要么明确地传递参数，要么使用全局变量，没有其他方法。如果使用全局变量来传递信息，就搞不清楚什么时候、谁在引用或者更新这一变量。除了全局变量之外，没有别的办法在函数间共享信息，这是C语言的局限。 可以保存外部环境的闭包Ruby中，增加了引用函数外部变量的功能。与C语言指针的例子比较，Ruby具有以下两个易于使用的优点： 可以再使用时定义； 可以引用外部的局部变量。 java的匿名类和C语言的函数指针也能实现同样的功能，但是没有那么简洁。在块中可以引用外部局部变量的方法，这说明不只是简单的程序代码，而且把外部“环境”也包括进来，像这样的块叫做闭包。通常的局部变量在方法执行结束时就不存在了，但如果被包括进了闭包，闭包存在期间，局部变量也会一直存在。 块的两种使用方法Ruby的块是可以追加给调用方法的代码块，块自身不是对象（对象化后的块是闭包）。参数传递的方法和普通函数不同。在被调用的方法中有两种方式来使用传递过来的块。一种是用“块参数”的方式明确声明接受块作为参数，另一种是使用yield这个Ruby的保留词。块作为参数具有三个优点： 明确表示了块处理 块和对象一样被统一处理 检查参数是否为nil就可以判断出是否传递了块参数。 另外，yield具有下面两个优点： 没有用到闭包，执行速度少快 错误提示信息比较容易理解 最终来看，块到底是什么Ruby的块具有以下三个特点： 代码块可以作为参数传递给方法 在被调用的方法中可以执行传递过来的代码块，执行后程序的控制权返还给方法。 块中最后执行的算式的值是块的值，这个值可以返回给方法。 块也可以被看做只是高阶函数的一种特殊形式的语法。虽然只是稍作改进，但Ruby中块的各种灵活应用的方法还是让人赞叹不已。 块在循环处理中的应用最典型的用法是，在逐个处理集合对象的元素的方法中使用块。 屏幕快照 2018-07-06 上午11.19.23 Ruby中几乎所有的容器类都有each这个方法。使用这个方法可以循环处理容器类中的所有元素。也可以用for语句来实现each方法。本来，Ruby就是为了要实现循环功能才导入了块。所以，在以前的文档中把具有块的方法称为迭代器（iterator）。iterate就是循环、迭代的意思。但是，如今块的应用范围比当初所能想到的要广泛的多，和循环没有关系的处理中也大量的用到块。所以现在仍把块称为迭代器就很不恰当了。 内部迭代器和外部迭代器像Ruby块这样，把对各个元素的处理逻辑传送给容器类的方法，然后在方法中对容器类中每个元素调用指定的处理逻辑，这种迭代方式称为内部迭代器的方式。与之对应，C++和java中所谓的迭代器，是用别的类对象来循环处理容器中的元素，这种循环处理的方式称为外部迭代器方式。在外部迭代器方式中，把顺序取出容器中元素对象称为迭代器，也称为游标。内部迭代器不用额外生成类，使用和实现都很简单，但是，对于不支持闭包的编程语言，想要拥有循环外部的信息就要费些功夫。外部迭代器可以简单地处理从多个容器中逐个取出数据进行并行处理。从设计模式来看，内部迭代器是访问者模式，外部迭代器是迭代器模式。 在排序和比较大小中的应用用块保证程序的后处理用块实现新的控制结构用块的话，不需要改变文法，就可以控制结构的定义。 在回调中使用块块处理的特别理由ruby的块具有以下特点： 在普通参数以外，另外被传送； 块不是对象（lambda方法可以作闭包对象化）。 其他具有闭包功能的编程语言，比如Lisp和Smalltalk，它们没有这样的区别，总是把闭包作为对象来处理。Ruby作了改进，因为： 减少对象的生成数。初期Ruby生成闭包对象的代价很高，所以尽量避免了闭包对象的生成。即使是真正必要的对象，也尽量延迟到必要的时候才生成。 外观上的理由。 调用方法时只能用一个块，是Ruby中的一个限制，但实际情况中也几乎没有必要使用多个块。 用块做循环Ruby的块本来就是在循环的抽象化过程中诞生的。现在除了循环以外，在其他一些场合也得到广泛应用，但这并未有改变其实现循环的初衷。 块是处理的集合循环是程序的基本元素。从结构化编程的原理来说，所有算法都是有顺序、分支和循环的组合来实现的。可以说处理好了循环，也就处理好了程序。Ruby也用while循环，但是循环还有其他更为深奥的表现形式。Ruby中有until语句。块是处理的集合。Ruby中，在方法调用的最后，可以附加上块。Ruby的简洁性不只体现在程序简短，更重要的是体现在对本质问题的处理，使程序更为灵活。 屏幕快照 2018-07-09 上午9.00.34 第二行大括号中的部分是块，这行程序是作为参数来调用数组的each方法。用Ruby实现这种循环非常简单，知识在块调用的地方用yield来指定。 屏幕快照 2018-07-09 上午9.08.46 1一个方法的定义，在方法内部有yield的出现；在方法的调用处会有程序块的出现。 也可以用do-end来定义块。大括号和do-end基本是一样的。但是，在块是多行时。用do-end结构统一性更好一些。 块是一行的时候用大括号，是多行的时候用do-end; 块作为表达式的一部分，给方法返回值时用大括号，块作为处理语句或程序流程控制时用do-end。大括号的优先级更高。 在省略括号调用方法时，一定要注意块的结合优先顺序。 块应用范围的扩展当时块主要使用在循环里。在Ruby中不必特别的结构，在任意的方法中都可以使用块，所以不仅仅在循环中，块在各种各样的领域中都得到了应用。 高阶函数和块本质一样编程语言要实现高阶函数，就必须把函数或者方法作为数据来处理。反之，具有这样功能的编程语言就可以利用高阶函数。可以把块看做高阶函数调用，只能有一个函数参数。事实上，在高阶函数中94%都只有一个函数参数，有两个以上函数参数是极少的。Ruby以更易于使用的形式，把只有一个函数参数的情形在语法上加以特殊处理，导入了块功能。 用Enumerable来利用块把块应用于循环抽象化的，最典型的应该是Enumerable模块。Enumerable模块以each方法为基础，定义了each方法的类提供了多种功能。如果继承（Mix-in）了这个模块，就可以很方便地利用它的各种功能。Enumberable的意思是可数的。它是对数组等各种集合元素做循环处理的方法的集成。可大致分为： 循环 指定条件 排序、比较大小 Enumerable的局限 循环都依赖each方法，而且不能并行执行。 Enumerable可以用each方法简单的实现循环，反过来也是一个局限。 精通集合的使用使用Ruby的数组在动态语言ruby中，集合可以混合存在各种类型的对象，所以可以定义复杂得数组。 修改指定范围的元素的内容和C语言、java语言相比，ruby的数组具有以下特点。 Ruby的数组是对象，可以调用各种方法。 用【】访问数组实际上是方法调用。【】是方法名，里面的值是参数。 变更数组元素实际上也是方法调用。【】=是方法名，里面和右边的值是参数。 Ruby中的哈希处理 屏幕快照 2018-07-09 上午9.55.21 支持循环的EnumerableRuby中提供的方法可以更好地发挥集合的作用。Ruby中，集合的功能都定义在Enumerable这个Mix-in中了。从另一个角度来说，只要把Enumerable模块通过Mix-in继承进来，就可以使用集合对象的大量方法了。 用于循环的each方法在Enumerable中没有定义each方法，反之，Enumerable中所有方法都是在内部调用each方法实现的。 使用inject、zip和grepinject是用块吧各个元素结合起来。zip是从多个集合并行取得元素的方法。grep方法可以对集合中的元素进行模式匹配。 用来指定条件的select方法对集合的各个元素进行块处理的是循环类型的方法。和它相对的，对各个元素进行块处理，用快处理的结果作为下个处理的判定条件的是条件指定型方法。条件指定型方法中最常用的是select方法。select方法把快处理结果为真的元素存放在数组中返回。 排序与比较大小在类中包括（include）Enumerable模块列表内包表达式和块的区别","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"艺术的力量 卡拉瓦乔","slug":"艺术的力量 卡拉瓦乔","date":"2018-07-06T09:56:20.000Z","updated":"2018-07-06T09:58:37.000Z","comments":true,"path":"2018/07/06/艺术的力量 卡拉瓦乔/","link":"","permalink":"https://github.com/zdkswd/2018/07/06/艺术的力量 卡拉瓦乔/","excerpt":"","text":"艺术的力量 卡拉瓦乔这个天才，是个恶人教堂寻寻觅觅及卡拉瓦乔生来注定要做的，就是在罪人的生命中找到超凡入圣之处。卡拉瓦乔笔下的主角不是圣人，而是罪人。这名画家，对穷苦信徒的处境感身受他艺术的力量来自于真实的力量，其中包括了对自身真相的觉醒。 青年音乐家 1595 自比酒神的自画像 赌博 圣母之死 圣母玛利亚 男孩与水果篮 有人说他是艺术天才，也有人说他是血性魔鬼，他的一生可以说就是一部历险记。卡拉瓦乔出生在米兰，家庭状况还阔以，爸妈在当时有点名气和地位。在卡拉瓦乔5岁的时候发生了一场瘟疫，为了躲避瘟疫，他们全家搬离了米兰。但不幸还是发生了，他的爸爸和爷爷都感染了这种瘟疫，并在同一天去世了，生活的重担就都落到他妈妈一个人身上，那时候的卡拉瓦乔才6岁。等到他卡拉瓦乔13岁时候，妈妈也离开了这个世界，于是他就成了孤儿。也就是在妈妈去世那一年，卡拉瓦乔开始跟着意大利画家西蒙·彼得扎诺学画画，一画就是四年，期间他也看了很多大师的作品，比如达芬奇的最后的晚餐啥的，增加了对艺术的了解。画家靠自己是很难的，因为你要搞商业你就无心创作，毕竟一个人的精力有限，所以需要钱的帮助，就是一定资金上的支持…卡拉瓦乔的命就很好。 多疑的thomas 召唤使徒马太 马太的殉难 手提歌利亚头的大卫 画中的男子手里提的，正是卡拉瓦乔的头。 意大利画家卡拉瓦乔，作为一个被通缉的画家，常年过着颠沛流离的逃亡生活。罪行满满的卡拉瓦乔最终想回到那个让他登上巅峰的罗马，但是他在那里杀过人啊，所以他决定画一幅画讨掌权者的欢心…… 被斩首的施洗约翰","categories":[{"name":"纪录片","slug":"纪录片","permalink":"https://github.com/zdkswd/categories/纪录片/"}],"tags":[{"name":"艺术","slug":"艺术","permalink":"https://github.com/zdkswd/tags/艺术/"}]},{"title":"松本行弘的程序世界 2 面向对象","slug":"松本行弘的程序世界 2 面向对象","date":"2018-07-05T14:14:32.000Z","updated":"2018-07-25T02:33:55.000Z","comments":true,"path":"2018/07/05/松本行弘的程序世界 2 面向对象/","link":"","permalink":"https://github.com/zdkswd/2018/07/05/松本行弘的程序世界 2 面向对象/","excerpt":"","text":"松本行弘的程序世界 2 面向对象编程和面向对象的关系计算机只会高速运算，到底是最大程度地发挥计算机的能力还是扼杀它的能力都取决于我们编写的程序。 颠倒的构造程序员要夺得主动权。 主宰计算机的武器为了能够主宰计算机，必须以计算机的特性和编程语言作为武器。 怎样写程序编程风格 算法 数据结构 设计模式 开发方法 面向对象的编程方法smalltalk为面向对象编程语言之母。 面向对象的难点面向对象编程语言中最重要的技术是“多态性”。 多态性多态就是可以把不同种类的东西当做相同的东西处理。操作对象是三个箱子，分别是盖着盖子的箱子、加了锁的箱子、系着彩带的箱子。在编程中，“打开箱子”的命令，称之为消息；打开不同箱子的具体操作，称之为方法。 具体的程序调用box_open这个方法，根据参数（箱子的种类）的不同做相应的处理。 屏幕快照 2018-07-04 上午8.11.02 但是如果增加种类代码就要重写，修改的地方越来越多，追加箱子的种类就会变得非常困难。修改程序，实现真正的多态。“.”可以理解为“给前面的式子的值发送一个open消息”。 屏幕快照 2018-07-04 上午8.14.46 多态性的优点首先，各种数据可以统一地处理。关注要处理什么，而不是怎么处理。其次，根据对象选择方法，程序内部不会冲突。减轻程序员的负担。再次，新数据简单的追加可以实现，不需要改动以前程序，具备了扩展性。 数据抽象和继承面向对象编程的三原则：多态性，数据抽象，继承。别称：多态性：动态绑定，数据抽象：信息隐藏或封装。 面向对象的历史simula的“发明”面向对象编程思想起源于瑞典20世纪60年代后期发展起来的模拟编程语言Simula。以前，表示模拟对象的数据和实际的模拟方法是互相独立的，需要分别管理。 Smalltalk的发展smalltalke的开发宗旨是“让儿童也可以使用”，吸收了Simula的面向对象思想，且独居一格。不仅如此，还有一个很好的图形用户界面。使得世人开始了解面向对象编程的概念。 Lisp的发展许多重要的面向对象的概念都是从Lisp的面向对象功能中诞生的。 和c语言的相遇C++是直接受到了simula语言的影响而没有受到smalltalk多大影响。 Java的诞生java语言放弃了和C语言的兼容性，并增加了Lisp语言中一些好的功能。此外，通过Java虚拟机（JVM），java程序可以不用重新编译而在所有操作系统中运行。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。Java虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行。这就是Java的能够“一次编译，到处运行”的原因。 复杂性是面向对象的敌人软件开发的最大敌人是复杂性。人类的大脑无法做台复杂得处理，记忆力和理解力也是有限的。在计算机性能这么高的今天，人们为了找到迅速开发大规模复杂软件的方法，哪怕牺牲一些性能也在所不辞。 结构化编程如果不考虑黑盒内部的处理，系统复杂性就可以降低到人类的可控范围内。针对程序控制流的复杂问题，结构化编程采用看限制和抽象化的武器解决问题。 数据抽象化数据抽象是数据和处理方法结合。对数据内容的处理和操作，必须通过实先定义好的方法来进行。数据和处理方法结合起来成为了黑盒子。比如说栈。有了数据抽象，程序处理的数据就不再是单纯的数值或者文字这些概念性的东西，而变成了人脑容易想象的具体事物。而代码的“抽象化”则是把想象的过程“具体化”了。 雏形同样的对象大量存在时，为避免重复，可以采用两种方法管理对象。 原型。用原始对象的副本来作为新的相同的对象，JS用的原型。 模板，称为类。跟原型不同，面向对象编程语言的类和对象有明显区别。对象又称作实例。 找出相似的部分来继承类的增多会用到很多性质相似的类。这就违背了我们的DRY（Don’t Repeat Yourself）原则。把这些相似的部分汇总到一起就好了。继承就是这种方法。子类继承父类所有方法，如有需要可以增加新的方法，也可以重写父类方法。Ruby跟多数编程语言一样，一个子类只能有一个父类，即单一继承，C++、Lisp等编程语言中，一个子类可以有多个父类，这称为“多重继承”。 多重继承的缺点继承的原本目的实际上是逐步细化。所以为解决抽出类中相似部分的问题并不完全准确。 为什么需要多继承一个程序员也可能是一个作家。 多重继承和单一继承不可分离单一继承的特点： 继承关系单纯，有利有弊 多重继承的特点： 很自然的做到了单一继承的扩展。 可以继承多个类的功能。单一继承可以实现的功能，多重继承都可以实现，但是类之间的关系变得复杂。这是多重继承的一个缺点。 goto语句和多重继承比较相似多重继承导致的问题： 结构复杂化 优先顺序模糊 功能冲突 解决多重继承的问题继承作为抽象化的手段，是需要实现多重继承功能的，如果一个类只允许抽出一个功能，那么限制就太多了。受限制的多重继承，这个解决或改善多重继承问题的方法出现了，它在Java中被称为接口（interface）,在Lisp或Ruby中是Mix-in。 静态语言与动态语言的区别编程语言可以分为静态语言和动态语言两种。像Java这样规定变量和算式类型的语言称为静态语言。在静态语言中，不能给变量赋不同类型的值，会导致编译错误，不通过执行就可以发现类型不匹配是静态语言的一个优点。如果只能给一个变量赋值同类对象，就不可能根据对象的类自动选择合适的处理方式（多态性）。 静态语言的特点当给一个类变量赋值时，既可以用这个类的对象来赋值，也可以用这个类的子类对象来赋值。这样就可以实现多态性。但是这时，如果定义了父类变量，赋值子类对象，变量不能调用子类特有的方法。 动态语言的特点动态语言允许调用没有继承关系的方法。静态语言中只能调用有继承关系的方法，数组、哈希表和字符串都能调用的方法，只能是在它们共同的父类（恐怕是Object）中定义。在静态语言中，如果要调用类层次中平行类的方法，那么必须要有一个可以表现这些对象的类型。如果没有这个类型，可调用的方法是十分有限的。由此我们看到静态语言中某种形式的多重继承是不可少的。 静态语言与动态语言的比较静态语言即使不通过执行也可以检查出类型是否匹配。但是逐个来定义算式和变量的类型又会使程序变得冗长。只有包含继承关系的类才会具有多态性。对于动态语言来说，静态语言显得限制过多，灵活性差。程序中有没有错误只有执行了才会知道。程序中没有类型定义，这样程序会变得很简洁。只要方法名一样，这些对象可以以相同的方式去处理。这样生产效率会大大提高，这种宽松的编程机制称为Duck Typing（鸭子类型检测） 继承的两种含义继承包括两种含义，一种是“类都有哪些方法”，也就是说这个类都支持些什么操作，即规格的继承。另一种是“类中都用了什么数据结构什么算法”，也就是实现的继承。静态语言中这两者的区别很重要，动态语言中区别规格的继承和实现的继承意义不大。即使没有继承关系，方法也可以自由地调用。java对两者有很明确的区分，实现的继承用extends来继承父类，规格的继承用implements来指定接口。类是用来指定对象实现的，而接口只是指定对象的外观（都有哪些方法）。类的继承是单一的，implements可以指定多个接口。接口对实现没有任何限制，也就是说，接口可以由跟实现的继承没有任何关系的类来实现。 接口的缺点为了解决多重继承的问题，人们允许了规格的多重继承，但是还是不允许实现多重继承。 继承实现的方法和静态语言Java不同，动态语言本来就没有继承规格这种概念。动态语言需要解决的就是实现的多重继承。Lisp、Perl和Python都提供了多重继承功能，这样就不存在单一继承的问题了。 从多重继承变形而来的Mix-inMix-in是降低多重继承复杂性的一个技术，最初是在Lisp中开始使用的。按以下规则来限制多重继承： 通常的继承用单一继承 第二个以及两个以上的父类必须是Mix-in的抽象类。 Mix-in类是具有以下特征的抽象类。 不能单独生成实例 不能继承普通类 积极支持Mix-in的Ruby 屏幕快照 2018-07-04 下午5.39.58 12345678我理解的接口的作用：接口是一种协议，满足同一接口实际上是告诉计算机你们是满足了同一样协议，你们是有关系的，java以这种方式间接实现了多态。当然可以实现多个接口，抽象为不同的“种类”，这样就相当于某种意义上的”多继承“。InterA a; a= new B(); a.fun(); a = new C(); a.fun(); bc都实现a的接口 两个误解 对象是对现实世界中具体物体的反应，继承是对物体分类的反应。（误） 多重继承是不好的。Mix-in不错。（误） 澄清：如果多继承用的不好就会出问题，Mix-in只不过是实现多重继承的一个技巧而已。 面向对象的编程不管过去怎样，现在面向对象最好的理解是，面向对象编程是结构化编程的延伸。随着软件的复杂化，开发越来越复杂，Dijkstra提倡把程序控制限制为（1）顺序（2）循环（3）分支 使得程序变得简单且容易理解。面向对象的设计方法是在结构化编程对控制流程实现了结构化后，又加上对数据的结构化。面向对象编程，封装（黑盒）和多态（减少分支处理）是提高生产率的技术。结构化编程通过整理数据流，提高程序的生成效率和可维护性。同样，面向对象编程通过对数据结构的整理，提高了程序的生产效率和可维护性。 对象的模板=类类是吧数据黑盒化的工具，由于对类内部的操作都是通过类的方法来实现的，所以内部数据结构即使在以后发生变化，对外部也没有影响。 利用模板的手段=继承类是模块，继承就是利用模块的方法。传统的面向对象编程语言是一下子把规格和实现都继承下来，在最近，有的是把这两种继承分开了。比如java里的接口就是规格继承。 多重继承不好吗单一继承的类之间的关系是很单纯的树结构。但是对于多重继承而言，类之间的关系却是复杂得网状结构。静态语言中可以实现多态性只是局限于拥有共通父类的对象。为了解决这个问题，静态面向对象编程语言的代表C++支持多重继承。java也可以通过接口来支持规格的多重继承。1234**静态类型语言**: 是指在编译时变量的数据类型即可确定的语言，多数静态类型语言要求在使用变量之前必须声明数据类型，某些具有类型推导能力的现代语言可能能够部分减轻这个要求. **动态类型语言**: 是在运行时确定数据类型的语言。变量使用之前不需要类型声明，通常变量的类型是被赋值的那个值的类型。 **强类型语言**: 是一旦变量的类型被确定，就不能转化的语言。实际上所谓的貌似转化，都是通过中间变量来达到，原本的变量的类型肯定是没有变化的。 **弱类型语言**: 则反之，一个变量的类型是由其应用上下文确定的。比如语言直接支持字符串和整数可以直接用 + 号搞定。当然，在支持运算符重载的强类型语言中也能通过外部实现的方式在形式上做到这一点，不过这个是完全不一样的内涵 动态编程语言也需要多重继承动态编程语言没有类型检查，从这方面来说没有理由用多重继承，但是动态编程语言肯定需要多重继承。实现共享可以通过多个对象的组合（composition）和委托（delegate）来做到。 驯服多重继承的方法多重继承可能引发的问题： 类关系复杂化 继承功能名字重复最初的问题是因为类关系从简单的树结构变成了复杂的网状结构。 屏幕快照 2018-07-05 上午9.18.30 父类的优先级并不明确，多重继承设计的一个有效的技巧是Mix-in。用Mix-in做多继承设计时，从第2个父类开始的类要满足以下条件。 不能单独生成实例的抽象类。 不能继承Mix-in以外的类。 抽象类和接口的对比 屏幕快照 2018-07-05 上午10.41.50 mix-in的例子 屏幕快照 2018-07-05 上午10.44.57 通过对功能的分离，多重继承就可以由单一继承加上Mix-in类来实现。利用Mix-in就可以同时享有单一继承的单纯性和多重继承的共有性。 对于名字重复问题（如函数名），多重继承编程语言都有自己的应对方法，大致分为以下3种： 给父类定义优先级 把重复的名字替换掉 指定使用类的名字 ruby中多重继承的实现方法Mix-in java实现多重继承的方法接口。。 Duck Typing诞生之前静态是指程序执行之前，从代码中就可以知道一切。程序静态的部分包括变量、方法的名称和类型以及控制程序的结构等等。相对于静态，动态是指在程序执行之前有些地方是不知道的。程序动态的部分包括变量的值、执行时间和使用的内存等等。通常情况下、程序本来就是不被执行就不知道结果的，所以在一定程度上说程序都具有动态特性。因此，严格说静态和动态之间的界限是很微妙的。 为什么需要类型动态的类型是从Lisp中诞生的动态类型在面向对象中发展起来了对象保存着有关自己种类的信息，某个变量可以用各种类型的数据来赋值，这两点是多态这一面向对象重要特性的必要条件。 动态类型和静态类型的邂逅20世纪80年代，面向对象编程语言主流是包含动态数据类型的语言，但是在21世纪的今天，使用最广泛的面向对象编程语言是具有静态类型的java和c++。受simula很大影响的c++引入了子类对象可以看成是父类对象这个原则，对象也采用了静态类型。根据这个原则，在编译时就可以知道变量或算式的类型，又可以根据执行时的数据类型自动选择合适的处理，从而同时具备了静态类型的优点和动态类型的多态性。 静态类型的优点 最大的优点是在编译时能够发现不匹配的错误。 如果明确指定了数据类型，在编译时可以用到的信息就很多，利用这种信息可以在编译时对程序做优化，提高程序执行速度。 在读程序时提高理解度，IDE也可以自动补充。 问题： 不指定类型就写不了程序，数据类型只是一些辅助信息，并不是程序本质。有的类型声明仅仅是为了满足编译器的要求。程序规模也因为数据类型的定义而变大。 灵活性问题。静态类型本身限制了给某个变量只能赋值某种类型的对象，这种限制可能成为妨碍将来变化的枷锁。 动态类型的优点 源代码简洁，提高生产力。 会不会更难以理解，更突出程序处理的实质，程序函数相差几十倍并不少见，理解起来反而简单。 会不会运行更缓慢，同样的处理，在大多数情况下，静态类型编程语言运行得要快些。这是因为动态类型程序执行时要做类型检查。另外，静态类型的编程语言大都是通过编译把程序源代码转换成可以直接执行的形式，而动态类型的编程语言大多是边解释源代码（转换成内部形式）边执行，这种编译型处理和解释型处理的区别也是影响程序执行速度的愿意之一。 灵活，灵活性的关键是Duck Typing。 最大的缺点是不执行就检测不出错误。 只关心行为的Duck TypingIf it walks like a duck and quacks like a duck,it must be a duck.（走起路来像鸭子，叫起来也像鸭子，那么他就是鸭子）。根本不考虑一个对象属于什么类，只关心它有什么样的行为（它有哪些方法）。动态语言用Duck Typing的概念设计时需要遵循的原则最低限度是避免明确的类型检查。 避免明确的类型检查克服动态类型的缺点 执行时才能发现可以用完备的单元测试来解决，如果能严格实行完备的单元测试的话，即使没有编译时的错误检查，程序的可靠性也不会降低。 读程序时可用到的线索少这一点可以通过完整的文档来解决。可以在源代码中同时写文档，减轻维护文档的负担。 运行速度慢，随着计算机性能的提升已经不再重要，现在的程序开发中，程序的灵活性和生产力更为重要。 动态编程语言现在我们对程序开发生产力的要求越来越高，也就是说，要在更短的时间内开发出更多的功能。尽快着手开发，快速应对需求变更的开发方式变得越来越重要。在这种快速开发模式中，Duck Typing所代表的执行时的灵活性就非常有用。Ruby、Python、Perl和PHP等优秀的动态类型编程语言，因为它们在执行时所具有的灵活性而越来越受到人们的关注。 元编程元编程是对程序进行编程的意思。 元编程利用元编程可以动态生成类的方法，而且重要的是你可以自己编写生成过程，不支持元编程的编程语言实现这样的功能是很麻烦的，要么需要扩展语言的语法，要么用宏定义等预处理方法来实现。 反射元编程的反射（reflection）,在编程语言中它是指在程序执行时取出程序的信息或者改变程序的信息。Ruby彻底实现了对程序的动态操作。 屏幕快照 2018-07-05 下午7.10.21 元编程的例子Ruby使用Delegator这个库实现了委托功能，调用对象d的方法时可以转变为调用a的方法。我们还可以给这个对象增加特意方法来改变它的部分行为，这就大大扩展了它的应用范围。 使用反射功能分布式Ruby的实现Delegator将被调用的方法直接委派到其他对象，这一功能在很多领域都有应用。如dRuby。dRuby是通过网络来调用方法的库。dRuby可以生成服务器上存在的远程对象（Proxy），Proxy的方法调用可以通过网络执行。调用的方法在服务器上的远程对象中执行，执行结果可以通过网络返回。这和java的RMI(Remote Method Invocation)功能比较相似。但是，利用Ruby的元编程功能，不用明确定义接口，也可以通过网络调用任一对象的方法。C++和Java的远程调用是用IDL（Interface Definition Language）等语言来定义接口的，自动生成的存根（stub）必须编译和连接。和这些相比，Ruby的元编程更简单。 数据库的应用在数据库领域，元编程也很有用。web应用程序框架Ruby on Rails(也称为Rails或RoR)中也应用了元编程。具体地说是在与数据库关联的类库（ActiveRecord）中，利用元编程简单的把数据记录定义为对象。由于元编程功能让我们可以获取类名，在执行时增加方法。元编程的功能使得Rails被称赞为生产效率高的Web应用程序框架。 输出xml手工写XML是很麻烦的，利用Ruby块功能则可以很方便的处理。 元编程和小编程语言元编程功能可以运用到DSL领域，DSL是针对特定领域强化了功能的小规模编程语言。通过DSL用户可以强化应用程序的功能或者定制一些功能。 声明的实现Ruby的方法可以读取或改变程序自身的状态，利用普通的方法调用，可以实现其他编程语言中声明所完成的工作。 上下文相关的实现instance_eval方法接受块作为参数，把调用对象置换成self来执行块。 单位的实现词汇的实现针对特定领域，如果用Ruby来定义需要的类和方法，那么就可以认为Ruby是这个领域的专用语言。这些类和方法可以称为这个领域的词汇。 层次数据的实现适合DSL的语言，不适合DSL的语言Ruby是非常适合DSL的语言。首先定义好DSL用的小语言，然后编译成C++、java等目标语言。编译器经常用到Ruby这种具有优秀文本处理的语言。另一种实现DSL方法的例子是解释器。比如开发应用程序时从设计到实现是很复杂的，可以利用固定的语法和类库函数来读取程序。具体方法是用XML、DOM等XML处理类库来解释小语言语法。这是Java应用程序的配置文件曹勇XML的原因之一。通过XML文件，不用每次编译Java程序就可以改变配置，定制程序的行为。这种用法可以把XML称为Java界的DSL，或是Java应用程序的脚本语言。12脚本语言又被称为扩建的语言，或者动态语言，是一种编程语言，用来控制软件应用程序，脚本通常以文本（如ASCII)保存，只在被调用时进行解释或编译。早期的脚本语言经常被称为批处理语言或工作控制语言。一个脚本通常是--解释运行--而非编译。虽然许多脚本语言都超越了计算机简单任务自动化的领域，成熟到可以编写精巧的程序，但仍然还是被称为脚本。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"周海宏音乐鉴赏 一 打开你的耳朵","slug":"周海宏音乐鉴赏 一 打开你的耳朵","date":"2018-07-04T14:28:13.000Z","updated":"2018-07-04T14:28:47.000Z","comments":true,"path":"2018/07/04/周海宏音乐鉴赏 一 打开你的耳朵/","link":"","permalink":"https://github.com/zdkswd/2018/07/04/周海宏音乐鉴赏 一 打开你的耳朵/","excerpt":"","text":"周海宏音乐鉴赏 一 打开你的耳朵1.1音乐鉴赏的误区音乐中包含各种内容的表现，说不出来是什么是因为你“听不懂”.专业学生也”听不懂“。音乐两个基本属性1 没有视觉性2 没有语义性“听不懂”–说不出音乐表现的是什么并非听者欣赏水平差，因为音乐不能直接传达视觉性与语义性的内容。 在音乐的欣赏中-不一定非要听出明确的视觉性、语义性内容。-不一定非要用文学化、美术化的内容去解说音乐。 在音乐中追求明确的概念性、视觉性内容，用文学化与美术化的方式欣赏音乐是一个误区。 音乐何须“懂”。 1.2音乐的艺术本质音乐是动态的。音乐是情绪的艺术。1 纯听觉感受2 情绪的感受动态纪实细腻地描摹内心的感受。 1.3 音乐审美的基本概念幸福人生最重要的是丰富多彩，真正的欣赏音乐，就去听最伟大的音乐。世界是这么龌龊这么黑暗，可悲的不是世界这么龌龊这么黑暗，而是不知道世界还有光明。音乐是人类精神的避难所。","categories":[{"name":"听课笔记","slug":"听课笔记","permalink":"https://github.com/zdkswd/categories/听课笔记/"}],"tags":[{"name":"音乐鉴赏","slug":"音乐鉴赏","permalink":"https://github.com/zdkswd/tags/音乐鉴赏/"}]},{"title":"松本行弘的程序世界1 我为什么开发Ruby","slug":"松本行弘的程序世界1 我为什么开发Ruby","date":"2018-07-04T10:38:32.000Z","updated":"2018-07-04T10:38:47.000Z","comments":true,"path":"2018/07/04/松本行弘的程序世界1 我为什么开发Ruby/","link":"","permalink":"https://github.com/zdkswd/2018/07/04/松本行弘的程序世界1 我为什么开发Ruby/","excerpt":"","text":"松本行弘的程序世界1 我为什么开发Ruby编程语言的重要性程序员由于使用的编程语言不同，思考方法和编写出的代码都会受到很大的影响。 Ruby的原则 简洁性 扩展性 稳定性简洁性随着编程语言的演进，程序员已经可以更简单、更抽象地编程了。面向对象的方法没有实现任何新的东西，却要在运行时判定要调用的方法，倾向于增大程序运行开销。现在由于计算机性能大大提高，只要可以提高软件的开发效率，浪费一些计算机资源也无所谓了。ruby的目标是成为开发效率高、能直接运行的伪码式编程语言。省去了不必要的声明。扩展性Ruby看重的不是明哲保身，而是如何最大限度的发挥程序员自身的能力。编程的历史就是因为想当然而失败的历史，ruby对整数范围不做任何限定，尽最大努力排除“想当然”。稳定性虽然ruby非常重视扩展性，但明知道LISP风格的宏能带来巨大的扩展性，仍没有使用。一切皆因兴趣","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"松本行弘的程序世界0 说在前面","slug":"松本行弘的程序世界0 说在前面","date":"2018-07-04T10:35:32.000Z","updated":"2018-07-04T10:36:06.000Z","comments":true,"path":"2018/07/04/松本行弘的程序世界0 说在前面/","link":"","permalink":"https://github.com/zdkswd/2018/07/04/松本行弘的程序世界0 说在前面/","excerpt":"","text":"松本行弘的程序世界0 说在前面vczh如何设计一门语言（一）好的语言，除了库写起来又容易又好用以外，还有两个重要的特点：容易学，容易分析。关于容易学这一点，其实不是说，你随便看一看就能学会，而是说，只要你掌握了门道，很多未知的特性你都可以猜中。这就有一个语法的一致性问题在里面了。 前言ruby code for fun这本书是松本行弘从一个编程语言设计者的角度去看待各种各样的流行编程语言，分析它们有哪些特点以及ruby编程语言如何进行取舍。ruby本身大量参考了一个更古老而著名的面向对象编程方法的开山鼻祖smalltalk以及偷师函数式编程语言鼻祖LISP。程序员社区有种说法：任何现代编程语言都脱胎于smalltalk于LISP。看看Ruby设计师是怎么设计Ruby语言的，则可以高屋建瓴的理解一些主流的编程语言。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"程序语言","slug":"程序语言","permalink":"https://github.com/zdkswd/tags/程序语言/"}]},{"title":"growth全栈","slug":"growth全栈","date":"2018-07-03T01:12:25.000Z","updated":"2018-07-03T03:01:34.000Z","comments":true,"path":"2018/07/03/growth全栈/","link":"","permalink":"https://github.com/zdkswd/2018/07/03/growth全栈/","excerpt":"","text":"基础知识篇环境是生产率的一部分。高效的程序员与低效的程序员间十倍的差距，至少有三倍是因为环境差异。语言和开发软件都是工具，都有相对更合适的情况。 提高效率的工具：快速启动软件windows-&gt; launcy IDEDEBUG工具终端或命令提示符包管理环境搭建OSXHomebrew包管理工具，官方称之为 The missing package manager for OS X。 Homebrew Caskbrew-cask 允许你使用命令行安装 OS X 应用。 iTerm2iTerm2 是最常用的终端应用，是 Terminal 应用的替代品。 ZshZsh 是一款功能强大终端(shell)软件，既可以作为一个交互式终端，也可以作为 一个脚本解释器。它在兼容 Bash 的同时 (默认不兼容，除非设置成 emulate sh) 还有提 供了很多改进，例如:• 更高效• 更好的自动补全• 更好的文件名展开(通配符展开) • 更好的数组处理• 可定制性高 Oh My ZshOh My Zsh 同时提供一套插件和工具，可以简化命令行操作。 MacDownMacDown 是 Markdown 编辑器。 CheatSheetCheatSheet 能够显示当前程序的快捷键列表，默认的快捷键是长按 。 SourceTreeSourceTree 是 Atlassian 公司出品的一款优秀的 Git 图形化客户端。 AlfredMac 用户不用鼠标键盘的必备神器，配合大量 Workflows，习惯之后可以大 大减少操作时间。上手简单，调教成本在后期自定义 Workflows，不过有大量雷锋使用者提供的现成 扩展，访问这里挑选喜欢的，并可以极其简单地根据自己的需要修改。 VimiumVimium 是一个 Google Chrome 扩展，让你可以纯键盘操作 Chrome。 WindowsChocolateyChocolatey 是一个软件包管理工具，类似于 Ubuntu 下面的 apt-get, 不过是 运行在 Windows 环境下面。 WoxWox 是一个高效的快速启动器工具，通过快捷键呼出，然后输入关键字来搜 索程序进行快速启动，或者搜索本地硬盘的文件，打开百度、Google 进行搜 索，甚至是通过一些插件的功能实现单词翻译、关闭屏幕、查询剪贴板历史、 查询编程文档、查询天气等更多功能。它最大的特点是可以支持中文拼音的 模糊匹配。 PowerShellWindows PowerShell 是微软公司为 Windows 环境所开发的壳程序(shell) 及脚本语言技术，采用的是命令行界面。这项全新的技术提供了丰富的控制 与自动化的系统管理能力。 cmdercmder 把 conemu，msysgit 和 clink 打包在一起，让你无需配置就能使用一 个真正干净的 Linux 终端!她甚至还附带了漂亮的 monokai 配色主题。 Total CommanderTotal Commander 是一款应用于 Windows 平台的文件管理器，它包含两个 并排的窗又，这种设计可以让用户方便地对不同位置的 “文件或文件夹” 进 行操作，例如复制、移动、删除、比较等，相对 Windows 资源管理器而言 方便很多，极大地提高了文件操作的效率，被广大软件爱好者亲切地简称为: TC 。 GNU/LinuxZshZsh 是一款功能强大终端(shell)软件，既可以作为一个交互式终端，也可以作为 一个脚本解释器。它在兼容 Bash 的同时 (默认不兼容，除非设置成 emulate sh) 还有提 供了很多改进，例如:• 更高效• 更好的自动补全• 更好的文件名展开(通配符展开)• 更好的数组处理• 可定制性高 Oh My ZshOh My Zsh 同时提供一套插件和工具，可以简化命令行操作。 ReTextReText 是一个使用 Markdown 语法和 reStructuredText (reST) 结构的文本 编辑器，编辑的内容支持导出到 PDF、ODT 和 HTML 以及纯文本，支持即 时预览、网页生成以及 HTML 语法高亮、全屏模式，可导出文件到 Google Docs 等。 LaunchyLaunchy 是一款免费开源的协助您摒弃 Windows “运行” 的 Dock 式替代工 具，既方便又实用，自带多款皮肤，作为美化工具也未尝不可。 学习一门语言，输出是最好的输入，实践更是硬道理。 Web编程基础运用HTTP传递数据,浏览器第一步Parser HTML,Paser HTML 实质上就是将其 将解析为 DOM Tree。与此同时，CSS 解析器会解析 CSS 会产生 CSS 规则树。随后会根据生成的 DOM 树和 CSS 规则树来构建 Render Tree，接着生成 Render Tree 的布局，最后就是绘制出 Render Tree。 HTML超文本标记语言 浏览器解析器对中文支持不友好。 浏览器解析器对英文支持友好。 CSS选择器类选择器，id选择器JavaScriptHTML 中插入 JavaScript 的方法，就需要用到 HTML 中的 &lt; script&gt; 标签 完整的 JavaScript 应该由下列三个部分组成:• 核心 (ECMAScript)——核心语言功能• 文档对象模型 (DOM)——访问和操作网页内容的方法和接口• 浏览器对象模型 (BOM)——与浏览器交互的方法和接口 有了 DOM 我们就可以对页面进行操作，可以说我们看到的绝大部分的页面效果都是通过 DOM 操作实现的。 前端与后端后台语言选择javascript只要是 Web 就会有前端,只要有前端就需要有 JavaScript。与此同时 Node.js在后台中的地位已经愈发重要了。对于 JavaScript 来说，它可以做很多类型的应用。这些应用都是基于浏览器来运行 的，有:• Electron + Node.js + JavaScript 做桌面应用• Ionic + JavaScript 做移动应用• Node.js + JavaScript 网站前后台• JavaScript + Tessl 做硬件 PythonJavaphpMVCModel模型用于封装与应用程序的业务逻辑相关的数据以及对数据的处理方法。View 层只是单纯的一个显示作用，这也是我们推荐的做法。业务逻辑应 该尽可能的放置于业务层。Controller控制器层起到不同层面间的组织作用，用于控制应用程序的流程。 后台即服务移动端应用程序 前端框架选择AngularAngularJS 对于后端人员写前端代码来说，是一个非常不错的选择。Angular 框架 采用并扩展了传统 HTML，通过双向的数据绑定来适应动态内容，双向的数据绑定允许 模型和视图之间的自动同步。 ReactReact 只是我们在上面章节里说到的 View 层，而这个 View 层需要辅以其他框架才 能完成更多的工作。并且 React 还有一个不错的杀手锏——React Native，虽然这个框架还在有条不紊地 挖坑中，但是这真的是太爽了。以后我们只需要一次开发就可以多处运行了，再也没有 比这更爽的事情发生了。 VueVue.js 是一个轻量级的前端框架。它是一个更加灵活开放的解决方案。它允许你以 希望的方式组织应用程序，你可以将它嵌入一个现有页面而不一定要做成一个庞大的单页应用。 jQuery系jQuery 还是一个不错的选择，不仅仅对于学习来说，而且对于工作来说也是如此。 如果你们不是新起一个项目或者重构旧的项目，那么必然你是没有多少机会去超越 DOM。 前台与后台交互AjaxAJAX 即 “Asynchronous JavaScript And XML”(异步 JavaScript 和 XML)，是指一种创建交互式网页应用的网页开发技术。通过在后台与服务器进行少量数据交换，AJAX 可以使网页实现异步更 新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。传统的 网页如果需要更新内容，必须重载整个网页页面。 JSON WEB TokensJSON Web Token (JWT) 是一种基于 token 的认证方案。在人们大规模地开始 Web 应用的时候，我们在授权的时候遇到了一些问题，而这些 问题不是 Cookie 所能解决的。通过 JWT 我们可以更方便地写出适用于前端应用的认证方案，如登陆、注册这些功能。在使用 JWT 的时候也需要注意安全问题，在允许的情况下应该使用 HTTPS 协议。 WebSocketHTML5 推出了一种 在单个 TCP 连接上进行全双工通讯的协议 WebSocket。WebSocket 可以让客户端和服务器之间存在持久的连接，而且双方都可以随时开始 发送数据。 编码Web 应用的构建系统构建系统 (build system) 是用来从源代码生成用户可以使用的目标的自动化 工具。目标可以包括库、可执行文件、或者生成的脚本等等。 常用的构建工具包括 GNU Make、GNU autotools、CMake、Apache Ant(主要用于 JAVA)。此外，所有的集成开发环境(IDE)比如 Qt Creator、Microsoft Visual Studio 和 Eclipse 都对他们支持的语言添加了自己的构建系统配置工具。通常 IDE 中的构建系 统只是基于控制台的构建系统(比如 Autotool 和 CMake )的前端。对比于 Web 应用开发来说，构建系统应该还包括应用打包 (如 Java 中的 Jar 包，或 者用于部署的 RPM 包、源代码分析、测试覆盖率分析等等。 Web 应用的构建GulpGulp.js是一个自动化构建工具，开发者可以使用它在项目开发过程中自动执行常见任务。Gulp.js 是基于 Node.js 构建的，利用 Node.js 流的威力，你 可以快速构建项目并减少频繁的 IO 操作。Gulp.js 源文件和你用来定义任务 的 Gulp 文件都是通过 JavaScript(或者 CoffeeScript )源码来实现的。 JSHint最初，lint这个工具用来扫描C源文件并对源程序中不可移植的代码提出警告。但是现在大多数lint实用程序已经变得更加严密，它不但可以检查出可移植性问题，而且可以检查出那些虽然可移植并且完全合乎语法但却很可能是错误的特性。对应于不同的语言都会有不同的 lint 工具，在 JavaScript 中就有JSLint。JavaScript 是一门年轻、语法灵活多变且对格式要求相对松散的语言，因此这样的工具对于这门语 言来说比较重要。• 可配置规则，每个团队可以自己定义自己想要的代码规范。• 对社区非常友好，社区支持度高。• 可定制的结果报表。 自动化测试工具Mocha 是一个可以运行在 Node.js 和浏览器环境里的测试框架。 编译对于静态型语言来说，编译是一个很重要的步骤。不过，对于动态语言来说也存在这样的工具。动态语言的编译:是以我们常见的 JavaScript 为代表。打包,1. DEB 2.RPM 3.压缩文档 tar.gz 如何编写测试TODO测试金字塔 从上到下 ui测试 服务测试 单元测试测试替身 Stub Mock 代码重构TODO重构，一言以蔽之，就是在不改变外部行为的前提下，有条不紊地改善代码。 上线HTTP服务器目前最主流的三个 Web 服务器是 Apache、Nginx、IIS。 ApacheApache 是世界使用排名第一的 Web 服务器软件。它可以运行在几乎所有广 泛使用的计算机平台上，由于其跨平台和安全性被广泛使用，是最流行的 Web 服务器 端软件之一。它快速、可靠并且可通过简单的 API 扩充，将 Perl/Python 等解释器编译 到服务器中。 NginxNginx 是一款轻量级的 Web 服务器/反向代理服务器及电子邮件(IMAP/ POP3)代理服务器，并在一个 BSD-like 协议下发行。由俄罗斯的程序设计师 Igor Sysoev 所开发，供俄国大型的入又网站及搜索引擎 Rambler(俄文:Рамблер)使用。 其特点是占有内存少，并发能力强，事实上 Nginx 的并发能力确实在同类型的网页服务 器中表现较好，中国大陆使用 Nginx 网站用户有:百度、新浪、网易、腾讯等。 IISInternet Information Services(IIS，互联网信息服务)，是由微软公司提供的基 于运行 Microsoft Windows 的互联网基本服务。最初是 Windows NT 版本的可选包，随 后内置在 Windows 2000、Windows XP Professional 和 Windows Server 2003 一起发 行，但在 Windows XP Home 版本上并没有 IIS。 代理服务器代理服务器(Proxy Server)是一种重要的服务器安全功能，它的工作主要在 开放系统互联 (OSI) 模型的会话层，从而起到防火墙的作用。代理服务器大 多被用来连接 INTERNET(国际互联网)和 Local Area Network(局域网)。 Web缓存• 数据库端缓存• 应用层缓存• 前端缓存• 客户端缓存 功能开关当我们上线了我们的新功能的时候，这时候如果有个 Bug，那么我们是下线么?要 知道这个版本里面包含了很多的 Bug 修复。Feature Toggle 它是一种允许控制线上功能开启或者关闭的方式 依赖与包仓库数据分析SEO 搜索引擎优化分析工具 google analytics网站性能 Apdex联盟","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"全栈","slug":"全栈","permalink":"https://github.com/zdkswd/tags/全栈/"}]},{"title":"[Linux内核设计与实现]中断与中断处理","slug":"【Linux内核设计与实现】中断与中断处理","date":"2018-07-01T11:37:32.000Z","updated":"2018-07-01T11:37:21.000Z","comments":true,"path":"2018/07/01/【Linux内核设计与实现】中断与中断处理/","link":"","permalink":"https://github.com/zdkswd/2018/07/01/【Linux内核设计与实现】中断与中断处理/","excerpt":"","text":"【Linux内核设计与实现】中断与中断处理中断中断处理程序在Linux中，中断处理程序就是普普通通的C函数。 上半部与下半部的对比把中断处理分为两部分。中断处理程序是上半部–接收到一个中断，就立即开始执行，但只做有严格时限的工作。能够被允许稍后完成的工作会推迟到下半部。 注册中断处理程序中断处理程序是管理硬件的驱动程序的组成部分。每一设备都有相关的驱动程序，如果设备使用中断，则对应的驱动程序就注册一个中断处理程序。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"纸质书笔记","slug":"纸质书笔记","permalink":"https://github.com/zdkswd/tags/纸质书笔记/"},{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"引入module后的问题 ; AsyncTask ;Make Clean Project;abiFilters","slug":"引入module后的问题 ; AsyncTask ;Make Clean Project;abiFilters","date":"2018-06-15T09:49:56.000Z","updated":"2018-06-15T03:55:47.000Z","comments":true,"path":"2018/06/15/引入module后的问题 ; AsyncTask ;Make Clean Project;abiFilters/","link":"","permalink":"https://github.com/zdkswd/2018/06/15/引入module后的问题 ; AsyncTask ;Make Clean Project;abiFilters/","excerpt":"","text":"引入module后的问题 ; AsyncTask ;Make Clean Project;abiFiltersimport module在import module时，如果图标没有变化，不要忘了改setting.gradle AsyncTaskAsyncTask,即异步任务,是Android给我们提供的一个处理异步任务的类.通过此类,可以实现UI线程和后台线程进行通讯,后台线程执行异步任务,并把结果返回给UI线程. AsyncTask&lt;Params,Progress,Result&gt;是一个抽象类,通常用于被继承.继承AsyncTask需要指定如下三个泛型参数:Params:启动任务时输入的参数类型.Progress:后台任务执行中返回进度值的类型.Result:后台任务执行完成后返回结果的类型. AsyncTask主要有如下几个方法:doInBackground:必须重写,异步执行后台线程要完成的任务,耗时操作将在此方法中完成.onPreExecute:执行后台耗时操作前被调用,通常用于进行初始化操作.onPostExecute:当doInBackground方法完成后,系统将自动调用此方法,并将doInBackground方法返回的值传入此方法.通过此方法进行UI的更新.onProgressUpdate:当在doInBackground方法中调用publishProgress方法更新任务执行进度后,将调用此方法.通过此方法我们可以知晓任务的完成进度. Make Project Clean Project Make Project：编译Project下所有Module，一般是自上次编译后Project下有更新的文件，不生成apk。 Make Selected Modules：编译指定的Module，一般是自上次编译后Module下有更新的文件，不生成apk。 Clean Project：删除之前编译后的编译文件，并重新编译整个Project，比较花费时间，不生成apk。 Rebuild Project：先执行Clean操作，删除之前编译的编译文件和可执行文件，然后重新编译新的编译文件，不生成apk，这里效果其实跟Clean Project是一致的，这个不知道Google搞什么鬼～～ Build APK：前面4个选项都是编译，没有生成apk文件，如果想生成apk，需要点击Build APK。 Generate Signed APK：生成有签名的apk。 平时小的改动直接用Make Project就可以，可以看到只有它有快捷方式，表明这个功能要经常用。对于一些大的改动比如更新lib，大功能修改等，用Clean或Rebuild，毕竟这两个编译起来要费时间。如果有的时候死活编译不过，多试试Clean吧，会有意想不到的效果！ 关于abiFilters的使用最近项目中遇到了要使用opencv的情况，涉及到了abi兼容的选择。因为如果全部都适配的话，包很大，这样兼容那些用户数极少的cpu就很不划算，所以我只适配了armeabi-v7a这一个。但是今天在x64-v8a的模拟器上看的时候，提示我的library.so文件找不到，我记得这个应该是向下兼容的，但是出现这种情况很奇怪，于是我就在网上找了找答案。解决方法：abiFilters在app的gradle的defaultConfig里面加上这么一句ndk { abiFilters “armeabi-v7a” // 指定要ndk需要兼容的架构(这样其他依赖包里mips,x86,armeabi,arm-v8之类的so会被过滤掉)} 这句话的意思就是指定ndk需要兼容的架构，把除了v7a以外的兼容包都过滤掉，只剩下一个v7a的文件夹。用了这个方法之后，确实解决了问题。这就是解决方法。具体分析其实这个方法我开始是很奇怪的，我明明没有指定其他的兼容框架，为什么会需要一个过滤。我打来了apk的包，找到了里面的lib目录，发现里面有很多的兼容目录，然后看到里面目录里面的是一个fresco的.so文件。也就是说，fresco做了各个平台的兼容，所以它创建了各个兼容平台的目录。因为只要出现了这个目录，系统就只会在这个目录里找.so文件而不会遍历其他的目录，所以就出现了之前找不到.so文件的情况（因为其他目录没有我的.so文件）。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"},{"name":"AndroidStudio","slug":"AndroidStudio","permalink":"https://github.com/zdkswd/tags/AndroidStudio/"}]},{"title":"[Linux内核设计与实现]系统调用","slug":"[Linux内核设计与实现]系统调用","date":"2018-06-15T03:53:32.000Z","updated":"2018-06-18T02:49:58.000Z","comments":true,"path":"2018/06/15/[Linux内核设计与实现]系统调用/","link":"","permalink":"https://github.com/zdkswd/2018/06/15/[Linux内核设计与实现]系统调用/","excerpt":"","text":"[Linux内核设计与实现]系统调用内核提供接口让应用程序调用实现特定功能，避免应用程序肆意妄为。 与内核通信系统调用在用户空间进程和硬件设备间添加了一个中间层。 提供硬件的抽象接口，即无需管磁盘类型，介质等问题。 保证系统的安全。 告知内核自己在使用硬件以实现多任务和虚拟内存。内核知道了才能更好的管理分配。系统调用是用户空间访问内核的唯一手段。 API、POSIX、和C库用户程序在用户空间使用API进行编程。API可以实现零个，一个或多个系统调用。UNIX世界中，最流行的应用程序接口是基于POSIX标准的。在大多数Unix上，根据POSIX定义的API函数和系统调用之间有着直接的关系。这个协议是对操作系统服务接口的标准化，从而保证了应用程序在源码层次的可移植性。具体来说是应用程序调用API，API中包含有系统调用，调用内核。程序员与API打交道，内核与系统调用打交道。 系统调用要访问系统调用（在Linux中常称为syscall）,通常通过C库中定义的函数调用来进行。 系统调用号在Linux中，每个系统调用被赋予一个系统调用号。通过这个独一无二的号可以关联系统调用。系统调用号非常重要，一旦分配就不能变更，否则编译好的应用就会崩溃。Linux中的sys_ni_syscall()系统调用几乎不做任何操作，相当于白板儿，用来替代那些被删除的或不可用的系统调用。内核用sys_call_table记录注册过的系统调用。 系统调用的性能Linux系统调用比其他操作系统执行的快。一是因为Linux有很短的上下文切换时间。二是系统调用处理程序和每个系统调用都很简洁。 系统调用的处理程序应用程序实际在API中调用的系统调用也并不是直接执行内核代码。应用程序以软中断的方式来通知系统执行一个系统的调用。通过引发异常来促使系统切换到内核态去执行异常处理程序。正是系统调用的处理程序。通过int$0x80指令触发中断。 指定恰当的系统调用系统调用号通过eax寄存器传递给内核。 参数传递也可以通过寄存器进行参数的传递。 系统调用的实现实现系统调用Unix格言提供机制而不是策略，当写一个系统调用时，要时刻注意可移植性和健壮性，还要为以后做打算。 参数验证系统调用必须仔细检查参数是否合法有效最重要的检查是用户提供的指针知否有效。内核无论何时都不能轻率接受来自用户空间的指针。 系统调用上下文在Context中，内核可以休眠可以被抢占。 绑定一个系统调用的最后步骤从用户空间访问系统调用","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"纸质书笔记","slug":"纸质书笔记","permalink":"https://github.com/zdkswd/tags/纸质书笔记/"},{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"Surface、SurfaceView、SurfaceHolder及SurfaceHolder.Callback","slug":"Surface、SurfaceView、SurfaceHolder及SurfaceHolder.Callback","date":"2018-05-31T09:49:56.000Z","updated":"2018-05-31T09:51:27.000Z","comments":true,"path":"2018/05/31/Surface、SurfaceView、SurfaceHolder及SurfaceHolder.Callback/","link":"","permalink":"https://github.com/zdkswd/2018/05/31/Surface、SurfaceView、SurfaceHolder及SurfaceHolder.Callback/","excerpt":"","text":"SurfaceSurface本身的作用类似一个句柄，得到了这个句柄就可以得到其中的Canvas、原生缓冲器以及其它方面的内容。原生缓冲器（rawbuffer）是用于保存当前窗口的像素数据的。通常画图是在一个Canvas对象上面进行的。 SurfaceViewSurfaceView，顾名思义就是Surface的View，通过SurfaceView就可以看到Surface的部分或者全部的内容.也就是说，Surface是用通过SurfaceView才能展示其中的内容。SurfaceView是Android中View的子类。事实上，在Android中所有用于界面展示的类皆为View的子类，包括那些不可见的、各种各样的Layout。 在Android中Surface是从Object派生而来，且实现了Parcelable接口。看到Parcelable就让人能很自然地想到数据容器，SurfaceView就是用来展示Surface中的数据的。在这个层面上而言，Surface就是管理数据的地方，SurfaceView就是展示数据的地方。 这个类的目的之一，就是提供一个可以用另外一个线程（第二个线程）进行屏幕渲染的surface（译注：即UI线程和绘制线程可以分离）。如果你打算这样使用，那么应当注意一些线程方面的语义： 所有SurfaceView和SurfaceHolder.Callback中声明的方法，必须在运行SurfaceView窗口中的线程中调用（典型地，就是应用的主线程。译注：即UI线程），因为它们需要正确地将同时被绘制线程访问的各种状态进行同步。 必须保证，只有在背后的Surface有效的时候 – 在SurfaceHolder.Callback.surfaceCreated()和 SurfaceHolder.Callback.surfaceDestroyed()这两个方法调用之间，访问它。 Android中实现序列化有两个选择：一是实现Serializable接口（是JavaSE本身就支持的），一是实现Parcelable接口（是Android特有功能，效率比实现Serializable接口高效，可用于Intent数据传递，也可以用于进程间通信（IPC））。实现Serializable接口非常简单，声明一下就可以了，而实现Parcelable接口稍微复杂一些，但效率更高，推荐用这种方法提高性能。 SurfaceHolderSurfaceHolder是一个接口，其作用就像一个关于Surface的监听器。提供访问和控制SurfaceView背后的Surface 相关的方法.它通过三个回调方法，让我们可以感知到Surface的创建、销毁或者改变。在SurfaceView中有一个方法getHolder，可以很方便地获得SurfaceView所对应的Surface所对应的SurfaceHolder.从设计模式的高度来看，Surface、SurfaceView和SurfaceHolder实质上就是广为人知的MVC，即Model-View-Controller。 SurfaceHolder.Callback前面已经讲到SurfaceHolder是一个接口，它通过回到方法的方式，让我们可以感知到Surface的创建、销毁或者改变。其实这一点是通过其内部的静态子接口SurfaceHolder.Callback来实现的。SurfaceHolder.Callback中定义了三个接口方法： abstract void surfaceChanged(SurfaceHolderholder, int format, int width, int height)当surface发生任何结构性的变化时（格式或者大小），该方法就会被立即调用。 abstract void surfaceCreated(SurfaceHolderholder)当surface对象创建后，该方法就会被立即调用。 abstract void surfaceDestroyed(SurfaceHolderholder)当surface对象在将要销毁前，该方法会被立即调用。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"}]},{"title":"implementation 与 compile 的区别 .iml build文件夹 安卓视图","slug":"implementation 与 compile 的区别 .iml build文件夹 安卓视图","date":"2018-05-31T09:49:56.000Z","updated":"2018-05-31T09:51:21.000Z","comments":true,"path":"2018/05/31/implementation 与 compile 的区别 .iml build文件夹 安卓视图/","link":"","permalink":"https://github.com/zdkswd/2018/05/31/implementation 与 compile 的区别 .iml build文件夹 安卓视图/","excerpt":"","text":"##implement概念 : 将该依赖隐藏在内部，而不对外部公开。理解 : 在 app mudule 中使用 implement 依赖的第三方库, 在其他 mudule 是无法调用的.举例 : 此时项目中有一个 mudule 是 ImageLoader ,其内部用 implement 指令依赖了 glide 这个库, 那么此时我们在 app mudule 中无法调用 glide 库中的方法. ##compile概念: android studio 3.0 版本后废弃该指令 改用 api 代替, api 完全等同于之前的 compile 指令, 也就是普通的依赖, 第三方库在 mudule 中依赖后其他 mudule 都可以使用该库.官方推荐在不影响的前提下优先使用 implement 指令依赖. .iml文件iml是 intellij idea的工程配置文件，里面是当前project的一些配置信息可以配置不输出文件夹。 build文件夹中的generated intermediates成功build后会产生以下文件夹：generated：The “generated“ folder contains java code generated by Android Studio for the module. The primary file here is “R.java“ which assigns symbolic names to each of the items in the “res” directory so they can be referenced in java source code.intermediates：The “intermediates“ folder contains individual files that are created during the build process and which are eventually combined to produce the “apk” file. Android视图与Project视图Project视图：Project视图是真实的文件结构，真实文件就是这么存放的。Android视图:可以说是build成功后根据配置信息，生成的结构。结构与配置信息有关，与build文件夹有关。不是真实文件的存放方式。其项目树的名字也不一定是真实名字，与配置信息有关。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"},{"name":"AndroidStudio","slug":"AndroidStudio","permalink":"https://github.com/zdkswd/tags/AndroidStudio/"}]},{"title":"【安卓开发艺术探索】JNI和NDK编程","slug":"【安卓开发艺术探索】JNI和NDK编程","date":"2018-05-31T09:49:56.000Z","updated":"2018-05-31T12:53:11.000Z","comments":true,"path":"2018/05/31/【安卓开发艺术探索】JNI和NDK编程/","link":"","permalink":"https://github.com/zdkswd/2018/05/31/【安卓开发艺术探索】JNI和NDK编程/","excerpt":"","text":"NDK还提供了交叉编译器，开发人员只需要简单地修改mk文件就可以生成特定CPU平台的动态库。 JNI开发流程 在java中声明native方法声明native方法，且在类头部有加载动态库的过程，库的真实名字为加载所用名字加前缀lib，这是加载so库的规范。 编译java源文件得到class文件，然后通过javah命令导出JNI的头文件 javac com/ddd/example.javajavah com.ddd.example 在当前目录会产生一个com_ddd_example.h的头文件，它是javah命令自动生成的。函数名的格式遵循java_包名_类名_方法名 实现JNI方法，JNI方法是指java中声明的native方法，在工程的主目录下创建一个子目录，名称随意，将上一步生成的头文件复制其中，接着创建.cpp文件，include它。实现其中的方法。 编译so库并在java中调用so库这里采用gcc编译，切换到刚刚生成的子目录中，对于cpp编译指令如下： gcc -shared-I /本地jdk的安装路径/include -fPIC .cpp -o libexample.so so库编译完成后，就可以在Java程序中调用so库了，切换至主目录，执行指令 java -Djava.library.path=子目录名 com.ddd.example 其中-Djava.library.path指明了so库的路径。 NDK开发流程 下载并配置NDK 创建一个安卓项目，并声明所需的native方法如： public static native String hello(); 3.实现安卓项目中声明的native方法,在外部创建一个名为jni的目录，然后在jni目录下创建3个文件，.cpp,Android.mk和Application.mk .h中： JNIEXPORT jstring JNICALL Java_com_aiseminar_EasyPR_PlateRecognizer_hello(JNIEnv *, jclass); .cpp中实现其.h中的函数。Android.mk中，LOCAL_MODULE表示模块的名称，LOCAL_SRC_FILES表示需要参与编译的源文件。Application.mk中常用的配置项是APP_ABI,它表示CPU架构平台的类型，默认NDK编译全平台的so库，但可以指定编译特定平台的so库。 切换到jni目录的父目录，然后通过ndk-build命令编译产生so库这时NDK会创建一个和jni平级的目录libs，存放so库的目录。需要注意ndk-build命令默认指定jni目录为本地源码目录。若不是则无法成功编译。然后在app/src/main中创建一个名为jniLibs目录，将生成so库复制过去，通过AndroidStudio编译运行即可。jniLibs目录是AndroidStudio默认目录，也可修改App build.gradle文件，jniLibs.srcDir选项指定了新的存放so库的目录。 也可以通过AndroidStudio来自动编译来产生so库。首先需要在App的build.gradle的defaultConfig区域内添加NDK选项，其中moduleName制定了模块的名称，这个名称指定看打包后的so库文件名。ndk{\u0010 moduleName”example”}接着需要将JNI代码放在app/src/main/jni目录中，注意存JNI必须为jni，也可以通过如下方式指定JNI代码路径，其中jni.srcDirs指定JNI代码路径：jni.srcDirs ‘src/main/lib_src’经过上面的步骤，AndroidStudio就可以自动编译JNI代码了。 JNI的数据类型和类型签名JNI调用Java方法1 找到类名2 找到方法id3 调用方法对于非静态方法要先生成类才行","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"},{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"}]},{"title":"Bazel 和Protocol Buffer","slug":"Bazel 和Protocol Buffer","date":"2018-05-25T11:00:56.000Z","updated":"2018-05-25T11:01:05.000Z","comments":true,"path":"2018/05/25/Bazel 和Protocol Buffer/","link":"","permalink":"https://github.com/zdkswd/2018/05/25/Bazel 和Protocol Buffer/","excerpt":"","text":"BazelBazel是一个类似于Make的编译工具，是Google为其内部软件开发的特点量身定制的工具，如今Google使用它来构建内部大多数的软件。Google认为直接用Makefile构建软件速度太慢，结果不可靠，所以构建了一个新的工具叫做Bazel，Bazel的规则层级更高。 Protocol BufferProtocol Buffer是谷歌开发的处理结构化数据的工具。解决结构数据在信息持久化或网络传输时需要进行序列化以及还原数据的问题。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://github.com/zdkswd/tags/TensorFlow/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"Tensorflow模型持久化","slug":"Tensorflow模型持久化","date":"2018-05-25T11:00:56.000Z","updated":"2018-05-25T11:10:23.000Z","comments":true,"path":"2018/05/25/Tensorflow模型持久化/","link":"","permalink":"https://github.com/zdkswd/2018/05/25/Tensorflow模型持久化/","excerpt":"","text":"持久化代码实现通过tf.train.Saver类来保存和还原一个神经网络，模型文件目录下会出现三个文件。这是因为Tensorflow会将计算图的结构和图上参数取值分开保存。 model.ckpt.meta,保存了计算图的结构。 model.ckpt,保存程序中每一个变量的取值。 checkpoint,保存了一个目录下所有的模型文件列表。 加载已经保存的Tensorflow模型方法。1.使用和保存模型代码中一样的方法来声明变量。2.加载已经保存的模型。sever.restore(sess,”.ckpt”) 加载模型的程序也是定义了Tensorflow计算图上的所有运算，并声明了一个tf.train.Saver类。区别在于加载模型的代码中没有运行变量的初始化过程而是将变量的值通过已经保存的模型加载了进来。也可以直接加载已经持久化的图saver=tf.train.import_meta_graph(…..meta) 函数tf.get_default_graph().get_tensor_by_name(“add:0”)可以通过张量的名称获取张量。 也可以声明tf.train.Saver类时提供一个列表指定需要保存或者加载的变量。同样可以在保存和加载时使用字典给变量重命名。 使用Saver会保存运行程序所需的全部信息，然而有时不需要某些信息。在测试或者离线预测时，不需要某些辅助节点的信息。且多个文件存储时也并不方便。convert_variables_to_constants将计算图中的变量及其取值通过常亮保存。导出当前计算图的GraphDef部分只需要这一部分就可以完成从输入层到输出层的计算过程。 graph_def=tf.get_default_graph().as_graph_def() 将图中的变量及其取值转化为常量，同时将图中不必要的节点去掉。一些如变量初始化操作的系统运算也会被转化为计算图的节点。可以通过【】指定需要保存的操作。 output_graph_def=graph_util.convert_variables_to_constants(sess,graph_def,[‘add’])//add为节点名 将导出模型存入文件： with tf.gfile.GFile(“…pb”,”wb”) as f: f.write(output_graph_def.SerialzeToString()) 加载模型： with gflie.FastGFile(model_filename//.pb,’rb’) as f: graph_def=tf.GraphDef() graph_def.ParseFromString(f.read())result=tf.import_graph_def(graph_def,return_elements=[“add:0”])//add:0为一个张量sess.run(result) Saver持久化原理及数据格式Tensorflow通过元图（MetaGraph）来记录计算图中节点信息以及运行计算图中节点所需要的元数据。由Protocol Buffer定义，记录了五类信息： meta_info_def属性,记录计算图中的元数据以及所有使用到运算方法的信息。 graph_def属性，记录计算图的节点信息。 saver_def属性，记录了持久化模型时需要用到的一些参数。 collection_def属性维护集合的底层实现是通过collection_def这个属性。5 signature_def属性。 model.ckpt保存所有变量的取值，通过SSTable格式存储，大致为一个（key，value）列表。checkpoint是Saver类自动生成自动维护的。当某个保存的TensorFlow模型文件被删除时，这个模型对应的文件名也会从checkpoint文件中删除。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://github.com/zdkswd/tags/TensorFlow/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"Gradle","slug":"Gradle","date":"2018-05-20T09:28:56.000Z","updated":"2018-05-20T09:42:19.000Z","comments":true,"path":"2018/05/20/Gradle/","link":"","permalink":"https://github.com/zdkswd/2018/05/20/Gradle/","excerpt":"","text":"差异管理说到多渠道问题,不同的渠道一般会对应不同的渠道号,你当然可以通过修改一次打一个包这种纯手工的方式来生成你的多渠道包,但据听说国内某团购网站的Android App有100多个渠道.这里出现了什么?重复,反复的去打包而且这些包之前的差异很小(只是渠道号不同),和写代码一样我们应该复用,通过Gradle可以实现一个命令打出所有的渠道包,一个命令打出指定的渠道包.再复杂一点,你可能需要不同的渠道对应不同的签名文件,不同的icon,不同的服务器地址…这些都可以通过Gradle来方便的实现. 依赖管理:做软件开发你可能需要依赖各种不同的jar,library.你当然可以通过将.jar/library工程下载到本地再copy到你的工程中,但不知你是否听说过国外有个叫中央仓库的东西,在这个仓库里你可以找到所有你能想到以及你从来没听说过的jar,aar…The Central Repository Search Engine 这里可以找到所有你需要的依赖,而你需要的只是指定一个坐标,如下:compile’com.squareup.picasso:picasso:2.3.3剩下的依赖的寻找,下载,添加到classpath等你都不需要去关心,通过这种方式来维护依赖的好处有以下几点:剩下的依赖的寻找,下载,添加到classpath等你都不需要去关心,通过这种方式来维护依赖的好处有以下几点: 依赖不会进入到你的版本控制仓库中(默认会缓存到~/.gradle/下) 方便卸载装载依赖(只是一条坐标依赖,不需要删除即可) 方便的版本管理,如上图中的2.3.3既是picasso的版本号,若改为+就表示从中央仓库中下载最新的版本 不同工程的相同依赖不会存在重复副本(只在~/.gradle下存在一份)项目部署这方面我没怎么接触过,但据我所知通过一些插件,可以实现自动将你的输出(.jar,.apk,.war…)上传到指定仓库,自动部署… Gradle概念Gradle，这是一个基于 JVM 的富有突破性构建工具。Gradle不单单是一个配置脚本，它的背后是三门语言。 ◦ Groovy Language ◦ Gradle DSL ◦ Android DSLDSL的全称是Domain Specific Language，即领域特定语言。 The Gradle wrapperGradle Wrapper 允许你在没有安装 Gradle 的机器上执行 Gradle 构建。 Gradle构建基础build.gradle一个项目中会有一个project build.gradle。与若干个module build.gradle.你可以通过在命令行运行 gradle 命令来执行构建，gradle 命令会从当前目录下寻找 build.gradle 文件来执行构建。我们称 build.gradle 文件为构建脚本。严格来说这其实是一个构建配置脚本。 project与taskGradle中，每一个待编译的工程都叫一个Project。每一个Project在构建的时候都包含一系列的Task。比如一个Android APK的编译可能包含：Java源码编译Task、资源编译Task、JNI编译Task、lint检查Task、打包生成APK的Task、签名Task等。插件本身就是包含了若干Task的。 Gradle脚本的执行时序 初始化，分析有哪些module将要被构建，为每个module创建对应的 project实例。这个时候settings.gradle文件会被解析。 配置,处理所有的模块的 build 脚本，处理依赖，属性等。这个时候每个模块的build.gradle文件会被解析并配置，这个时候会构建整个task的链表（这里的链表仅仅指存在依赖关系的task的集合，不是数据结构的链表）。先是project build.gradle后是module build.gradle,且从依赖树的叶节点执行。配置完了以后，有一个重要的回调project.afterEvaluate，它表示所有的模块都已经配置完了，可以准备执行task了。 执行，根据task链表来执行某一个特定的task，这个task所依赖的其他task都将会被提前执行。 Groovy基础[原创：任玉刚]Groovy和Java的关系Groovy是一门jvm语言，它最终是要编译成class文件然后在jvm上执行，所以Java语言的特性Groovy都支持，我们完全可以混写Java和Groovy。 Groovy的变量和方法声明在Groovy中，通过 def 关键字来声明变量和方法。 def a = 1def b = “hello world”def int c = 1 def hello() { println “hello world” // 方法调用省略括号 1; // 方法返回值省略return}def hello(String msg) { println (msg)} // 方法省略参数类型int hello(msg) { println (msg) return 1} // 方法省略参数类型int hello(msg) { println msg return 1 // 这个return不能省略 println “done”} Groovy的数据类型 String,用于字符串拼接。 闭包，Groovy中有一种特殊的类型，叫做Closure，翻译过来就是闭包，这是一种类似于C语言中函数指针的东西。闭包用起来非常方便，在Groovy中，闭包作为一种特殊的数据类型而存在，闭包可以作为方法的参数和返回值，也可以作为一个变量而存在。 声明闭包 { parameters -&gt; code} List和Map,Groovy加强了Java中的集合类，比如List、Map、Set等.List还有一种看起来很奇怪的操作符&lt;&lt;，表示向List中添加新元素的意思. 加强的IO. 其他特性 所有的Class类型，都可以省略.class 只要有属性就有Getter/Setter，反之亦然。 with操作符 Book bk = new Book()bk.id = 1bk.name = “android art”bk.press = “china press” 可以简写为： Book bk = new Book()bk.with { id = 1 name = “android art” press = “china press”} 等等http://www.jianshu.com/p/ba55dc163dfd 定义Task task myTask { println “config myTask”} 通过上述方式定义的task,括号内部的代码会在配置阶段执行。 要括号内的代码仅仅在执行我们的task的时候才执行，这个时候可以通过doFirst或者doLast来完成。 • doFirst：task执行时，最开始的操作 • doLast：task执行时，最后的操作 myTask.doLast { println “after execute myTask”}myTask.doFirst { println “before execute myTask”} doLast还有一个等价的操作leftShift，leftShift还可以缩写为&lt;&lt; myTask &lt;&lt; { println “after execute myTask”} 剩下的细节还是需要大家查看Gradle文档，其实学习Gradle就是一个查文档的过程。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"},{"name":"软件构筑","slug":"软件构筑","permalink":"https://github.com/zdkswd/tags/软件构筑/"}]},{"title":"x86 ARM MIPS NDK JNI 交叉编译 ABI","slug":"x86 ARM MIPS NDK JNI 交叉编译 ABI","date":"2018-05-19T13:46:56.000Z","updated":"2018-05-25T10:28:41.000Z","comments":true,"path":"2018/05/19/x86 ARM MIPS NDK JNI 交叉编译 ABI/","link":"","permalink":"https://github.com/zdkswd/2018/05/19/x86 ARM MIPS NDK JNI 交叉编译 ABI/","excerpt":"","text":"X86和ARM,MIPS架构x86架构采用CISC，代表公司Intel。而ARM采用RISC，代表公司ARM。MIPS架构多用在网关、猫、机顶盒等设备。 X86以增加处理器本身复杂度作为代价，去换取更高的性能，但集成的指令集数量越来越多，给硬件带来的负荷也就越来越大，无形中增加了功耗和设计难度。x86为此还必须有复杂的分支预测机构，确保流水线的效率。再加上多级cache，支持超线程、虚拟化等等，x86的复杂度其实相当高ARM（Advanced RISC Machines）一个32位元精简指令集(RISC)处理器架构可以说在性能和生产工艺方面ARM根本不是X86结构系统的对手。但ARM的优势不在于性能强大而在于效率，ARM采用RISC流水线指令集，在完成综合性工作方面根本就处于劣势，而在一些任务相对固定的应用场合其优势就能发挥得淋漓尽致。 扩展性X86结构的电脑采用“桥”的方式与扩展设备（如：硬盘、内存等）进行连接，x86结构的电脑能很容易进行性能扩展，如增加内存、硬盘等。ARM结构的电脑是通过专用的数据接口使CPU与数据存储设备进行连接，所以ARM的存储、内存等性能扩展难以进行 功耗X86电脑因考虑要适应各种应用的需求，其发展思路是：性能+速度，考虑其完成复杂操作的能力，功耗很大。ARM则功耗很低。ARM阵营努力增加其性能和系统（特别是操作系统）的通用性，蚕食x86系统的部分终端应用市场，ARM目前是移动处理器的老大；X86阵营努力降低功耗保住其市场，同时侵入手持移动终端市场。 x86是PC端老大。 NDKNative Development Kit（NDK）是一系列工具的集合。它提供了一系列的工具，帮助开发者快速开发C/C++的动态库，并能自动将so和java一起打包成apk。NDK就是帮助我们可以在Android应用中使用C/C++来完成特定功能的一套工具.NDK的作用有很多，我们简单的列举两个:1.首先NDK可以帮助开发者“快速”开发C(或C++)的动态库。2.其次，NDK集成了“交叉编译器”。使用NDK，我们可以将要求高性能的应用逻辑使用C开发，从而提高应用程序的执行效率。 JNIJava Native Interface（JNI）标准是java平台的一部分，JNI是Java语言提供的Java和C/C++相互沟通的机制，其实JNI它就是一种协议,Java可以通过JNI调用C/C++代码，C/C++的代码也可以调用java代码。 交叉编译编译器在将中间代码连接成当前计算机可执行的二进制程序时，连接程序会根据当前计算机的CPU、操作系统的类型来转换。交叉编译就是在一个平台下（比如：CPU架构为X86，操作系统为Windows）编译出在另一个平台上（比如：CPU架构为arm,操作系统为Linux）可以执行的二进制代码。Google提供的NDK就可以完成交叉编译的工作。【Android：基于Linux 内核arm架构的操作系统，装在arm上的linux是需要重新编译内核的 所以和x86上的linux内核是不一样的】 Android 设备的CPU类型(通常称为”ABIs”) armeabiv-v7a: 第7代及以上的 ARM 处理器。2011年15月以后的生产的部分Android设备都使用它. arm64-v8a: 第8代、64位ARM处理器，很少设备，三星 Galaxy S6是其中之一。 armeabi: 第5代、第6代的ARM处理器，早期的手机用的比较多。 x86: 平板、模拟器用得比较多。 x86_64: 64位的平板。 arm64-v8a是可以向下兼容的，但前提是你的项目里面没有arm64-v8a的文件夹，如果你有两个文件夹armeabi和arm64-v8a，两个文件夹，armeabi里面有a.so 和 b.so,arm64-v8a里面只有a.so，那么arm64-v8a的手机在用到b的时候发现有arm64-v8a的文件夹，发现里面没有b.so，就报错了，所以这个时候删掉arm64-v8a文件夹，这个时候手机发现没有适配arm64-v8a，就会直接去找armeabi的so库，所以要么你别加arm64-v8a,要么armeabi里面有的so库，arm64-v8a里面也必须有。 对策： 为了减小 apk 体积，只保留 armeabi 和 armeabi-v7a 两个文件夹，并保证这两个文件夹中.so数量一致 对只提供 armeabi 版本的第三方 .so，原样复制一份到 armeabi-v7a 文件夹 应用程序二进制接口（Application Binary Interface）定义了二进制文件（尤其是.so文件）如何运行在相应的系统平台上，从使用的指令集，内存对齐到可用的系统函数库。在Android系统上，每一个CPU架构对应一个ABI：armeabi，armeabi-v7a，x86，mips，arm64-v8a，mips64，x86_64。 当一个应用安装在设备上，只有该设备支持的CPU架构对应的.so文件会被安装。在x86设备上，libs/x86目录中如果存在.so文件的话，会被安装，如果不存在，则会选择armeabi-v7a中的.so文件，如果也不存在，则选择armeabi目录中的.so文件（因为x86设备也支持armeabi-v7a和armeabi）。我们往往很容易对.so文件应该放在或者生成到哪里感到困惑，下面是一个总结：Android Studio工程放在jniLibs/ABI目录中（当然也可以通过在build.gradle文件中的设置jniLibs.srcDir属性自己指定）","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://github.com/zdkswd/tags/Android/"},{"name":"计算机科学","slug":"计算机科学","permalink":"https://github.com/zdkswd/tags/计算机科学/"},{"name":"c/c++","slug":"c-c","permalink":"https://github.com/zdkswd/tags/c-c/"}]},{"title":"lib dll .h .hpp 预编译","slug":"lib,dll,.h,.hpp,预编译","date":"2018-05-17T13:46:56.000Z","updated":"2018-05-17T13:48:13.000Z","comments":true,"path":"2018/05/17/lib,dll,.h,.hpp,预编译/","link":"","permalink":"https://github.com/zdkswd/2018/05/17/lib,dll,.h,.hpp,预编译/","excerpt":"","text":"静态库动态库静态库和动态库是两种共享程序代码的方式，它们的区别是：静态库在程序的链接阶段被复制到了程序中，和程序运行的时候没有关系；动态库在链接阶段没有被复制到程序中，而是程序在运行时由系统动态加载到内存中供程序调用。使用动态库的优点是系统只需载入一次动态库，不同的程序可以得到内存中相同的动态库的副本，因此节省了很多内存。 这种链接方式的好处是：方便程序移植，因为可执行程序与库函数再无关系，放在如何环境当中都可以执行。 是动态链接有一个缺点就是可移植性太差，如果两台电脑运行环境不同，动态库存放的位置不一样，很可能导致程序运行失败。 头文件编译时，编译器通过头文件.h找到对应的函数库，预编译时将整个.h文件插入目标文件头部，项目中需要有其对应的.c文件进行编译生成中间文件进行连接。.hpp，本质就是将.cpp的实现代码混入.h头文件当中，定义与实现都包含在同一文件，则该类的调用者只需要include该.hpp文件即可，无需再将cpp加入到project中进行编译。而实现代码将直接编译到调用者的obj文件中，不再生成单独的obj，采用hpp将大幅度减少调用project中的cpp文件数与编译次数 一个头文件被别的源文件重复包含是经常发生的，如何避免某个头文件被重复包含呢？利用条件编译轻松解决。在头文件的开始加入： #ifndef HEADER_NAME#define HEADER_NAME 在头文件的结尾加上： #endif C/C++中的预编译指令程序的编译过程可以分为预处理、编译、汇编三部分，其中预处理是首先执行的过程，预处理过程扫描程序源代码，对其进行初步的转换，产生新的源代码提供给编译器。 #include指令，#include预处理指令的作用是在指令处展开被包含的文件。#include \\&lt;xxx.h&gt;#include “xxx.h”第一种方法将待包含的头文件使用尖括号括起来，预处理程序会在系统默认目录或者括号内的路径查找，通常用于包含系统中自带的公共头文件。第二种方法将待包含的头文件使用双引号引起来，预处理程序会在程序源文件所在目录查找，如果未找到则去系统默认目录查找，通常用于包含程序作者编写的私有头文件。 2.#define、#undef指令,#define指令定义了一个标识符及一个串，标识符称为宏名，源程序中宏名的每次出现都会用其定义的串进行替换，称为宏替换。#undef指令取消一个已定义的宏。 3.#if、#elif、#else、#endif指令，这几个指令称为条件编译指令，可对程序源代码的各部分有选择地进行编译。跟一般的if、else if、else语句类似，如果一个条件上的值为真，则编译它对应的代码，否则提过这些代码，测试下一个条件上的值是否为真。注意，作为条件的表达式是在编译时求值的，它必须仅含常量及已定义过的标识符，不可使用变量，也不可以含有操作符sizeof（sizeof也是编译时求值）。感觉这主要是用来设置一个宏选择性的编译一部分的代码。 4.#ifdef、#ifndef、#endif指令，这几个也是条件编译指令，其检查后面指定的宏是否已经定义，然后根据检查结果选择是否要编译后面语句。其中#ifdef表示”如果有定义“，#ifndef表示”如果没有定义“。这个通常可以用于防止重复包含头文件的问题 #ifndef MYHEAD_H#define MYHEAD_H#include “myHead.h”#endif 5.#line指令,C语言中可以使用FILE表示本行语句所在源文件的文件名，使用LINE表示本行语句在源文件中的位置信息。#line指令可以重新设定这两个变量的值，其语法格式为#line number[“filename”] 6.#error指令,#error指令在编译时输出编译错误信息，可以方便程序员检查出现的错误。 7.#pragma指令,该指令用来来设定编译器的状态或者是指示编译器完成一些特定的动作，它有许多不同的参数。7.1. #pragma once在头文件的最开始加入这条指令可以保证头文件只被编译一次。它可以实现上述使用#ifndef实现不重复包含头文件同样的功能，但可能会有部分编译系统不支持。 7.2.#pragma message该指令能够让编译器遇到这条指令时就在编译输出窗口中将消息文本打印出来。 7.3.#pragma warning…等等其他参数","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"计算机科学","slug":"计算机科学","permalink":"https://github.com/zdkswd/tags/计算机科学/"},{"name":"c/c++","slug":"c-c","permalink":"https://github.com/zdkswd/tags/c-c/"}]},{"title":"Tensorflow可视化","slug":"Tensorflow可视化","date":"2018-05-17T10:11:41.000Z","updated":"2018-11-05T11:50:44.000Z","comments":true,"path":"2018/05/17/Tensorflow可视化/","link":"","permalink":"https://github.com/zdkswd/2018/05/17/Tensorflow可视化/","excerpt":"","text":"Tensorflow计算模型–计算图计算图的使用tensorflow程序可分为两个阶段，第一阶段定义图中所有的计算。第二阶段为执行阶段。tensorflow中，系统会自动维护一个默认的计算图，通过tf.get_default_graph函数可以获取当前默认的计算图。除了使用默认的计算图，Tensorflow支持通过tf.Graph函数来生成新的计算图。不同计算图上的张量和运算都不会共享。计算图可以通过tf.Graph.device函数来指定运行计算的设备。有效地整理TensorFlow程序的资源也是计算图的一个重要功能。在一个集合（collection）来管理不同类型的资源。 集合名称 集合内容 使用场景 tf.GraphKeys.VARIABLES 所有变量 持久化Tensorflow模型 tf.GraphKeys.TRAINABLE_VARIABLES 可学习的变量（一般指神经网络中的参数） 模型训练、生成模型可视化内容 tf.GraphKeys.SUMMARIES 日志生成的相关的张量 TensorFlow计算可视化 tf.GraphKeys.QUEUE_RUNNERS 处理输入的QueueRunner 输入处理 tf.GraphKeys.MOVING_AVERAGE_VARIABLES 所有计算了滑动平均值的变量 计算变量的滑动平均值 如通过tf.add_to_collection将资源加入一个或多个集合中。通过tf.get_collection获取一个集合里面的所有资源。tf.add_to_collection(‘losses’,regularizer(var_weights)):将数值regularizer(var_weights)添加到集合‘losses’中tf.get_collection(‘losses’):获取集合“losses”中的所有元素，生成一个列表并返回该列表 TensorBoard可视化TensorBoard简介TensorBoard可以通过TensorFlow程序运行过程中输出的日志文件可视化TensorFlow程序的运行状态。两者跑在不同进程中，TensorBoard会自动读取TensorFlow最新的日志文件。 #运行TensorBoard，将地址执行日志输出地址tensorboard –logdir=/path/to/log 命令启动服务默认端口号6006，localhost:6006可以看到界面。使用–port参数可以改变启动服务的端口。 变量管理TensorFLow提供了通过变量名称来创建或者获取一个变量的机制。通过这个机制在不同的函数中可以直接通过变量的名称来使用变量，而不需要将变量通过参数的形式到处传递。TensorFLow中通过变量名称获取变量的机制主要是通过tf.get_variable和tf.variable_scope函数实现。 v.get_variable和tf.Variable定义等价。区别在于前者变量名称是个必填项，后者是个选填项。v.get_variable会根据这个名字去创建或者获取变量。首先会试图创建一个变量，如有同名则创建失败。如果需要通v.get_variable获取一个已经创建的变量，需要tf.variable_scope函数生成一个上下文管理器。将参数reuse设置为True(获取唯一途径)，v.get_variable将只能获取已经创建过的变量。否则将尝试创建变量。 with tf.variable_scope(“name”,reuse=”True”): v=v.get_variable(“var”,[1]) tf.variable_scope会创建一个命名空间。foo/v:0 “:0”表示这个变量是生成变量这个运算的第一个结果。 TensorFlow计算图可视化命名空间与TensorBoard图上节点变量的初始化过程也会产生新的计算节点。为了更好的组织可视化效果图中的计算节点，TensorBoard支持通过TensorFlow命名空间来整理可视化效果图上的节点。在Tensorflow默认视图中同一命名空间计算图为一个节点，只有顶层命名空间的节点显示。除了tf.Variable_scope函数，tf.name_scope函数也提供了命名空间管理的功能，两者大部分情况下等价。唯一的区别是tf.get_Variable不受tf.name_scope函数的影响。即在tf.name_scope域里tf.get_Variable生成变量也不是域内的变量。节点之间有两种不同的边，一种是通过实线表示的，刻画了数据传输，箭头表示传输方向。另一种箭头是双向的，表示会修改，会互相影响。TensorBoard边上标注了张量的维度信息。如100*784说明batch为100，输入节点个数为784，粗细代表维度的总大小。若张量数量大于1时。图上将只显示张量的个数。虚线表示计算之间的依赖关系，如tf.control_dependencies函数指定操作同时进行。则存在虚线。TensorBoard会自动将连接比较多的节点放在辅助图中，可以手动移入主图或移出主图。TensorBoard不会保存用户对计算图可视化结果的手工修改，页面刷新之后计算图可视化结果又会回到最初的样子。 节点信息使用TensorBoard可以非常直观地展现所有Tensorflow计算节点在某一次运行时所消耗的时间和内存。 run_options =tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)// 运行时记录运行信息的proto。run_metadata = tf.RunMetadata() m, loss_value, step = sess.run( [train_op, loss, global_step], feed_dict={x: xs, y_: ys}, options=run_options, run_metadata=run_metadata) //将节点在运行时的信息写入日志文件。 writer.add_run_metadata(run_metadata=run_metadata,tag=(“tag%d” % i),global_step=i) 使用程序输出的日志启动TensorBoard,就可以了。进入GRAPHS栏，选择Session runs,Color会出现Compute time和Memory这两个选项。颜色越深消耗越大。Structure中如果有两个节点结构相同就会涂上相同的颜色。Device中可显示哪些使用了相同的设备（CPU/GPU）。点击节点时弹出的信息卡片也会显示这个节点的各种信息。 监控指标可视化 TensorFlow日志生成函数 TensorBoard界面栏 显示内容 tf.scalar_summary EVENTS TensorFlow中标量（scalar）监控数据随着迭代进行的变化趋势。 tf.image_summary IMAGES TensorFlow中使用的图片数据，这一栏一般用于可视化当前使用的训练/测试图片。 tf.audio_summary AUDIO TensorFlow中使用的音频数据。 tf.histogram_summary HISTOGRAMS TensorFlow中张量分布监控数据随着迭代轮次的变化趋势。 上述生成函数都不会立即执行，需要通过sess.run来明确调用这些函数。tf.merge_all_summaries()可将定义的所有日志文件执行一次。 writer writer=tf.train.SummaryWriter(path,tf.get_default_graph())writer.close() 或者 with tf.Session() as sess: writer=tf.train.SummaryWriter(path,sess.graph) 上述比较过时，若报错则改为writer = tf.summary.FileWriter(“output”, sess.graph) 可视化时，需要在程序中给必要的节点添加摘要（summary）,摘要会收集该节点的数据，并标记上第几步、时间戳等标识，写入事件文件（event file）中。tf.summary.FileWriter类用于在目录中创建事件文件，并且向文件中添加摘要和事件，用来在TensorBoard中展示。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://github.com/zdkswd/tags/TensorFlow/"},{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"}]},{"title":"[Linux内核设计与实现]进程调度","slug":"【Linux】进程调度","date":"2018-05-15T13:39:12.000Z","updated":"2018-05-16T11:00:02.000Z","comments":true,"path":"2018/05/15/【Linux】进程调度/","link":"","permalink":"https://github.com/zdkswd/2018/05/15/【Linux】进程调度/","excerpt":"","text":"多任务现代Linux系统也许有100个进程在内存，但是只有一个处于可运行状态。Linux是抢占式多任务模式。 Linux的进程调度Linux2.5内核开始采用O（1）调度程序，对大服务器工作负载很理想但对于交互性桌面系统表现不佳。2.6.23内核后使用RSDL增加了交互性，此时被称为CFS（完全公平调度算法） 策略I/O消耗型和处理器消耗型的进程GUI属于I/O消耗型，多数时间都在等待键鼠交互操作。应当降低处理器消耗型的调度频率，以延长其运行时间。Linux更倾向于IO消耗型进程，也并未忽略处理器消耗型进程。 进程优先级Linux采用了两种不同范围的优先级范围。1：使用nice值，范围【-20，19】，默认0，越大优先级越低。Linux nice代表时间片比例，mac os nice代表时间片的绝对值。2：实时优先级，其值可配。范围【0，99】，越高优先级越大。任何实时进程优先级都高于普通进程。 时间片Linux的CFS调度器并没有直接分配时间片到进程，将处理器的使用比划分给了进程。进程所获处理器的时间和负载密切相关。受nice值得影响。Linux的CFS调度器抢占时机取决于进程的处理器使用比，若大于当前进程则抢占。 调度策略的活动对于一个文字编辑程序和一个视频处理程序，一般操作系统会分配文字编辑器更高的优先级和更多的时间片。Linux则是nice值相同，即平分50%时间，但是当文字编辑程序要使用处理器时，CFS发现其时间没到50%，会抢占视频处理程序执行。 Linux调度算法调度器类Linux调度器是模块方式，可以针对不同类型的进程选择合适的调度算法。完全公平调度（CFS）是针对普通进程的调度类。 Unix系统的进程调度CFS完全摒弃时间片而是分配进程一个处理器的使用比重，这样CFS确保了进程调度有恒定的公平性，将切换频率置于不断变动中。 公平调度CFS的最小粒度（最小时间片长度）为1ms，时间片分配时间根据目标延迟以及nice值决定的比例计算而得。所以说其实如果进程无限大的话，改法并不公平。但是能保证正常情况下是公平的。 Linux调度的实现时间记账 所有的调度器都必须对进程运行时间做记账。 调度器实体结构,CFS不再有时间片的概念，但是它也必须维护每个进程运行时间记账，为了确保每个进程只在公平分配给它的处理器时间运行。CFS使用调度器实体结构struct sched_entity作为名为se的成员变量，嵌入进程描述符struct task_struct内。 虚拟实时，struct sched_entity结构中的vruntime变量存放进程的虚拟运行时间，虚拟时间是以ns为单位的，与定时器节拍不再相关。vruntime可以准确地测量给定进程的运行时间，而且可知道谁应该是下一个被运行的进程。 进程选择当CFS需要选择下一个运行进程时，它会挑一个具有最小vruntime的进程。CFS使用红黑树来组织可运行进程队列，并利用其迅速找到最小的vruntime值的进程。红黑树是一种以树节点形式存储的数据，这些数据都对应一个键值，可通过键值快速检索节点上的数据。 挑选下一个任务，CFS调度器选取待运行的下一个进程，是所有进程中vruntime最小的那一个，对应的便是树最左侧的叶子节点。 向树中加入进程，CFS如何将进程加入rbtree中，以及如何缓存最左叶子节点。这一切发生在进程变为可运行状态（被唤醒）或是通过fork()调用第一次创建进程时。enqueue_entity()函数实现了这一目的。改函数更新运行时间和其他一些统计数据，然后调用_enqueue_entity()进行繁重的插入操作，把数据项真正插入到红黑树中。 从树中删除进程, 删除动作发生在进程堵塞或者终止时。调度器入口进程调度的主要入口点是函数schedule()，它会找到一个最高优先级的调度类，其需要有自己的可运行队列。睡眠和唤醒休眠（被阻塞）进程把自己标记成休眠状态，从可执行红黑树中移出，放入等待队列，然后调用schedule()选择和执行一个其他进程。唤醒的过程刚好相反：进程被设置为可执行状态，然后再从等待队列中移到可执行红黑树中。 等待队列， 等待队列是由等待某些事件发生的进程组成的简单链表。 唤醒， 唤醒指定等待队列上的所有进程。抢占和上下文切换上下文切换，就是从一个可执行进程切换到另一个可执行的进程。由函数context_switch()负责，每当新的进程被选出来准备投入运行时，schedule()就会调用该函数。内核提供了一个need_resched标志表明是否需要重新执行一次调度，内核也就知道什么时候调用schedule()。当某个进程应该被抢占或优先级高的进程进入可执行状态时或中断返回或系统调用返回用户空间，会设置标志位。用户抢占内核即将返回用户空间的时候，如果need_resched标志被设置，会导致schedule()被调用，此时就会发生用户抢占。即用户抢占发生在 从系统调用返回用户空间时。 从中断处理程序返回用户空间时。 内核抢占Linux完整地支持内核抢占，只要重新调度是安全的，内核就可以在任何时候抢占正在执行的内核任务。安全即没有持有锁，即preempy_count=0且need_resched被设置，中断返回内核空间时，就可调度。同样若内核阻塞或显式调用schedule()也会显式抢占。 实时调度策略Linux提供了两种实时调度策略：SCHED_FIFO和SCHED_RR，普通的非实时的调度策略是SCHED_NORMAL.这些策略被一个特殊的实时调度器管理。 SCHED_FIFO, 不基于时间片，可以一直执行下去，其比任何SCHED_NORMAL级的进程都先得到调度。更高优先级的SCHED_FIFO或SCHED_RR才能抢占。优先级一样的就轮流执行。 SCHED_RR,带有时间片的SCHED_FIFO，耗尽时间片时，只能调度同一优先级的进程。【 总结】：对于SCHED_FIFO进程，高优先级总是立即抢占低优先级进程，但低优先级决不能抢占SCHED__RR任务，即使它的时间片耗尽。Linux提供的是软实时工作方式，SCHED_RR与SCHED_FIFO优先级范围【0，99】，而SCHED_NORMAL使用nice值。与调度相关的系统调度Linux提供了一个系统调用族，用于管理与调度程序的相关参数。这些系统调用可以用来操作和处理进程优先级、调度策略及处理器绑定，同时还提供了显式地将处理器交给其他进程的机制。与调度策略和优先级相关的系统调用sched_setscheduler()和sched_getscheduler()用于设置和获取进程的调度策略和实时优先级。sched_setparam()和sched_getparam()用于设置和获取进程的实时优先级。与处理器绑定有关的系统调用Linux调度程序提供强制的处理器绑定机制。放弃处理器时间Linux通过sched_yield()系统调用，提供了一种让进程显式地将处理器时间让给其他等待执行进程的机制。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"纸质书笔记","slug":"纸质书笔记","permalink":"https://github.com/zdkswd/tags/纸质书笔记/"},{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"初识makefile_make_cmake","slug":"cmake","date":"2018-04-29T14:11:20.000Z","updated":"2018-05-16T11:02:54.000Z","comments":true,"path":"2018/04/29/cmake/","link":"","permalink":"https://github.com/zdkswd/2018/04/29/cmake/","excerpt":"","text":"初识makefile,make,cmake什么是makefilemake命令执行时，需要一个 Makefile 文件，以告诉make命令需要怎么样的去编译和链接程序。makefile关系到了整个工程的编译规则。makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。只要我们的Makefile写得够好，所有的这一切，我们只用一个make命令就可以完成，make命令会自动智能地根据当前的文件修改的情况来确定哪些文件需要重编译，从而自己编译所需要的文件和链接目标程序。 什么是makemakefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率。 make是一个命令工具，是一个解释makefile中指令的命令工具，一般来说，大多数的IDE都有这个命令，比如：Delphi的make，Visual C++的nmake，Linux下GNU的make。可见，makefile都成为了一种在工程方面的编译方法（包括链接）。 关于程序的编译和链接在大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便，所以，我们要给中间目标文件打个包，在Windows下这种包叫“库文件”（Library File)，也就是 .lib 文件，在UNIX下，是Archive File，也就是 .a 文件。Linux中的.so。一个lib文件是obj文件的集合。源文件首先会生成中间目标文件，再由中间目标文件生成执行文件。在编译时，编译器只检测程序语法，和函数、变量是否被声明。如果函数未被声明，编译器会给出一个警告，但可以生成Object File。而在链接程序时，链接器会在所有的Object File中找寻函数的实现，如果找不到，那到就会报链接错误码 文件路径usr文件夹称为是Unix System Resource，即Unix系统资源的缩写。 bin文件夹是一个二进制程序文件夹1.bin是binary的缩写，代表的意思是二进制，二进制数据是用0和1两个数码来表示的数。2.bin这个文件夹里存放的是二进制可执行的文件，比如exe，msi，com等的都是二进制文件，双击就能运行。 GUN下面绝大部分应用的编译系统都是用automake。于是乎，你看到的很多很多应用都安装在了/usr/local/目录下然后通常/usr/bin下面的都是系统预装的可执行程序，会随着系统升级而改变/usr/local/bin目录是给用户放置自己的可执行程序的地方，推荐放在这里，不会被系统升级而覆盖同名文件安装好的lib文件存放在“/usr/local/lib”文件夹，h文件存放在“/usr/local/include”（Unix） 什么是cmakeCMake是一个跨平台的安装（编译）工具，可以用简单的语句来描述所有平台的安装(编译过程)。他能够输出各种各样的makefile或者project文件，能测试编译器所支持的C++特性,类似UNIX下的automake。只是 CMake 的组态档取名为 CMakeLists.txt。cmake是跨平台项目管理工具，它用更抽象的语法来组织项目。在windows下它会支持生成visual studio的工程，在linux下它会生成Makefile，甚至它还能生成eclipse工程文件。也就是说，从同一个抽象规则出发，它为各个编译器定制工程文件。 dlldll存在于windows中 openCV安装过程 mkdir releasecd releasecmake -D CMAKE_BUILD_TYPE=RELEASE -D 换行CMAKE_INSTALL_PREFIX=usr/local/opencv3.1.0 -G “Unix Makefiles” ..makesudo make install","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"软件构筑","slug":"软件构筑","permalink":"https://github.com/zdkswd/tags/软件构筑/"},{"name":"计算机科学","slug":"计算机科学","permalink":"https://github.com/zdkswd/tags/计算机科学/"}]},{"title":"李宏毅2017听课笔记1-Where does the error come from?","slug":"李宏毅error","date":"2018-04-25T14:48:13.000Z","updated":"2018-05-16T11:00:59.000Z","comments":true,"path":"2018/04/25/李宏毅error/","link":"","permalink":"https://github.com/zdkswd/2018/04/25/李宏毅error/","excerpt":"","text":"李宏毅2017听课笔记1-Where does the error come from? 这么多线是多次试验，每次试验拟合出一条红线 在这里直观的解释了为什么简单的模型偏差更大，因为最终是在函数集中选取最佳函数，因为函数简单的话，一开始划定的范围就较小。 正则化会伤害bias，因为只选择更平滑的曲线，相当于划了范围。（其实是让模型更简单了） 分为训练集，验证集，测试集","categories":[{"name":"听课笔记","slug":"听课笔记","permalink":"https://github.com/zdkswd/categories/听课笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"},{"name":"李宏毅","slug":"李宏毅","permalink":"https://github.com/zdkswd/tags/李宏毅/"}]},{"title":"李宏毅2017听课笔记0","slug":"李宏毅2017听课笔记0","date":"2018-04-25T01:26:25.000Z","updated":"2018-07-03T02:34:22.000Z","comments":true,"path":"2018/04/25/李宏毅2017听课笔记0/","link":"","permalink":"https://github.com/zdkswd/2018/04/25/李宏毅2017听课笔记0/","excerpt":"","text":"李宏毅2017听课笔记0前言之前听了吴恩达2014大部分的课以及吴恩达最近在网易云上的CNN课程。听闻李宏毅的课程不错，主要比较系统全面，来听一哈喽。不错的博客 0-1Introduction找出function 准备一个function set (model) 机器决定function们的好坏 找出最好的function Deep Learning：分类，非线性 Learning Map Reinforcement Learning在实际运用中，以上方法并不能解决全部问题，常常会遇到Beyond Classification的情况，比如语音识别，人脸识别，语言翻译等，那么就要通过增强学习来解决问题。增强学习的一个非常知名的应用就是 google 阿法狗。 Reinforcement Learning VS SupervisedSupervised 就像给了机器一个点读机，他听到一句话时可以看到其含义，每一句话都有标签，就像有一个手把手教他的老师。而Reinforcement Learning 就像跟女朋友对话，反复讲来回讲很多句话，直到女朋友觉得你无言以对愤然离去，机器唯一可以知道的就是他做的好还是不好，除此之外没有任何information。而这更像人类现实生活中的学习过程，必须自己像哪里做得好做得不够好，怎么修正。 Learning Map: scenario:学习情景，不受自己控制。意思是你现在有什么类型的 training data。 machine learning scenario Supervised Learning 有标签data Semi-supervised Learning 部分有标签data Unsupervised Learning 无标签data Transfer Learning 一堆不相干data Reinforcement Learning 只有来自外界的评价 task，意思是现在function的output是什么，只体现在supervised中，但其实可以插在以上五种Learning的每一种内。 machine learning task(output) Regression scalar Classification class1、class2…之一 Structured Learning 有结构的内容 Method方法模型，比如在Classification中有Linear模型 or Non-linear模型，我们可以将绿色部分插入任何红色部分中。","categories":[{"name":"听课笔记","slug":"听课笔记","permalink":"https://github.com/zdkswd/categories/听课笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://github.com/zdkswd/tags/机器学习/"},{"name":"李宏毅","slug":"李宏毅","permalink":"https://github.com/zdkswd/tags/李宏毅/"}]},{"title":"[Linux内核设计与实现]进程管理","slug":"【Linux内核】进程管理","date":"2018-04-16T10:50:51.000Z","updated":"2018-07-26T09:22:24.000Z","comments":true,"path":"2018/04/16/【Linux内核】进程管理/","link":"","permalink":"https://github.com/zdkswd/2018/04/16/【Linux内核】进程管理/","excerpt":"","text":"进程内核调度的对象是线程，而不是进程。Linux系统的线程实现非常特别：它对线程和进程并不特别区分。进程提供两种虚拟机制，虚拟处理器与虚拟内存。一个是进程独享处理器的假象一个是独享内存资源的假象。线程之间共享虚拟内存，各自有虚拟处理器。父进程调用fork()复制现有进程创建一个全新的进程子进程。 每个线程都有一个独立的程序计数器、进程栈和一组进程寄存器。内核调度的对象是线程，而不是进程。Linux系统的线程实现非常特别：它对线程和进程并不特别区分。进程提供两种虚拟机制，虚拟处理器与虚拟内存。一个是进程独享处理器的假象一个是独享内存资源的假象。线程之间共享虚拟内存，各自有虚拟处理器。进程的另一个名字是task，Linux内核通常把进程也叫做任务。 进程描述符及任务结构内核把进程的列表存放在任务列表（task list）的双向循环列表中。链表的每一项都是类型为task_struct称为进程描述符的结构中，该结构相对较大，包含的数据能够完整的描述一个正在运行的程序：打开的文件，进程地址空间，挂起信号，进程状态及其他。 分配进程描述符Linux通过slab分配器分配task_struct结构,这样能够对象复用和缓存着色。使用slab动态生成task_struct需要用到结构thread_info,其task域有指向实际进程描述符的指针。每个任务的thread_info在它的内核栈的尾端分配。 进程描述符的存放内核通过唯一标识符PID（process indentification value）来标识每个进程，PID存放在进程描述符。为了兼容性设置其为short int型，故其最大值为32768.但是对于大型服务器需要更大值。可以不考虑兼容性修改/proc/sys/kernel/pid_max提高上限。 内核访问任务需要获取指向task_struct的指针，故通过宏找到当前正在运行的进程描述符的速度就尤为重要。硬件的结构体系不同，宏的实现不同。例如有的体系结构有专用寄存器用于加快访问task_struct的速度，x86结构寄存器并不富余，就只能通过计算偏移间接查找task_struct。 进程状态task_struct的state域描述当前状态，必为五中之一 TASK_RUNNING(运行)在运行或在运行队列等待 TASK_INTERRUPIBLE(可中断)被阻塞 TASK_UNINTERRUPTIBLE（不可中断）接到信号也不会唤醒 _TASK_TRACED被其他进程跟踪 _TASK_STOPPED停止执行 设置当前的进程状态调整某个进程状态 set_task_state(task,state); 进程上下文可执行代码是进程的重要组成部分。这些代码从一个可执行文件载入到进程的地址空间执行，一般在用户空间执行，执行系统调用或触发异常陷入内核空间。对内核的访问必须经过明确定义的接口。 进程家族树Linux和Unix一样所有的进程都是PID为1的init进程的后代。内核在系统启动的最后阶段启动init进程读取系统初始化脚本（initscript）并执行其他相关程序最终完成系统启动整个过程。init进程的进程描述符是作为init_task静态分配的。对于当前task_struct，可以通过task_struct类型parent指针访问其父进程（必有一个），还包含一个children的子进程链表。 进程创建许多其他操作系统：首先在新的地址空间创建进程，读入可执行文件，最后开始执行。Unix：首先通过fork（）拷贝当前进程创建一个子进程，父子进程区别仅限于PID，PPID（子进程将其设为父进程PID值）和某些资源统计量。exec（）负责读取可执行文件并将其载入地址空间运行。如果 exec 调用成功,调用进程将被覆盖,然后从新程序的入口开始执行。这样就产生了一个新的进程,但是它的进程标识符与调用进程相同。这就是说,exec 没有建立一个与调用进程并发的新进程,而是用新进程取代了原来的进程。 写时拷贝Linux的fork（）采用写时拷贝，只有子进程在父进程进行写入时再进行拷贝，其他的时候是只读共享。所以fork（）的实际开销就是复制父进程页表以及创建PID。 fork（）Linux通过clone（）系统调用实现fork（）fork（）-调用-&gt;clone()-调用-&gt;do_fork()（完成创建的大部分工作）-调用-&gt;copy_process()copy_process工作: 调用dup_task_strucr()为新进程创建一个内核栈、thread_info和task_struct，此时，父子进程描述符完全一样。 检查并确保新创建这个进程后进程数目没有超出资源限制。 子进程着手于区别父进程。task_struct的许多成员被清零或设为初始值。 子进程的状态被设置为TASK_UNINTERRUPTIBLE，以保证它不会投入运行。 copy_process()调用copy_flags()以更新task_struct的flags成员。表明进程是否拥有超级用户权限的PF_SUPERRIV标志被清0，表示进程还没有调用exec()函数的PF_FORKNOEXEC标志被设置。 调用alloc_pid()为新进程分配一个分配一个有效的PID。 根据传递给clone()的参数标志，copy_process()拷贝或共享打开的文件、文件系统信息、信息处理函数、进程地址空间和命名空间等。一般，这些资源会所有线程共享，否则资源对每个进程是不同的，因此拷贝到这里。 最后，copy_process做扫尾工作并返回一个指向子进程的指针。 如果copy_process()成功返回do_fork()，新创进程被唤醒且内核有意让其首先执行。因为一般子进程都会马上调用exec()函数，可以避免父进程首先执行可能的写入造成的额外开销。 vfork（）除了不拷贝父进程的页表项以外，vfork()和fork()功能相同。基本没啥用。 线程在Linux中的实现Linux中，线程具有task_struct,它看起来就是普通进程，只是和其他一些进程共享某些资源，如地址空间。对Linux来说，线程只是进程间共享资源的手段。 创建线程线程创建于进程类似，只是在调用clone时需要传递一些参数标明需要共享的资源。创建Linux进程所花时间和其他操作系统创建线程要少。 内核线程独立运行在内核空间的标准进程，和普通进程区别在于没有独立地址空间。只在内核空间运行，和普通进程一样，可以被调度，也可以被强占。新的任务是由kthread内核进程通过clone()系统调用而创建的。内核线程启动后就一直运行到调用do_exit（）退出或其他部分调用kthread_stop()退出。 进程终结终结时，释放资源并告诉父进程。可以调用exit()主动终结,也可以异常被动终结,但大部分靠do_exit()来完成do_exit(): 将task_struct标志设为PF_EXITING 调用del_time_sync()删除任一内核定时器。根据返回的结果，它确保没有定时器在排队也没有定时器处理程序在运行。 如果BSD的记账功能是开启的，do_exit()调acct_update_integrals()来输入记账信息。 调用exit_mm()函数释放进程占用的mm_struct，如果没有别的进程使用它们（也就是说，这个进程空间没有被共享），就彻底释放它们。 调用sem_exit()函数，如果进程排队等候IPC信号，它则离开队列。 调用exit_files()和exit_fs()，以分别递减文件描述符、文件系统数据的引用计数。如果其中某个引用计数的数值降为0，那么久代表没有进程在使用相应的资源可以释放。 接着把存放在task_struct和exit_code成员中的任务退出代码置为由exit（）提供的退出代码，或者去完成任何其他由内核机制规定的退出动作，退出代码存放在这里供父进程随时检索。 调用exit_notufy()向父进程发送信号，给子进程重新找养父，养父为线程组中的其他线程或为init进程，并把进程状态（存放在task_struct中的exit_state中）设成EXIT_ZOMBIE。 do_exit()调用schedule（）切换到新的进程。因为处于EXIT_ZOMBIE状态的进程不会再被调度，所以这是进程执行的最后一段代码。do_exit()永不返回。 至此进程仅剩的内存就是内核栈，Thread_info 和task_struct结构。此时进程存在的唯一目的数向它的父进程提供信息。父进程检索到信息后，或者通知内核那是无关信息后，内存释放。 删除进程描述符进程终结时的清理工作和进程描述符的删除被分开进行，这样做可以让系统有办法在子进程终结后仍能获得它的信息。过程如上段。 孤儿进程造成的进退维谷如果父进程在子进程之前退出，必须有机制来保证子进程能够找到一个新的父亲。解决方法是给子进程在当前线程组内找一个线程做父亲，如果不行，就让init做父进程。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"纸质书笔记","slug":"纸质书笔记","permalink":"https://github.com/zdkswd/tags/纸质书笔记/"},{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"[LINUX内核设计与实现]第二章","slug":"从内核出发","date":"2018-04-13T12:36:32.000Z","updated":"2018-05-16T10:02:54.000Z","comments":true,"path":"2018/04/13/从内核出发/","link":"","permalink":"https://github.com/zdkswd/2018/04/13/从内核出发/","excerpt":"","text":"从内核出发内核源码树内核源码树根目录描述 目录 描述 arch 特定体系结构的源码 block 块设备IO层 crypto 加密API Documentation 内核源码文档 drivers 设备驱动程序 firmware 使用某些驱动程序而需要的设备固件 fs VFS和各种文件系统 include 内核头文件 init 内核引导和初始化 ipc 进程间通信代码 kernel 像调度程序这样的核心子系统 lib 通用内核函数 mm 内存管理子系统和VM net 网络子系统 samples 实例，示范代码 scripts 编译内核所用的脚本 security Linux安全模块 sound 语音子系统 usr 早期用户空间代码（所谓的initramfs） tools 在Linux开发中有用的工具 virt 虚拟化基础结构 在源码根目录还有很多文件值得提及。COPYING文件是内核许可证（GNU GPL v2）。CREDITS是开发了很多内核代码的开发者列表。MAINTAINERS是维护者列表，负责维护内核子系统和驱动程序。Makefile是基本内核的Makefile。 编译内核配置内核在编译前可以把自己的需要的特定功能和驱动程序编译进内核，首先必须先配置，其以CONFIG_FEATURE形式表示。配置选项要么是二选一（yes/no）要么是三选一（yes/no/module）module表示这部分功能的实现代码是以模块的形式生成。驱动程序一般都是三选一选项。配置选项也可以是字符串或整数。这些选项并不控制编译过程，而只是指定内核源码可以访问的值，一般以预处理宏的形式表示。 $ make config 该工具会遍历所有配置项，但耗时过长 $make menuconfig$make gconfig 可破之。以上三种工具将所有配置分门别类的放置。 $make defconfig 创建默认配置。这些配置项被存放在根目录的.config文件中。在进行修改后，你应当验证和更新配置： $ make oldconfig 配置选项CONFIG_IKCONFIG_PROC把完整的压缩内核配置文件放在/proc/config.gz下，在编译新内核时可以克隆配置。 $zcat /proc/config.gz &gt; .config$make oldconfig 衍生多个编译作业make程序能把编译过程拆分成多个并行的作业。极大加快编译的过程。 $make -jn 安装新内核 %make modules_install 内核开发的特点 内核编程时既不能访问c库也不能访问标准c头文件。 内核编程时必须使用GNU C 内核编程时缺乏像用户空间那样的内存保护机制。 内核编程时难以执行浮点运算。 内核给每个进程只有一个很小的定长堆栈。 由于内核支持异步中断、抢占和SMP，因此必须时刻注意同步和并发。 要考虑可移植性的重要性。 无libc库或无标准头文件因为对内核来说，C库太大太低效了。但是大部分常用的C库函数在内核中都已经得到了实现。内核头文件位于根目录include目录下。&lt; linux/inotify.h&gt;对应内核include/linux/inotify.h体系结构相关的头文件位于源码树arch/&lt; architecture&gt;/include/asm目录下。内核代码通过如&lt; asm/youwant.h&gt;包含。 printk(“Hello world’%s’and ‘%d’”,str,i); 例如内核代码无法调用printf,但它提供printk()。其允许通过一个标志来设置优先级。 GNU Cgcc是多种GNU编译器的集合，它包含的C编译器既可以编译内核，也可以编译Linux系统上用C语言写的其他代码。 内联函数，用于时间要求高，本身长度短的函数。 定义内联函数时需要static 作为关键字，并且用inline限定它。为了类型安全和易读性，优先使用内联函数而不是复杂的宏。 内联汇编，gcc支持C函数嵌入汇编指令，需要知道其体系结构。使用asm()指令嵌入汇编代码。Linux内核混用了C语言和汇编语言。在偏近体系结构底层或对执行时间要求严格的地方，一般使用汇编语言，其他大部分代码是用C语言编写的。 分支声明，对于条件选择语句，gcc内建了优化指令，并封装成了宏。likely()和unlikely()，你的判断正确，性能会得到提升，如果判断错误，性能反而会下降。 没有内存保护机制在内核中不应该去做访问非法的内存地址，引用空指针一类的事，否则可能一声不响的死掉。内核的内存不分页。 不要轻易在内核中使用浮点数内核并不能完美地支持浮点操作，因为它本身不能陷入。在内核使用浮点数时，除了要人工保存和恢复浮点寄存器，还有一些其他的事情要处理。所以不要在内核中使用浮点操作。 容积小而固定的栈同步和并发可移植性的重要性大部分C代码应该与体系结构无关，在不同体系结构的计算机上都能够编译和执行。如保持字节序、64位对齐、不假定字长和页面长度等一系列准则都有助于移植性。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"纸质书笔记","slug":"纸质书笔记","permalink":"https://github.com/zdkswd/tags/纸质书笔记/"},{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"[LINUX内核设计与实现]第一章","slug":"LINUX内核设","date":"2018-04-13T11:45:41.000Z","updated":"2018-05-16T11:04:46.000Z","comments":true,"path":"2018/04/13/LINUX内核设/","link":"","permalink":"https://github.com/zdkswd/2018/04/13/LINUX内核设/","excerpt":"","text":"第一章主要是讲Linux的历史，而我的第一篇纸质书笔记主要是讲一下我的计划。纸质书做读书笔记的话，任务量会远远大于电子版的图书，所以我争取做到不引用原文，因为那样做任务量过于庞大，这就要求我必须以自己理解的方式概括，这样才能达到预期的效果。之后还会出的纸质书笔记预告：深入理解计算机系统 中英两版。深入理解安卓系统。所以说可以看出直到暑假的这一段时间，我的重点是放在c/c++以及操作系统上，之所以这样做是因为希望未来能够为Tensorflow等开源框架贡献自己的力量。希望大家可以共同学习，共同进步。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"纸质书笔记","slug":"纸质书笔记","permalink":"https://github.com/zdkswd/tags/纸质书笔记/"},{"name":"Linux","slug":"Linux","permalink":"https://github.com/zdkswd/tags/Linux/"}]},{"title":"[猴子都能懂的Git入门]高级篇","slug":"猴子都能懂的Git入门-高级篇","date":"2018-04-08T03:09:55.000Z","updated":"2018-05-16T10:59:22.000Z","comments":true,"path":"2018/04/08/猴子都能懂的Git入门-高级篇/","link":"","permalink":"https://github.com/zdkswd/2018/04/08/猴子都能懂的Git入门-高级篇/","excerpt":"","text":"分支什么是分支分支是为了将修改记录的整体流程分叉保存。分叉后的分支不受其他分支的影响，所以在同一个数据库里可以同时进行多个修改。 master分支在数据库进行最初的提交后, Git会创建一个名为master的分支。因此之后的提交，在切换分支之前都会添加到master分支里。 分支的运用merge分支Merge分支是为了可以随时发布release而创建的分支，它还能作为Topic分支的源分支使用。保持分支稳定的状态是很重要的。如果要进行更改，通常先创建Topic分支，而针对该分支，可以使用Jenkins之类的CI工具进行自动化编译以及测试。 通常，大家会将master分支当作Merge分支使用。 Topic分支Topic分支是为了开发新功能或修复Bug等任务而建立的分支。若要同时进行多个的任务，请创建多个的Topic分支。 Topic分支是从稳定的Merge分支创建的。完成作业后，要把Topic分支合并回Merge分支。 分支的切换若要切换作业的分支，就要进行checkout操作。进行checkout时，git会从工作树还原向目标分支提交的修改内容。checkout之后的提交记录将被追加到目标分支 HEADHEAD指向的是现在使用中的分支的最后一次更新。通常默认指向master分支的最后一次更新。通过移动HEAD，就可以变更使用的分支。NOTE:提交时使用~(tilde)和^(caret)就可以指定某个提交的相对位置。最常用的就是相对于HEAD的位置。HEAD后面加上~(tilde）可以指定HEAD之前的提交记录。合并分支会有多个根节点，您可以用^(caret) 来指定使用哪个为根节点。 stashstash是临时保存文件修改内容的区域。stash可以暂时保存工作树和索引里还没提交的修改内容，您可以事后再取出暂存的修改，应用到原先的分支或其他的分支上。 分支的合并合并分支有2种方法：使用merge或rebase。使用这2种方法，合并后分支的历史记录会有很大的差别。 merge合并 bugfix分支到master分支时，如果master分支的状态没有被更改过,把master分支的位置移动到bugfix的最新分支上，Git 就会合并。这样的合并被称为fast-forward（快进）合并。HEAD还在原位。master分支的历史记录有可能在bugfix分支分叉出去后有新的更新。这种情况下，要把master分支的修改内容和bugfix分支的修改内容汇合起来。合并两个修改会生成一个提交。这时，master分支的HEAD会移动到该提交上。NOTE:执行合并时，如果设定了non fast-forward选项，即使在能够fast-forward合并的情况下也会生成新的提交并合并。 一个圆圈代表一个提交 rebasetopic分支和merge分支的运用实例分支操作示例建立分支 $ git branch &lt; branchname&gt; 不指定参数直接执行branch命令的话，可以显示分支列表。 前面有*的就是现在的分支。 $ git branch issue1 *master 切换分支执行checkout命令以退出分支。 $ git checkout &lt; branch&gt; NOTE:在checkout命令指定 -b选项执行，可以创建分支并进行切换。 $ git checkout -b &lt; branch&gt; 合并分支执行merge命令以合并分支。 $ git merge &lt; commit&gt; 该命令将指定分支导入到HEAD指定的分支。如当HEAD指向issue1时，先切换到master分支，然后把issue1分支导入到master分支。 $ git checkout master$ git merge issue1 删除分支在branch命令指定-d选项执行，以删除分支。 $ git branch -d &lt; branchname&gt; 用rebase合并切换到issue3分支后，对master执行rebase。 $ git checkout issue3$ git rebase master rebase的时候，修改冲突后的提交不是使用commit命令，而是执行rebase命令指定 –continue选项。若要取消rebase，指定 –abort选项。 $ git add myfile.txt$ git rebase –continue 这样，在master分支的issue3分支就可以fast-forward合并了。切换到master分支后执行合并.看来rebase是将issue3分支消失而生成一个新的提交，就像fast-forward的情形一样。切换到master分支后执行合并。 $ git checkout master$ git merge issue3 上图为rebase图 上图为merge图 Merge和rebase都是合并历史记录，但是各自的特征不同。 merge保持修改内容的历史记录，但是历史记录会很复杂。rebase历史记录简单，是在原有提交的基础上将差异内容反映进去。因此，可能导致原本的提交内容无法正常运行。您可以根据开发团队的需要分别使用merge和rebase。例如，想简化历史记录，在topic分支中更新merge分支的最新代码，请使用rebase。向merge分支导入topic分支的话，先使用rebase，再使用merge。 远端数据库pull首先确认更新的本地数据库分支没有任何的更改。这时只执行fast-forward合并。如果本地数据库的分支有新的历史记录，就需要合并双方的修改。执行pull就可以进行合并。这时，如果没有冲突的修改，就会自动创建合并提交。如果发生冲突的话，要先解决冲突，再手动提交。 fetch执行pull，远程数据库的内容就会自动合并。但是，有时只是想确认本地数据库的内容而不想合并。这种情况下，请使用fetch。执行fetch就可以取得远程数据库的最新历史记录。取得的提交会导入到没有名字的分支，这个分支可以从名为FETCH_HEAD的退出。就相当于在本地数据库建立了一个和远程数据库一样的分支，还没合并。合并后，历史记录会和pull相同。实际上pull的内容是fetch + merge组成的。 push从本地数据库push到远程数据库时，要fast-forward合并push的分支。如果发生冲突，push会被拒绝的。若要共享在本地数据库创建的分支，需要明确的push。因此，没有执行push就不会给远程数据库带来影响，因而可以自由的创建自己的分支。基本上，远程数据库共享的提交是不能修改的。如果修改的话，跟远程数据库同步的其他数据库的历史记录会变得很奇怪的。 标签标签是为了更方便地参考提交而给它标上易懂的名称。Git可以使用2种标签：轻标签和注解标签。打上的标签是固定的，不能像分支那样可以移动位置。轻标签：添加名称注解标签：添加名称 添加注解 添加签名一般情况下，发布标签是采用注解标签来添加注解或签名的。轻标签是为了在本地暂时使用或一次性使用。 使用标签 使用tag命令来添加标签，在&lt; tagname&gt;执行标签的名称。 $ git tag &lt; tagname&gt; 在HEAD指向的提交里添加名为apple的标签，请执行以下的命令。 $ git tag apple 如果没有使用参数而执行tag，可以显示标签列表。 $ git tag 如果在log命令添加 –decorate选项执行，可以显示包含标签资料的历史记录。 $ git log –decorate 添加注解标签若要添加注解标签，可以在tag命令指定 -a选项执行,以指定-m选项来添加注解。 $ git tag -a &lt; tagname&gt; $ git tag -am “连猴子都懂的Git” banana 如果在tag命令指定-n选项执行，可以显示标签的列表和注解。 $ git tag -n 删除标签若要删除标签，在tag命令指定 -d选项执行。 $ git tag -d &lt; tagname&gt; 改写提交修改最近的提交指定amend选项执行提交的话，可以修改同一个分支最近的提交内容和注解。 主要使用的场合：添加最近提交时漏掉的档案修改最近提交的注解 取消过去的提交在revert可以取消指定的提交内容。使用后面要提到的rebase -i或reset也可以删除提交。但是，不能随便删除已经发布的提交，这时需要通过revert创建要否定的提交。 主要使用的场合：安全地取消过去发布的提交 遗弃提交在reset可以遗弃不再使用的提交。执行遗弃时，需要根据影响的范围而指定不同的模式，可以指定是否复原索引或工作树的内容。除了默认的mixed模式，还有soft和hard模式。欲了解受各模式影响的部分，请参照下面的表格。 模式名称 HEAD的位置 索引 工作树 soft 修改 不修改 不修改 mixed 修改 修改 不修改 hard 修改 修改 修改 主要使用的场合： 复原修改过的索引的状态(mixed)彻底取消最近的提交(hard)只取消提交(soft) 提取提交在cherry-pick，您可以从其他分支复制指定的提交，然后导入到现在的分支。 主要使用的场合： 把弄错分支的提交移动到正确的地方把其他分支的提交添加到现在的分支 改写提交历史记录在rebase指定i选项，您可以改写、替换、删除或合并提交。 主要使用的场合： 在push之前，重新输入正确的提交注解清楚地汇合内容含义相同的提交。添加最近提交时漏掉的档案 汇合分支上的提交，然后一同合并到分支merge的特殊选项：squash用这个选项指定分支的合并，就可以把所有汇合的提交添加到分支上。 主要使用的场合： 汇合主题分支的提交，然后合并提交到目标分支。 改写提交训练commit –amend git commit –amend revert $ git revert HEAD 在git log中会出现–Revert “添加pull的说明” reset $ git reset –hard HEAD~~ 在git中，我们其实可以通过^和~来定位某个具体的commit，而不用每次都去敲繁琐的hash值。“^”代表父提交,当一个提交有多个父提交时，可以通过在”^”后面跟上一个数字，表示第几个父提交，”^”相当于”^1”.~&lt; n&gt;相当于连续的&lt; n&gt;个”^”.在reset之前的提交可以参照ORIG_HEAD。Reset错误的时候，在ORIG_HEAD上reset 就可以还原到reset前的状态。 $ git reset –hard ORIG_HEAD cherry-pick $ git checkout master$ git cherry-pick 99daed2 如果发生冲突，修改冲突的部分之后再提交。 用rebase -i 汇合提交若要汇合过去的提交，请用rebase -i。 $ git rebase -i HEAD~~ 两个提交就合并成一个提交了。 用rebase -i 修改提交merge –squash","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"Git","slug":"Git","permalink":"https://github.com/zdkswd/tags/Git/"}]},{"title":"[猴子都能懂的Git入门]入门篇","slug":"猴子都能懂的Git入门-入门篇","date":"2018-04-06T02:03:47.000Z","updated":"2018-05-16T10:59:40.000Z","comments":true,"path":"2018/04/06/猴子都能懂的Git入门-入门篇/","link":"","permalink":"https://github.com/zdkswd/2018/04/06/猴子都能懂的Git入门-入门篇/","excerpt":"","text":"前言不知道这是第几次学习Git了，每次都是学完过一段就忘了，这次决定自己写出点东西，深入的再把Git再过一遍。写一下自己的东西，真真正正的把Git转化为自己的东西。这次选用的资料是猴子都能懂的Git入门。之所以选用该资料是因为语言比较通俗易懂，而我也正好想把知识总结的通俗易懂一些，算是两重学习。那么话不多说，现在开始吧~~~(写到后面发现这书已经足够通俗，很难再。。。啊，失败。) Git的基础首先git是版本控制工具，用来解决大家对同一文件操作时的协作问题。Git可以在任何时间点，把文档的状态作为更新记录保存起来。因此可以把编辑过的文档复原到以前的状态，也可以显示编辑前后的内容差异。而且，编辑旧文件后，试图覆盖较新的文件的时候（即上传文件到服务器时），系统会发出警告，因此可以避免在无意中覆盖了他人的编辑内容。 管理历史数据的数据库数据库 (Repository) 是记录文件或目录状态的地方，存储着内容修改的历史记录。在数据库的管理下，把文件和目录修改的历史记录放在对应的目录下。 远程数据库和本地数据库。Git的数据库分为远程数据库和本地数据库的两种。 创建数据库创建本地数据库的方法有两种：一种是创建全新的数据库，另一种是复制远程数据库。 修改记录的提交若要把文件或目录的添加和变更保存到数据库，就需要进行提交。执行提交后，数据库中会生成上次提交的状态与当前状态的差异记录（也被称为revision）。Tips:不同类别的修改 (如：Bug修复和功能添加) 要尽量分开提交，以方便以后从历史记录里查找特定的修改内容。执行提交时，系统会要求输入提交信息。请务必输入提交信息，因为在空白的状态下执行提交会失败的。Tips:查看其他人提交的修改内容或自己的历史记录的时候，提交信息是需要用到的重要资料。所以请用心填写修改内容的提交信息，以方便别人理解。以下是Git的标准注解： 第1行：提交修改内容的摘要第2行：空行第3行以后：修改的理由 请以这种格式填写提交信息。 工作树和索引在Git管理下，大家实际操作的目录被称为工作树。 在数据库和工作树之间有索引，索引是为了向数据库提交作准备的区域。 Git在执行提交的时候，不是直接将工作树的状态保存到数据库，而是将设置在中间索引区域的状态保存到数据库。因此，要提交文件，首先需要把文件加入到索引区域中。 凭借中间的索引，可以避免工作树中不必要的文件提交，还可以将文件修改内容的一部分加入索引区域并提交。 教程1 Git基础Git安装略 初期设定安装Git之后，请输入您的用户名和电子邮件地址。该设置操作在安装Git后进行一次就够了。这些信息将作为提交者信息显示在更新历史中。 Git的设定被存放在用户本地目录的.gitconfig档案里。可以直接编辑配置文件。 $ git config –global user.name “&lt;用户名&gt;”$ git config –global user.email “&lt;电子邮件&gt;” $ git config –global color.ui auto //git彩色显示 可以为Git命令设定别名。例如：把「checkout」缩略为「co」，然后就使用「co」来执行命令。 $ git config –global alias.co checkout 如果在Windows使用命令行 (Git Bash), 含非ASCII字符的文件名会显示为 “\\346\\226\\260\\350\\246…”。若设定如下，就可以让含非ASCII字符的文件名正确显示了。 $ git config –global core.quotepath off 若在Windows使用命令行，您只能输入ASCII字符。所以，如果您的提交信息包含非ASCII字符，请不要使用-m选项，而要用外部编辑器输入。 外部编辑器必须能与字符编码UTF-8和换行码LF兼容。 git config –global core.editor “\\”[使用编辑区的路径]\\”” 新建数据库在目录下使用init命令将该目录移动到本地的Git数据库。 $ git init 提交文件对于一个文件，使用status命令确认工作树和索引的状态。 $ git status 将文件加入到索引，要使用add命令。在&lt; file&gt;指定加入索引的文件。用空格分割可以指定多个文件。 $ git add &lt; file&gt;..$ git add . //将所有的文件加入索引 已加入到索引，我们就可以提交文件了。 $ git commit -m “” 使用log命令，我们可以在数据库的提交记录看到新的提交。 $ git log commit ac56e474afbbe1eab9ebce5b3ab48ac4c73ad60eAuthor: eguchi &#x65;&#103;&#x75;&#x63;&#x68;&#105;&#64;&#110;&#117;&#x6c;&#x61;&#98;&#46;&#99;&#111;&#x2e;&#106;&#x70;Date: Thu Jul 12 18:00:21 2012 +0900first commit 安装git的同时会安装名为gitk的工具。使用这个工具，可以在GUI下确认提交记录。 $ gitk 共享数据库push到远端数据库注意：对于别人的项目你只能 pull 不能 push，只有你自己（或有权限）的项目才能 push。或者说只有你把 ssk key 添加到账号里才能无密码 push。如果你想参与别人的开源项目，先建立自己的 github 账号，然后 fork 那个项目到自己的账号里，然后在自己的项目里修改，然后发出 pull request，然后看对方愿不愿意接受你的提交。 作者：Intopass链接：https://www.zhihu.com/question/29894004/answer/45956664来源：知乎 推送为了将本地数据库的修改记录共享到远程数据库，必须上传本地数据库中存储的修改记录。所以远程数据库的修改记录就会和本地数据库的修改记录保持同步。 克隆远程数据库克隆执行克隆后，远程数据库的全部内容都会被下载。之后您在另一台机器的本地数据库上进行操作。克隆后的本地数据库的变更履历也会被复制，所以可以像原始的数据库一样进行查看记录或其他操作。 从远程服务器Pull若是共享的远程数据库由多人同时作业，那么作业完毕后所有人都要把修改推送到远程数据库。然后，自己的本地数据库也需要更新其他人推送的变更内容。 Pull进行拉取(Pull) 操作，就是从远程数据库下载最近的变更日志，并覆盖自己本地数据库的相关内容。 clone与pull的区别clone是本地没有repository时，将远程repository整个下载过来。 pull是本地有repository时，将远程repository里新的commit数据(如有的话)下载过来，并且与本地代码merge。 对远程服务器进行操作向远程数据库推送本地数据库的修改记录远程数据库命名为“origin”。 请使用remote指令添加远程数据库。在&lt; name&gt;处输入远程数据库名称，在&lt; url&gt;处指定远程数据库的URL。 $ git remote add &lt; name&gt; &lt; url&gt; TIPS:执行推送或者拉取的时候，如果省略了远程数据库的名称，则默认使用名为”origin“的远程数据库。因此一般都会把远程数据库命名为origin。 使用push命令向数据库推送更改内容。&lt; repository&gt;处输入目标地址，&lt; refspec&gt;处指定推送的分支。 $ git push &lt; repository&gt; &lt; refspec&gt;… 当执行命令时，如果您指定了-u选项，那么下一次推送时就可以省略分支名称了。但是，首次运行指令向空的远程数据库推送时，必须指定远程数据库名称和分支名称。 $ git push -u origin master 使用clone指令可以复制数据库，在&lt; repository&gt;指定远程数据库的URL，在&lt; directory&gt;指定新目录的名称。 $ git clone &lt; repository&gt; &lt; directory&gt;$ git clone https://nulab.backlog.jp/git/BLG/tutorial.git tutorial2 当在克隆的数据库目录执行推送时，您可以省略数据库和分支名称。 $ git push 使用pull指令进行拉取操作。省略数据库名称的话，会在名为origin的数据库进行pull。 $ git pull &lt; repository&gt; &lt; refspec&gt;…$ git pull origin master 合并修改记录合并在执行pull之后，进行下一次push之前，如果其他人进行了推送内容到远程数据库的话，那么你的push将被拒绝。这种情况下，在读取别人push的变更并进行合并操作之前，你的push都将被拒绝。这是因为，如果不进行合并就试图覆盖已有的变更记录的话，其他人push的变更（图中的提交C）就会丢失。 合并的时候，Git会自动合并已有的变更点！不过，也存在不能自动合并的情况。此时需要手动合并。 解决冲突如果远程数据库和本地数据库的同一个地方都发生了修改的情况下，因为无法自动判断要选用哪一个修改，所以就会发生冲突。Git会在发生冲突的地方修改文件的内容 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;这就是发生 》 =======冲突的地方 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; ==分割线上方是本地数据库的内容,下方是远程数据库的编辑内容。需要手动的修改。 整合修改记录操作为了把变更内容推送到远程数据库，我们必须手动解决冲突。 $ git pull origin master 导入两方的修改，并删除多余的标示行以解决冲突 Github多人协作的三种方式 Fork 方式pull request是一个request，它的目的是让别人pull你的东西。 组织组织的所有者可以针对不同的代码仓库建立不同访问权限的团队。 合作者代码仓库的所有者可以为单个仓库增加具备只读或者读写权限的协作者。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://github.com/zdkswd/categories/读书笔记/"}],"tags":[{"name":"电子书笔记","slug":"电子书笔记","permalink":"https://github.com/zdkswd/tags/电子书笔记/"},{"name":"Git","slug":"Git","permalink":"https://github.com/zdkswd/tags/Git/"}]},{"title":"新增评论区功能","slug":"新增评论区功能","date":"2018-04-05T09:49:48.000Z","updated":"2018-05-16T11:02:14.000Z","comments":true,"path":"2018/04/05/新增评论区功能/","link":"","permalink":"https://github.com/zdkswd/2018/04/05/新增评论区功能/","excerpt":"","text":"今天算是折腾了一下评论区，不得不佩服评论区作者的脑洞。运用github issues的机制来自己创建评论区，运用插件—传送门。 在此过程中也算踩了一些坑，特别感谢有人能无私分享自己的踩坑经历–踩坑教程 我自己也顺便试着改了下模板的源码，感觉有、收获。 分享出去，如果可以帮助到更多的人，那将将是更大的快乐。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"个人博客","slug":"个人博客","permalink":"https://github.com/zdkswd/tags/个人博客/"},{"name":"Gitment","slug":"Gitment","permalink":"https://github.com/zdkswd/tags/Gitment/"}]},{"title":"Hexo+ github Pages建立个人博客","slug":"Hexo+github-Pages建立个人博客","date":"2018-04-04T09:30:56.000Z","updated":"2018-05-16T11:03:32.000Z","comments":true,"path":"2018/04/04/Hexo+github-Pages建立个人博客/","link":"","permalink":"https://github.com/zdkswd/2018/04/04/Hexo+github-Pages建立个人博客/","excerpt":"","text":"折腾了一段时间，还算顺利的把博客给建立好了，以下是参考链接建立过程这个过程大体上是没有问题的，但是我碰到几个小小的问题，大家也可以参考一下 当打开配置文件时，文中说的是用记事本打开，但是我用记事本打开文本完全没有格式，再用写字板打开时，豁然开朗。 再一个就是当上传以后访问自己的首页时,输入https://zdkswd.github.io 死活打不开，我又检查了好几遍，后来直接输入zdkswd.github.io就成功进去了，之后再输入https://zdkswd.github.io 又可以愉快的访问了，感觉特别神奇，也感觉很费解。 第一篇博客就先到这里吧，这一段时间我会上传一些读书笔记，毕竟砖头书不好啃，这既是分享，又是进一步的学习，也是对我自己的一种激励。希望这个博客真正能起到学习，练习，积累，分享的作用。","categories":[{"name":"知识总结","slug":"知识总结","permalink":"https://github.com/zdkswd/categories/知识总结/"}],"tags":[{"name":"个人博客","slug":"个人博客","permalink":"https://github.com/zdkswd/tags/个人博客/"},{"name":"Hexo","slug":"Hexo","permalink":"https://github.com/zdkswd/tags/Hexo/"}]}]}