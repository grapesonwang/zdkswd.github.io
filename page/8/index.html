<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0"/>

<link rel="stylesheet" href="/css/main.css?v=7.2.0"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.2.0',
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>



  <meta property="og:type" content="website">
<meta property="og:title" content="ZDK&#39;s blog">
<meta property="og:url" content="https://github.com/zdkswd/page/8/index.html">
<meta property="og:site_name" content="ZDK&#39;s blog">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ZDK&#39;s blog">



  <link rel="alternate" href="/atom.xml" title="ZDK's blog" type="application/atom+xml"/>



  
  
  <link rel="canonical" href="https://github.com/zdkswd/page/8/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>ZDK's blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZDK's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br/>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/zdkswd/2019/03/20/百面  模型评估/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZDK"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZDK's blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/20/百面  模型评估/" class="post-title-link" itemprop="url">百面 模型评估</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-20 13:57:47" itemprop="dateCreated datePublished" datetime="2019-03-20T13:57:47+08:00">2019-03-20</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-04-23 12:23:52" itemprop="dateModified" datetime="2019-04-23T12:23:52+08:00">2019-04-23</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/知识总结/" itemprop="url" rel="index"><span itemprop="name">知识总结</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/03/20/百面  模型评估/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/20/百面  模型评估/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/03/20/百面  模型评估/" class="post-meta-item leancloud_visitors" data-flag-title="百面 模型评估">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="百面-模型评估"><a href="#百面-模型评估" class="headerlink" title="百面  模型评估"></a>百面  模型评估</h1><p>模型评估主要分为离线评估和在线评估两个阶段。针对分类、排序、回归、序列预测等不同类型的机器学习问题，评估指标的选择也有所不同。知道每种评估指标的精确定义、有针对性地选择合适的评估指标、根据评估指标的反馈进行模型调整，这些都是机器学习在模型评估阶段的关键问题，也是一名合格的算法工程师应当具备的基本功。</p>
<h1 id="评估指标的局限性"><a href="#评估指标的局限性" class="headerlink" title="评估指标的局限性"></a>评估指标的局限性</h1><p>在模型评估过程中，分类问题、排序问题、回归问题往往需要使用不同的指标进行评估。在诸多的评估指标中，大部分指标只能片面地反映模型的一部分性能。如果不能合理地运用评估指标，不仅不能发现模型本身的问题，而且会得出错误的结论。</p>
<h2 id="问题1-准确率-Accuracy-的局限性"><a href="#问题1-准确率-Accuracy-的局限性" class="headerlink" title="问题1  准确率(Accuracy)的局限性"></a>问题1  准确率(Accuracy)的局限性</h2><p>问：Hulu的奢侈品广告主们希望把广告定向投放给奢侈品用户。Hulu通过第三方的数据管理平台(Data Management Platform, DMP)拿到了一部分奢侈品用户的数据，并以此为训练集和测试集，训练和测试奢侈品用户的分类模型。该模型的分类准确率超过了95%，但在实际广告投放过程中，该模型还是把大部分广告投给了非奢侈品用户，这可能是什么原因造成的?</p>
<p>答：准确率是指分类正确的样本占总样本个数的比例，即<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/page40image4976.jpg" alt=""><br>其中n_corrrct为被正确分类的样本个数，n_total为总样本的个数。</p>
<p>准确率是分类问题中最简单也是最直观的评价指标，但存在明显的缺陷。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。所以，<strong>当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。</strong></p>
<p>明确了这一点，这个问题也就迎刃而解了。显然，奢侈品用户只占Hulu全体用户的一小部分，虽然模型的整体分类准确率高，但是不代表对奢侈品用户的分类准确率也很高。在线上投放过程中，我们只会对模型判定的“奢侈品用户”进行投放，因此，对“奢侈品用户”判定的准确率不够高的问题就被放大了。为了解决这个问题，可以使用更为有效的平均准确率(每个类别下的样本准确率的算术平均)作为模型评估的指标。</p>
<h2 id="问题2-精确率-Precision-与召回率的权衡"><a href="#问题2-精确率-Precision-与召回率的权衡" class="headerlink" title="问题2  精确率(Precision)与召回率的权衡"></a>问题2  精确率(Precision)与召回率的权衡</h2><p>问题描述：Hulu提供视频的模糊搜索功能，搜索排序模型返回的Top5的精确率非常高,但在实际使用过程中，用户还是经常找不到想要的视频，特别是一些比较冷门的剧集，这可能是哪个环节出了问题呢?</p>
<p>答：<strong>精确率</strong>是指<strong>分类正确的正样本个数占分类器判定为正样本的样本</strong>个数的比例。描述返回值的质量。<strong>召回率</strong>是指<strong>分类正确的正样本个数占真正的正样本</strong>个数的比例。</p>
<p>在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top N返回结果的Precision值和Recall值来衡量排序模型的性能，即认为模型返回的Top N的结果就是模型判定的正样本，然后计算前N个位置上的准确率Precision@N和前N个位置上的召回率Recall@N。</p>
<p>Precision值和Recall值是既矛盾又统一的两个指标，为了提高<strong>Precision</strong>值，分类器需要尽量在“<strong>更有把握</strong>”时才把样本预测为正样本,但此时往往会因为过于保守而漏掉很多“没有把握”的正样本，导致<strong>Recall</strong>值降低。</p>
<p>模型返回的Precision@5的结果非常好，也就是说排序模型Top 5的返回值的质量是很高的。但在实际应用过程中，用户为了找一些冷门的视频,往往会寻找排在较靠后位置的结果，甚至翻页去查找目标视频。但根据题目描述，用户经常找不到想要的视频，这说明模型没有把相关的视频都找出来呈现给用户。显然，问题出在<strong>召回率</strong>上。如果相关结果有100个，即使Precision@5达到了100%，Recall@5也仅仅是5%。在模型评估时，我们是否应该同时关注Precision值和Recall值。进一步而言， 应该选取不同的Top N的结果进行观察，应该选取更高阶的评估指标来更全面地反映模型在Precision值和Recall值两方面的表现。最好绘制出模型的PR曲线。</p>
<p><strong>P-R曲线</strong>的横轴是召回率，纵轴是精确率。对于一个排序模型来说，其P-R曲线上的一个点代表着，在某一阈值下，模型将大于该阈值的结果判定为正样本，小于该阈值的结果判定为负样本，此时返回结果对应的召回率和精确率。整条P-R.曲线是通过将阈值从高到低移动而生成的。图P-R曲线样例图中，其中实线代表模型A的P-R曲线，虚线代表模型B的P-R曲线。原点附近代表当阈值最大时模型的精确率和召回率。<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-19%20%E4%B8%8B%E5%8D%887.32.06.png" alt=""><br>由图可见，当召回率接近于0时，模型A的精确率为0.9，模型B的精确率是1,这说明模型B得分前几位的样本全部是真正的正样本，而模型A即使得分最高的几个样本也存在预测错误的情况。并且，随着召回率的增加，精确率整体呈下降趋势。但是，当召回率为1时，模型A的精确率反而超过了模型B。这充分说明，<strong>只用某个点对应的精确率和召回率是不能全面地衡量模型的性能，只有通过PR曲线的整体表现，才能够对模型进行更为全面的评估。</strong></p>
<p>F1 score能综合反映一个排序模型的性能。F1 score是精确率和召回率的调和平均值，定义为：<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/page43image400.jpg" alt=""><br>F1分数可以看作是模型准确率和召回率的一种加权平均，它的最大值是1，最小值是0。</p>
<p>更一般的，我们定Fβ分数为<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/c2cec3fdfc039245afef86848594a4c27c1e25e6.png" alt=""></p>
<p>Fβ的物理意义就是将准确率和召回率这两个分值合并为一个分值，在合并的过程中，召回率的权重是准确率的β倍。F1分数认为召回率和准确率同等重要，F2分数认为召回率的重要程度是准确率的2倍，而F0.5分数认为召回率的重要程度是准确率的一半。</p>
<h2 id="问题3-平方根误差的“意外”"><a href="#问题3-平方根误差的“意外”" class="headerlink" title="问题3   平方根误差的“意外”"></a>问题3   平方根误差的“意外”</h2><p>问题描述：Hulu作为一家流媒体公司，拥有众多的美剧资源，预测每部美剧的流量趋势对于广告投放、用户增长都非常重要。我们希望构建一个回归模型来预测某部美剧的流量趋势，但无论采用哪种回归模型，得到的RMSE指标都非常高。然而事实是，模型在95%的时间区间内的预测误差都小于1%，取得了相当不错的预测结果。那么，造成RMSE指标居高不下的最可能的原因是什么?</p>
<p>答：RMSE经常被用来衡量回归模型的好坏，但根据题目的叙述，RMSE这个指标却失效了。RMSE的计算公式如下：<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/page43image6176.jpg" alt=""><br>其中，yi是第i个样本点的真实值，y帽i是第i个样本点的预测值，n是样本点的个数。</p>
<p>一般情况下，RMSE能够很好地反映回归模型预测值与真实值的偏离程度。但在实际问题中，如果存在个别偏离程度非常大的离群点(Outlier) 时，即使离群点数量非常少，也会让RMSE指标变得很差。 </p>
<p>回到问题中来，模型在95%的时间区间内的预测误差都小于1%，这说明，在大部分时间区间内，模型的预测效果都是非常优秀的。然而，RMSE却一直很差，这很可能是由于在其他的5%时间区间内存在非常严重的离群点。事实上，在流量预估这个问题中，噪声点确实是很容易产生的，比如流量特别小的美剧、刚上映的美剧或者刚获奖的美剧，甚至一-些相关社交媒体突发事件带来的流量，都可能会造成离群点。</p>
<p>针对该问题可以有三种不同的解决方案。1，如果认定这些离群点是噪声点的话，就需要在数据预处理的阶段把这些噪声点过滤掉。第二，如果不认为这些离群点是噪声点的话，就需要进一步提高模型的预测能力，将离散点产生的机制建模进去。第三，可以找一个更合适的指标来评估该模型。关于评估指标，其实是存在比RMSE的鲁棒性更好的指标，比如平均绝对百分比误差，MAPE，定义为：<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/page44image3632.jpg" alt=""><br>相比RMSE, MAPE相当于把每个点的误差进行了归一化，降低了个别离群点带来的绝对误差的影响。</p>
<h1 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h1><p>二值分类器( Binary Classifier)是机器学习领域中最常见也是应用最广泛的分类器。评价二值分类器的指标很多,比如 precision、 recall F1 score、PR曲线等。上一小节已对这些指标做了一定的介绍,但也发现这些指标或多或少只能反映模型在某一方面的性能。相比而言,ROC曲线则有很多优点,经常作为评估二值分类器最重要的指标之一。</p>
<h2 id="问题1-什么是ROC曲线？"><a href="#问题1-什么是ROC曲线？" class="headerlink" title="问题1  什么是ROC曲线？"></a>问题1  什么是ROC曲线？</h2><p>ROC曲线的横坐标为假阳性率(False Positive Rate，FPR) ;纵坐标为真阳性率, (True Positive Rate, TPR)。FPR和TPR的计算方法分别为<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/page45image4736.jpg" alt=""><br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/page45image6248.jpg" alt=""><br>上式中，P是真实的正样本的数量，N是真实的负样本的数量，TP是P个正样本中被分类器预测为正样本的个数，FP是N个负样本中被分类器预测为正样本的个数。<strong>发现TPR与Recall是相等的。</strong>FPR即为误诊率，公式为<br>（N被认为P） / N。</p>
<p>举个例子，假设有10位疑似癌症患者，其中有3位很不幸确实患了癌症(P=3)，另外7位不是癌症患者(N=7) 。医院对这10位疑似患者做了诊断，诊断出3位癌症患者，其中有2位确实是真正的患者(TP=2) 。那么真阳性率TPR=TP \ P=2\ 3。对于7位非癌症患者来说，有一位很不幸被误诊为癌症患者(FP= 1)，那么假阳性率FPR=FP \ N=1\ 7。对于“该医院”这个分类器来说，这组分类结果就对应ROC曲线上的一个点(1\7, 2\3)。</p>
<h2 id="问题2-如何绘制ROC曲线？"><a href="#问题2-如何绘制ROC曲线？" class="headerlink" title="问题2 如何绘制ROC曲线？"></a>问题2 如何绘制ROC曲线？</h2><p>事实上，ROC曲线是通过不断移动分类器的“截断点”来生成曲线上的一组关键点的。</p>
<p>在二值分类问题中，模型的输出一般都是预测样本为正例的概率，所以下表中的概率值都为<strong>正值的概率</strong>，在输出最终的正例，负例之前，我们需要指定一个<strong>阈值</strong>，预测概率大于该阈值的样本会被判为正例，小于该阈值的样本则会被判为负例。<strong>截断点</strong>指的是区分<strong>正负预测结果的阈值</strong>。下图是模型的输出结果,样本按照预测概率从高到低排序。<br><img src="/img/add/32.png" alt=""> </p>
<p>通过动态地调整截断点，从最高的得分开始(实际上是从正无穷开始，对应着ROC曲线的零点)，逐渐调整到最低得分，每一个截断点都会对应一个FPR和TPR，在ROC图上绘制出每个截断点对应的位置，再连接所有点就得到最终的ROC曲线。</p>
<p>例如下图的ROC曲线。<br>当截断点选择为正无穷时，模型把全部样本预测为负例，那么FP和TP必然都为0，FPR和TPR也都为0，因此曲线的第一个点的坐标就是(0,0)。当把截断点调整为0.9时，模型预测1号样本为正样本，并且该样本确实是正样本，因此，TP=1, 20个样本中，所有正例数量为P=10,故TPR=TP/ P=1/ 10;这里没有预测错的正样本，即FP=0, 负样本总数N=10,故FPR=FP /N=0 /10=0,对应ROC曲线上的点(0,0.1) 。依次调整截断点，直到画出全部的关键点，再连接关键点即得到最终的ROC曲线。<strong>不是说以假阳性率为自变量以真阳性率为因变量哦</strong>。<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-20%20%E4%B8%8A%E5%8D%8810.09.37.png" alt=""></p>
<p>还有一种更直观地绘制ROC曲线的方法。首先根据样本标签统计出正负样本的数量，假设正样本数量为P，负样本数量为N。接下来把横轴刻度间隔设置为1 / N,纵轴的刻度间隔设置为1 / P。再根据模型输出的预测概率对样本进行排序（从高到低）；依次遍历样本，同时从零点开始绘制ROC曲线，每遇到一个正样本就沿着纵轴方向绘制一个刻度间隔的曲线，每遇到一个负样本就沿横轴方向绘制一个刻度间隔的曲线，直到遍历完所有样本，曲线最终停在（1，1）整个ROC曲线绘制完成。这样就很好理解<strong>为什么面积越大，分类性能越好了</strong>，想象这个过程即可。</p>
<h2 id="问题3-如何计算AUC？"><a href="#问题3-如何计算AUC？" class="headerlink" title="问题3  如何计算AUC？"></a>问题3  如何计算AUC？</h2><p>AUC指的是ROC曲线下的面积大小，该值能够量化地反映基于ROC曲线衡量出的模型性能。ROC曲线一般都处于y=x这条直线的上方，如果不是的话，只要把模型预测的概率反转成1-p就可以得到一个更好的分类器。所以AUC的取值一般在0.5至1之间。<strong>AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。</strong>比如极端好，那就是条x=0这条直线啊。对于不均衡数据来说，AUC衡量的是有没有为了高的召回率来牺牲精确度，越高说明牺牲的越少。</p>
<h2 id="树的AUC的计算"><a href="#树的AUC的计算" class="headerlink" title="树的AUC的计算"></a>树的AUC的计算</h2><p>很多机器学习的模型对分类问题的预测结果都是概率，如果要计算accuracy，需要把概率转化为类别，这就需要手动设置一个阈值。可以结合着第一种画AUC的方法来看，对于决策树，这种，可以使用第二种方法比较好理解，当然都用第二种都比较好理解。</p>
<h2 id="AUC缺点"><a href="#AUC缺点" class="headerlink" title="AUC缺点"></a>AUC缺点</h2><p>AUC的最大问题在于它并不在乎所有实例的绝对预测数值，而只在乎它们的相对数值。</p>
<h2 id="问题4-ROC曲线相比PR曲线有什么特点？"><a href="#问题4-ROC曲线相比PR曲线有什么特点？" class="headerlink" title="问题4 ROC曲线相比PR曲线有什么特点？"></a>问题4 ROC曲线相比PR曲线有什么特点？</h2><p><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-20%20%E4%B8%8A%E5%8D%8810.37.59.png" alt=""><br>将测试集中的负样本数量增加10倍后，可以看出PR曲线发生了明显的变化，而ROC曲线形状基本不变。这个特点让ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。实际问题中，正负样本的数量往往很不均衡。比如计算广告领域经常涉及转化率模型，正样本的数量往往是负样本数量的1比1000甚至1比10000。若选择不同的测试集，P-R曲线的变化就会非常大，而ROC曲线则能够更加稳定地反映模型本身的好坏。所以，ROC曲线的适用场景更多，被广泛用于排序、推荐、广告等领域。但需要注意的是，选择P-R曲线还是ROC曲线是因实际问题而异的，如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。</p>
<h1 id="AB测试"><a href="#AB测试" class="headerlink" title="AB测试"></a>AB测试</h1><h2 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h2><p>问：在对模型进行过充分的离线评估后，为什么还要进行在线AB测试？</p>
<p>答：需要进行在线A/B测试的原因如下。<br>(1)离线评估无法完全消除模型过拟合的影响，因此，得出的离线评估结果无法完全替代线上评估结果。</p>
<p>(2)离线评估无法完全还原线上的工程环境。一般来讲， 离线评估往往不会考虑线上环境的延迟、数据丢失、标签数据缺失等情况。因此，离线评估的结果是理想工程环境下的结果。</p>
<p>(3)线上系统的某些商业指标在离线评估中无法计算。离线评估一般是针对模型本身进行评估，而与模型相关的其他指标，特别是商业指标，往往无法直接获得。比如，上线 了新的推荐算法，离线评估往往关注的是ROC曲线、P-R曲线等的改进，而线上评估可以全面了解该推荐算法带来的用户点击率、留存时长、PV访问量等的变化。这些都要由A/B测试来进行全面的评估。</p>
<h2 id="问题2-如何进行线上AB测试？"><a href="#问题2-如何进行线上AB测试？" class="headerlink" title="问题2  如何进行线上AB测试？"></a>问题2  如何进行线上AB测试？</h2><p>答：进行AB测试的主要手段是进行用户分桶，即将用户分成实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型。在分桶的过程中，要注意<strong>样本的独立性</strong>和<strong>采样方式的无偏性</strong>，确保同一个用户每次只能分到同一个桶中，在分桶过程中所选取的user_id需要是一个随机数，这样才能保证桶中的样本是无偏的。</p>
<h1 id="模型评估的方法"><a href="#模型评估的方法" class="headerlink" title="模型评估的方法"></a>模型评估的方法</h1><p>在机器学习中，我们通常把样本分为训练集和测试集，训练集用于训练模型，测试集用于评估模型。在样本划分和模型验证的过程中，存在着不同的抽样方法和验证方法。</p>
<h2 id="问题1-1"><a href="#问题1-1" class="headerlink" title="问题1"></a>问题1</h2><p>问：在模型评估过程中，有哪些主要的验证方法，它们的优缺点是什么？</p>
<p>答：<br>（1）<strong>Holdout检验</strong><br>Holdout检验是最简单也是最直接的验证方法，它将原始的样本集合随机划分成训练集和验证集两部分。比方说，对于一个点击率预测模型，我们把样本按照70%~30%的比例分成两部分，70%的样本用于模型训练; 30%的样本用于模型验证，包括绘制ROC曲线、计算精确率和召回率等指标来评估模型性能。</p>
<p>Holdout检验的缺点很明显，即在验证集上计算出来的最后评估指标与原始分组有很大关系。为了消除随机性，研究者们引入了“交叉检验”的思想。<br>（2）<strong>交叉检验</strong><br>k-fold交叉验证:首先将全部样本划分成k个大小相等的样本子集;依次遍历这k个子集，每次把当前子集作为验证集，其余所有子集作为训练集，进行模型的训练和评估;最后把k次评估指标的平均值作为最终的评估指标。在实际实验中，经常取10。</p>
<p>（3）<strong>自助法</strong><br>不管是Holdout检验还是交叉检验，都是基于划分训练集和测试集的方法进行模型评估的。然而，<strong>当样本规模比较小时</strong>，将样本集进行划分会让训练集进一步减小，这可能会影响模型训练效果。</p>
<p>自助法是基于自助采样法的检验方法。对于总数为n的样本集合，进行n次有放回的随机抽样，得到大小为n的训练集。n次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，将这些没有被抽出的样本作为验证集,进行模型验证，这就是自助法的验证过程。</p>
<h2 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h2><p>问：在自助法的采样过程中，对n个样本进行n次自助抽样，当n趋于无穷大时，最终有多少数据从未被选择过?<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-20%20%E4%B8%8B%E5%8D%881.55.13.png" alt=""><br>根据重要极限，当样本量很大时，大约有0.368的样本从未被选择过，可做为验证集。</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/zdkswd/2019/03/19/CNN 个人总结/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZDK"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZDK's blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/19/CNN 个人总结/" class="post-title-link" itemprop="url">CNN 个人总结</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-19 15:45:12 / 修改时间：19:37:24" itemprop="dateCreated datePublished" datetime="2019-03-19T15:45:12+08:00">2019-03-19</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/知识总结/" itemprop="url" rel="index"><span itemprop="name">知识总结</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/03/19/CNN 个人总结/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/19/CNN 个人总结/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/03/19/CNN 个人总结/" class="post-meta-item leancloud_visitors" data-flag-title="CNN 个人总结">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="尺寸问题"><a href="#尺寸问题" class="headerlink" title="尺寸问题"></a>尺寸问题</h1><p><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/20180404150134375.png" alt=""><br>图中，输入层个数为1，深度为3，所以每个filter对应深度也要为。filter数量为2，对应输出层的深度为2，个数为1。</p>
<p>即输入层的深度与filter深度相等，输出层深度与filter个数相等。</p>
<h1 id="卷积层的梯度传递"><a href="#卷积层的梯度传递" class="headerlink" title="卷积层的梯度传递"></a>卷积层的梯度传递</h1><p><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/2256672-52295dad2641037f.png" alt="图1"><br><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/2256672-2fb37b0a3ff0e1f9.png" alt="图2"><br><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/2256672-754f37eb7603e99f.png" alt="图3"><br><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/2256672-af2da9701a03dc3c.png" alt="图4"><br><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG601552981169_.pic_hd.jpg" alt=""></p>
<h1 id="卷积层filter权重梯度的计算"><a href="#卷积层filter权重梯度的计算" class="headerlink" title="卷积层filter权重梯度的计算"></a>卷积层filter权重梯度的计算</h1><p><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/2256672-afe6d3a863b7cbcc.png" alt="图5"><br><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG571552981164_.pic.jpg" alt=""></p>
<h1 id="Pooling层的训练"><a href="#Pooling层的训练" class="headerlink" title="Pooling层的训练"></a>Pooling层的训练</h1><p><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/2256672-af77e98c09fad84c.png" alt="图6"><br><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/2256672-c3a6772cb07b416a.png" alt="图7"><br><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG591552981167_.pic_hd.jpg" alt=""></p>
<h1 id="CNN的反向传播"><a href="#CNN的反向传播" class="headerlink" title="CNN的反向传播"></a>CNN的反向传播</h1><p><img src="/img/media/CNN%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG581552981167_.pic.jpg" alt=""></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/zdkswd/2019/03/18/EM GMM 个人总结/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZDK"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZDK's blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/18/EM GMM 个人总结/" class="post-title-link" itemprop="url">EM GMM 个人总结</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-18 16:40:47 / 修改时间：16:40:20" itemprop="dateCreated datePublished" datetime="2019-03-18T16:40:47+08:00">2019-03-18</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/知识总结/" itemprop="url" rel="index"><span itemprop="name">知识总结</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/03/18/EM GMM 个人总结/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/18/EM GMM 个人总结/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/03/18/EM GMM 个人总结/" class="post-meta-item leancloud_visitors" data-flag-title="EM GMM 个人总结">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="EM-GMM-个人总结"><a href="#EM-GMM-个人总结" class="headerlink" title="EM GMM 个人总结"></a>EM GMM 个人总结</h1><p><img src="/img/media/EM%20GMM%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG541552897534_.pic_hd.jpg" alt=""></p>
<p><img src="/img/media/EM%20GMM%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG551552897535_.pic_hd.jpg" alt=""></p>
<p><img src="/img/media/EM%20GMM%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG531552897534_.pic_hd.jpg" alt=""></p>
<p><img src="/img/media/EM%20GMM%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG501552897530_.pic.jpg" alt=""></p>
<p><img src="/img/media/EM%20GMM%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG511552897532_.pic.jpg" alt=""></p>
<p><img src="/img/media/EM%20GMM%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/WechatIMG521552897533_.pic.jpg" alt=""></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/zdkswd/2019/03/15/百面 非监督学习/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZDK"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZDK's blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/15/百面 非监督学习/" class="post-title-link" itemprop="url">百面 非监督学习</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-15 14:48:47" itemprop="dateCreated datePublished" datetime="2019-03-15T14:48:47+08:00">2019-03-15</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-29 21:42:48" itemprop="dateModified" datetime="2019-03-29T21:42:48+08:00">2019-03-29</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/知识总结/" itemprop="url" rel="index"><span itemprop="name">知识总结</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/03/15/百面 非监督学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/15/百面 非监督学习/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/03/15/百面 非监督学习/" class="post-meta-item leancloud_visitors" data-flag-title="百面 非监督学习">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="EM算法（期望最大）"><a href="#EM算法（期望最大）" class="headerlink" title="EM算法（期望最大）"></a>EM算法（期望最大）</h1><p>解决隐变量混合模型的参数估计。</p>
<p>是软性的聚类，某个数据点可以不同强弱程度地同时属于不同的聚类。</p>
<p>极大似然估计，只是一种概率论在统计学的应用，它是参数估计的方法之一。说的是已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，通过若干次试验，观察其结果，利用结果推出参数的大概值。</p>
<p>如何感性地理解EM算法<br><a href="https://www.jianshu.com/p/1121509ac1dc" target="_blank" rel="noopener">https://www.jianshu.com/p/1121509ac1dc</a></p>
<h1 id="K均值聚类"><a href="#K均值聚类" class="headerlink" title="K均值聚类"></a>K均值聚类</h1><p>它的基本思想是，通过迭代方式寻找K个簇(Cluster) 的一种划分方案，使得聚类结果对应的代价函数最小。特别地，代价函数可以定义为各个样本距离所属簇中心点的误差平方和<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/page110image5024.jpg" alt=""><br>其中xi代表第i个样本，ci是xi所属于的簇，μci代表簇对应的中心点，M是样本总数。</p>
<h2 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h2><p>问：简述K均值算法的具体步骤。</p>
<p>答：K均值聚类的核心目标是将给定的数据集划分成K个簇，并给出每个数据对应的簇中心点。<br>（1）数据预处理，如归一化、离群点处理等。<br>（2）随机选取K个簇中心，记为<img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/page111image2648.jpg" alt=""><br>（3）定义代价函数:<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/page111image3160.jpg" alt=""><br>（4）令t=0,1,2,…为迭代步数，重复下面过程直到J收敛:<br>●对于每一个样本xi,将其分配到距离最近的簇<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%886.53.47.png" alt=""><br>● 对于每一个类簇k，重新计算该类簇的中心<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%886.54.23.png" alt=""></p>
<p>K均值算法在迭代时,假设当前J没有达到最小值,那么首先固定簇中心{μx},调整每个样例xi所属的类别ci来让J函数减少;然后固定{ci},调整簇中心{μk}使J减小。这两个过程交替循环,J单调递减:当J递减到最小值时,{μk}和{ci}也同时收敛。<img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/page112image848.jpg" alt=""><br>如图所示，首先初始化中心点，叉子代表中心点，根据中心点的位置计算每个样本所属的簇，用不同颜色表示，然后根据每个簇中的所有点平均值计算新的中心点位置。</p>
<h2 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h2><p>问：K均值算法的优缺点是什么?如何对其进行调优?</p>
<p>答：K均值算法有一些缺点，例如受初值和离群点的影响每次的结果不稳定、结果通常不是全局最优而是局部最优解、无法很好地解决数据簇分布差别比较大的情况(比如一类是另一类样本数量的100倍)、不太适用于离散分类等。但是瑕不掩瑜，K均值聚类的优点也是很明显和突出的，主要体现在:对于大数据集，K均值聚类算法相对是可伸缩和高效的，它的计算复杂度是O(NKt)接近于线性，其中N是数据对象的数目，<strong>K是聚类的簇数</strong>，堤迭代的轮数。尽管算法经常以局部最优结束，但一般情况下达到的局部最优已经可以满足聚类的需求。</p>
<p>K均值算法的调优一般可以从以下几个角度出发。<br>（1）<strong>数据归一化和离群点处理</strong>。<br>K均值聚类本质上是—种基于欧式距离度量的数据划分方法，均值和方差大的<br>维度将对数据的聚类结果产生决定性的影响，所以未做归一化处理和统一单位的数据是无法直接参与运算和比较的。同时，离群点或者少量的噪声数据就会对均值产生较大的影响，导致中心偏移，因此使用K均值聚类算法之前通常需要对数据做预处理。<br>（2）<strong>合理选择K值</strong><br>K值的选择是K均值聚类最大的问题之一，这也是K均值聚类算法的主要缺点。实际上，我们希望能够找到一些可行的办法来弥补这一缺点，或者说找到K值的合理估计方法。但是，K值的选择一般基于经验和多次实验结果。例如采用手肘法，我们可以尝试不同的K值，并将不同K值所对应的损失函数画成折线，横轴为K的取值，纵轴为误差平方和所定义的损失函数。<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%888.11.32.png" alt=""><br>由图可见，K值越大，距离和越小;并且，当K=3时， 存在一个拐点，就像人的肘部一样;当K∈(1,3)时，曲线急速下降;当K&gt;3时，曲线趋于平稳。手肘法认为拐点就是K的最佳值。</p>
<p>手肘法是一个经验方法，缺点就是不够自动化，Gap Statistic方法的优点是，不再需要肉眼判断，而只需要找到最大的Gap statistic所对应的K即可,因此该方法也适用于批量化作业。在这里继续使用上面的损失函数，当分为K簇时，对应的损失函数为Dk。Gap Statistics定义为<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%888.42.40.png" alt=""><br>其中E(logDk)是logDk.的期望，一般通过蒙特卡洛模拟产生。我们在样本所在的区域内按照均匀分布随机地产生和原始样本数一样多的随机样本，并对这个随机样本做K均值，得到一个D;重复多次就可以计算出E(logDk)的近似值。那么Gap(K)物理含义可以视为随机样本的损失与实际样本的损失之差。试想实际样本对应的最佳簇数为K，那么实际样本的损失应该相对较小，随机样本损失与实际样本损失之差也相应地达到最小值，从而Gap(K)取得最大值所对应的K值就是最佳的簇数。<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%888.50.02.png" alt=""><br>（3）<strong>采用核函数</strong><br>采用核函数是另一种可以尝试的改进方向。传统的欧式距离度量方式，使得K<br>均值算法本质_上假设了各个数据簇的数据具有-样的先验概率，并呈现球形或者高维球形分布，这种分布在实际生活中并不常见。面对非凸的数据分布形状时，可能需要引入核函数来优化，这时算法又称为核K均值算法，是核聚类方法的一种。<strong>核聚类方法的主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的特征空间中进行聚类。</strong>非线性映射增加了数据点线性可分的概率，从而在经典的聚类算法失效的情况下，通过引入核函数可以达到更为准确的聚类结果。</p>
<h2 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h2><p>问：针对K均值算法的缺点，有哪些改进的模型？</p>
<p>答：K均值的主要缺点有。<br>（1）需要人工预先确定初始K值，且该值和真实的数据分布未必吻合。<br>（2）K均值只能收敛到局部最优，效果受到初始值很大。<br>（3）易受到噪点的影响。<br>（4）样本点只能被划分到单一的类中。</p>
<p><strong>K-means++算法</strong><br>K均值的改进算法中，对初始值选择的改进是很重要的一部分。而这类算法<br>中，最具影响力的当属K-means++算法。原始K均值算法最开始随机选取数据集中K个点作为聚类中心，而K-means++ 按照如下的思想选取K个聚类中心。假设已经选取了n个初始聚类中心(0&lt;n&lt;K) ，则在选取第n+1个聚类中心时，距离当前n个聚类中心越远的点会有更高的概率被选为第n+1个聚类中心。在选取第一个聚类中心(n=1) 时同样通过随机的方法。可以说这也符合我们的直觉，聚类中心当然是互相离得越远越好。当选择完初始点后，K-means++ 后续的执行和经典K均值算法相同，这也是对初始值选择进行改进的方法等共同点。</p>
<p><strong>ISODATA算法</strong><br>当K值的大小不确定时，可以使用<strong>ISODATA</strong>算法。ISODATA的全称是迭代自<br>组织数据分析法。在K均值算法中，聚类个数K的值需要预先人为地确定，并且在整个算法过程中无法更改。而当遇到高维度、海量的数据集时，人们往往很难准确地估计出K的大小。ISODATA算法就是针对这个问题进行了改进，它的思想也很直观。当属于某个类别的样本数过少时，把该类别去除;当属于某个类别的样本数过多、分散程度较大时，把该类别分为两个子类别。ISODATA算法在K均值算法的基础之上增加了两个操作，一是<strong>分裂</strong>操作，对应着增加聚类中心数;二是<strong>合并</strong>操作，对应着减少聚类中心数。ISODATA算法是一个比较常见的算法，其缺点是需要指定的参数比较多，不仅仅需要一个参考的聚类数量K，还需要制定3个阈值。下面介绍ISODATA算法的各个输入参数。<br>（1）预期的聚类中心数目K。在ISODATA运行过程中聚类中心数可以变化，K0是一个用户指定的参考值，该算法的聚类中心数目变动范围也由其决定。具体地，最终输出的聚类中心数目常见范围是从K0的一半，到两倍K0。<br>（2）每个类所要求的最少样本数目Nmin。如果分裂后会导致某个子类别所包   含样本数目小于该阈值,就不会对该类别进行分裂操作。<br>（3）最大方差Sigma。用于控制某个类别中样本的分散程度。当样本的分散程度超过这个阈值时，且分裂后满足(1),进行分裂操作。<br>(4) 两个聚类中心之间所允许最小距离Dmin。如果两个类靠得非常近(即这两个类别对应聚类中心之间的距离非常小)，小于该阈值时，则对这两个类进行合并操作。</p>
<p>如果希望样本不划分到单一的类中，可以使用模糊C均值或者高斯混合模型。</p>
<h2 id="问题4"><a href="#问题4" class="headerlink" title="问题4"></a>问题4</h2><p>问：证明K均值算法的收敛性。</p>
<p>答：首先，我们需要知道K均值聚类的迭代算法实际上是一种最大期望算法(Expectation-Maximization algorithm)，简称EM算法。EM算法解决的是在概率模型中含有无法观测的隐含变量情况下的参数估计问题。即证明EM算法的收敛性。详见zdk的自己的公式推导。</p>
<h1 id="高斯混合模型"><a href="#高斯混合模型" class="headerlink" title="高斯混合模型"></a>高斯混合模型</h1><p>高斯混合模型( Gaussian Mixed Model,GMM)也是一种常见的聚类算法, 与K均值算法类似,同样使用了EM算法进行迭代计算。高斯混合模型假设每个簇的数据都是符合高斯分布(又叫正态分布)的,当前数据呈现的分布就是各个簇的高斯分布叠加在一起的结果。</p>
<h2 id="问题1-1"><a href="#问题1-1" class="headerlink" title="问题1"></a>问题1</h2><p>问：高斯混合模型的核心思想是什么?它是如何迭代计算的?</p>
<p>答：<br>高斯混合模型的核心思想是，假设数据可以看作从多个高斯分布中生成出来<br>的。在该假设下，每个单独的分模型都是标准高斯模型，其均值μ和方差Σ,是待估计的参数。此外，每个分模型都还有一个参数π，可以理解为权重或生成数据的概率。高斯混合模型的公式为<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/page120image6336.jpg" alt=""><br>然而，通常我们并不能直接得到高斯混合模型的参数，而是观察到了一系列数据点，给出一个类别的数量K后，希望求得最佳的K个高斯分模型。因此，高斯<br>混合模型的计算，便成了最佳的均值μ,方差Σ、权重π的寻找，这类问题通常通过最大似然估计来求解。遗憾的是，此问题中直接使用最大似然估计,得到的是一个复杂的非凸函数，目标函数是和的对数，难以展开和对其求偏导。</p>
<p>在这种情况下，可以用上一节已经介绍过的EM算法框架来求解该优化问题。<br>EM算法是在最大化目标函数时，先固定-一个变量使整体函数变为凸优化函数，求导得到最值，然后利用最优参数更新被固定的变量，进入下一一个循环。具体到高斯混合模型的求解，EM算法的迭代过程如下。</p>
<p>首先，初始随机选择各参数的值。然后，重复下述两步，直到收敛。<br>(1)E步骤。根据当前的参数，计算每个点由某个分模型生成的概率。<br>(2) M步骤。使用E步骤估计出的概率，来改进每个分模型的均值，方差和权重。</p>
<p>也就是说，我们并不知道最佳的K个高斯分布的各自3个参数，也不知道每个数据点究竟是哪个高斯分布生成的。所以每次循环时，先固定当前的高斯分布不变，获得每个数据点由各个高斯分布生成的概率。然后固定该生成概率不变，根据数据点和生成概率，获得-一个组更佳的高斯分布。循环往复，直到参数不再变化，或者变化非常小时，便得到了比较合理的一组高斯分布。</p>
<p>高斯混合模型与K均值算法的相同点是，它们都是可用于聚类的算法;都需要指定K值;都是使用EM算法来求解;都往往只能收敛于局部最优。而它相比于K均值算法的优点是，可以给出一个样本属于某类的概率是多少;不仅仅可以用于聚类，还可以用于概率密度的估计;并且可以用于生成新的样本点。</p>
<h1 id="聚类算法的评估"><a href="#聚类算法的评估" class="headerlink" title="聚类算法的评估"></a>聚类算法的评估</h1><h2 id="问题1-2"><a href="#问题1-2" class="headerlink" title="问题1"></a>问题1</h2><p>问：以聚类问题为例，假设没有外部标签数据，如何评估两个聚类算法的优劣?</p>
<p>答：非监督学习通常没有标注数据，模型、算法的设计直接影响最终的输出和模型的性能。为了评估不同聚类算法的性能优劣，我们需要了解常见的数据簇的特点。</p>
<p>●以中心定义的数据簇:这类数据集合倾向于球形分布，通常中心被定义为质心，即此数据簇中所有点的平均值。集合中的数据到中心的距离相比到其他簇中心的距离更近。<br>●以密度定义的数据簇:这类数据集合呈现和周围数据簇明显不同的密度，或稠密或稀疏。当数据簇不规则或互相盘绕，并且有噪声和离群点时，常常使用基于密度的簇定义。<br>● 以连通定义的数据簇:这类数据集合中的数据点和数据点之间有连接关系，整个数据簇表现为图结构。该定义对不规则形状或者缠绕的数据簇有效。<br>● 以概念定义的数据簇:这类数据集合中的所有数据点具有某种共同性质。</p>
<p>由于数据以及需求的多样性，没有一种算法能够适用于所有的数据类型、数据簇或应用场景，似乎每种情况都可能需要一种不同的评估方法或度量标准。例<br>如，K均值聚类可以用误差平方和来评估,但是基于密度的数据簇可能不是球形，误差平方和则会失效。在许多情况下，判断聚类算法结果的好坏强烈依赖于主观解释。尽管如此，聚类算法的评估还是必需的，它是聚类分析中十分重要的部分之一。</p>
<p>聚类评估的任务是估计在数据集上进行聚类的可行性，以及聚类方法产生结<br>果的质量。这一过程又分为三个子任务。<br>(1)估计聚类趋势。<br>(2)判定数据簇数<br>(3)测定聚类质量</p>
<h1 id="自组织映射神经网络"><a href="#自组织映射神经网络" class="headerlink" title="自组织映射神经网络"></a>自组织映射神经网络</h1><p>自组织映射神经网络(Self-Organizing Map，SOM)是无监督学习方法中一类重要方法，可以用作聚类、高维可视化、数据压缩、特征提取等多种用途。在深度神经网络大为流行的今天，谈及自组织映射神经网络依然是一件非常有意义的事情，这主要是由于自组织映射神经网络融入了大量人脑神经元的信号处理机制，有着独特的结构特点。</p>
<h2 id="问题1-3"><a href="#问题1-3" class="headerlink" title="问题1"></a>问题1</h2><p>问：自组织映射神经网络是如何工作的?它与K均值算法有何区别?</p>
<p>答：生物学研究表明，在人脑的感知通道上，神经元组织是有序排列的;同时，大脑皮层会对外界特定时空信息的输入在特定区域产生兴奋，而且相类似的外界信息输入产生对应兴奋的大脑皮层区域也连续映像的。例如，生物视网膜中有许多特定的细胞对特定的图形比较敏感，当视网膜中有若千个接收单元同时受特定模式刺激时，就使大脑皮层中的特定神经元开始兴奋，且输入模式接近时与之对应的兴奋神经元也接近;在听觉通道上，神经元在结构排列上与频率的关系十分密切，对于某个频率，特定的神经元具有最大的响应，位置相邻的神经元具有相近的频率特征，而远离的神经元具有的频率特征差别也较大。大脑皮层中神经元的这种响应特点不是先天安排好的，而是通过后天的学习自组织形成的。</p>
<p>在生物神经系统中，还存在着一种侧抑制现象，即一个神经细胞兴奋后，会对周围其他神经细胞产生抑制作用。这种抑制作用会使神经细胞之间出现竞争，其结果是某些获胜，而另一些则失败。表现形式是获胜神经细胞兴奋，失败神经细胞抑制。自组织神经网络就是对上述生物神经系统功能的一种人工神经网络模拟。</p>
<p>自组织映射神经网络本质上是一个两层的神经网络，包含输入层和输出层(竞争层)。输入层模拟感知外界输入信息的视网膜,输出层模拟做出响应的大脑皮层。输出层中神经元的个数通常是聚类的个数，代表每一个需要聚成的类。训练时采用“竞争学习”的方式，每个输入的样例在输出层中找到一个和它最匹配的节点，称为激活节点，也叫winning neuron;紧接着用随机梯度下降法更新激活节点的参数;同时，和激活节点临近的点也根据它们距离激活节点的远近而适当地更新参数。这种竞争可以通过神经元之间的横向抑制连接(负反馈路径)来实现。自组织映射神经网络的输出层节点是有拓扑关系的。这个拓扑关系依据需求确定，如果想要-维的模型，那么隐藏节点可以是“-维线阵”;如果想要二维的拓扑关系，那么就行成一个“二维平面阵”，如图5.8所示。也有更高维度的拓扑关系的，比如“三维栅格阵”，但并不常见。<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8B%E5%8D%889.56.05.png" alt=""><br>假设输入空间是D维，输入模式为x={xi,i=1.=…D}, 输入单元i和神经元j之间在计算层的连接权重为w= {wi,j= 1,..N,i=1,..,,D},其中N是神经元的总数。自组织映射神经网络的自组织学习过程可以归纳为以下几个子过程。<br>(1)初始化。所有连接权重都用小的随机值进行初始化。<br>(2)竞争。神经元计算每一个输入模式各自的判别函数值，并宣布具有最小判别函数值的特定神经元为胜利者，其中每个神经元j的判别函数为<br><img src="/img/media/%E7%99%BE%E9%9D%A2%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8B%E5%8D%8810.00.29.png" alt=""><br>(3)合作。获胜神经元(ω)决定了兴奋神经元拓扑邻域的空间位置。确定激活结点I(x)之后,我们也希望更新和它临近的节点。简单地说,临近的节点距离越远,更新的程度要打更大折扣。<br>(4)适应。适当调整相关兴奋神经元的连接权重,使得获胜的神经元对相似输入模式的后续应用的响应增强。<br>(5)迭代。继续回到步骤(2),直到特征映射趋于稳定。</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/zdkswd/2019/03/12/聚类/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZDK"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZDK's blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/12/聚类/" class="post-title-link" itemprop="url">聚类</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-12 15:34:12 / 修改时间：15:35:44" itemprop="dateCreated datePublished" datetime="2019-03-12T15:34:12+08:00">2019-03-12</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/知识总结/" itemprop="url" rel="index"><span itemprop="name">知识总结</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/03/12/聚类/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/12/聚类/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/03/12/聚类/" class="post-meta-item leancloud_visitors" data-flag-title="聚类">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>在“无监督学习”( unsupervised learning)中,训练样本的标记信息是未知的,目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律,为进一步的数据分析提供基础.此类学习任务中研究最多、应用最广的是“聚类”( clustering）</p>
<p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集,每个子集称为一个“簇”(cluster).通过这样的划分，每个簇可能对应于一些潜在的概念(类别),如“浅色瓜”“深色瓜” ，“有籽瓜”，“无籽瓜”,甚至“本地瓜”，“外地瓜”等;需说明的是,这些概念对聚类算法而言事先是未知的，聚类过程仅能自动形成簇结构,簇所对应的概念语义需由使用者来把握和命名.对聚类算法而言，标记簇亦称为类。</p>
<p>聚类既能作为一个单独过程,用于找寻数据内在的分布结构,也可作为分类等其他学习任务的前驱过程.例如,在一些商业应用中需对新用户的类型进行判别，但定义“用户类型”对商家来说却可能不太容易，此时往往可先对用户数据进行聚类，根据聚类结果将每个簇定义为一个类,然后再基于这些类训练分类模型,用于判别新用户的类型.</p>
<h1 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h1><p>对聚类结果,我们需通过某种性能度量来评估其好坏;另一方面，若明确了最终将要使用的性能度量,则可直接将其作为聚类过程的优化目标，从而更好地得到符合要求的聚类结果.</p>
<p>什么样的聚类结果比较好呢?直观上看,我们希望“物以类聚” ’，即同簇的样本尽可能彼此相似,不同簇的样本尽可能不同.换言之,聚类结果的“簇内相似度”(intra-cluster similarity)高且“簇间相似度”(inter-cluster similarity)低.</p>
<p>聚类性能度量大致有两类一 类是将聚类结果与某个“参考模型”(reference model)进行比较,称为“外部指标”(external index); 另一类是直接考察聚类结果而不利用任何参考模型,称为“内部指标”(internal index).</p>
<h2 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h2><p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.00.59.png" alt=""></p>
<h3 id="Jaccard系数-Jaccard-Coefficient-简称JC"><a href="#Jaccard系数-Jaccard-Coefficient-简称JC" class="headerlink" title="Jaccard系数(Jaccard Coefficient, 简称JC)"></a>Jaccard系数(Jaccard Coefficient, 简称JC)</h3><p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.02.02.png" alt=""></p>
<h3 id="FM指数-Fowlkes-and-Mallows-Index-简称FMI"><a href="#FM指数-Fowlkes-and-Mallows-Index-简称FMI" class="headerlink" title="FM指数(Fowlkes and Mallows Index,简称FMI)"></a>FM指数(Fowlkes and Mallows Index,简称FMI)</h3><p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.02.28.png" alt=""></p>
<h3 id="Rand指数-Rand-Index-简称RI"><a href="#Rand指数-Rand-Index-简称RI" class="headerlink" title="Rand指数(Rand Index,简称RI)"></a>Rand指数(Rand Index,简称RI)</h3><p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.02.59.png" alt=""></p>
<p>上述性能度量的结果值均在[0, 1]区间,值越大越好。</p>
<h2 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h2><p>距离越大则样本的相似度越低。<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.17.20.png" alt=""></p>
<h3 id="DB指数-Davies-Bouldin-Index-简称DBI"><a href="#DB指数-Davies-Bouldin-Index-简称DBI" class="headerlink" title="DB指数(Davies- Bouldin Index,简称DBI)"></a>DB指数(Davies- Bouldin Index,简称DBI)</h3><p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.18.07.png" alt=""></p>
<h3 id="Dunn指数-Dunn-Index-简称DI"><a href="#Dunn指数-Dunn-Index-简称DI" class="headerlink" title="Dunn指数(Dunn Index,简称DI)"></a>Dunn指数(Dunn Index,简称DI)</h3><p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.18.28.png" alt=""></p>
<p>DBI的值越小越好，而DI则相反，值越大越好。</p>
<h2 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h2><p>对函数dist(,),若它是一个“距离度量”(distance measure),则需满足一些基本性质:<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.36.49.png" alt=""><br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.37.01.png" alt=""><br>直递性常被直接称为“三角不等式”。<br>给定样本xi = (xi1;xi2;…;xin) 与xj = (xj1;xj2;..;xjn), 最常用的是“闵可夫斯基距离”(Minkowski distance)<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.38.35.png" alt=""><br>上式即为xi-xj的Lp范数。<br>当p=2时，闵可夫斯基距离即欧氏距离。<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.40.34.png" alt=""><br>当p=1时，闵可夫斯基距离即曼哈顿距离。<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.42.10.png" alt=""></p>
<p>闵可夫斯基距离适用于{1,2,3}这样的有序属性，而不适用于{飞机，火车，轮船}这样的无序属性。对无序属性可采用VDM。<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.46.29.png" alt=""><br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8A%E5%8D%8810.47.01.png" alt=""></p>
<p>当样本空间中不同属性的重要性不同时,还可使用“加权距离“</p>
<p>通常我们是基于某种形式的距离来定义“相似度度量”(similarity measure), 距离越大,相似度越小.然而，用于相似度度量的距离未必一定要满足距离度量的所有基本性质,尤其是直递性。</p>
<h1 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h1><h2 id="k均值算法"><a href="#k均值算法" class="headerlink" title="k均值算法"></a>k均值算法</h2><p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.30.35.png" alt=""><br>最小化式(9.24)并不容易，找到它的最优解需考察样本集D所有可能的簇划分,这是一个NP难问题.因此, k均值算法采用了贪心策略,通过迭代优化来近似求解式(9.24).</p>
<p>对于以下数据集，为方便叙述，将编号为i的样本称为xi，这是一个包含密度与含糖率两个属性值的二维向量。<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.38.59.png" alt=""></p>
<p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.44.09.png" alt=""><br>为避免运行时间过长,通常设置一一个最大运行轮数或最小调整幅度阈值,若达到最大轮数或调整幅度小于阈值,则停止运行。</p>
<p>假定聚类簇数k= 3,算法开始时随机选取三个样本x6, x12, x27作为初始均值向量,即<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.46.12.png" alt=""><br>考察样本x1 = (0.697; 0.460),它与当前均值向量μ1, μu2, μ3的距离分别为0.369, 0.506, 0.166, 因此x1将被划入簇C3中.类似的,对数据集中的所有样本<br>考察一遍后, 可得当前簇划分为<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.47.13.png" alt=""><br>于是，可从C1、C2、C3分别求出新的均值向量<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.47.59.png" alt=""><br>更新当前均值向量后，不断重复上述过程,如图9.3所示，第五轮迭代产生的结<br>果与第四轮迭代相同，于是算法停止得到最终的簇划分.<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.48.47.png" alt=""></p>
<h2 id="学习向量量化"><a href="#学习向量量化" class="headerlink" title="学习向量量化"></a>学习向量量化</h2><p>与k均值算法类似，“ 学习向量量化”(Learning Vector Quantization,简称LVQ)也是试图找到一组原型向量来刻画聚类结构,但与一般聚类算法不同的是,LVQ假设数据样本带有类别标记，学习过程利用样本的这些监督信息来辅助聚类.</p>
<p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.53.04.png" alt=""></p>
<p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%8812.57.41.png" alt=""><br>在每一轮迭代中，算法随机选取一个有标记的训练样本，找出与其距离最近的原型向量，并根据两者的类别标记是否一致来对原型向量进行响应的更新。若算法的停止条件已满足，例如已达到最大迭代轮数，或原型向量更新很小甚至不再更新，则将当前原型向量作为最终结果返回。</p>
<p>以西瓜数据集为例演示LVQ的学习过程。假定q=5，即学习目标是找到5个原型向量<strong>p1,p2,p3,p4,p5</strong>,并假定其对应的类别标记分别为c1,c2,c2,c1,c1。</p>
<p>算法开始时,根据样本的类别标记和簇的预设类别标记对原型向量进行随机初始化，假定初始化为样本<strong>x5, x12, x18, x23, x29</strong>.在第一轮迭代中，假定随机选取的样本为x1,该样本与当前原型向量<strong>p1,p2,p3,p4,p5</strong>的距离分别为0.283, 0.506, 0.434, 0.260, 0.032.由于<strong>p5</strong>与<strong>x1</strong>距离最近且两者具有相同的类别标记c2,假定学习率η= 0.1,则LVQ更新<strong>p5</strong>得到新原型向量<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%881.28.14.png" alt=""></p>
<p><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%881.45.59.png" alt=""></p>
<h2 id="高斯混合聚类"><a href="#高斯混合聚类" class="headerlink" title="高斯混合聚类"></a>高斯混合聚类</h2><p>与k均值、LVQ用原型向量来刻画聚类结构不同,高斯混合(Mixture-of-Gaussian)聚类采用概率模型来表达聚类原型.<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%881.54.09.png" alt=""><br>可定义高斯混合分布<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.02.00.png" alt=""><br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.03.41.png" alt=""><br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.03.28.png" alt=""><br>按下不表</p>
<h1 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h1><p>密度聚类亦称“基于密度的聚类”(density-based clustering), 此类算法假设聚类结构能通过样本分布的紧密程度确定.通常情形下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果.<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.10.09.png" alt=""><br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.11.07.png" alt=""><br>密度直达关系通常不满足对称性，密度可达关系满足直递性,但不满足对称性.密度相连关系满足对称性。<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.22.09.png" alt=""><br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.24.24.png" alt=""><br>D中不属于任何簇的样本被认为是噪声(noise)或异常(anomaly)样本。</p>
<p>若x为核心对象,由x密度可达的所有样本组成的集合记为X = {x’∈D |x’由x密度可达},则不难证明X即为满足连接性与最大性的簇.</p>
<p> DBSCAN算法先任选数据集中的一个核心对象为“种子”(seed),再由此出发确定相应的聚类簇，算法先根据给定的邻域参数找到所有核心对象；然后以任一核心对象为出发点，找到由其密度可达的样本生成聚类簇，直到所有核心对象均被访问过为止。<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.41.24.png" alt=""><br>以西瓜数据集为例，假定邻域参数设置为e=0.11，MinPts=5.DBSCAN算法先找出各样本的∈-邻域并确定核心对象集合: S= {x3, x5, x6, x8, x9, x13, x14, x18, x19, x24, x25, x28, x29}.然后，从Ω中随机选取一个核心对象作为种子，找出由它密度可达的所有样本,这就构成了第一个聚类簇.不失一般性,假定核心对象x8被选中作为种子，则DBSCAN生成的第一个聚类簇为<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%882.45.11.png" alt=""><br>然后, DBSCAN将C1中包含的核心对象从几中去除:Ω=Ω \ C1 ={x3, x5, x9, x13, x14, x24, x25, x28, x2g}.再从更新后的集合8中随机选取一个核心对象作为种子来生成下一一个聚类簇..上述过程不断重复,直至I为空.图9.10显示DBSCAN先后生成聚类簇的情况. C1之后生成的聚类簇为<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%883.12.14.png" alt=""><br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%883.12.30.png" alt=""></p>
<h1 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h1><p>层次聚类(hierarchical clustering)试图在不同层次对数据集进行划分，从而形成树形的聚类结构.数据集的划分可采用“自底向上”的聚合策略,也可采用“自顶向下”的分拆策略.</p>
<p>AGNES是一种采用自底向上聚合策略的层次聚类算法.它先将数据集中的每个样本看作一个初始聚类簇,然后在算法运行的每一步中找出距离最近的两个聚类簇进行合并,该过程不断重复,直至达到预设的聚类簇个数.这里的关键是如何计算聚类簇之间的距离.实际上,每个簇是一个样本集合,因此,只需采用关于集合的某种距离即可。</p>
<p>对于给定聚类簇Ci，Cj，可通过下面式子来计算距离：<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%883.25.52.png" alt=""><br>显然,最小距离由两个簇的最近样本决定,最大距离由两个簇的最远样本决定，而平均距离则由两个簇的所有样本共同决定.当聚类簇距离由dmin，dmax或davg计算时，AGNES算法被相应地称为“单链接”(single-linkage)、 “ 全链接”(complete linkage)或“均链接”(average-linkage)算法.</p>
<p>AGNES算法先对仅含一个样本的初始聚类簇和相应的距离矩阵进行初始化;然后AGNES不断合并距离最近的聚类簇,并对合并得到的聚类簇的距离矩阵进行更新;上述过程不断重复,直至达到预设的聚类簇数.<br><img src="/img/media/%E8%81%9A%E7%B1%BB/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-12%20%E4%B8%8B%E5%8D%883.31.13.png" alt=""></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/zdkswd/2019/03/07/决策树 个人总结/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZDK"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZDK's blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/07/决策树 个人总结/" class="post-title-link" itemprop="url">决策树 个人总结</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-07 20:22:47 / 修改时间：20:22:06" itemprop="dateCreated datePublished" datetime="2019-03-07T20:22:47+08:00">2019-03-07</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/知识总结/" itemprop="url" rel="index"><span itemprop="name">知识总结</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/03/07/决策树 个人总结/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/07/决策树 个人总结/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/03/07/决策树 个人总结/" class="post-meta-item leancloud_visitors" data-flag-title="决策树 个人总结">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="决策树-个人总结"><a href="#决策树-个人总结" class="headerlink" title="决策树 个人总结"></a>决策树 个人总结</h1><p><img src="/img/media/%E5%86%B3%E7%AD%96%E6%A0%91%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/22.png" alt=""></p>
<p><img src="/img/media/%E5%86%B3%E7%AD%96%E6%A0%91%20%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/23.png" alt=""></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://github.com/zdkswd/2019/03/05/循环神经网络/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZDK"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZDK's blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/05/循环神经网络/" class="post-title-link" itemprop="url">循环神经网络</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-05 09:21:47 / 修改时间：09:23:04" itemprop="dateCreated datePublished" datetime="2019-03-05T09:21:47+08:00">2019-03-05</time>
            </span>
          

          
            

            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/知识总结/" itemprop="url" rel="index"><span itemprop="name">知识总结</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/03/05/循环神经网络/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/05/循环神经网络/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
            <span id="/2019/03/05/循环神经网络/" class="post-meta-item leancloud_visitors" data-flag-title="循环神经网络">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          

          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h1><p>参考<a href="https://cuijiahua.com/blog/2018/12/dl-11.html" target="_blank" rel="noopener">深度学习实战教程(五)：循环神经网络</a></p>
<p>RNN是在自然语言处理领域中最先被用起来的，使用RNN之前，语言模型主要是采用N-Gram。N可以是一个自然数，比如2或者3。它的含义是，假设一个词出现的概率只与前面N个词相关。</p>
<p><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-03%20%E4%B8%8B%E5%8D%887.26.20.png" alt=""><br>如果用2-Gram进行建模，那么电脑在预测的时候，只会看到前面的『了』，然后，电脑会在语料库中，搜索『了』后面最可能的一个词。不管最后电脑选的是不是『我』，我们都知道这个模型是不靠谱的，因为『了』前面说了那么一大堆实际上是没有用到的。如果是3-Gram模型呢，会搜索『批评了』后面最可能的词，感觉上比2-Gram靠谱了不少，但还是远远不够的。因为这句话最关键的信息『我』，远在9个词之前！</p>
<p>读者可能会想，可以提升继续提升N的值呀，比如4-Gram、5-Gram…….。实际上，这个想法是没有实用性的。因为我们想处理任意长度的句子，N设为多少都不合适；另外，模型的大小和N的关系是指数级的，4-Gram模型就会占用海量的存储空间。</p>
<p>所以，该轮到RNN出场了，RNN理论上可以往前看(往后看)任意多个词。</p>
<h2 id="基本循环神经网络"><a href="#基本循环神经网络" class="headerlink" title="基本循环神经网络"></a>基本循环神经网络</h2><p>下图是一个简单的循环神经网络如，它由输入层、一个隐藏层和一个输出层组成：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-1.jpg" alt=""><br>循环神经网络实在是太难画出来了，网上所有大神们都不得不用了这种抽象艺术手法。如果把上面有W的那个带箭头的圈去掉，它就变成了最普通的全连接神经网络。x是一个向量，它表示输入层的值（这里面没有画出来表示神经元节点的圆圈）；s是一个向量，它表示隐藏层的值（这里隐藏层面画了一个节点，你也可以想象这一层其实是多个节点，节点数与向量s的维度相同）；U是输入层到隐藏层的权重矩阵。o也是一个向量，它表示输出层的值；V是隐藏层到输出层的权重矩阵。循环神经网络的隐藏层的值s不仅仅取决于当前这次的输入x，还取决于上一次隐藏层的值s。权重矩阵 W就是隐藏层上一次的值作为这一次的输入的权重。</p>
<p>把上面的图展开，循环神经网络也可以画成下面这个样子：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-2.jpg" alt=""><br>现在看上去就比较清楚了，这个网络在t时刻接收到输入x𝑡之后，隐藏层的值是s𝑡，输出值是o𝑡。关键一点是，s𝑡的值不仅仅取决于x𝑡，还取决于s𝑡−1。我们可以用下面的公式来表示循环神经网络的计算方法：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-3.jpg" alt=""><br>式1是输出层的计算公式，输出层是一个全连接层，也就是它的每个节点都和隐藏层的每个节点相连。V是输出层的权重矩阵，g是激活函数。式2是隐藏层的计算公式，它是循环层。U是输入x的权重矩阵，W是上一次的值s𝑡−1作为这一次的输入的权重矩阵，f是激活函数。</p>
<p>如果反复把式2带入到式1，我们将得到：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-4.jpg" alt=""><br>从上面可以看出，循环神经网络的输出值𝑜𝑡，是受前面历次输入值x𝑡、x𝑡−1、x𝑡−2、x𝑡−3…影响的，这就是为什么循环神经网络可以往前看任意多个输入值的原因。</p>
<h2 id="双向循环神经网络"><a href="#双向循环神经网络" class="headerlink" title="双向循环神经网络"></a>双向循环神经网络</h2><p>对于语言模型来说，很多时候光看前面的词是不够的，比如下面这句话：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-03%20%E4%B8%8B%E5%8D%887.49.40.png" alt=""><br>我们需要双向循环神经网络，如下图所示：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-5-1024x358.png" alt=""><br>从上图可以看出，双向卷积神经网络的隐藏层要保存两个值，一个A参与正向计算，另一个值A’参与反向计算。最终的输出值y2取决于𝐴2和𝐴′2。其计算方法为：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-6.jpg" alt=""><br>𝐴2 和𝐴′2则分别计算：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-7.jpg" alt=""><br>现在，我们已经可以看出一般的规律：正向计算时，隐藏层的值s𝑡与s𝑡−1有关；反向计算时，隐藏层的值s′𝑡与s′𝑡+1有关；最终的输出取决于正向和反向计算的加和。现在，我们仿照式1和式2，写出双向循环神经网络的计算方法：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-8.jpg" alt=""><br>从上面三个公式我们可以看到，正向计算和反向计算不共享权重，也就是说U和U’、W和W’、V和V’都是不同的权重矩阵。</p>
<h2 id="深度循环神经网络"><a href="#深度循环神经网络" class="headerlink" title="深度循环神经网络"></a>深度循环神经网络</h2><p>前面我们介绍的循环神经网络只有一个隐藏层，我们当然也可以堆叠两个以上的隐藏层，这样就得到了深度循环神经网络。<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-9.png" alt=""><br>我们把第i个隐藏层的值表示为s(𝑖)𝑡和s′(𝑖)𝑡，则深度循环神经网络的计算方式可以表示为：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-10.jpg" alt=""></p>
<h2 id="循环神经网络的训练"><a href="#循环神经网络的训练" class="headerlink" title="循环神经网络的训练"></a>循环神经网络的训练</h2><p>循环神经网络的训练算法：BPTT<br>BPTT算法是针对循环层的训练算法，它的基本原理和BP算法是一样的，也包含同样的三个步骤：</p>
<ol>
<li>前向计算每个神经元的输出值</li>
<li>反向计算每个神经元的误差项𝛿𝑗值，它是误差函数E对神经元j的加权输入𝑛𝑒𝑡𝑗的偏导数；</li>
<li>计算每个权重的梯度。</li>
</ol>
<p>最后再用随机梯度下降算法更新权重。</p>
<p>循环层如下图所示：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-11.png" alt=""><br><strong>前向计算：</strong><br>使用前面的式2对循环层进行前向计算：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-12.jpg" alt=""><br>注意，上面的s𝑡、x𝑡、s𝑡−1都是向量，用黑体字母表示；而U、V是矩阵，用大写字母表示。向量的下标表示时刻，例如，s𝑡表示在t时刻向量s的值。</p>
<p>我们假设输入向量x的维度是m，输出向量s的维度是n，则矩阵U的维度是n <em> m，矩阵W的维度是n </em> m。下面是上式展开成矩阵的样子，看起来更直观一些：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-13.jpg" alt=""><br>在这里我们用手写体字母表示向量的一个元素，它的下标表示它是这个向量的第几个元素，它的上标表示第几个时刻。例如，𝑠𝑡𝑗表示向量s的第j个元素在t时刻的值。𝑢𝑗𝑖表示输入层第i个神经元到循环层第j个神经元的权重。𝑤𝑗𝑖表示循环层第t-1时刻的第i个神经元到循环层第t个时刻的第j个神经元的权重。</p>
<p><strong>误差项的计算</strong><br>BTPP算法将第l层t时刻的误差项𝛿𝑙𝑡值沿两个方向传播，一个方向是其传递到上一层网络，得到𝛿𝑙−1𝑡，这部分只和权重矩阵U有关；另一个是方向是将其沿时间线传递到初始𝑡1时刻，得到𝛿𝑙1，这部分只和权重矩阵W有关。</p>
<p>我们用向量net𝑡表示神经元在t时刻的加权输入，因为：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-14.jpg" alt=""><br>因此：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-15.jpg" alt=""><br>我们用a表示列向量，用a𝑇表示行向量。上式的第一项是向量函数对向量求导，其结果为Jacobian矩阵：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-16.jpg" alt=""><br>同理，上式第二项也是一个Jacobian矩阵：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-17.jpg" alt=""><br>其中，diag[a]表示根据向量a创建一个对角矩阵，即<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-18.jpg" alt=""><br>最后，将两项合在一起，可得：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-19.jpg" alt=""><br>上式描述了将𝛿沿时间往前传递一个时刻的规律，有了这个规律，我们就可以求得任意时刻k的误差项𝛿𝑘：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-20.jpg" alt=""><br>式3就是将误差项沿时间反向传播的算法。循环层将误差项反向传递到上一层网络，与普通的全连接层是完全一样的。<br>循环层的加权输入net𝑙与上一层的加权输入net𝑙−1关系如下：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-21.jpg" alt=""><br>上式中net𝑙𝑡是第l层神经元的加权输入(假设第l层是循环层)；net𝑙−1𝑡是第l-1层神经元的加权输入；a𝑙−1𝑡是第l-1层神经元的输出；𝑓𝑙−1是第l-1层的激活函数。<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-23.png" alt=""><br>所以，<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-24.png" alt=""><br>式4就是将误差项传递到上一层算法。</p>
<p><strong>权重梯度的计算</strong><br>现在，我们终于来到了BPTT算法的最后一步：计算每个权重的梯度。</p>
<p>首先，我们计算误差函数E对权重矩阵W的梯度∂𝐸 / ∂𝑊。<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-25.png" alt=""></p>
<p><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-28.png" alt=""><br>具体推导参考<br><a href="https://cuijiahua.com/blog/2018/12/dl-11.html" target="_blank" rel="noopener">https://cuijiahua.com/blog/2018/12/dl-11.html</a></p>
<h2 id="RNN的梯度爆炸和消失问题"><a href="#RNN的梯度爆炸和消失问题" class="headerlink" title="RNN的梯度爆炸和消失问题"></a>RNN的梯度爆炸和消失问题</h2><p>不幸的是，实践中前面介绍的几种RNNs并不能很好的处理较长的序列。一个主要的原因是，RNN在训练中很容易发生梯度爆炸和梯度消失，这导致训练时梯度不能在较长序列中一直传递下去，从而使RNN无法捕捉到长距离的影响。</p>
<p>为什么RNN会产生梯度爆炸和消失问题呢？我们接下来将详细分析一下原因。我们根据式3可得：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-40.png" alt=""><br>上式的𝛽定义为矩阵的模的上界。因为上式是一个指数函数，如果t-k很大的话（也就是向前看很远的时候），会导致对应的误差项的值增长或缩小的非常快，这样就会导致相应的梯度爆炸和梯度消失问题（取决于𝛽大于1还是小于1）。</p>
<p>通常来说，梯度爆炸更容易处理一些。因为梯度爆炸的时候，我们的程序会收到NaN错误。我们也可以设置一个梯度阈值，当梯度超过这个阈值的时候可以直接截取。</p>
<p>梯度消失更难检测，而且也更难处理一些。总的来说，我们有三种方法应对梯度消失问题：</p>
<ol>
<li>合理的初始化权重值。初始化权重，使每个神经元尽可能不要取极大或极小值，以躲开梯度消失的区域。</li>
<li>使用relu代替sigmoid和tanh作为激活函数。</li>
<li>使用其他结构的RNNs，比如长短时记忆网络（LTSM）和Gated Recurrent Unit（GRU），这是最流行的做法。</li>
</ol>
<h2 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h2><p>我们知道，神经网络的输入和输出都是向量，为了让语言模型能够被神经网络处理，我们必须把词表达为向量的形式，这样神经网络才能处理它。<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-43.png" alt=""><br>使用这种向量化方法，我们就得到了一个高维、稀疏的向量（稀疏是指绝大部分元素的值都是0）。处理这样的向量会导致我们的神经网络有很多的参数，带来庞大的计算量。因此，往往会需要使用一些降维方法，将高维的稀疏向量转变为低维的稠密向量。</p>
<p>语言模型要求的输出是下一个最可能的词，我们可以让循环神经网络计算计算词典中每个词是下一个词的概率，这样，概率最大的词就是下一个最可能的词。因此，神经网络的输出向量也是一个N维向量，向量中的每个元素对应着词典中相应的词是下一个词的概率。<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-44.png" alt=""></p>
<h2 id="Softmax层"><a href="#Softmax层" class="headerlink" title="Softmax层"></a>Softmax层</h2><p>语言模型是对下一个词出现的概率进行建模。那么，怎样让神经网络输出概率呢？方法就是用softmax层作为神经网络的输出层。</p>
<p>softmax函数的定义：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-45.png" alt=""><br>举一个例子。Softmax层如下图所示：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-46.png" alt=""><br>计算过程为：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-47.png" alt=""><br>输出向量y的特征：</p>
<ol>
<li>每一项为取值为0-1之间的正数；</li>
<li>所有项的总和是1。</li>
</ol>
<p>这些特征和概率的特征是一样的，因此我们可以把它们看做是概率。对于语言模型来说，我们可以认为模型预测下一个词是词典中第一个词的概率是0.03，是词典中第二个词的概率是0.09，以此类推。</p>
<p><strong>交叉熵误差</strong><br>一般来说，当神经网络的输出层是softmax层时，对应的误差函数E通常选择交叉熵误差函数，其定义如下：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-49.png" alt=""><br>在上式中，N是训练样本的个数，向量𝑦𝑛是样本的标记，向量𝑜𝑛是网络的输出。标记𝑦𝑛是一个one-hot向量，例如𝑦1=[1,0,0,0]，如果网络的输出𝑜=[0.03,0.09,0.24,0.64]，那么，交叉熵误差是（假设只有一个训练样本，即N=1）：<br><img src="/img/media/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/dl-11-50.png" alt=""><br>我们当然可以选择其他函数作为我们的误差函数，比如最小平方误差函数(MSE)。不过对概率进行建模时，选择交叉熵误差函数更make sense。具体原因，<br><a href="https://jamesmccaffrey.wordpress.com/2011/12/17/neural-network-classification-categorical-data-softmax-activation-and-cross-entropy-error/" target="_blank" rel="noopener">https://jamesmccaffrey.wordpress.com/2011/12/17/neural-network-classification-categorical-data-softmax-activation-and-cross-entropy-error/</a></p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.gif"
                alt="ZDK"/>
            
              <p class="site-author-name" itemprop="name">ZDK</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">191</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">9</span>
                    <span class="site-state-item-name">分类</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">48</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/zdkswd" title="GitHub &rarr; https://github.com/zdkswd"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:2822464407@qq.com" title="E-Mail &rarr; mailto:2822464407@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://github.com/zdkswd" title="https://github.com/zdkswd">Title</a>
                  </li>
                
              </ul>
            </div>
          

          
        </div>
      </div>

      

      
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZDK</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.2.0</div>




        








        
      </div>
    </footer>

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  













  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/affix.js?v=7.2.0"></script>

  <script src="/js/schemes/pisces.js?v=7.2.0"></script>




  

  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  

  
  

<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: true,
    appId: 'QiU7UFIdgTTauFTk89N47mQS-gzGzoHsz',
    appKey: 'gkBx5soQkBREmER84PWbNJeM',
    placeholder: 'have fun',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: '' || 'zh-cn'
  });
</script>





  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('5');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  

  

  

  

  

  

  

  


  

</body>
</html>
