<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>tx往届心得 | ZDK&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="机器学习">
    <meta name="description" content="stacking技术分享stacking不能称为一种算法，而是一种对模型的集成策略。在给定数据集的情况下，数据内部的空间结构和数据之间的关系是非常复杂得。不同的模型，其实很重要的一点就是在不同的角度去观测数据集。stacking框架就是用来取长补短进行结合的。 假设是五折的stacking，我们有一个train数据集和一个test数据集，那么一个基本的stacking框架会进行如下几个操作：  选">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="tx往届心得">
<meta property="og:url" content="https://github.com/zdkswd/2019/04/17/tx往届心得/index.html">
<meta property="og:site_name" content="ZDK&#39;s blog">
<meta property="og:description" content="stacking技术分享stacking不能称为一种算法，而是一种对模型的集成策略。在给定数据集的情况下，数据内部的空间结构和数据之间的关系是非常复杂得。不同的模型，其实很重要的一点就是在不同的角度去观测数据集。stacking框架就是用来取长补短进行结合的。 假设是五折的stacking，我们有一个train数据集和一个test数据集，那么一个基本的stacking框架会进行如下几个操作：  选">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://github.com/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.32.08.png">
<meta property="og:image" content="https://github.com/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.33.39.png">
<meta property="og:image" content="https://github.com/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/640.png">
<meta property="og:image" content="https://github.com/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%8810.30.48.png">
<meta property="og:image" content="https://github.com/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%8810.32.33.png">
<meta property="og:updated_time" content="2019-04-17T02:57:36.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="tx往届心得">
<meta name="twitter:description" content="stacking技术分享stacking不能称为一种算法，而是一种对模型的集成策略。在给定数据集的情况下，数据内部的空间结构和数据之间的关系是非常复杂得。不同的模型，其实很重要的一点就是在不同的角度去观测数据集。stacking框架就是用来取长补短进行结合的。 假设是五折的stacking，我们有一个train数据集和一个test数据集，那么一个基本的stacking框架会进行如下几个操作：  选">
<meta name="twitter:image" content="https://github.com/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.32.08.png">
    
        <link rel="alternate" type="application/atom+xml" title="ZDK&#39;s blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/tmg.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">ZDK</h5>
          <a href="mailto:2822464407@qq.com" title="2822464407@qq.com" class="mail">2822464407@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/zdkswd" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">tx往届心得</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">tx往届心得</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-04-17T08:49:47.000Z" itemprop="datePublished" class="page-time">
  2019-04-17
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/知识总结/">知识总结</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#stacking技术分享"><span class="post-toc-number">1.</span> <span class="post-toc-text">stacking技术分享</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#注意事项"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">注意事项</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#基本变种改进"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">基本变种改进</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Kaggle数据挖掘比赛经验分享"><span class="post-toc-number">2.</span> <span class="post-toc-text">Kaggle数据挖掘比赛经验分享</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#数据分析"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">数据分析</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#分析特征变量的分布"><span class="post-toc-number">2.1.1.</span> <span class="post-toc-text">分析特征变量的分布</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#分析目标变量的分布"><span class="post-toc-number">2.1.2.</span> <span class="post-toc-text">分析目标变量的分布</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#分析变量之间两两的分布和相关度"><span class="post-toc-number">2.1.3.</span> <span class="post-toc-text">分析变量之间两两的分布和相关度</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#数据清洗"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">数据清洗</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#数据的拼接"><span class="post-toc-number">2.2.1.</span> <span class="post-toc-text">数据的拼接</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#特征缺失值的处理"><span class="post-toc-number">2.2.2.</span> <span class="post-toc-text">特征缺失值的处理</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#文本数据的清洗"><span class="post-toc-number">2.2.3.</span> <span class="post-toc-text">文本数据的清洗</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#特征工程"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">特征工程</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#特征变换"><span class="post-toc-number">2.3.1.</span> <span class="post-toc-text">特征变换</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#特征编码"><span class="post-toc-number">2.3.2.</span> <span class="post-toc-text">特征编码</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#模型训练和验证"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">模型训练和验证</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#模型选择"><span class="post-toc-number">2.4.1.</span> <span class="post-toc-text">模型选择</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#调参和模型验证"><span class="post-toc-number">2.4.2.</span> <span class="post-toc-text">调参和模型验证</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#适当利用-Public-LB-的反馈"><span class="post-toc-number">2.4.3.</span> <span class="post-toc-text">适当利用 Public LB 的反馈</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#模型集成"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">模型集成</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Averaging-和-Voting"><span class="post-toc-number">2.5.1.</span> <span class="post-toc-text">Averaging 和 Voting</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Stacking"><span class="post-toc-number">2.5.2.</span> <span class="post-toc-text">Stacking</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Blending"><span class="post-toc-number">2.5.3.</span> <span class="post-toc-text">Blending</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Bagging-Ensemble-Selection"><span class="post-toc-number">2.5.4.</span> <span class="post-toc-text">Bagging Ensemble Selection</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#自动化框架"><span class="post-toc-number">2.6.</span> <span class="post-toc-text">自动化框架</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-tx往届心得"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">tx往届心得</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-04-17 16:49:47" datetime="2019-04-17T08:49:47.000Z"  itemprop="datePublished">2019-04-17</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/知识总结/">知识总结</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="stacking技术分享"><a href="#stacking技术分享" class="headerlink" title="stacking技术分享"></a>stacking技术分享</h1><p>stacking不能称为一种算法，而是一种对模型的集成策略。在给定数据集的情况下，数据内部的空间结构和数据之间的关系是非常复杂得。不同的模型，其实很重要的一点就是在不同的角度去观测数据集。stacking框架就是用来取长补短进行结合的。</p>
<p>假设是五折的stacking，我们有一个train数据集和一个test数据集，那么一个基本的stacking框架会进行如下几个操作：</p>
<ol>
<li>选择基模型。我们可以有xgboost，lightGBM，RandomForest，SVM，ANN，KNN，LR等等你能想到的各种基本算法模型。</li>
<li>把训练集分为不交叉的五份。我们标记为train1到train5。</li>
<li>从train1开始作为预测集，使用train2到train5建模，然后预测train1，并保留结果；然后，以train2作为预测集，使用train1，train3到train5建模，预测train2，并保留结果；如此进行下去，直到把train1到train5各预测一遍；</li>
<li>把预测的结果按照train1到trian5的位置对应填补上，得到对train整个数据集在第一个基模型的一个stacking转换。</li>
<li>在上述建立的五个模型过程中，每个模型分别对test数据集进行预测，并最终保留这五列结果，然后对这五列取平均，作为第一个基模型对test数据的一个stacking转换。</li>
<li>选择第二个基模型，重复以上2-5操作，再次得到train整个数据集在第二个基模型的一个stacking转换。</li>
<li>以此类推。有几个基模型，就会对整个train数据集生成几列新的特征表达。同样，也会对test有几列新的特征表达。</li>
<li>一般使用LR作为第二层的模型进行建模预测。</li>
</ol>
<p><img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.32.08.png" alt=""><br>上面这个框架说明的是：对训练数据进行无重复的五次划分之后，分别对其中每一部分进行一次预测，而预测的模型就是由其余四部分训练的；并且在预测了预测集之后，还需要对我们的test数据集也进行一次预测，这这样就会得到5个N/5行、1列的对train数据集的特征转换，和5个M行、1列的对test数据集的特征转换，由此进入下一个图。<br><img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.33.39.png" alt=""></p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>1.stacking的框架设计比较复杂，对于一个基模型要训练5次，如果你的一个xgb模型要训练2个小时，即使在进行stacking的时候每折减少了五分之一的数据量，你的计算时间仍然是很可观的，加起来应该还是8-9小时，所以耗费时间很长（想像一下一个stacking框架跑一个基模型要大半天，简直太可怕）。所以建议大家在使用的时候要计算时间的耗费，或者可以改为3折，4折等等；</p>
<p>2、我们前面讲过了，stacking框架是集成了不同的算法，充分利用不同算法从不同的数据空间角度和数据结构角度的对数据的不同观测，来取长补短，优化结果。所以，我们的基模型除了是不同参数的相同模型之外，比如不同参数的xgboost，或者不同K值的KNN等等；更重要的是要尽可能的多加一些不同种类的基模型进去，也就是说所谓的模型要“跨越空间”的概念。这样的话我们的集成结果会更加稳健，更加精确。（曾经有一个比赛集成了上百个基模型的stacking框架获奖）</p>
<h2 id="基本变种改进"><a href="#基本变种改进" class="headerlink" title="基本变种改进"></a>基本变种改进</h2><p>在变种改进方面，我们可以不仅对模型进行融合，还可以对特征级进行一些变化，比如选部分特征做stacking；或者对stacking的结果进行再次的stacking，上面介绍的是两层的stacking，可以有3层，或者更多。但是时间复杂度很高，效果并不一定明显。</p>
<h1 id="Kaggle数据挖掘比赛经验分享"><a href="#Kaggle数据挖掘比赛经验分享" class="headerlink" title="Kaggle数据挖掘比赛经验分享"></a>Kaggle数据挖掘比赛经验分享</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzIzMzgzOTUxNA==&amp;mid=2247483678&amp;idx=1&amp;sn=5f044dabfaa726e292686287a1dd5ca4&amp;chksm=e8fecfebdf8946fdabf71fd5c4c0e019144f105da993c12fa257c64f281ecfb3a7557f16b79e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【干货】Kaggle 数据挖掘比赛经验分享</a><br>一个完整的数据挖掘比赛基本流程如下：<br><img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/640.png" alt=""></p>
<h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><p>通过对数据进行探索性分析（甚至有些情况下需要肉眼观察样本），还可以有助于启发数据清洗和特征抽取，譬如缺失值和异常值的处理，文本数据是否需要进行拼写纠正等。</p>
<h3 id="分析特征变量的分布"><a href="#分析特征变量的分布" class="headerlink" title="分析特征变量的分布"></a>分析特征变量的分布</h3><ol>
<li><strong>特征变量</strong>为连续值：如果为长尾分布并且考虑使用线性模型，可以对变量进行幂变换或者对数变换。</li>
<li><strong>特征变量</strong>为离散值：观察每个离散值的频率分布，对于频次较低的特征，可以考虑统一编码为“其他”类别。</li>
</ol>
<h3 id="分析目标变量的分布"><a href="#分析目标变量的分布" class="headerlink" title="分析目标变量的分布"></a>分析目标变量的分布</h3><ol>
<li><strong>目标变量</strong>为连续值：查看其值域范围是否较大，如果较大，可以考虑对其进行对数变换，并以变换后的值作为新的目标变量进行建模（<strong>在这种情况下，需要对预测结果进行逆变换</strong>）。一般情况下，可以对连续变量进行<strong>Box-Cox</strong>变换。通过变换可以使得模型更好的优化，通常也会带来效果上的提升。</li>
<li><strong>目标变量</strong>为离散值：如果数据分布不平衡，考虑是否需要上采样/下采样；如果目标变量在某个ID上面分布不平衡，在划分本地训练集和验证集的时候，需要考虑<strong>分层采样（Stratified Sampling）</strong>。</li>
</ol>
<h3 id="分析变量之间两两的分布和相关度"><a href="#分析变量之间两两的分布和相关度" class="headerlink" title="分析变量之间两两的分布和相关度"></a>分析变量之间两两的分布和相关度</h3><ol>
<li>可以用于发现高相关和共线性的特征。</li>
</ol>
<h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><p>数据清洗是指对提供的原始数据进行一定的加工，使得其方便后续的特征抽取。其与特征抽取的界限有时也没有那么明确。常用的数据清洗一般包括：</p>
<h3 id="数据的拼接"><a href="#数据的拼接" class="headerlink" title="数据的拼接"></a>数据的拼接</h3><ol>
<li>提供的数据散落在多个文件，需要根据相应的键值进行数据的拼接。</li>
</ol>
<h3 id="特征缺失值的处理"><a href="#特征缺失值的处理" class="headerlink" title="特征缺失值的处理"></a>特征缺失值的处理</h3><ol>
<li>特征值为连续值：按不同的分布类型对缺失值进行补全：<strong>偏正态分布</strong>，使用均值代替，可以保持数据的均值；<strong>偏长尾分布</strong>，使用中值代替，避免受 outlier 的影响；</li>
<li>特征值为离散值：使用众数代替。</li>
</ol>
<h3 id="文本数据的清洗"><a href="#文本数据的清洗" class="headerlink" title="文本数据的清洗"></a>文本数据的清洗</h3><ol>
<li>在比赛当中，如果数据包含文本，往往需要进行大量的数据清洗工作。如去除HTML 标签，分词，拼写纠正, 同义词替换，去除停词，抽词干，数字和单位格式统一等。</li>
</ol>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>有一种说法是，特征决定了效果的上限，而不同模型只是以不同的方式或不同的程度来逼近这个上限。这样来看，好的特征输入对于模型的效果至关重要，正所谓”Garbage in, garbage out”。要做好特征工程，往往跟领域知识和对问题的理解程度有很大的关系，也跟一个人的经验相关。特征工程的做法也是Case by Case，以下就一些点，谈谈自己的一些看法。</p>
<h3 id="特征变换"><a href="#特征变换" class="headerlink" title="特征变换"></a>特征变换</h3><p>主要针对一些长尾分布的特征，<strong>需要进行幂变换或者对数变换，使得模型（LR或者DNN）能更好的优化</strong>。需要注意的是，Random Forest 和 GBDT 等模型对单调的函数变换不敏感。其原因在于树模型在求解分裂点的时候，只考虑排序分位点。</p>
<h3 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h3><p>对于离散的类别特征，往往需要进行必要的特征转换/编码才能将其作为特征输入到模型中。常用的编码方式有 LabelEncoder，OneHotEncoder（sklearn里面的接口）。譬如对于”性别”这个特征（取值为男性和女性），使用这两种方式可以分别编码为{0,1}和{[1,0], [0,1]}。</p>
<p>对于取值较多（如几十万）的类别特征（ID特征），直接进行OneHotEncoder编码会导致特征矩阵非常巨大，影响模型效果。可以使用如下的方式进行处理：<br>◆ 统计每个取值在样本中出现的频率，取 Top N 的取值进行 One-hot 编码，剩下的类别分到“其他“类目下，其中 N 需要根据模型效果进行调优；<br>◆ 统计每个 ID 特征的一些统计量（譬如历史平均点击率，历史平均浏览率）等代替该 ID 取值作为特征，具体可以参考 Avazu 点击率预估比赛第二名的获奖方案；<br>◆ 参考 word2vec 的方式，将每个类别特征的取值映射到一个连续的向量，对这个向量进行初始化，跟模型一起训练。训练结束后，可以同时得到每个ID的Embedding。具体的使用方式，可以参考 Rossmann 销量预估竞赛第三名的获奖方案，<a href="https://github.com/entron/entity-embedding-rossmann。">https://github.com/entron/entity-embedding-rossmann。</a></p>
<p>对于 Random Forest 和 GBDT 等模型，如果类别特征存在较多的取值，可以直接使用 LabelEncoder 后的结果作为特征（这里应该只是将数字来代替类别，数字并不具有实际含义）。注意labelEncoder将文字变换为数字，是虚拟数据，不一定有意义，建模时要注意去除。</p>
<h2 id="模型训练和验证"><a href="#模型训练和验证" class="headerlink" title="模型训练和验证"></a>模型训练和验证</h2><h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><p>在处理好特征后，我们可以进行模型的训练和验证。<br>◆ 对于稀疏型特征（如文本特征，One-hot的ID类特征），我们一般使用线性模型，譬如 Linear Regression 或者 Logistic Regression。Random Forest 和 GBDT 等树模型不太适用于稀疏的特征，但可以先对特征进行降维（如PCA，SVD/LSA等），再使用这些特征。稀疏特征直接输入 DNN 会导致网络 weight 较多，不利于优化，也可以考虑先降维，或者对 ID 类特征使用 Embedding 的方式；<br>◆ 对于稠密型特征，推荐使用 XGBoost 进行建模，简单易用效果好；<br>◆ 数据中既有稀疏特征，又有稠密特征，可以考虑使用线性模型对稀疏特征进行建模，将其输出与稠密特征一起再输入 XGBoost/DNN 建模，具体可以参考Stacking 部分。</p>
<h3 id="调参和模型验证"><a href="#调参和模型验证" class="headerlink" title="调参和模型验证"></a>调参和模型验证</h3><p>对于选定的特征和模型，我们往往还需要对模型进行超参数的调优，才能获得比较理想的效果。调参一般可以概括为以下三个步骤：</p>
<p>1.<strong>训练集和验证集的划分。</strong>根据比赛提供的训练集和测试集，模拟其划分方式对训练集进行划分为本地训练集和本地验证集。划分的方式视具体比赛和数据而定，常用的方式有：<br>a) 随机划分：譬如随机采样 70% 作为训练集，剩余的 30% 作为测试集。在这种情况下，本地可以采用 KFold 或者 Stratified KFold 的方法来构造训练集和验证集。<br>b) 按时间划分：一般对应于时序序列数据，譬如取前 7 天数据作为训练集，后 1 天数据作为测试集。这种情况下，划分本地训练集和验证集也需要按时间先后划分。常见的错误方式是随机划分，这种划分方式可能会导致模型效果被高估。<br>c) 按某些规则划分：在 HomeDepot 搜索相关性比赛中，训练集和测试集中的 Query 集合并非完全重合，两者只有部分交集。而在另外一个相似的比赛中（CrowdFlower 搜索相关性比赛），训练集和测试集具有完全一致的 Query 集合。对于 HomeDepot 这个比赛中，训练集和验证集数据的划分，需要考虑 Query 集合并非完全重合这个情况，其中的一种方法可以参考第三名的获奖方案，<a href="https://github.com/ChenglongChen/Kaggle_HomeDepot。">https://github.com/ChenglongChen/Kaggle_HomeDepot。</a></p>
<p>2.<strong>指定参数空间</strong>。在指定参数空间的时候，需要对模型参数以及其如何影响模型的效果有一定的了解，才能指定出合理的参数空间。譬如DNN或者XGBoost中学习率这个参数，一般就选 0.01 左右就 OK 了（太大可能会导致优化算法错过最优化点，太小导致优化收敛过慢）。再如 Random Forest，一般设定树的棵数范围为 100~200 就能有不错的效果，当然也有人固定数棵数为 500，然后只调整其他的超参数。</p>
<p>3.<strong>按照一定的方法进行参数搜索</strong>。常用的参数搜索方法有，Grid Search，Random Search以及一些自动化的方法（如 Hyperopt）。其中，Hyperopt 的方法，根据历史已经评估过的参数组合的效果，来推测本次评估使用哪个参数组合更有可能获得更好的效果。</p>
<h3 id="适当利用-Public-LB-的反馈"><a href="#适当利用-Public-LB-的反馈" class="headerlink" title="适当利用 Public LB 的反馈"></a>适当利用 Public LB 的反馈</h3><p><img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%8810.30.48.png" alt=""></p>
<h2 id="模型集成"><a href="#模型集成" class="headerlink" title="模型集成"></a>模型集成</h2><h3 id="Averaging-和-Voting"><a href="#Averaging-和-Voting" class="headerlink" title="Averaging 和 Voting"></a>Averaging 和 Voting</h3><p>直接对多个模型的预测结果求平均或者投票。对于目标变量为连续值的任务，使用平均；对于目标变量为离散值的任务，使用投票的方式。</p>
<h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><p><img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%8810.32.33.png" alt=""></p>
<ol>
<li><strong>数据集划分</strong>。将训练数据按照5-Fold进行划分（如果数据跟时间有关，需要按时间划分）</li>
<li><strong>基础模型训练 I</strong>。按照交叉验证（Cross Validation）的方法，在训练集（Training Fold）上面训练模型（如图灰色部分所示），并在验证集（Validation Fold）上面做预测，得到预测结果（如图黄色部分所示）。最后综合得到整个训练集上面的预测结果（如图第一个黄色部分的CV Prediction所示）。</li>
<li><strong>基础模型训练 II</strong>（如图5第二和三行左半部分所示）。在全量的训练集上训练模型（如图第二行灰色部分所示），并在测试集上面做预测，得到预测结果（如图第三行虚线后绿色部分所示）。</li>
<li><strong>Stage 1 模型集成训练 I</strong>（如图5第一行右半部分所示）。将步骤 2 中得到的 CV Prediction 当作新的训练集，按照步骤 2 可以得到 Stage 1模型集成的 CV Prediction。</li>
<li>Stage 1 模型集成训练 II（如图5第二和三行右半部分所示）。将步骤 2 中得到的 CV Prediction 当作新的训练集和步骤 3 中得到的 Prediction 当作新的测试集，按照步骤 3 可以得到 Stage 1 模型集成的测试集 Prediction。此为 Stage 1 的输出，可以提交至 Kaggle 验证其效果。</li>
</ol>
<p>在图5中，基础模型只展示了一个，而实际应用中，基础模型可以多种多样，如SVM，DNN，XGBoost 等。也可以相同的模型，不同的参数，或者不同的样本权重。重复4和5两个步骤，可以相继叠加 Stage 2, Stage 3 等模型。</p>
<h3 id="Blending"><a href="#Blending" class="headerlink" title="Blending"></a>Blending</h3><p>Blending 与 Stacking 类似，但单独留出一部分数据（如 20%）用于训练 Stage X 模型。</p>
<h3 id="Bagging-Ensemble-Selection"><a href="#Bagging-Ensemble-Selection" class="headerlink" title="Bagging Ensemble Selection"></a>Bagging Ensemble Selection</h3><p>Bagging Ensemble Selection [5] 是我在 CrowdFlower 搜索相关性比赛中使用的方法，其主要的优点在于可以以优化任意的指标来进行模型集成。这些指标可以是可导的（如 LogLoss 等）和不可导的（如正确率，AUC，Quadratic Weighted Kappa等）。它是一个前向贪婪算法，存在过拟合的可能性，作者在文献 [5] 中提出了一系列的方法（如 Bagging）来降低这种风险，稳定集成模型的性能。使用这个方法，需要有成百上千的基础模型。为此，在 CrowdFlower 的比赛中，我把在调参过程中所有的中间模型以及相应的预测结果保留下来，作为基础模型。这样做的好处是，不仅仅能够找到最优的单模型（Best Single Model），而且所有的中间模型还可以参与模型集成，进一步提升效果。</p>
<h2 id="自动化框架"><a href="#自动化框架" class="headerlink" title="自动化框架"></a>自动化框架</h2><p>这份代码开源在 Github 上面，目前是 Github 有关 Kaggle 竞赛解决方案的 Most Stars，地址：<a href="https://github.com/ChenglongChen/Kaggle_CrowdFlower。">https://github.com/ChenglongChen/Kaggle_CrowdFlower。</a></p>
<p>其主要包含以下部分：</p>
<p>1.模块化特征工程<br>a) 接口统一，只需写少量的代码就能够生成新的特征；<br>b) 自动将单独的特征拼接成特征矩阵。</p>
<p>2.自动化模型调参和验证<br>a) 自定义训练集和验证集的划分方法；<br>b) 使用 Grid Search / Hyperopt 等方法，对特定的模型在指定的参数空间进行调优，并记录最佳的模型参数以及相应的性能。</p>
<p>3.自动化模型集成<br>a) 对于指定的基础模型，按照一定的方法（如Averaging_Stacking_Blending 等）生成集成模型。</p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2019-04-17T02:57:36.000Z" itemprop="dateUpdated">2019-04-17 10:57:36</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="https://github.com/zdkswd">
            <img src="/img/tmg.jpg" alt="ZDK">
            ZDK
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>


            


        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2019/04/17/PyTorch get started/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">PyTorch get started</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/04/17/LightGBM Python quick start/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">LightGBM Python quick start</h4>
      </a>
    </div>
  
</nav>



    











    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'true' == 'true',
            verify: 'false' == 'true',
            appId: "QiU7UFIdgTTauFTk89N47mQS-gzGzoHsz",
            appKey: "gkBx5soQkBREmER84PWbNJeM",
            avatar: "mm",
            placeholder: "ヾﾉ≧∀≦)o来啊，快活啊!",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->







</article>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>ZDK &copy; 2017 - 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
    <span id="busuanzi_container_site_uv">
        本站访客数<span id="busuanzi_value_site_uv"></span>人次
      </span>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
    </script>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: false, REWARD: false };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'zdk'blog';
            clearTimeout(titleTime);
        } else {
            document.title = '';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
