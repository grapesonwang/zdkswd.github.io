<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>Hadoop综述 | ZDK&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="大数据">
    <meta name="description" content="大数据发展的历史2004 Google发表的三篇论文，“三驾马车”，分别是分布式文件系统GFS、大数据分布式计算框架MapReduce和NoSQL数据库系统BigTable。 一个文件系统，一个计算框架，一个数据库系统。Hadoop，主要包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。 Facebook发布了Hive，支持SQL语法来进行大数据计算。 在Hadoop早期，">
<meta name="keywords" content="大数据">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop综述">
<meta property="og:url" content="https://github.com/zdkswd/2019/07/09/大数据综述/index.html">
<meta property="og:site_name" content="ZDK&#39;s blog">
<meta property="og:description" content="大数据发展的历史2004 Google发表的三篇论文，“三驾马车”，分别是分布式文件系统GFS、大数据分布式计算框架MapReduce和NoSQL数据库系统BigTable。 一个文件系统，一个计算框架，一个数据库系统。Hadoop，主要包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。 Facebook发布了Hive，支持SQL语法来进行大数据计算。 在Hadoop早期，">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://github.com/img/add/36.png">
<meta property="og:image" content="https://github.com/img/add/37.png">
<meta property="og:image" content="https://github.com/img/add/38.png">
<meta property="og:image" content="https://github.com/img/add/39.png">
<meta property="og:image" content="https://github.com/img/add/40.png">
<meta property="og:image" content="https://github.com/img/add/41.png">
<meta property="og:image" content="https://github.com/img/add/42.png">
<meta property="og:image" content="https://github.com/img/add/43.png">
<meta property="og:image" content="https://github.com/img/add/44.png">
<meta property="og:image" content="https://github.com/img/add/45.png">
<meta property="og:updated_time" content="2019-07-09T14:17:16.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop综述">
<meta name="twitter:description" content="大数据发展的历史2004 Google发表的三篇论文，“三驾马车”，分别是分布式文件系统GFS、大数据分布式计算框架MapReduce和NoSQL数据库系统BigTable。 一个文件系统，一个计算框架，一个数据库系统。Hadoop，主要包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。 Facebook发布了Hive，支持SQL语法来进行大数据计算。 在Hadoop早期，">
<meta name="twitter:image" content="https://github.com/img/add/36.png">
    
        <link rel="alternate" type="application/atom+xml" title="ZDK&#39;s blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/tmg.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">ZDK</h5>
          <a href="mailto:2822464407@qq.com" title="2822464407@qq.com" class="mail">2822464407@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/zdkswd" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Hadoop综述</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Hadoop综述</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-07-09T02:16:47.000Z" itemprop="datePublished" class="page-time">
  2019-07-09
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/知识总结/">知识总结</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#大数据发展的历史"><span class="post-toc-number">1.</span> <span class="post-toc-text">大数据发展的历史</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#处理PB级数据"><span class="post-toc-number">2.</span> <span class="post-toc-text">处理PB级数据</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#垂直伸缩到水平伸缩"><span class="post-toc-number">3.</span> <span class="post-toc-text">垂直伸缩到水平伸缩</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#HDFS"><span class="post-toc-number">4.</span> <span class="post-toc-text">HDFS</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#MapReduce概述"><span class="post-toc-number">5.</span> <span class="post-toc-text">MapReduce概述</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MapReduce作业启动和运行机制"><span class="post-toc-number">5.1.</span> <span class="post-toc-text">MapReduce作业启动和运行机制</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#MapReduce数据合并与连接机制"><span class="post-toc-number">5.2.</span> <span class="post-toc-text">MapReduce数据合并与连接机制</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#资源调度框架Yarn"><span class="post-toc-number">6.</span> <span class="post-toc-text">资源调度框架Yarn</span></a></li></ol>
        </nav>
    </aside>


<article id="post-大数据综述"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Hadoop综述</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-07-09 10:16:47" datetime="2019-07-09T02:16:47.000Z"  itemprop="datePublished">2019-07-09</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/知识总结/">知识总结</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="大数据发展的历史"><a href="#大数据发展的历史" class="headerlink" title="大数据发展的历史"></a>大数据发展的历史</h1><p>2004 Google发表的三篇论文，“三驾马车”，分别是<strong>分布式文件系统GFS</strong>、<strong>大数据分布式计算框架MapReduce</strong>和<strong>NoSQL数据库系统BigTable。</strong></p>
<p>一个文件系统，一个计算框架，一个数据库系统。Hadoop，主要包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。</p>
<p>Facebook发布了<strong>Hive</strong>，支持SQL语法来进行大数据计算。</p>
<p>在Hadoop早期，MapReduce既是一个执行引擎，又是一个资源调度框架，服务器集群的资源调度管理由MapReduce完成。这样不利于资源复用，也使得MapReduce非常臃肿。于是一个新项目启动了，将MapReduce执行引擎和资源调度分离开来，这就是<strong>Yarn</strong>。<strong>2012年，Yarn成为一个独立的项目开始运营，随后被各类大数据产品支持，成为大数据平台上最主流的资源调度系统</strong>。</p>
<p>MapReduce进行机器学习计算的时候性能非常差，因为机器学习算法通常需要进行很多次的迭代计算，而MapReduce每执行一次Map和Reduce计算都需要重新启动一次作业，带来大量的无谓消耗。还有一点就是MapReduce主要使用磁盘作为存储介质，而2012年的时候，内存已经突破容量和成本限制，成为数据运行过程中主要的存储介质。<strong>Spark</strong>一经推出，立即受到业界的追捧，并逐步替代MapReduce在企业应用中的地位。</p>
<p>一般说来，像MapReduce、Spark这类计算框架处理的业务场景都被称作<strong>批处理计算</strong>，因为它们通常针对以“天”为单位产生的数据进行一次计算，然后得到需要的结果，这中间计算需要花费的时间大概是几十分钟甚至更长的时间。因为计算的数据是非在线得到的实时数据，而是历史数据，所以这类计算也被称为<strong>大数据离线计算</strong>。</p>
<p>而在大数据领域，还有另外一类应用场景，需要对实时产生的大量数据进行即时计算。这类计算称为<strong>大数据流计算</strong>，相应地，有Storm、Flink、Spark Streaming等流计算框架来满足此类大数据应用的场景。 流式计算要处理的数据是实时在线产生的数据，所以这类计算也被称为<strong>大数据实时计算</strong>。</p>
<p>在典型的大数据的业务场景下，数据业务最通用的做法是，采用批处理的技术处理历史全量数据，采用流式计算处理实时新增数据。而像Flink这样的计算引擎，可以同时支持流式计算和批处理计算。</p>
<p>除了大数据批处理和流处理，NoSQL系统处理的主要也是大规模海量数据的存储与访问，所以也被归为大数据技术。 NoSQL曾经在2011年左右非常火爆，涌现出HBase、Cassandra等许多优秀的产品，其中HBase是从Hadoop中分离出来的、基于HDFS的NoSQL系统。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/36.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h1 id="处理PB级数据"><a href="#处理PB级数据" class="headerlink" title="处理PB级数据"></a>处理PB级数据</h1><p>网站实时处理通常针对单个用户的请求操作，虽然大型网站面临大量的高并发请求，比如天猫的“双十一”活动。但是每个用户之间的请求是独立的，只要网站的分布式系统能将不同用户的不同业务请求分配到不同的服务器上，只要这些分布式的服务器之间耦合关系足够小，就可以通过添加更多的服务器去处理更多的用户请求及由此产生的用户数据。这也正是网站系统架构的<strong>核心原理</strong>。</p>
<p><strong>大数据计算处理通常针对的是网站的存量数据</strong>，也就是刚才我提到的全部用户在一段时间内请求产生的数据，这些数据之间是有大量关联的，比如购买同一个商品用户之间的关系，这是使用协同过滤进行商品推荐；比如同一件商品的历史销量走势，这是对历史数据进行统计分析。<strong>网站大数据系统要做的就是将这些统计规律和关联关系计算出来，并由此进一步改善网站的用户体验和运营决策</strong>。</p>
<p>这套方案的核心思路是，既然数据是庞大的，而程序要比数据小得多，将数据输入给程序是不划算的，那么就反其道而行之，<strong>将程序分发到数据所在的地方进行计算，也就是所谓的移动计算比移动数据更划算</strong>。</p>
<p>两台计算机要想合作构成一个系统，必须要在技术上重新架构。这就是现在互联网企业广泛使用的负载均衡、分布式缓存、分布式数据库、分布式服务等种种分布式系统。</p>
<p>移动计算程序到数据所在位置进行计算的实现：</p>
<ol>
<li>将待处理的大规模数据存储在服务器集群的所有服务器上，主要使用HDFS分布式文件存储系统，将文件分成很多块（Block），以块为单位存储在集群的服务器上。</li>
<li>将待处理的大规模数据存储在服务器集群的所有服务器上，主要使用HDFS分布式文件存储系统，将文件分成很多块（Block），以块为单位存储在集群的服务器上。</li>
<li>使用大数据计算框架支持的编程模型进行编程，比如Hadoop的MapReduce编程模型，或者Spark的RDD编程模型。应用程序编写好以后，将其打包，MapReduce和Spark都是在JVM环境中运行，所以打包出来的是一个Java的JAR包。</li>
<li>用Hadoop或者Spark的启动命令执行这个应用程序的JAR包，首先执行引擎会解析程序要处理的数据输入路径，根据输入数据量的大小，将数据分成若干片（Split），每一个数据片都分配给一个任务执行进程去处理。</li>
<li>任务执行进程收到分配的任务后，检查自己是否有任务对应的程序包，如果没有就去下载程序包，下载以后通过反射的方式加载程序。走到这里，最重要的一步，也就是移动计算就完成了。</li>
<li>加载程序后，任务执行进程根据分配的数据片的文件地址和数据在文件内的偏移量读取数据，并把数据输入给应用程序相应的方法去执行，从而实现在分布式服务器集群中移动计算程序，对大规模数据进行并行处理的计算目标。</li>
</ol>
<p>杀毒软件从服务器更新病毒库，然后在Windows内查杀病毒，就是一种移动计算（病毒库）比移动数据（Windows可能感染病毒的程序）更划算的例子。</p>
<h1 id="垂直伸缩到水平伸缩"><a href="#垂直伸缩到水平伸缩" class="headerlink" title="垂直伸缩到水平伸缩"></a>垂直伸缩到水平伸缩</h1><p>大规模数据存储都需要解决几个核心问题：</p>
<p>1.<strong>数据存储容量的问题</strong>。是数以PB计的数据计算问题，而一般的服务器磁盘容量通常1～2TB，如何存储这么大规模的数据呢？</p>
<p>2.<strong>数据读写速度的问题</strong>。一般磁盘的连续读写速度为几十MB，以这样的速度，几十PB的数据恐怕要读写到天荒地老。</p>
<p>3.<strong>数据可靠性的问题</strong>。磁盘大约是计算机设备中最易损坏的硬件了，通常情况一块磁盘使用寿命大概是一年，如果磁盘损坏了，数据怎么办？</p>
<p>RAID（独立磁盘冗余阵列）技术是将多块普通磁盘组成一个阵列，共同对外提供服务。主要是为了改善磁盘的存储容量、读写速度，增强磁盘的可用性和容错能力。</p>
<p>目前服务器级别的计算机都支持插入多块磁盘（8块或者更多），通过使用RAID技术，实现数据在多块磁盘上的并发读写和数据备份。</p>
<p><strong>RAID 0</strong>是数据在从内存缓冲区写入磁盘时，根据磁盘数量将数据分成N份，这些数据同时并发写入N块磁盘，使得数据整体写入速度是一块磁盘的N倍；读取的时候也一样，因此RAID 0具有极快的数据读写速度。但是RAID 0不做数据备份，N块磁盘中只要有一块损坏，数据完整性就被破坏，其他磁盘的数据也都无法使用了。</p>
<p><strong>RAID 1</strong>是数据在写入磁盘时，将一份数据同时写入两块磁盘，这样任何一块磁盘损坏都不会导致数据丢失，插入一块新磁盘就可以通过复制数据的方式自动修复，具有极高的可靠性。</p>
<p>结合RAID 0和RAID 1两种方案构成了<strong>RAID 10</strong>，它是将所有磁盘N平均分成两份，数据同时在两份磁盘写入，相当于RAID 1；但是平分成两份，在每一份磁盘（也就是N/2块磁盘）里面，利用RAID 0技术并发读写，这样既提高可靠性又改善性能。不过RAID 10的磁盘利用率较低，有一半的磁盘用来写备份数据。</p>
<p><strong>RAID 3</strong>可以在数据写入磁盘的时候，将数据分成N-1份，并发写入N-1块磁盘，并在第N块磁盘记录校验数据，这样任何一块磁盘损坏（包括校验数据磁盘），都可以利用其他N-1块磁盘的数据修复。但是在数据修改较多的场景中，任何磁盘数据的修改，都会导致第N块磁盘重写校验数据。频繁写入的后果是第N块磁盘比其他磁盘更容易损坏，需要频繁更换，所以RAID 3很少在实践中使用。</p>
<p>相比RAID 3，<strong>RAID 5</strong>是使用更多的方案。RAID 5和RAID 3很相似，但是校验数据不是写入第N块磁盘，而是螺旋式地写入所有磁盘中。这样校验数据的修改也被平均到所有磁盘上，避免RAID 3频繁写坏一块磁盘的情况。</p>
<p><strong>RAID 6</strong>和RAID 5类似，但是数据只写入N-2块磁盘，并螺旋式地在两块磁盘中写入校验信息（使用不同算法生成）。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/37.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>RAID可以看作是一种垂直伸缩，一台计算机集成更多的磁盘实现数据更大规模、更安全可靠的存储以及更快的访问速度。而HDFS则是水平伸缩，通过添加更多的服务器实现数据更大、更快、更安全存储与访问。<strong>将RAID思想原理应用到分布式服务器集群上，就形成了Hadoop分布式文件系统HDFS的架构思想</strong>。</p>
<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p>Hadoop的第一个产品是HDFS，可以说分布式文件存储是分布式计算的基础，也可见分布式文件存储的重要性。<strong>HDFS也许不是最好的大数据存储技术，但依然最重要的大数据存储技术</strong>。</p>
<p>HDFS是在一个大规模分布式服务器集群上，对数据分片后进行并行读写及冗余存储。因为HDFS可以部署在一个比较大的服务器集群上，集群中所有服务器的磁盘都可供HDFS使用，所以整个HDFS的存储空间可以达到PB级容量。<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/38.png" alt="img" title="">
                </div>
                <div class="image-caption">img</div>
            </figure></p>
<p>两个关键组件：<strong>DataNode</strong>和<strong>NameNode</strong>。</p>
<p><strong>DataNode负责文件数据的存储和读写操作，HDFS将文件数据分割成若干数据块（Block），每个DataNode存储一部分数据块，这样文件就分布存储在整个HDFS服务器集群中</strong>。应用程序客户端（Client）可以并行对这些数据块进行访问，从而使得HDFS可以在服务器集群规模上实现数据并行访问，极大地提高了访问速度。在实践中，HDFS集群的DataNode服务器会有很多台，一般在几百台到几千台这样的规模，每台服务器配有数块磁盘，整个集群的存储容量大概在几PB到数百PB。</p>
<p><strong>NameNode负责整个分布式文件系统的元数据（MetaData）管理，也就是文件路径名、数据块的ID以及存储位置等信息，相当于操作系统中文件分配表（FAT）的角色</strong>。HDFS为了保证数据的高可用，会将一个数据块复制为多份（缺省情况为3份），并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上。这样当有磁盘损坏，或者某个DataNode服务器宕机，甚至某个交换机宕机，导致其存储的数据块不能访问的时候，客户端会查找其备份的数据块进行访问。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/39.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中对于文件/ users / sameerp / data / part-0，其复制备份数设置为2，存储的BlockID分别为1、3。Block1的两个备份存储在DataNode0和DataNode2两个服务器上，Block3的两个备份存储DataNode4和DataNode6两个服务器上，上述任何一台服务器宕机后，每个数据块都至少还有一个备份存在，不会影响对文件/ users / sameerp / data / part-0的访问。</p>
<p>和RAID一样，数据分成若干数据块后存储到不同服务器上，可以实现数据大容量存储，并且不同分片的数据可以并行进行读/写操作，进而实现数据的高速访问。你可以看到，HDFS的<strong>大容量存储</strong>和<strong>高速访问</strong>相对比较容易实现，下面就是关于HDFS的<strong>高可用</strong>设计。</p>
<ol>
<li><strong>数据存储故障容错</strong>，磁盘介质在存储过程中受环境或者老化影响，其存储的数据可能会出现错乱。HDFS的应对措施是，对于存储在DataNode上的数据块，计算并存储校验和（CheckSum）。在读取数据的时候，重新计算读取出来的数据的校验和，如果校验不正确就抛出异常，应用程序捕获异常后就到其他DataNode上读取备份数据。</li>
<li><strong>磁盘故障容错</strong>，如果DataNode监测到本机的某块磁盘损坏，就将该块磁盘上存储的所有BlockID报告给NameNode，NameNode检查这些数据块还在哪些DataNode上有备份，通知相应的DataNode服务器将对应的数据块复制到其他服务器上，以保证数据块的备份数满足要求。</li>
<li><strong>DataNode故障容错</strong>，DataNode会通过心跳和NameNode保持通信，如果DataNode超时未发送心跳，NameNode就会认为这个DataNode已经宕机失效，立即查找这个DataNode上存储的数据块有哪些，以及这些数据块还存储在哪些服务器上，随后通知这些服务器再复制一份数据块到其他服务器上，保证HDFS存储的数据块备份数符合用户设置的数目，即使再出现服务器宕机，也不会丢失数据。</li>
<li><strong>NameNode故障容错</strong>，NameNode是整个HDFS的核心，记录着HDFS文件分配表信息，所有的文件路径和数据块存储信息都保存在NameNode，如果NameNode故障，整个HDFS系统集群都无法使用；如果NameNode上记录的数据丢失，整个集群所有DataNode存储的数据也就没用了。所以，NameNode高可用容错能力非常重要。NameNode采用主从热备的方式提供高可用服务。</li>
</ol>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/40.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>集群部署两台NameNode服务器，一台作为主服务器提供服务，一台作为从服务器进行热备，两台服务器通过ZooKeeper选举，主要是通过争夺znode锁资源，决定谁是主服务器。而DataNode则会向两个NameNode同时发送心跳数据，但是只有主NameNode才能向DataNode返回控制信息。</p>
<p>正常运行期间，主从NameNode之间通过一个共享存储系统shared edits来同步文件系统的元数据信息。当主NameNode服务器宕机，从NameNode会通过ZooKeeper升级成为主服务器，并保证HDFS集群的元数据信息，也就是文件分配表信息完整一致。</p>
<p>分布式系统可能出故障地方又非常多，内存、CPU、主板、磁盘会损坏，服务器会宕机，网络会中断，机房会停电，所有这些都可能会引起软件系统的不可用，甚至数据永久丢失。<br><strong>常用的保证系统可用性的策略有冗余备份、失效转移和降级限流。</strong></p>
<ol>
<li><strong>冗余备份</strong>，任何程序、任何数据，都至少要有一个备份，也就是说程序至少要部署到两台服务器，数据至少要备份到另一台服务器上。此外，稍有规模的互联网企业都会建设多个数据中心，数据中心之间互相进行备份，用户请求可能会被分发到任何一个数据中心，即所谓的异地多活，在遭遇地域性的重大故障和自然灾害的时候，依然保证应用的高可用。</li>
<li><strong>失效转移</strong>，当要访问的程序或者数据无法访问时，需要将访问请求转移到备份的程序或者数据所在的服务器上。失效转移应该注意的是<strong>失效的鉴定</strong>，像NameNode这样主从服务器管理同一份数据的场景，如果从服务器错误地以为主服务器宕机而接管集群管理，会出现主从服务器一起对DataNode发送指令，进而导致集群混乱，也就是所谓的“<strong>脑裂</strong>”。这也是这类场景选举主服务器时，引入ZooKeeper的原因。</li>
<li>当大量的用户请求或者数据处理请求到达的时候，由于计算资源有限，可能无法处理如此大量的请求，进而导致资源耗尽，系统崩溃。这种情况下，可以拒绝部分请求，即进行<strong>限流</strong>；也可以关闭部分功能，降低资源消耗，即进行<strong>降级</strong>。限流是互联网应用的常备功能，因为超出负载能力的访问流量在何时会突然到来，根本无法预料，所以必须提前做好准备，当遇到突发高峰流量时，就可以立即启动限流。而降级通常是为可预知的场景准备的，比如电商的“双十一”促销，为了保障促销活动期间应用的核心功能能够正常运行，比如下单功能，可以对系统进行降级处理，关闭部分非重要功能，比如商品评价功能。</li>
</ol>
<p>HDFS是通过大规模分布式服务器集群实现数据的大容量、高速、可靠存储、访问的。</p>
<ol>
<li>文件数据以数据块的方式进行切分，数据块可以存储在集群任意DataNode服务器上，所以HDFS存储的文件可以非常大，一个文件理论上可以占据整个HDFS服务器集群上的所有磁盘，实现了大容量存储。</li>
<li>HDFS一般的访问模式是通过MapReduce程序在计算时读取，MapReduce对输入数据进行分片读取，通常一个分片就是一个数据块，每个数据块分配一个计算进程，这样就可以同时启动很多进程对一个HDFS文件的多个数据块进行并发访问，从而实现数据的高速访问。</li>
<li>DataNode存储的数据块会进行复制，使每个数据块在集群里有多个备份，保证了数据的可靠性，并通过一系列的故障容错手段实现HDFS系统中主要组件的高可用，进而保证数据和整个系统的高可用。</li>
</ol>
<h1 id="MapReduce概述"><a href="#MapReduce概述" class="headerlink" title="MapReduce概述"></a>MapReduce概述</h1><p><strong>MapReduce既是一个编程模型，又是一个计算框架</strong>。开发人员必须基于MapReduce编程模型进行编程开发，然后将程序通过MapReduce计算框架分发到Hadoop集群中运行。</p>
<p>其编程模型只包含Map和Reduce两个过程，map的主要输入是一对&lt;Key, Value&gt;值，经过map计算后输出一对&lt;Key, Value&gt;值；然后将相同Key合并，形成&lt;Key, Value集合&gt;；再将这个&lt;Key, Value集合&gt;输入reduce，经过计算输出零个或多个&lt;Key, Value&gt;对。</p>
<p>MapReduce非常强大的，不管是关系代数运算（SQL计算），还是矩阵运算（图计算），大数据领域几乎所有的计算需求都可以通过MapReduce编程来实现。</p>
<p>以wordcount为例</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/41.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>少量数据一个哈希表就能够完成。MapReduce版本WordCount程序的核心是一个map函数和一个reduce函数。</p>
<p><strong>map函数</strong>的输入主要是一个&lt;Key, Value&gt;对，map函数的计算过程是，将这行文本中的单词提取出来，针对每个单词输出一个&lt;word, 1&gt;这样的&lt;Key, Value&gt;对。</p>
<p>MapReduce计算框架会将这些<word 1="" ,="">收集起来，将相同的word放在一起，形成&lt;word , &lt;1,1,1,1,1,1,1…&gt;&gt;这样的&lt;Key, Value集合&gt;数据，然后将其输入给reduce函数。</word></p>
<p>这里<strong>reduce</strong>的输入参数Values就是由很多个1组成的集合，而Key就是具体的单词word。reduce函数的计算过程是，将这个集合里的1求和，再将单词（word）和这个和（sum）组成一个&lt;Key, Value&gt;，也就是&lt;word, sum&gt;输出。每一个输出就是一个单词和它的词频统计总和。</p>
<p>一个map函数可以针对一部分数据进行运算，这样就可以将一个大数据切分成很多块（这也正是HDFS所做的），MapReduce计算框架为每个数据块分配一个map函数去计算，从而实现大数据的分布式计算。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/42.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>红圈对应的分别是MapReduce作业启动和运行，以及MapReduce数据合并与连接。</p>
<h2 id="MapReduce作业启动和运行机制"><a href="#MapReduce作业启动和运行机制" class="headerlink" title="MapReduce作业启动和运行机制"></a>MapReduce作业启动和运行机制</h2><p>MapReduce运行过程涉及三类关键进程。</p>
<ol>
<li><strong>大数据应用进程</strong>。这类进程是启动MapReduce程序的主入口，主要是指定Map和Reduce类、输入输出文件路径等，并提交作业给Hadoop集群，比如WordCount程序。</li>
<li><strong>JobTracker进程</strong>。这类进程根据要处理的输入数据量，命令<strong>TaskTracker</strong>进程启动相应数量的Map和Reduce进程任务，并管理整个作业生命周期的任务调度和监控。这是Hadoop集群的<strong>常驻进程</strong>，需要注意的是，JobTracker进程在整个Hadoop集群<strong>全局唯一</strong>。</li>
<li><strong>TaskTracker进程</strong>。这个进程负责启动和管理Map进程以及Reduce进程。因为需要每个数据块都有对应的map函数，TaskTracker进程通常和HDFS的DataNode进程启动在同一个服务器。也就是说，Hadoop集群中绝大多数服务器同时运行DataNode进程和TaskTracker进程。</li>
</ol>
<p><strong>JobTracker</strong>进程和<strong>TaskTracker</strong>进程是主从关系，MapReduce的主服务器就是JobTracker，从服务器就是TaskTracker。HDFS也是主从架构吗，HDFS的主服务器是NameNode，从服务器是DataNode。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/43.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>计算流程为：</p>
<ol>
<li>应用进程JobClient将用户作业JAR包存储在HDFS中，将来这些JAR包会分发给Hadoop集群中的服务器执行MapReduce计算。</li>
<li>应用程序提交job作业给JobTracker。</li>
<li>JobTracker根据作业调度策略创建JobInProcess树，每个作业都会有一个自己的JobInProcess树。</li>
<li>JobInProcess根据输入数据分片数目（通常情况就是数据块的数目）和设置的Reduce数目创建相应数量的TaskInProcess。</li>
<li>TaskTracker进程和JobTracker进程进行定时通信。</li>
<li>如果TaskTracker有空闲的计算资源（有空闲CPU核心），JobTracker就会给它分配任务。分配任务的时候会根据TaskTracker的服务器名字匹配在同一台机器上的数据块计算任务给它，使启动的计算任务正好处理本机上的数据，以实现我们一开始就提到的“移动计算比移动数据更划算”。</li>
<li>TaskTracker收到任务后根据任务类型（是Map还是Reduce）和任务参数（作业JAR包路径、输入数据文件路径、要处理的数据在文件中的起始位置和偏移量、数据块多个备份的DataNode主机名等），启动相应的Map或者Reduce进程。</li>
<li>Map或者Reduce进程启动后，检查本地是否有要执行任务的JAR包文件，如果没有，就去HDFS上下载，然后加载Map或者Reduce代码开始执行。</li>
<li>如果是Map进程，从HDFS读取数据（通常要读取的数据块正好存储在本机）；如果是Reduce进程，将结果数据写出到HDFS。</li>
</ol>
<h2 id="MapReduce数据合并与连接机制"><a href="#MapReduce数据合并与连接机制" class="headerlink" title="MapReduce数据合并与连接机制"></a>MapReduce数据合并与连接机制</h2><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/44.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>每个Map任务的计算结果都会写入到本地文件系统，等Map任务快要计算完成的时候，MapReduce计算框架会启动<strong>shuffle</strong>过程，在Map任务进程调用一个<strong>Partitioner</strong>接口，对Map产生的每个&lt;Key, Value&gt;进行Reduce分区选择，然后通过HTTP通信发送给对应的Reduce进程。这样不管Map位于哪个服务器节点，相同的Key一定会被发送给相同的Reduce进程。Reduce任务进程对收到的&lt;Key, Value&gt;进行排序和合并，<strong>相同的Key放在一起，组成一个&lt;Key, Value集合&gt;传递给Reduce执行。</strong></p>
<p>map输出的&lt;Key, Value&gt;shuffle到哪个Reduce进程是这里的关键，它是由Partitioner来实现，<strong>MapReduce框架默认的Partitioner用Key的哈希值对Reduce任务数量取模</strong>，相同的Key一定会落在相同的Reduce任务ID上。</p>
<p><strong>分布式计算需要将不同服务器上的相关数据合并到一起进行下一步计算，这就是shuffle</strong>。</p>
<p>shuffle是大数据计算过程中最神奇的地方，不管是MapReduce还是Spark，只要是大数据批处理计算，一定都会有shuffle过程，只有<strong>让数据关联起来</strong>，数据的内在关系和价值才会呈现出来。<strong>shuffle也是整个MapReduce过程中最难、最消耗性能的地方</strong>。</p>
<h1 id="资源调度框架Yarn"><a href="#资源调度框架Yarn" class="headerlink" title="资源调度框架Yarn"></a>资源调度框架Yarn</h1><p>Hadoop主要是由三部分组成，分布式文件系统HDFS、分布式计算框架MapReduce，还有一个是<strong>分布式集群资源调度框架Yarn</strong>。</p>
<p>在MapReduce应用程序的启动过程中，最重要的就是要把MapReduce程序分发到大数据集群的服务器上，在Hadoop 1中，这个过程主要是通过TaskTracker和JobTracker通信来完成。这种架构方案的主要缺点是，<strong>服务器集群资源调度管理和MapReduce执行过程耦合在一起，如果想在当前集群中运行其他计算任务，比如Spark或者Storm，就无法统一使用集群中的资源了</strong>。</p>
<p><strong>Hadoop 2最主要的变化，</strong>就是将Yarn从MapReduce中分离出来，成为一个独立的资源调度框架。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="/img/add/45.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Yarn包括两个部分：一个是<strong>资源管理器（Resource Manager）</strong>，一个是<strong>节点管理器（Node Manager）</strong>。这也是Yarn的两种主要进程：<strong>ResourceManager进程</strong>负责整个集群的资源调度管理，<strong>通常部署在独立的服务器</strong>上；<strong>NodeManager进程</strong>负责具体服务器上的资源和任务管理，在集群的每一台计算服务器上都会启动，<strong>基本上跟HDFS的DataNode进程一起出现。</strong></p>
<hr>
<p><strong>资源管理器</strong>又包括两个主要组件：<strong>调度器</strong>和<strong>应用程序管理器</strong>。</p>
<ol>
<li><strong>调度器</strong>其实就是一个资源分配算法，根据应用程序（Client）提交的资源申请和当前服务器集群的资源状况进行资源分配。Yarn内置了几种资源调度算法，包括Fair Scheduler、Capacity Scheduler等，也可以开发自己的资源调度算法供Yarn调用。Yarn进行资源分配的单位是<strong>容器</strong>（Container），每个容器包含了一定量的内存、CPU等计算资源，默认配置下，每个容器包含一个CPU核心。<strong>容器由NodeManager进程启动和管理，NodeManger进程会监控本节点上容器的运行状况并向ResourceManger进程汇报。</strong></li>
<li><strong>应用程序管理器</strong>负责应用程序的提交、监控应用程序运行状态等。应用程序启动后需要在集群中运行一个<strong>ApplicationMaster</strong>，<strong>ApplicationMaster也需要运行在容器里面。每个应用程序启动后都会先启动自己的ApplicationMaster，由ApplicationMaster根据应用程序的资源需求进一步向ResourceManager进程申请容器资源，得到容器以后就会分发自己的应用程序代码到容器上启动，进而开始分布式计算。</strong></li>
</ol>
<hr>
<p>一个MapReduce程序，Yarn的整个工作流程：</p>
<ol>
<li>我们向Yarn提交应用程序，包括MapReduce ApplicationMaster、我们的MapReduce程序，以及MapReduce Application启动命令。</li>
<li>ResourceManager进程和NodeManager进程通信，根据集群资源，为用户程序分配第一个容器，并将MapReduce ApplicationMaster分发到这个容器上面，并在容器里面启动MapReduce ApplicationMaster。</li>
<li>MapReduce ApplicationMaster启动后立即向ResourceManager进程注册，并为自己的应用程序申请容器资源。</li>
<li>MapReduce ApplicationMaster申请到需要的容器后，立即和相应的NodeManager进程通信，将用户MapReduce程序分发到NodeManager进程所在服务器，并在容器中运行，运行的就是Map或者Reduce任务。</li>
<li>Map或者Reduce任务在运行期和MapReduce ApplicationMaster通信，汇报自己的运行状态，如果运行结束，MapReduce ApplicationMaster向ResourceManager进程注销并释放所有的容器资源。</li>
</ol>
<p>MapReduce如果想在Yarn上运行，就需要开发遵循Yarn规范的MapReduce ApplicationMaster，相应地，其他大数据计算框架也可以开发遵循Yarn规范的ApplicationMaster，这样在一个Yarn集群中就可以同时并发执行各种不同的大数据计算框架，实现资源的统一调度管理。</p>
<hr>
<p>管HDFS叫分布式文件<strong>系统</strong>，管MapReduce叫分布式计算<strong>框架</strong>，管Yarn叫分布式集群资源调度<strong>框架</strong>。</p>
<p>框架在架构设计上遵循一个重要的设计原则叫“<strong>依赖倒转原则</strong>”，依赖倒转原则是<strong>高层模块不能依赖低层模块，它们应该共同依赖一个抽象，这个抽象由高层模块定义，由低层模块实现。</strong></p>
<p>实现MapReduce编程接口、遵循MapReduce编程规范就可以被MapReduce框架调用，在分布式集群中计算大规模数据；实现了Yarn的接口规范，比如Hadoop 2的MapReduce，就可以被Yarn调度管理，统一安排服务器资源。所以说，MapReduce和Yarn都是框架。</p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2019-07-09T14:17:16.000Z" itemprop="dateUpdated">2019-07-09 22:17:16</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="https://github.com/zdkswd">
            <img src="/img/tmg.jpg" alt="ZDK">
            ZDK
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/大数据/">大数据</a></li></ul>


            


        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2019/07/14/Tomcat综述/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">Tomcat综述</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/06/28/字符串匹配算法 KMP/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">字符串匹配算法 KMP</h4>
      </a>
    </div>
  
</nav>



    











    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'true' == 'true',
            verify: 'false' == 'true',
            appId: "QiU7UFIdgTTauFTk89N47mQS-gzGzoHsz",
            appKey: "gkBx5soQkBREmER84PWbNJeM",
            avatar: "mm",
            placeholder: "ヾﾉ≧∀≦)o来啊，快活啊!",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->







</article>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>ZDK &copy; 2017 - 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
    <span id="busuanzi_container_site_uv">
        本站访客数<span id="busuanzi_value_site_uv"></span>人次
      </span>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
    </script>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: false, REWARD: false };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'zdk'blog';
            clearTimeout(titleTime);
        } else {
            document.title = '';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
