<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ZDK&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://github.com/zdkswd/"/>
  <updated>2019-04-17T02:57:36.841Z</updated>
  <id>https://github.com/zdkswd/</id>
  
  <author>
    <name>ZDK</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>tx往届心得</title>
    <link href="https://github.com/zdkswd/2019/04/17/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/"/>
    <id>https://github.com/zdkswd/2019/04/17/tx往届心得/</id>
    <published>2019-04-17T08:49:47.000Z</published>
    <updated>2019-04-17T02:57:36.841Z</updated>
    
    <content type="html"><![CDATA[<h1 id="stacking技术分享"><a href="#stacking技术分享" class="headerlink" title="stacking技术分享"></a>stacking技术分享</h1><p>stacking不能称为一种算法，而是一种对模型的集成策略。在给定数据集的情况下，数据内部的空间结构和数据之间的关系是非常复杂得。不同的模型，其实很重要的一点就是在不同的角度去观测数据集。stacking框架就是用来取长补短进行结合的。</p><p>假设是五折的stacking，我们有一个train数据集和一个test数据集，那么一个基本的stacking框架会进行如下几个操作：</p><ol><li>选择基模型。我们可以有xgboost，lightGBM，RandomForest，SVM，ANN，KNN，LR等等你能想到的各种基本算法模型。</li><li>把训练集分为不交叉的五份。我们标记为train1到train5。</li><li>从train1开始作为预测集，使用train2到train5建模，然后预测train1，并保留结果；然后，以train2作为预测集，使用train1，train3到train5建模，预测train2，并保留结果；如此进行下去，直到把train1到train5各预测一遍；</li><li>把预测的结果按照train1到trian5的位置对应填补上，得到对train整个数据集在第一个基模型的一个stacking转换。</li><li>在上述建立的五个模型过程中，每个模型分别对test数据集进行预测，并最终保留这五列结果，然后对这五列取平均，作为第一个基模型对test数据的一个stacking转换。</li><li>选择第二个基模型，重复以上2-5操作，再次得到train整个数据集在第二个基模型的一个stacking转换。</li><li>以此类推。有几个基模型，就会对整个train数据集生成几列新的特征表达。同样，也会对test有几列新的特征表达。</li><li>一般使用LR作为第二层的模型进行建模预测。</li></ol><p><img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.32.08.png" alt=""><br>上面这个框架说明的是：对训练数据进行无重复的五次划分之后，分别对其中每一部分进行一次预测，而预测的模型就是由其余四部分训练的；并且在预测了预测集之后，还需要对我们的test数据集也进行一次预测，这这样就会得到5个N/5行、1列的对train数据集的特征转换，和5个M行、1列的对test数据集的特征转换，由此进入下一个图。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.33.39.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>1.stacking的框架设计比较复杂，对于一个基模型要训练5次，如果你的一个xgb模型要训练2个小时，即使在进行stacking的时候每折减少了五分之一的数据量，你的计算时间仍然是很可观的，加起来应该还是8-9小时，所以耗费时间很长（想像一下一个stacking框架跑一个基模型要大半天，简直太可怕）。所以建议大家在使用的时候要计算时间的耗费，或者可以改为3折，4折等等；</p><p>2、我们前面讲过了，stacking框架是集成了不同的算法，充分利用不同算法从不同的数据空间角度和数据结构角度的对数据的不同观测，来取长补短，优化结果。所以，我们的基模型除了是不同参数的相同模型之外，比如不同参数的xgboost，或者不同K值的KNN等等；更重要的是要尽可能的多加一些不同种类的基模型进去，也就是说所谓的模型要“跨越空间”的概念。这样的话我们的集成结果会更加稳健，更加精确。（曾经有一个比赛集成了上百个基模型的stacking框架获奖）</p><h2 id="基本变种改进"><a href="#基本变种改进" class="headerlink" title="基本变种改进"></a>基本变种改进</h2><p>在变种改进方面，我们可以不仅对模型进行融合，还可以对特征级进行一些变化，比如选部分特征做stacking；或者对stacking的结果进行再次的stacking，上面介绍的是两层的stacking，可以有3层，或者更多。但是时间复杂度很高，效果并不一定明显。</p><h1 id="Kaggle数据挖掘比赛经验分享"><a href="#Kaggle数据挖掘比赛经验分享" class="headerlink" title="Kaggle数据挖掘比赛经验分享"></a>Kaggle数据挖掘比赛经验分享</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzIzMzgzOTUxNA==&amp;mid=2247483678&amp;idx=1&amp;sn=5f044dabfaa726e292686287a1dd5ca4&amp;chksm=e8fecfebdf8946fdabf71fd5c4c0e019144f105da993c12fa257c64f281ecfb3a7557f16b79e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【干货】Kaggle 数据挖掘比赛经验分享</a><br>一个完整的数据挖掘比赛基本流程如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/640.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><p>通过对数据进行探索性分析（甚至有些情况下需要肉眼观察样本），还可以有助于启发数据清洗和特征抽取，譬如缺失值和异常值的处理，文本数据是否需要进行拼写纠正等。</p><h3 id="分析特征变量的分布"><a href="#分析特征变量的分布" class="headerlink" title="分析特征变量的分布"></a>分析特征变量的分布</h3><ol><li><strong>特征变量</strong>为连续值：如果为长尾分布并且考虑使用线性模型，可以对变量进行幂变换或者对数变换。</li><li><strong>特征变量</strong>为离散值：观察每个离散值的频率分布，对于频次较低的特征，可以考虑统一编码为“其他”类别。</li></ol><h3 id="分析目标变量的分布"><a href="#分析目标变量的分布" class="headerlink" title="分析目标变量的分布"></a>分析目标变量的分布</h3><ol><li><strong>目标变量</strong>为连续值：查看其值域范围是否较大，如果较大，可以考虑对其进行对数变换，并以变换后的值作为新的目标变量进行建模（<strong>在这种情况下，需要对预测结果进行逆变换</strong>）。一般情况下，可以对连续变量进行<strong>Box-Cox</strong>变换。通过变换可以使得模型更好的优化，通常也会带来效果上的提升。</li><li><strong>目标变量</strong>为离散值：如果数据分布不平衡，考虑是否需要上采样/下采样；如果目标变量在某个ID上面分布不平衡，在划分本地训练集和验证集的时候，需要考虑<strong>分层采样（Stratified Sampling）</strong>。</li></ol><h3 id="分析变量之间两两的分布和相关度"><a href="#分析变量之间两两的分布和相关度" class="headerlink" title="分析变量之间两两的分布和相关度"></a>分析变量之间两两的分布和相关度</h3><ol><li>可以用于发现高相关和共线性的特征。</li></ol><h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><p>数据清洗是指对提供的原始数据进行一定的加工，使得其方便后续的特征抽取。其与特征抽取的界限有时也没有那么明确。常用的数据清洗一般包括：</p><h3 id="数据的拼接"><a href="#数据的拼接" class="headerlink" title="数据的拼接"></a>数据的拼接</h3><ol><li>提供的数据散落在多个文件，需要根据相应的键值进行数据的拼接。</li></ol><h3 id="特征缺失值的处理"><a href="#特征缺失值的处理" class="headerlink" title="特征缺失值的处理"></a>特征缺失值的处理</h3><ol><li>特征值为连续值：按不同的分布类型对缺失值进行补全：<strong>偏正态分布</strong>，使用均值代替，可以保持数据的均值；<strong>偏长尾分布</strong>，使用中值代替，避免受 outlier 的影响；</li><li>特征值为离散值：使用众数代替。</li></ol><h3 id="文本数据的清洗"><a href="#文本数据的清洗" class="headerlink" title="文本数据的清洗"></a>文本数据的清洗</h3><ol><li>在比赛当中，如果数据包含文本，往往需要进行大量的数据清洗工作。如去除HTML 标签，分词，拼写纠正, 同义词替换，去除停词，抽词干，数字和单位格式统一等。</li></ol><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>有一种说法是，特征决定了效果的上限，而不同模型只是以不同的方式或不同的程度来逼近这个上限。这样来看，好的特征输入对于模型的效果至关重要，正所谓”Garbage in, garbage out”。要做好特征工程，往往跟领域知识和对问题的理解程度有很大的关系，也跟一个人的经验相关。特征工程的做法也是Case by Case，以下就一些点，谈谈自己的一些看法。</p><h3 id="特征变换"><a href="#特征变换" class="headerlink" title="特征变换"></a>特征变换</h3><p>主要针对一些长尾分布的特征，<strong>需要进行幂变换或者对数变换，使得模型（LR或者DNN）能更好的优化</strong>。需要注意的是，Random Forest 和 GBDT 等模型对单调的函数变换不敏感。其原因在于树模型在求解分裂点的时候，只考虑排序分位点。</p><h3 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h3><p>对于离散的类别特征，往往需要进行必要的特征转换/编码才能将其作为特征输入到模型中。常用的编码方式有 LabelEncoder，OneHotEncoder（sklearn里面的接口）。譬如对于”性别”这个特征（取值为男性和女性），使用这两种方式可以分别编码为{0,1}和{[1,0], [0,1]}。</p><p>对于取值较多（如几十万）的类别特征（ID特征），直接进行OneHotEncoder编码会导致特征矩阵非常巨大，影响模型效果。可以使用如下的方式进行处理：<br>◆ 统计每个取值在样本中出现的频率，取 Top N 的取值进行 One-hot 编码，剩下的类别分到“其他“类目下，其中 N 需要根据模型效果进行调优；<br>◆ 统计每个 ID 特征的一些统计量（譬如历史平均点击率，历史平均浏览率）等代替该 ID 取值作为特征，具体可以参考 Avazu 点击率预估比赛第二名的获奖方案；<br>◆ 参考 word2vec 的方式，将每个类别特征的取值映射到一个连续的向量，对这个向量进行初始化，跟模型一起训练。训练结束后，可以同时得到每个ID的Embedding。具体的使用方式，可以参考 Rossmann 销量预估竞赛第三名的获奖方案，<a href="https://github.com/entron/entity-embedding-rossmann。">https://github.com/entron/entity-embedding-rossmann。</a></p><p>对于 Random Forest 和 GBDT 等模型，如果类别特征存在较多的取值，可以直接使用 LabelEncoder 后的结果作为特征（这里应该只是将数字来代替类别，数字并不具有实际含义）。注意labelEncoder将文字变换为数字，是虚拟数据，不一定有意义，建模时要注意去除。</p><h2 id="模型训练和验证"><a href="#模型训练和验证" class="headerlink" title="模型训练和验证"></a>模型训练和验证</h2><h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><p>在处理好特征后，我们可以进行模型的训练和验证。<br>◆ 对于稀疏型特征（如文本特征，One-hot的ID类特征），我们一般使用线性模型，譬如 Linear Regression 或者 Logistic Regression。Random Forest 和 GBDT 等树模型不太适用于稀疏的特征，但可以先对特征进行降维（如PCA，SVD/LSA等），再使用这些特征。稀疏特征直接输入 DNN 会导致网络 weight 较多，不利于优化，也可以考虑先降维，或者对 ID 类特征使用 Embedding 的方式；<br>◆ 对于稠密型特征，推荐使用 XGBoost 进行建模，简单易用效果好；<br>◆ 数据中既有稀疏特征，又有稠密特征，可以考虑使用线性模型对稀疏特征进行建模，将其输出与稠密特征一起再输入 XGBoost/DNN 建模，具体可以参考Stacking 部分。</p><h3 id="调参和模型验证"><a href="#调参和模型验证" class="headerlink" title="调参和模型验证"></a>调参和模型验证</h3><p>对于选定的特征和模型，我们往往还需要对模型进行超参数的调优，才能获得比较理想的效果。调参一般可以概括为以下三个步骤：</p><p>1.<strong>训练集和验证集的划分。</strong>根据比赛提供的训练集和测试集，模拟其划分方式对训练集进行划分为本地训练集和本地验证集。划分的方式视具体比赛和数据而定，常用的方式有：<br>a) 随机划分：譬如随机采样 70% 作为训练集，剩余的 30% 作为测试集。在这种情况下，本地可以采用 KFold 或者 Stratified KFold 的方法来构造训练集和验证集。<br>b) 按时间划分：一般对应于时序序列数据，譬如取前 7 天数据作为训练集，后 1 天数据作为测试集。这种情况下，划分本地训练集和验证集也需要按时间先后划分。常见的错误方式是随机划分，这种划分方式可能会导致模型效果被高估。<br>c) 按某些规则划分：在 HomeDepot 搜索相关性比赛中，训练集和测试集中的 Query 集合并非完全重合，两者只有部分交集。而在另外一个相似的比赛中（CrowdFlower 搜索相关性比赛），训练集和测试集具有完全一致的 Query 集合。对于 HomeDepot 这个比赛中，训练集和验证集数据的划分，需要考虑 Query 集合并非完全重合这个情况，其中的一种方法可以参考第三名的获奖方案，<a href="https://github.com/ChenglongChen/Kaggle_HomeDepot。">https://github.com/ChenglongChen/Kaggle_HomeDepot。</a></p><p>2.<strong>指定参数空间</strong>。在指定参数空间的时候，需要对模型参数以及其如何影响模型的效果有一定的了解，才能指定出合理的参数空间。譬如DNN或者XGBoost中学习率这个参数，一般就选 0.01 左右就 OK 了（太大可能会导致优化算法错过最优化点，太小导致优化收敛过慢）。再如 Random Forest，一般设定树的棵数范围为 100~200 就能有不错的效果，当然也有人固定数棵数为 500，然后只调整其他的超参数。</p><p>3.<strong>按照一定的方法进行参数搜索</strong>。常用的参数搜索方法有，Grid Search，Random Search以及一些自动化的方法（如 Hyperopt）。其中，Hyperopt 的方法，根据历史已经评估过的参数组合的效果，来推测本次评估使用哪个参数组合更有可能获得更好的效果。</p><h3 id="适当利用-Public-LB-的反馈"><a href="#适当利用-Public-LB-的反馈" class="headerlink" title="适当利用 Public LB 的反馈"></a>适当利用 Public LB 的反馈</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%8810.30.48.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="模型集成"><a href="#模型集成" class="headerlink" title="模型集成"></a>模型集成</h2><h3 id="Averaging-和-Voting"><a href="#Averaging-和-Voting" class="headerlink" title="Averaging 和 Voting"></a>Averaging 和 Voting</h3><p>直接对多个模型的预测结果求平均或者投票。对于目标变量为连续值的任务，使用平均；对于目标变量为离散值的任务，使用投票的方式。</p><h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%8810.32.33.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><ol><li><strong>数据集划分</strong>。将训练数据按照5-Fold进行划分（如果数据跟时间有关，需要按时间划分）</li><li><strong>基础模型训练 I</strong>。按照交叉验证（Cross Validation）的方法，在训练集（Training Fold）上面训练模型（如图灰色部分所示），并在验证集（Validation Fold）上面做预测，得到预测结果（如图黄色部分所示）。最后综合得到整个训练集上面的预测结果（如图第一个黄色部分的CV Prediction所示）。</li><li><strong>基础模型训练 II</strong>（如图5第二和三行左半部分所示）。在全量的训练集上训练模型（如图第二行灰色部分所示），并在测试集上面做预测，得到预测结果（如图第三行虚线后绿色部分所示）。</li><li><strong>Stage 1 模型集成训练 I</strong>（如图5第一行右半部分所示）。将步骤 2 中得到的 CV Prediction 当作新的训练集，按照步骤 2 可以得到 Stage 1模型集成的 CV Prediction。</li><li>Stage 1 模型集成训练 II（如图5第二和三行右半部分所示）。将步骤 2 中得到的 CV Prediction 当作新的训练集和步骤 3 中得到的 Prediction 当作新的测试集，按照步骤 3 可以得到 Stage 1 模型集成的测试集 Prediction。此为 Stage 1 的输出，可以提交至 Kaggle 验证其效果。</li></ol><p>在图5中，基础模型只展示了一个，而实际应用中，基础模型可以多种多样，如SVM，DNN，XGBoost 等。也可以相同的模型，不同的参数，或者不同的样本权重。重复4和5两个步骤，可以相继叠加 Stage 2, Stage 3 等模型。</p><h3 id="Blending"><a href="#Blending" class="headerlink" title="Blending"></a>Blending</h3><p>Blending 与 Stacking 类似，但单独留出一部分数据（如 20%）用于训练 Stage X 模型。</p><h3 id="Bagging-Ensemble-Selection"><a href="#Bagging-Ensemble-Selection" class="headerlink" title="Bagging Ensemble Selection"></a>Bagging Ensemble Selection</h3><p>Bagging Ensemble Selection [5] 是我在 CrowdFlower 搜索相关性比赛中使用的方法，其主要的优点在于可以以优化任意的指标来进行模型集成。这些指标可以是可导的（如 LogLoss 等）和不可导的（如正确率，AUC，Quadratic Weighted Kappa等）。它是一个前向贪婪算法，存在过拟合的可能性，作者在文献 [5] 中提出了一系列的方法（如 Bagging）来降低这种风险，稳定集成模型的性能。使用这个方法，需要有成百上千的基础模型。为此，在 CrowdFlower 的比赛中，我把在调参过程中所有的中间模型以及相应的预测结果保留下来，作为基础模型。这样做的好处是，不仅仅能够找到最优的单模型（Best Single Model），而且所有的中间模型还可以参与模型集成，进一步提升效果。</p><h2 id="自动化框架"><a href="#自动化框架" class="headerlink" title="自动化框架"></a>自动化框架</h2><p>这份代码开源在 Github 上面，目前是 Github 有关 Kaggle 竞赛解决方案的 Most Stars，地址：<a href="https://github.com/ChenglongChen/Kaggle_CrowdFlower。">https://github.com/ChenglongChen/Kaggle_CrowdFlower。</a></p><p>其主要包含以下部分：</p><p>1.模块化特征工程<br>a) 接口统一，只需写少量的代码就能够生成新的特征；<br>b) 自动将单独的特征拼接成特征矩阵。</p><p>2.自动化模型调参和验证<br>a) 自定义训练集和验证集的划分方法；<br>b) 使用 Grid Search / Hyperopt 等方法，对特定的模型在指定的参数空间进行调优，并记录最佳的模型参数以及相应的性能。</p><p>3.自动化模型集成<br>a) 对于指定的基础模型，按照一定的方法（如Averaging_Stacking_Blending 等）生成集成模型。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;stacking技术分享&quot;&gt;&lt;a href=&quot;#stacking技术分享&quot; class=&quot;headerlink&quot; title=&quot;stacking技术分享&quot;&gt;&lt;/a&gt;stacking技术分享&lt;/h1&gt;&lt;p&gt;stacking不能称为一种算法，而是一种对模型的集成策略。
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM Python quick start</title>
    <link href="https://github.com/zdkswd/2019/04/17/LightGBM%20Python%20quick%20start/"/>
    <id>https://github.com/zdkswd/2019/04/17/LightGBM Python quick start/</id>
    <published>2019-04-17T06:00:32.000Z</published>
    <updated>2019-04-17T06:00:16.594Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LightGBM-Python-quick-start"><a href="#LightGBM-Python-quick-start" class="headerlink" title="LightGBM Python quick start"></a>LightGBM Python quick start</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.00.51.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="Data-Interface"><a href="#Data-Interface" class="headerlink" title="Data Interface"></a>Data Interface</h1><p>The LightGBM Python module can load data from:</p><p>1.libsvm/ tsv / csv / txt format file<br>2.NumPy 2D array(s), pandas DataFrame, H2O DataTable’s Frame, SciPy sparse matrix<br>3.LightGBM binary file</p><p>The data is stored in a <strong>Dataset</strong> object.</p><p><strong>To load a libsvm text file or a LightGBM binary file into Dataset:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.02.58.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>To load a numpy array into Dataset:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.02.47.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>Saving Dataset into a LightGBM binary file will make loading faster:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.03.46.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>Create validation data:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.05.34.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>or<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.06.14.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>In LightGBM, the validation data should be aligned with training data.</p><p><strong>Specific feature names and categorical features:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.22.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>LightGBM can use categorical features as input directly. It doesn’t need to convert to one-hot coding, and is much faster than one-hot coding (about 8x speed-up).</p><p><strong>Note</strong>: You should convert your categorical features to <strong>int</strong> type before you construct <strong>Dataset</strong>.</p><p><strong>Weights can be set when needed:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.22.53.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>or<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.23.06.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>And you can use <strong>Dataset.set_init_score()</strong> to set initial score, and <strong>Dataset.set_group()</strong> to set group/query data for ranking tasks.</p><p><strong>Memory efficient usage:</strong><br>The <strong>Dataset</strong> object in LightGBM is very memory-efficient, it only needs to save discrete bins. However, Numpy / Array / Pandas object is memory expensive. If you are concerned about your memory consumption, you can save memory by:</p><ol><li>Set <strong>free_raw_data=True</strong> (default is <strong>True</strong>) when constructing the <strong>Dataset</strong></li><li>Explicitly set <strong>raw_data=None</strong> after the <strong>Dataset</strong> has been constructed</li><li>Call <strong>gc</strong></li></ol><h1 id="Setting-Parameters"><a href="#Setting-Parameters" class="headerlink" title="Setting Parameters"></a>Setting Parameters</h1><p>LightGBM can use either a list of pairs or a dictionary to set <strong>Parameters</strong>. For instance:<br><strong>Booster parameters</strong>:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.56.05.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.27.59.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>You can also specify multiple eval metrics:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.28.16.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><p>Training a model requires a parameter list and data set:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.29.43.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>After training, the model can be saved:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.30.14.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>The trained model can also be dumped to JSON format:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.31.17.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>A saved model can be loaded:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.31.36.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h1><p>Training with 5-fold CV:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.33.58.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h1><p>If you have a validation set, you can use early stopping to find the optimal number of boosting rounds. Early stopping requires at least one set in <strong>valid_sets</strong>. If there is more than one, it will use all of them except the training data:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.35.00.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>The model will train until the validation score stops improving. Validation score needs to improve at least every <strong>early_stopping_rounds</strong> to continue training.</p><p>The index of iteration that has the best performance will be saved in the <strong>best_iteration</strong> field if early stopping logic is enabled by setting <strong>early_stopping_rounds</strong>. Note that <strong>train()</strong> will return a model from the best iteration.</p><p>This works with both metrics to minimize (L2, log loss, etc.) and to maximize (NDCG, AUC, etc.). Note that if you specify more than one evaluation metric, all of them will be used for early stopping. However, you can change this behavior and make LightGBM check only the first metric for early stopping by creating <strong>early_stopping</strong> callback with <strong>first_metric_only=True</strong>.</p><h1 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h1><p>A model that has been trained or loaded can perform predictions on datasets:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.51.55.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>If early stopping is enabled during training, you can get predictions from the best iteration with <strong>bst.best_iteration</strong>:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.52.37.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;LightGBM-Python-quick-start&quot;&gt;&lt;a href=&quot;#LightGBM-Python-quick-start&quot; class=&quot;headerlink&quot; title=&quot;LightGBM Python quick start&quot;&gt;&lt;/a&gt;Light
      
    
    </summary>
    
      <category term="教程" scheme="https://github.com/zdkswd/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>word2vec</title>
    <link href="https://github.com/zdkswd/2019/04/17/word2vec/"/>
    <id>https://github.com/zdkswd/2019/04/17/word2vec/</id>
    <published>2019-04-17T01:55:47.000Z</published>
    <updated>2019-04-17T01:56:26.837Z</updated>
    
    <content type="html"><![CDATA[<h1 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h1><p>谷歌2013年提出的word2vec是目前最常用的词嵌入模型之一。Word2ec实际是一种<strong>浅层的神经网络模型</strong>,它有两种网络结构,分别是CBOW( Continues Bag      of words)和 Skip-gram。</p><h1 id="百面-Word2Vec"><a href="#百面-Word2Vec" class="headerlink" title="百面  Word2Vec"></a>百面  Word2Vec</h1><h2 id="问-Word2Vec是如何工作的？"><a href="#问-Word2Vec是如何工作的？" class="headerlink" title="问  Word2Vec是如何工作的？"></a>问  Word2Vec是如何工作的？</h2><p>答：CBOW的目标是根据上下文出现的词语来预测当前词的生成概率，如图1.3 (a) 所示;而Skip-gram是根据当前词来预测上下文中各词的生成概率，如图1.3 (b)所示。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-26%20%E4%B8%8B%E5%8D%884.54.01.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中w(t)是当前所关注的词，w(t-2)、 w(t-1)、 w(t+1)、 w(t+2)是 上下文中出现的词。这里前后滑动窗口大小均设为2。</p><p>CBOW和Skip-gram都可以表示成由输入层(Input)、映射层(Projection)和输出层(Output)组成的神经网络。</p><p>输入层中的每个词由独热编码方式表示,即所有词均表示成一个N维向量,其中N为词汇表中单词的总数。在向量中,每个词都将与之对应的维度置为1,其余维度的值均设为0。</p><p>在映射层(又称隐含层)中,K个隐含单元( Hidden units)的取值可以由N维输入向量以及连接输入和隐含单元之间的N乘K维权重矩阵计算得到。在CBOV中,还需要将各个输入词所计算出的隐含单元求和。补一个其他博客的图。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/20180113213325970.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/20180113212531373.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>同理，输出层向量的值可以通过隐含层向量(K维)，以及连接隐含层和输出层之间的KxN维权重矩阵计算得到。输出层也是一个N维向量，每维与词汇表中的一个单词相对应。最后，对输出层向量应用Softmax激活函数，可以计算出每个单词的生成概率。Softmax激活函数的定义为：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-26%20%E4%B8%8B%E5%8D%886.21.23.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中x代表N维的原始输出向量,xn为在原始输出向量中，与单词wn所对应维度的取值。</p><p>接下来的任务就是训练神经网络的权重,使得语料库中所有单词的整体生成概率最大化。从输入层到隐含层需要一个维度为NxK的权重矩阵，从隐含层到输出层又需要一个维度为KxN的权重矩阵，学习权重可以用反向传播算法实现，每次迭代时将权重沿梯度更优的方向进行一小步更新。但是由于Softmax激活函数中存在归一化项的缘故，推导出来的迭代公式需要对词汇表中的所有单词进行遍历，使得每次迭代过程非常缓慢，由此产生了Hierarchical Softmax和Negative Sampling两种改进方法。训练得到维度为NxK和KxN的两个权重矩阵之后，可以选择其中一个作为N个词的K维向量表示。</p><h1 id="王喆-知乎"><a href="#王喆-知乎" class="headerlink" title="王喆 知乎"></a>王喆 知乎</h1><p><a href="https://zhuanlan.zhihu.com/p/53194407" target="_blank" rel="noopener">万物皆Embedding，从经典的word2vec到深度学习基本操作item2vec - 知乎</a><br><strong>万物皆Embedding，从经典的word2vec到深度学习基本操作item2vec</strong></p><h2 id="什么是embedding？"><a href="#什么是embedding？" class="headerlink" title="什么是embedding？"></a>什么是embedding？</h2><p>简单来说，embedding就是用一个低维的向量表示一个物体，可以是一个词，或是一个商品，或是一个电影等等。这个<strong>embedding向量的性质是能使距离相近的向量对应的物体有相近的含义</strong>，比如 Embedding(复仇者联盟)和Embedding(钢铁侠)之间的距离就会很接近，但 Embedding(复仇者联盟)和Embedding(乱世佳人)的距离就会远一些。</p><p>除此之外Embedding<strong>甚至还具有数学运算</strong>的关系，比如Embedding（马德里）-Embedding（西班牙）+Embedding(法国)≈Embedding(巴黎)</p><p>从另外一个空间表达物体，甚至揭示了物体间的潜在关系，从某种意义上来说，Embedding方法甚至具备了一些本体论的哲学意义。</p><h2 id="为什么说embedding是深度学习的基本操作？"><a href="#为什么说embedding是深度学习的基本操作？" class="headerlink" title="为什么说embedding是深度学习的基本操作？"></a>为什么说embedding是深度学习的基本操作？</h2><p>Embedding能够用低维向量对物体进行编码还能保留其含义的特点非常适合深度学习。在传统机器学习模型构建过程中，经常使用one hot encoding对离散特征，特别是id类特征进行编码，但由于one hot encoding的维度等于物体的总数，比如阿里的商品one hot encoding的维度就至少是千万量级的。这样的编码方式对于商品来说是极端稀疏的，甚至用multi hot encoding对用户浏览历史的编码也会是一个非常稀疏的向量。</p><p>而深度学习的特点以及工程方面的原因使其不利于稀疏特征向量的处理。因此如果能把物体编码为一个低维稠密向量再喂给DNN，自然是一个高效的基本操作。因为从梯度下降的过程来说，如果特征过于稀疏会导致整个网络收敛过慢，因为每次更新只有极少数的权重会得到更新。这样在样本有限的情况下会导致模型不收敛。而且还会导致全连接层有过多的参数。</p><p>尽管有采用relu函数等各种手段减少梯度消失现象的发生，但nn还是会存在梯度消失问题，所以到输入层的时候梯度受输出层diff的影响已经很小了因此收敛慢再加上大量稀疏特征导致一次只有个别权重更新这个现象就更严重了。对于lr来说，梯度能够直接传导到权重，因为其只有一层。倒不是说lr更适合处理大规模离散特征 而是相比nn 需要更少的数据收敛 如果数据量和时间都无限的话nn也适合处理稀疏特征。</p><h1 id="McCormick-W2V"><a href="#McCormick-W2V" class="headerlink" title="McCormick W2V"></a>McCormick W2V</h1><p><a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/" target="_blank" rel="noopener">http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/</a></p><h2 id="The-Model"><a href="#The-Model" class="headerlink" title="The Model"></a>The Model</h2><p>Word2Vec uses a trick you may have seen elsewhere in machine learning. We’re going to train a simple neural network with a single hidden layer to perform a certain task, but then we’re not actually going to use that neural network for the task we trained it on! Instead, the goal is actually just to learn the weights of the <strong>hidden layer</strong>。</p><p>We’ll train the neural network to do this by feeding it word pairs found in our training documents.The word highlighted in blue is the input word.</p><p>this is skip-gram.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/training_data.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="Model-Details"><a href="#Model-Details" class="headerlink" title="Model Details"></a>Model Details</h2><p>let’s say we have a vocabulary of 10,000 unique words.We’re going to represent an input word  as a one-hot vector. This vector will have 10,000 components.The output of the network is a single vector (also with 10,000 components) Here’s the architecture of our neural network.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/skip_gram_net_arch.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>There is <strong>no activation function</strong> on the hidden layer neurons, but the output neurons use <strong>softmax</strong>.</p><p>When training this network on word pairs, the input is a one-hot vector representing the input word and the training output is also a one-hot vector representing the output word.But when you evaluate the trained network on an input word, the output vector will actually be a probability distribution (i.e., a bunch of floating point values, not a one-hot vector).</p><h2 id="The-Hidden-Layer"><a href="#The-Hidden-Layer" class="headerlink" title="The Hidden Layer"></a>The Hidden Layer</h2><p>For our example, we’re going to say that we’re learning word vectors with 300 features. So the hidden layer is going to be represented by a weight matrix with 10,000 rows (one for every word in our vocabulary) and 300 columns (one for every hidden neuron).The number of features is a “hyper parameter” that you would just have to tune to your application .</p><p>显然，每个单词对应一个300维的隐向量，也可以理解为300维的语义。</p><p>that is why we use one-hot .<strong>右边矩阵中绿色的值即为左边矩阵中1对应的词的隐向量。</strong> 对应的，竖着的第一列即为隐藏层第一个神经元连接的上一层的神经元权重。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/matrix_mult_w_one_hot.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>just as this image.根据反向传播公式，当梯度传递到这一层时，只有非0的值才会对梯度进行更新。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%889.42.26.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>This means that the hidden layer of this model is really just operating as a <strong>lookup</strong> table. The output of the hidden layer is just the “word vector” for the input word.</p><h2 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h2><p> The skip-gram neural network contains a huge number of weights… For our example with 300 features and a vocab of 10,000 words, that’s 3M weights in the hidden layer and output layer each! Training this on a large dataset would be prohibitive, And to make matters worse, you need a huge amount of training data in order to tune that many weights and avoid over-fitting. so the word2vec authors introduced a number of tweaks to make training feasible.The first one is Negative Sampling</p><p>the innovations:</p><ol><li><strong>Subsampling</strong> frequent words to decrease the number of training examples.</li><li>Modifying the optimization objective with a technique they called “<strong>Negative Sampling</strong>”, which causes each training sample to update only a small percentage of the model’s weights.</li></ol><p>It’s worth noting that subsampling frequent words and applying Negative Sampling not only reduced the compute burden of the training process, but also improved the quality of their resulting word vectors as well.</p><h2 id="Subsampling-Frequent-Words"><a href="#Subsampling-Frequent-Words" class="headerlink" title="Subsampling Frequent Words"></a>Subsampling Frequent Words</h2><p>The word highlighted in blue is the input word.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/training_data%202.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>There are two “problems” with common words like “the”:</p><ol><li>When looking at word pairs, (“fox”, “the”) doesn’t tell us much about the meaning of “fox”. “the” appears in the context of pretty much every word.</li><li>We will have many more samples of (“the”, …) than we need to learn a good vector for “the”.</li></ol><p>Word2Vec implements a “subsampling” scheme to address this. For each word we encounter in our training text, there is a chance that we will effectively delete it from the text. The probability that we cut the word is related to the word’s frequency.</p><p>If we have a window size of 10, and we remove a specific instance of “the” from our text:</p><ol><li>As we train on the remaining words, “the” will not appear in any of their context windows.</li><li>We’ll have 10 fewer training samples where “the” is the input word.</li></ol><h3 id="Sample-rate"><a href="#Sample-rate" class="headerlink" title="Sample rate"></a>Sample rate</h3><p>wi is the word, z(wi) is the fraction of the total words in the corpus that are that word. For example, if the word “peanut” occurs 1,000 times in a 1 billion word corpus, then z(‘peanut’) = 1E-6.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%889.13.31.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%889.13.53.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>1.P(wi)=1.0 (100% chance of being kept) when z(wi)&lt;=0.0026.<br>This means that only words which represent more than 0.26% of the total words will be subsampled.<br>2.P(wi)=0.5 (50% chance of being kept) when z(wi)=0.00746.<br>3.P(wi)=0.033 (3.3% chance of being kept) when z(wi)=1.0.<br>That is, if the corpus consisted entirely of word wi, which of course is ridiculous.</p><h2 id="Negative-Sampling-1"><a href="#Negative-Sampling-1" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h2><p>Negative sampling addresses this by having each training sample only modify a small percentage of the weights, rather than all of them. Here’s how it works.</p><p>When training the network on the word pair (“fox”, “quick”), recall that the “label” or “correct output” of the network is a one-hot vector. That is, for the output neuron corresponding to “quick” to output a 1, and for all of the other thousands of output neurons to output a 0.</p><p>With negative sampling, we are instead going to randomly select just a small number of “negative” words (let’s say 5) to update the weights for. (In this context, a “negative” word is one for which we want the network to output a 0 for). We will also still update the weights for our “positive” word (which is the word “quick” in our current example).</p><p>Recall that the output layer of our model has a weight matrix that’s 300 x 10,000. So we will just be updating the weights for our positive word (“quick”), plus the weights for 5 other words that we want to output 0. That’s a total of 6 output neurons, and 1,800 weight values total. That’s only 0.06% of the 3M weights in the output layer!</p><p>In the hidden layer, only the weights for the input word are updated (this is true whether you’re using Negative Sampling or not).</p><h3 id="Selecting-Negative-Samples"><a href="#Selecting-Negative-Samples" class="headerlink" title="Selecting Negative Samples"></a>Selecting Negative Samples</h3><p>The “negative samples” (that is, the 5 output words that we’ll train to output 0) are selected using a “unigram distribution”, where more frequent words are more likely to be selected as negative samples.</p><p>For instance, suppose you had your entire training corpus as a list of words, and you chose your 5 negative samples by picking randomly from the list. In this case, the probability for picking the word “couch” would be equal to the number of times “couch” appears in the corpus, divided the total number of word occus in the corpus. This is expressed by the following equation:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%889.27.08.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>The authors state in their paper that they tried a number of variations on this equation, and the one which performed best was to raise the word counts to the 3/4 power:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%889.27.29.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="Applying-word2vec-to-Recommenders-and-Advertising"><a href="#Applying-word2vec-to-Recommenders-and-Advertising" class="headerlink" title="Applying word2vec to Recommenders and Advertising"></a>Applying word2vec to Recommenders and Advertising</h2><p>The key principle behind word2vec is the notion that the meaning of a word can be inferred from it’s context–what words tend to be around it. To abstract that a bit, text is really just a sequence of words, and the meaning of a word can be extracted from what words tend to be just before and just after it in the sequence.</p><p>What researchers and companies are finding is that the time series of online user activity offers the same opportunity for inferring meaning from context. That is, as a user browses around and interacts with different content, the abstract qualities of a piece of content can be inferred from what content the user interacts with before and after. This allows ML teams to apply word vector models to learn good vector representations for products, content, and ads.</p><p>The word2vec approach has proven successful in extracting these hidden insights, and being able to compare, search, and categorize items on these abstract dimensions opens up a lot of opportunities for smarter, better recommendations. </p><h2 id="Four-Production-Examples"><a href="#Four-Production-Examples" class="headerlink" title="Four Production Examples"></a>Four Production Examples</h2><h3 id="Music-Recommendations"><a href="#Music-Recommendations" class="headerlink" title="Music Recommendations"></a>Music Recommendations</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/Spotify_user_activity.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>One use is to create a kind of “music taste” vector for a user by averaging together the vectors for songs that a user likes to listen to. This taste vector can then become the query for a similarity search to find songs which are similar to the user’s taste vector.<br>and Listing Recommendations at Airbnb,Product Recommendations in Yahoo Mail,Matching Ads to Search Queries</p><h1 id="几篇论文"><a href="#几篇论文" class="headerlink" title="几篇论文"></a>几篇论文</h1><p> <strong>Distributed Representations of Words and Phrases and their Compositionality</strong><br>Google的Tomas Mikolov提出word2vec的两篇文章之一，这篇文章更具有综述性质，列举了NNLM、RNNLM等诸多词向量模型，但最重要的还是提出了CBOW和Skip-gram两种word2vec的模型结构。虽然词向量的研究早已有之，但不得不说还是Google的word2vec的提出让词向量重归主流，拉开了整个embedding技术发展的序幕。</p><p><strong>Efficient Estimation of Word Representations in Vector Space</strong><br>Tomas Mikolov的另一篇word2vec奠基性的文章。相比上一篇的综述，本文更详细的阐述了Skip-gram模型的细节，包括模型的具体形式和 Hierarchical Softmax和 Negative Sampling两种可行的训练方法。</p><p> <strong>Word2vec Parameter Learning Explained</strong><br>虽然Mikolov的两篇代表作标志的word2vec的诞生，但其中忽略了大量技术细节，如果希望完全读懂word2vec的原理和实现方法，比如词向量具体如何抽取，具体的训练过程等，强烈建议大家阅读UMich Xin Rong博士的这篇针对word2vec的解释性文章。惋惜的是Xin Rong博士在完成这篇文章后的第二年就由于飞机事故逝世，在此也致敬并缅怀一下Xin Rong博士。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;word2vec&quot;&gt;&lt;a href=&quot;#word2vec&quot; class=&quot;headerlink&quot; title=&quot;word2vec&quot;&gt;&lt;/a&gt;word2vec&lt;/h1&gt;&lt;p&gt;谷歌2013年提出的word2vec是目前最常用的词嵌入模型之一。Word2ec实际是一种&lt;
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>About id </title>
    <link href="https://github.com/zdkswd/2019/04/16/About%20id/"/>
    <id>https://github.com/zdkswd/2019/04/16/About id/</id>
    <published>2019-04-16T12:42:47.000Z</published>
    <updated>2019-04-17T04:35:42.947Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何利用id类特征"><a href="#如何利用id类特征" class="headerlink" title="如何利用id类特征"></a>如何利用id类特征</h1><p><a href="https://www.zhihu.com/question/34819617" target="_blank" rel="noopener">机器学习中如何利用id类特征？ - 知乎</a></p><h2 id="为什么用"><a href="#为什么用" class="headerlink" title="为什么用"></a>为什么用</h2><p>会极大提高模型的个性化能力和实际效果。而且可以对抗热度穿透现象。</p><p>直接加入id类特征，尽管并不能实现完全的个性化，但是可以把每个用户的行为模式区分开，从而提高了其他特征的泛化能力。</p><p>例如有两个id和一项特征来进行一个回归预测。一个id是正常用户，一个id是刷子用户。式子可以表示为w1x1+w2x2+w3x3=rate<br>对于正常用户rate值低，刷子用户rate值高。即w1x1+w3x3值较小，w2x2+w3x3值较大。可得是w2x2项较大即模型学习到了提高w2，对于不同的id就进行了区别对待。</p><p>加入id类特征的价值：</p><ol><li>可以使得在学习过程中每个人的信号更合理地影响整体模型，使得模型泛化能力更好。</li><li>可以使得模型能够对每个id有更细粒度的排序能力，使得模型的个性化效果更好。</li></ol><h2 id="怎么用"><a href="#怎么用" class="headerlink" title="怎么用"></a>怎么用</h2><ol><li>id类特征上的信号是及其稀疏的，所以意味着我们需要更大量的数据，但是其实这并不困难，在计算广告，推荐系统的场景下，单个id上收集的数据其实是非常多的，但是一定要通过正则化的方法来限制以使id类特征不过拟合。</li><li>id类特征在预测中的命中率可能并不高，但这其实也不是问题。因为一个特征就是一个体系，一个体系化的特征是通过层次化的特征设计来达到命中率和个性化的综合。比如说 用户id-&gt;用户GPS坐标+用户喜好Tag+用户最近行为-&gt;用户年龄，用户性别。通过分层，由最细粒度到最粗粒度的特征搭配来保证特征命中率。</li><li>组合。单独的id类特征时意义并没有那么高，有意义的是不同层次的交叉组合。userid和itemid交互后，也就是用户对物品的评分矩阵，这时候就可以使用itemcf或svd等等。</li><li>模型和算法。实际上，LR是适合使用ID类特征One-hot编码的，原因在于LR适合接受超高维度的特征输入。但是这么做的前提是训练样本足够多。对于XGBoost，DNN，就要先对id特征one-hot进行embedding。</li></ol><h1 id="Entity-Embeddings-of-Categorical-Variables"><a href="#Entity-Embeddings-of-Categorical-Variables" class="headerlink" title="Entity Embeddings of Categorical Variables"></a>Entity Embeddings of Categorical Variables</h1><p><a href="https://arxiv.org/pdf/1604.06737.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1604.06737.pdf</a></p><h2 id="Intorduction"><a href="#Intorduction" class="headerlink" title="Intorduction"></a>Intorduction</h2><p>神经网路不适合去拟合非连续的函数，因为其假定一般形式具有连续性。在训练阶段，数据的连续性保证了优化的收敛性，在预测阶段，输入值的微小变化保证了输出的稳定。另一方面，决策树不假定特征变量有任何的连续性。</p><p>有意思的是，如果我们使用了正确的表示数据的形式，在现实世界中，我们面对的问题总是连续的。每当我们找到了一个更好的方式来表示连续数据，就提升了神经网络学习数据的能力。比如NLP是由于使用了w2v去将one-hot转为了连续的向量。</p><p>不同于自然中存在的非结构化数据，机器学习中使用的结构化数据可能很难发现连续性质。神经网络连续函数的特性限制了对于类别变量的应用。embedding解决了one-hot的两个问题，一是太过稀疏，而是类与类之间没有关联。</p><p>记号：（h,r,t），h和t是两个实体，r是关系。<br>在w2v中发现隐向量具有如下的关系：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/About%20id/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%881.49.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>w2v除了使用常规的滑动窗口学习还可以使用标记进行监督学习。<br>以及说树是结构化数据中用的最多的模型。以及该方法针对的是表格数据中的离散目标值，也就是类别值。</p><h2 id="Entity-Embedding"><a href="#Entity-Embedding" class="headerlink" title="Entity Embedding"></a>Entity Embedding</h2><p>embedding层的维度D是个超参数。范围是[1,m-1]，m是类别数。在实际中，根据实验来确定最后的维度数。下面是一些经验之谈，一，大体的估计一下需要描述的维度，二如果不知道怎么下手，从m-1开始。</p><p>定义衡量两个隐向量相似度的方法。最简单的就是隐向量求距离。</p><p>a example for dimension<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/About%20id/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%882.52.30.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>原始的数据是两部分，第一部分是train.csv,包含了2.5年的每日销售数据，包括1115种不同的商店，共计有1017210条数据。第二部分是关于1115店的更详细的信息。除了主办方给出的数据，外部的数据同样重要，比如日期的天气信息，流行信息，甚至于重大比赛的日期信息。</p><h1 id="业务实践"><a href="#业务实践" class="headerlink" title="业务实践"></a>业务实践</h1><p>场景：网络购物场景中，运用W2V+BP进行个性化推荐。</p><ol><li><strong>对物品进行向量化</strong>，把每个用户看作一篇文章，用户购买物品按照时间序列排序，物品看作词，带入W2V模型得到物品的向量。</li><li><strong>样本收集</strong>，收集客户端中，对用户的物品曝光及购买记录，以用户历史购买的物品列表作为用户画像，以给用户曝光物品后用户是否购买为目标变量。</li><li><strong>构造W2V + BP的模型</strong>，模型的输入有两个，第一个为用户历史购买物品的向量均值，第二个为曝光物品的向量。模型的输出为用户是否购买曝光的物品，中间用BP网络进行连接。</li><li><strong>模型训练与使用</strong>，模型训练：目前业界一般使用TF进行实现，BP网络的节点数及层数需要根据训练情况确定。模型使用：给定一个用户u及一个物品i，把用户u购买物品向量均值及物品i的向量作为模型输入，计算物品i的模型得分。重复该操作，计算出用户u所有候选物品的模型得分，根据物品的模型得分降序推荐给用户。</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/About%20id/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%884.23.44.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;如何利用id类特征&quot;&gt;&lt;a href=&quot;#如何利用id类特征&quot; class=&quot;headerlink&quot; title=&quot;如何利用id类特征&quot;&gt;&lt;/a&gt;如何利用id类特征&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/34
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Keras:getting started</title>
    <link href="https://github.com/zdkswd/2019/04/16/Keras:getting%20started/"/>
    <id>https://github.com/zdkswd/2019/04/16/Keras:getting started/</id>
    <published>2019-04-16T12:31:32.000Z</published>
    <updated>2019-04-16T12:32:08.098Z</updated>
    
    <content type="html"><![CDATA[<h1 id="30s-to-Keras"><a href="#30s-to-Keras" class="headerlink" title="30s to Keras"></a>30s to Keras</h1><p>The core data structure of Keras is a <strong>model</strong>,The simplest type of model is the Sequential model, a linear stack of layers.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.07.41.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Stacking layers is as easy as .add():<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.10.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>the first layer should specify input_dim.</p><p>Once your model looks good, configure its learning process with .compile():<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.11.58.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.13.57.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>通过引入Momentum可以让那些因学习率太大而来回摆动的参数，梯度能前后抵消，从而阻止发散。</p><p>You can now iterate on your training data in batches:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.15.15.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Alternatively, you can feed batches to your model manually:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.15.36.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Evaluate your performance in one line:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.16.01.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Or generate predictions on new data:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.23.03.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="a-densely-connected-network"><a href="#a-densely-connected-network" class="headerlink" title="a densely-connected network"></a>a densely-connected network</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.53.43.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p><strong>notice that a layer instance is callable on a tensor,and returns a tensor.</strong></p><h1 id="All-models-are-callable-just-like-layers"><a href="#All-models-are-callable-just-like-layers" class="headerlink" title="All models are callable, just like layers"></a>All models are callable, just like layers</h1><p>With the functional API, it is easy to reuse trained models: you can treat any model as if it were a layer, by calling it on a tensor. Note that by calling a model you aren’t just reusing the architecture of the model, you are also reusing its weights.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.00.22.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>This can allow, for instance, to quickly create models that can process sequences of inputs. You could turn an image classification model into a video classification model, in just one line.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.01.10.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Multi-input-and-multi-output-models"><a href="#Multi-input-and-multi-output-models" class="headerlink" title="Multi-input and multi-output models"></a>Multi-input and multi-output models</h1><p>Here’s a good use case for the functional API: models with multiple inputs and outputs. The functional API makes it easy to manipulate a large number of intertwined datastreams.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/multi-input-multi-output-graph.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>The main input will receive the headline, as a sequence of integers (each integer encodes a word). The integers will be between 1 and 10,000 (a vocabulary of 10,000 words) and the sequences will be 100 words long.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.13.45.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Here we insert the auxiliary loss, allowing the LSTM and Embedding layer to be trained smoothly even though the main loss will be much higher in the model.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.14.57.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>At this point, we feed into the model our auxiliary input data by concatenating it with the LSTM output:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.16.01.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>This defines a model with two inputs and two outputs:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.28.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>We compile the model and assign a weight of 0.2 to the auxiliary loss. To specify different loss_weights or loss for each different output, you can use a list or a dictionary. Here we pass a single loss as the loss argument, so the same loss will be used on all outputs.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.28.39.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>We can train the model by passing it lists of input arrays and target arrays:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.28.59.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Since our inputs and outputs are named (we passed them a “name” argument), we could also have compiled the model via:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.29.23.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h1><p>keras.layers.Embedding(input_dim, output_dim, embeddings_initializer=‘uniform’, embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)</p><p>This layer can only be used as the first layer in a model.<br>Example<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.27.54.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;30s-to-Keras&quot;&gt;&lt;a href=&quot;#30s-to-Keras&quot; class=&quot;headerlink&quot; title=&quot;30s to Keras&quot;&gt;&lt;/a&gt;30s to Keras&lt;/h1&gt;&lt;p&gt;The core data structure of Ker
      
    
    </summary>
    
      <category term="教程" scheme="https://github.com/zdkswd/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>转 逻辑回归LR的特征为什么要先离散化</title>
    <link href="https://github.com/zdkswd/2019/04/16/%E8%BD%AC%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92LR%E7%9A%84%E7%89%B9%E5%BE%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%85%88%E7%A6%BB%E6%95%A3%E5%8C%96/"/>
    <id>https://github.com/zdkswd/2019/04/16/转 逻辑回归LR的特征为什么要先离散化/</id>
    <published>2019-04-16T02:42:56.000Z</published>
    <updated>2019-04-16T02:43:13.399Z</updated>
    
    <content type="html"><![CDATA[<h1 id="转-逻辑回归LR的特征为什么要先离散化"><a href="#转-逻辑回归LR的特征为什么要先离散化" class="headerlink" title="转 逻辑回归LR的特征为什么要先离散化"></a>转 逻辑回归LR的特征为什么要先离散化</h1><p><a href="https://blog.csdn.net/yang090510118/article/details/39478033" target="_blank" rel="noopener">逻辑回归LR的特征为什么要先离散化 - yang090510118的专栏 - CSDN博客</a></p><p>在工业界，很少直接将连续值作为特征喂给逻辑回归模型，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：</p><ol><li>稀疏向量内积乘法运算速度快，计算结果方便存储，容易scalable（扩展）。</li><li>离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰。</li><li>逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。</li><li>离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力。</li><li>特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问。</li></ol><p>模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型” 同 “少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习。就看是喜欢折腾特征还是折腾模型了。通常来说，前者容易，而且可以n个人一起并行做，有成功经验；后者目前看很赞，能走多远还须拭目以待。</p><p>大概的理解：</p><p>1）计算简单<br>2）简化模型<br>3）增强模型的泛化能力，不易受噪声的影响</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;转-逻辑回归LR的特征为什么要先离散化&quot;&gt;&lt;a href=&quot;#转-逻辑回归LR的特征为什么要先离散化&quot; class=&quot;headerlink&quot; title=&quot;转 逻辑回归LR的特征为什么要先离散化&quot;&gt;&lt;/a&gt;转 逻辑回归LR的特征为什么要先离散化&lt;/h1&gt;&lt;p&gt;&lt;a
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>featexp</title>
    <link href="https://github.com/zdkswd/2019/04/14/featexp/"/>
    <id>https://github.com/zdkswd/2019/04/14/featexp/</id>
    <published>2019-04-14T12:15:32.000Z</published>
    <updated>2019-04-14T12:15:42.157Z</updated>
    
    <content type="html"><![CDATA[<h1 id="featexp"><a href="#featexp" class="headerlink" title="featexp"></a>featexp</h1><p><a href="https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c" target="_blank" rel="noopener">https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c</a></p><h1 id="feature-understanding"><a href="#feature-understanding" class="headerlink" title="feature understanding"></a>feature understanding</h1><p>if target is binary, scatter is not very useful.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%885.41.15.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>And for continuous target, too many data points make it difficult to understand the target vs. feature trend.</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%885.52.05.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>use above code,Featexp creates <strong>equal population bins (X-axis)</strong> of a numeric feature.It then calculates target’s <strong>mean</strong> in each bin and plots it in the left-hand side plot above. As you can see the plot on the right shows they are the same number.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%885.54.45.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Identifying-noisy-features"><a href="#Identifying-noisy-features" class="headerlink" title="Identifying noisy features"></a>Identifying noisy features</h1><p>Noisy features lead to overfitting and identifying them isn’t easy. In featexp, you can pass a test set and compare feature trends in train|test to identify noisy ones. This test set is not the actual test set. Its your local test set|validation set for which you know target.</p><blockquote><p>get_univariate_plots(data=data_train, target_col=’target’, data_test=data_test, features_list=[‘DAYS_EMPLOYED’])  </p></blockquote><p><img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%886.10.12.png" alt=""><br>Featexp calculates two metrics to display on these plots which help with gauging(计量；测量) noisiness:</p><p>1.<strong>Trend correlation</strong> (seen in test plot): If a feature doesn’t hold same trend w.r.t. target across train and evaluation sets, it can lead to overfitting. This happens because the model is learning something which is not applicable in test data. Trend correlation helps understand how similar train/test trends are and mean target values for bins in train &amp; test are used to calculate it. Feature above has 99% correlation. Doesn’t seem noisy!<br>2.<strong>Trend changes</strong>: Sudden and repeated changes in trend direction could imply noisiness. But, such trend change can also happen because that bin has a very different value in terms of <strong>other features</strong> and hence, its value can’t really be compared with other bins.</p><p>for example the nosiy feature.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%886.37.26.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>Dropping low trend-correlation features works well when <strong>there are a lot of features and they are correlated with each other</strong>. It leads to less overfitting and other correlated features avoid information loss. It’s also important to <strong>not drop too many important features</strong> as it might lead to a drop in performance. Also, <strong>you can’t identify these noisy features using feature importance</strong> because they could be fairly important and still be very noisy!</p><p><strong>Using test data from a different time period works better because then you would be making sure if feature trend holds over time.</strong></p><p><strong>get_trend_stats()</strong> function in featexp returns a dataframe with trend correlation and changes for each feature.</p><blockquote><p>from featexp import get_trend_stats  stats=get_trend_stats(data=data_train,target_col=’target’,data_test=data_test)  </p></blockquote><p><img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%886.54.44.png" alt=""><br> try dropping features with low trend-correlation in our data and see how results improve.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%886.56.50.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>We can see that higher the trend-correlation threshold to drop features, higher is the leaderboard (LB) AUC.</p><h1 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h1><p>The insights that you get by looking at these plots help with creating better features. Just having a better understanding of data can lead to better feature engineering. But, in addition to this, it can also help you in improving the existing features. Let’s look at another feature EXT_SOURCE_1:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%887.10.11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Feature-importance"><a href="#Feature-importance" class="headerlink" title="Feature importance"></a>Feature importance</h1><p>i choose xgboost this part.</p><h1 id="Feature-debugging"><a href="#Feature-debugging" class="headerlink" title="Feature debugging"></a>Feature debugging</h1><p>check the trend is or not as you wish.</p><h1 id="Leakage-Detection"><a href="#Leakage-Detection" class="headerlink" title="Leakage Detection"></a>Leakage Detection</h1><h1 id="Model-Monitoring"><a href="#Model-Monitoring" class="headerlink" title="Model Monitoring"></a>Model Monitoring</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;featexp&quot;&gt;&lt;a href=&quot;#featexp&quot; class=&quot;headerlink&quot; title=&quot;featexp&quot;&gt;&lt;/a&gt;featexp&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/my-secret-
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>美团  特征提取</title>
    <link href="https://github.com/zdkswd/2019/04/14/%E7%BE%8E%E5%9B%A2%20%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    <id>https://github.com/zdkswd/2019/04/14/美团  特征提取/</id>
    <published>2019-04-14T08:33:47.000Z</published>
    <updated>2019-04-14T08:33:37.891Z</updated>
    
    <content type="html"><![CDATA[<h1 id="美团-特征提取"><a href="#美团-特征提取" class="headerlink" title="美团  特征提取"></a>美团  特征提取</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BE%8E%E5%9B%A2%20%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/WechatIMG77.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BE%8E%E5%9B%A2%20%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/WechatIMG76.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;美团-特征提取&quot;&gt;&lt;a href=&quot;#美团-特征提取&quot; class=&quot;headerlink&quot; title=&quot;美团  特征提取&quot;&gt;&lt;/a&gt;美团  特征提取&lt;/h1&gt;&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div 
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle竞赛案例一</title>
    <link href="https://github.com/zdkswd/2019/04/14/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/"/>
    <id>https://github.com/zdkswd/2019/04/14/Kaggle竞赛案例一/</id>
    <published>2019-04-14T07:37:47.000Z</published>
    <updated>2019-04-14T07:44:25.371Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kaggle-CrowdFlower"><a href="#Kaggle-CrowdFlower" class="headerlink" title="Kaggle_CrowdFlower"></a>Kaggle_CrowdFlower</h1><p><a href="https://github.com/ChenglongChen/Kaggle_CrowdFlower">GitHub - ChenglongChen/Kaggle_CrowdFlower: 1st Place Solution for Search Results Relevance Competition on Kaggle (https://www.kaggle.com/c/crowdflower-search-relevance)</a><br>1st Place Solution for Search Results Relevance Competition on Kaggle<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/FlowChart.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>问题描述：搜索结果相关挑战，给定搜索结果，搜索出的产品名称，产品描述，建立模型去预测搜索结果的相关得分。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>解决方案分为两部分：特征工程和模型集成。</p><p>特征包括三部分的特征：<br>1.计数特征<br>2.距离特征<br>3.TF-IDF特征</p><p>在生产特征前，对数据进行拼写检查，同义词替换，词干提取是非常有用的。模型集成包括两个主要的步骤，首先，使用不同种，不同参数设置，不同特征子集去训练模型。然后使用训练的模型进行bagged集成选择。在训练集上使用交叉验证来评估表现。</p><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>进行了几步去清洗文本。</p><h2 id="去除HTML标签"><a href="#去除HTML标签" class="headerlink" title="去除HTML标签"></a>去除HTML标签</h2><p>在商品描述中存在html标签的干扰，使用bs4去除之。</p><h2 id="单词替换"><a href="#单词替换" class="headerlink" title="单词替换"></a>单词替换</h2><p>在搜索中会出现词义相关的搜索，要考虑到。<br>1.拼写纠正<br>2.同义词替换<br>3.词干提取</p><h2 id="特征提取-选择"><a href="#特征提取-选择" class="headerlink" title="特征提取/选择"></a>特征提取/选择</h2><p>$$\left(q_{i}, t_{i}, d_{i}\right)$$是train.csv以及test.csv中的第i个样本，qi是查询，ti是产品名，di是产品描述。使用ri和vi来表示<strong>median_relevance</strong>和<strong>relevance_variance</strong>。使用函数ngram(s,n)去提取句子中的n个词。例如<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.09.02.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h3 id="计数特征"><a href="#计数特征" class="headerlink" title="计数特征"></a>计数特征</h3><p>为$$\left{q_{i}, t_{i}, d_{i}\right}$$生成计数特征。</p><h4 id="基础计数特征"><a href="#基础计数特征" class="headerlink" title="基础计数特征"></a>基础计数特征</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.17.52.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h4 id="交叉计数特征"><a href="#交叉计数特征" class="headerlink" title="交叉计数特征"></a>交叉计数特征</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.20.07.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h4 id="交叉位置特征"><a href="#交叉位置特征" class="headerlink" title="交叉位置特征"></a>交叉位置特征</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.23.08.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="距离特征"><a href="#距离特征" class="headerlink" title="距离特征"></a>距离特征</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.24.35.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="TF-IDF特征"><a href="#TF-IDF特征" class="headerlink" title="TF-IDF特征"></a>TF-IDF特征</h3><h3 id="其他特征"><a href="#其他特征" class="headerlink" title="其他特征"></a>其他特征</h3><h4 id="查询ID"><a href="#查询ID" class="headerlink" title="查询ID"></a>查询ID</h4><p>将查询id进行独热编码。</p><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>相同的模型经常被用来在特征集上进行交叉验证来测试与之前的特征集合相比是否得分有所提升。对于高维特征，使用XGBoost with linear booster(MSE为目标函数)，对于低维特征使用sklearn中的ExtraTreesRegressor。</p><p>值得注意的是，有了集成选择(<strong>ensemble selection</strong>)，我们可以利用不同的特征集合来训练特征库，并且利用集成选择去挑选出最佳的集成。但是特征选择依旧有用。使用上述的特征选择，可以首先明确一些表现好的特征集合，然后使用其去训练模型，这会在一定程度上减少计算负担。</p><h2 id="模型技术和训练"><a href="#模型技术和训练" class="headerlink" title="模型技术和训练"></a>模型技术和训练</h2><h3 id="交叉验证方法学"><a href="#交叉验证方法学" class="headerlink" title="交叉验证方法学"></a>交叉验证方法学</h3><h4 id="划分"><a href="#划分" class="headerlink" title="划分"></a>划分</h4><p>StratifiedKFold</p><h1 id="Kaggle-HomeDepot"><a href="#Kaggle-HomeDepot" class="headerlink" title="Kaggle_HomeDepot"></a>Kaggle_HomeDepot</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/FlowChart%202.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="Kaggle——销售量预测"><a href="#Kaggle——销售量预测" class="headerlink" title="Kaggle——销售量预测"></a>Kaggle——销售量预测</h1><p>比赛地址<a href="https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data" target="_blank" rel="noopener">Predict Future Sales | Kaggle</a><br>这个比赛作为经典的时间序列问题之一，目标是为了预测下个月每种产品和商店的总销售额。</p><p>以下为<strong>1st solution</strong>。</p><h2 id="part1-hands-on-data"><a href="#part1-hands-on-data" class="headerlink" title="part1 hands on data"></a>part1 hands on data</h2><p><a href="https://www.kaggle.com/kyakovlev/1st-place-solution-part-1-hands-on-data/notebook" target="_blank" rel="noopener">https://www.kaggle.com/kyakovlev/1st-place-solution-part-1-hands-on-data/notebook</a></p><h3 id="数据域含义"><a href="#数据域含义" class="headerlink" title="数据域含义"></a>数据域含义</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%888.55.03.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>数据集情况：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%889.04.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%889.04.46.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="trick1"><a href="#trick1" class="headerlink" title="trick1"></a>trick1</h3><p><strong>downcasting DataFrame.</strong> It will save some memory, everyone will need all memory possible.</p><p>In this case from 134.4MB to 61.6 MB</p><h3 id="trick2"><a href="#trick2" class="headerlink" title="trick2"></a>trick2</h3><p>pd.pivot_table()透视表功能<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%888.52.35.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h3 id="trick3"><a href="#trick3" class="headerlink" title="trick3"></a>trick3</h3><p>利用图像去除极端值<br>使用<strong>seaborn</strong>。boxplot</p><h3 id="item-id"><a href="#item-id" class="headerlink" title="item_id"></a>item_id</h3><p>以item_id为索引，月份为列名生成表格来观察数据。<br>分析每个月销售的总和的趋势。<br>分析每个平均一个商品销售的趋势（和👆趋势一致）<br>查看有多少6个月来没有销售记录的商品<br>查看测试数据中有多少这样过期的商品<br>查看价格和销售额的离群点</p><p>可能的特征：</p><ol><li>时间间隔</li><li>商品放出的日期</li><li>上月的销售</li><li>销售的日期</li><li>临近的商品（id1000与1001的商品可能有所相似）</li></ol><h3 id="shop-id"><a href="#shop-id" class="headerlink" title="shop_id"></a>shop_id</h3><p>以shop_id为索引，月份为列名生成表格来观察数据。<br>查看最近开张的商店数<br>查看最近倒闭的商店数</p><p>可能的特征：</p><ol><li>时间间隔（shop_id/shp_cnt_mth）</li><li>开业月份（可能的开业促销活动）</li><li>倒闭月份（可能的清仓大甩卖）<h3 id="price"><a href="#price" class="headerlink" title="price"></a>price</h3>可能的特征：</li><li>价格分档（1/10/20/等等），显然，更低价的物品拥有着更大的销量。</li><li>打折和打折期间</li><li>价格的时间间隔（显示打折）</li><li>价格修正</li><li>店铺的收入<h3 id="dates"><a href="#dates" class="headerlink" title="dates"></a>dates</h3>可能的日期特征：</li><li>周末和假期的销售额（去修正月度的销售）</li><li>该月有几天（去修正月度的销售）</li><li>是第几个月（与季节性的物品有关）</li></ol><h3 id="shop-info"><a href="#shop-info" class="headerlink" title="shop info"></a>shop info</h3><p>shop city | shop type | shop name</p><p>可能的商店特征：</p><ol><li>shop city</li><li>shop type</li></ol><h3 id="items-csv"><a href="#items-csv" class="headerlink" title="items.csv"></a>items.csv</h3><p>从items.csv中挖掘特征<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%883.18.54.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>可能的特征，1.item name 2.Encoded aditional feature</p><h3 id="category-csv"><a href="#category-csv" class="headerlink" title="category.csv"></a>category.csv</h3><p>category.csv中满足的格式<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%883.25.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>可能的种类特征：</p><ol><li>部分</li><li>主要种类的名字</li><li>主要子种类的名字</li><li>第二子种类的名字</li></ol><h3 id="test-set"><a href="#test-set" class="headerlink" title="test set"></a>test set</h3><p>对测试数据集进行分析<br>将测试条目分为三组：</p><ol><li>Item/shop pairs that are in train</li><li>Items without any data</li><li>Items that are in train</li></ol><h1 id="Kaggle——销售量预测-1"><a href="#Kaggle——销售量预测-1" class="headerlink" title="Kaggle——销售量预测"></a>Kaggle——销售量预测</h1><p>没有看错，接下来是另一个solution<br>主要是Feature Engineering，XGBoost<br><a href="https://www.kaggle.com/dlarionov/feature-engineering-xgboost" target="_blank" rel="noopener">https://www.kaggle.com/dlarionov/feature-engineering-xgboost</a></p><h2 id="part1-，perfect-features"><a href="#part1-，perfect-features" class="headerlink" title="part1 ，perfect features"></a>part1 ，perfect features</h2><p>同样使用sns 显示后，去除离群点<br>其中有一个物品的价格是负，使用价格中位数来替换之。<br>根据名字来看有些商店id重复出现了，fix it。<br>对于商店，种类，物品进行预处理</p><h3 id="Monthly-sales"><a href="#Monthly-sales" class="headerlink" title="Monthly sales"></a>Monthly sales</h3><p>新增特征revenue：<br>train[‘revenue’] = train[‘item_price’] *  train[‘item_cnt_day’]</p><p>测试集是34个月中一些商店和一些物品的组合，共有5100 items * 42 shops = 2142400对组合。363个物品在训练集中是没有的。因此，对于大多数测试集中的物品目标值应该是0.另一个方面，训练集只包含过去售出或者退回的对。主要的思路是计算月度的销售将其在当月的对中用0值进行扩展。这样训练数据将会与测试数据相似。</p><p>将训练集中的 shop/item对去聚合去计算目标聚合，然后将目标值截取为（0，20），这样训练目标值将会与测试预测相似。</p><h3 id="测试集"><a href="#测试集" class="headerlink" title="测试集"></a>测试集</h3><p>将测试集的月份设置为34，并与训练集进行合并</p><h3 id="Shops-Items-Cats-features"><a href="#Shops-Items-Cats-features" class="headerlink" title="Shops/Items/Cats features"></a>Shops/Items/Cats features</h3><p>将shop，item，item_category表进行合并</p><h3 id="Traget-lags"><a href="#Traget-lags" class="headerlink" title="Traget lags"></a>Traget lags</h3><p>相当于将窗口移动，[0,33]，lags为1则为[1,33]</p><h3 id="均值编码特征"><a href="#均值编码特征" class="headerlink" title="均值编码特征"></a>均值编码特征</h3><p>表格的特征的命名形式为  feature1_feature2_avg_feature_cnt<br>意思为选定feature1,feature2,来聚合feature_cnt求均值。<br>求每个月中物品售出的均值数 0.3左右<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%888.09.49.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>求每个月中每个物品所对应的均值（可以理解为平均每家商店售出的值）<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%888.11.42.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>选定date_block_num，shop_id，在item_cnt_month聚合求均值<br>可以理解为一个月一家店销售物品数量的均值数<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%888.27.11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>同理还有：<br>选定date_block_num，item_category_id，在item_cnt_month聚合求均值<br>选定date_block_num，item_category_id，shop_id，在item_cnt_month聚合求均值<br>选定date_block_num，type_code，shop_id，在item_cnt_month聚合求均值<br>选定date_block_num，subtype_code，shop_id，在item_cnt_month聚合求均值<br>选定date_block_num，city_code，在item_cnt_month聚合求均值<br>选定date_block_num，city_code，item_id 在item_cnt_month聚合求均值<br>选定date_block_num，type_code 在item_cnt_month聚合求均值<br>选定date_block_num，subtype_code 在item_cnt_month聚合求均值</p><h3 id="trend-features"><a href="#trend-features" class="headerlink" title="trend features"></a>trend features</h3><p>上六个月的价格趋势。<br>上个月的商店的营收趋势。</p><h3 id="Special-features"><a href="#Special-features" class="headerlink" title="Special features"></a>Special features</h3><p>将月份中添加上天数</p><p>对于每个shop/item对上一笔销售的月，使用编程方法实现：<br>创建HashTable键值等于{shop_id,item_id},值等于date_block_num。对于数据表从上往下迭代。如果{row.shop_id,row.item_id}不在表中，则添加进表中，并将值设为row.date_block_num。如果HashTable中包含值，则计算cached value与row.date_block_num。</p><p>Months since the first sale for each shop/item pair and for item only.</p><h3 id="最终准备"><a href="#最终准备" class="headerlink" title="最终准备"></a>最终准备</h3><p>Because of the using 12 as lag value drop first 12 months. Also drop all the columns with this month calculated values (other words which can not be calcucated for the test set).</p><p>Producing lags brings a lot of nulls.</p><h2 id="part2-xgboost"><a href="#part2-xgboost" class="headerlink" title="part2 ,xgboost"></a>part2 ,xgboost</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Kaggle-CrowdFlower&quot;&gt;&lt;a href=&quot;#Kaggle-CrowdFlower&quot; class=&quot;headerlink&quot; title=&quot;Kaggle_CrowdFlower&quot;&gt;&lt;/a&gt;Kaggle_CrowdFlower&lt;/h1&gt;&lt;p&gt;&lt;a hre
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost调参</title>
    <link href="https://github.com/zdkswd/2019/04/14/XGBoost%E8%B0%83%E5%8F%82/"/>
    <id>https://github.com/zdkswd/2019/04/14/XGBoost调参/</id>
    <published>2019-04-14T06:54:47.000Z</published>
    <updated>2019-04-14T07:34:58.217Z</updated>
    
    <content type="html"><![CDATA[<h1 id="XGBoost调参"><a href="#XGBoost调参" class="headerlink" title="XGBoost调参"></a>XGBoost调参</h1><p><a href="https://www.cnblogs.com/mfryf/p/6293814.html" target="_blank" rel="noopener">XGBoost参数调优完全指南（附Python代码） - 知识天地 - 博客园</a></p><h1 id="XGBoost的优势"><a href="#XGBoost的优势" class="headerlink" title="XGBoost的优势"></a>XGBoost的优势</h1><ol><li><strong>正则化</strong>，标准GBM的实现没有像XGBoost这样的正则化步骤。正则化对减少过拟合也是有帮助的。</li><li><strong>并行处理</strong>，XGBoost可以实现并行处理，相比GBM有了速度的飞跃。主要不是生成树的Boosting阶段，而是计算gain的阶段。</li><li><strong>高度的灵活性</strong>，XGBoost 允许用户定义自定义优化目标和评价标准 它对模型增加了一个全新的维度，所以我们的处理不会受到任何限制。</li><li><strong>缺失值处理</strong>，XGBoost内置处理缺失值的规则。 用户需要提供一个和其它样本不同的值，然后把它作为一个参数传进去，以此来作为缺失值的取值。XGBoost在不同节点遇到缺失值时采用不同的处理方法，并且会学习未来遇到缺失值时的处理方法。</li><li><strong>剪枝</strong>，当分裂时遇到一个负损失时，GBM会停止分裂。因此GBM实际上是一个贪心算法。 XGBoost会一直分裂到指定的最大深度(max_depth)，然后回过头来剪枝。如果某个节点之后不再有正值，它会去除这个分裂。 这种做法的优点，当一个负损失（如-2）后面有个正损失（如+10）的时候，就显现出来了。GBM会在-2处停下来，因为它遇到了一个负值。但是XGBoost会继续分裂，然后发现这两个分裂综合起来会得到+8，因此会保留这两个分裂。</li><li><strong>内置交叉验证</strong>，XGBoost允许在每一轮boosting迭代中使用交叉验证。因此，可以方便地获得最优boosting迭代次数。 而GBM使用网格搜索，只能检测有限个值。</li><li><strong>在已有的模型基础上继续</strong>，XGBoost可以在上一轮的结果上继续训练。这个特性在某些特定的应用上是一个巨大的优势。 sklearn中的GBM的实现也有这个功能，两种算法在这一点上是一致的。</li></ol><h1 id="XGBoost的参数"><a href="#XGBoost的参数" class="headerlink" title="XGBoost的参数"></a>XGBoost的参数</h1><h2 id="通用参数"><a href="#通用参数" class="headerlink" title="通用参数"></a>通用参数</h2><ol><li><strong>booster[默认gbtree]</strong>，选择每次迭代的模型，有两种选择：gbtree：基于树的模型，gbliner：线性模型。尽管有两种booster可供选择，这里只介绍tree booster，因为它的表现远远胜过linear booster，所以linear booster很少用到。</li><li><strong>silent[默认0]</strong>，当这个参数值为1时，静默模式开启，不会输出任何信息。一般这个参数就保持默认的0，因为这样能帮我们更好地理解模型。</li><li><strong>nthread[默认值为最大可能的线程数]</strong>，这个参数用来进行多线程控制，应当输入系统的核数。 如果你希望使用CPU全部的核，那就不要输入这个参数，算法会自动检测它。<h2 id="booster参数"><a href="#booster参数" class="headerlink" title="booster参数"></a>booster参数</h2></li><li><strong>eta[默认0.3]</strong>，和GBM中的 learning rate 参数类似。 通过减少每一步的权重，可以提高模型的鲁棒性。 典型值为0.01-0.2。</li><li><strong>min_child_weight[默认1]</strong>，决定最小叶子节点样本权重和。 和GBM的 min_child_leaf 参数类似，但不完全一样。XGBoost的这个参数是最小样本权重的和，而GBM参数是最小样本总数。 这个参数用于避免过拟合。当它的值较大时，可以避免模型学习到局部的特殊样本。 但是如果这个值过高，会导致欠拟合。这个参数需要使用CV  (cross_validition) 来调整。</li><li><strong>max_depth[默认6]</strong>，和GBM中的参数相同，这个值为树的最大深度。 这个值也是用来避免过拟合的。max_depth越大，模型会学到更具体更局部的样本。 需要使用CV函数来进行调优。 典型值：3-10</li><li><strong>max_leaf_nodes</strong>，树上最大的节点或叶子的数量。 可以替代max_depth的作用。因为如果生成的是二叉树，一个深度为n的树最多生成n2个叶子。 如果定义了这个参数，GBM会忽略max_depth参数。</li><li><strong>gamma[默认0]</strong>，在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma指定了节点分裂所需的最小损失函数下降值。 这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。</li><li><strong>max_delta_step[默认0]</strong>，这参数限制每棵树权重改变的最大步长。如果这个参数的值为0，那就意味着没有约束。如果它被赋予了某个正值，那么它会让这个算法更加保守。 通常，这个参数不需要设置。但是当各类别的样本十分不平衡时，它对逻辑回归是很有帮助的。 这个参数一般用不到，但是你可以挖掘出来它更多的用处。</li><li><strong>subsample[默认1]</strong>，和GBM中的subsample参数一模一样。这个参数控制对于每棵树，随机采样的比例。 减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。 典型值：0.5-1</li><li><strong>colsample_bytree[默认1]</strong>，和GBM里面的max_features参数类似。用来控制每棵随机采样的列数的占比(每一列是一个特征)。 典型值：0.5-1</li><li><strong>colsample_bylevel[默认1]</strong>,用来控制树的每一级的每一次分裂，对列数的采样的占比。 我个人一般不太用这个参数，因为subsample参数和colsample_bytree参数可以起到相同的作用。但是如果感兴趣，可以挖掘这个参数更多的用处。</li><li><strong>lambda[默认1]</strong>,权重的L2正则化项。(和Ridge regression类似)。 这个参数是用来控制XGBoost的正则化部分的。虽然大部分数据科学家很少用到这个参数，但是这个参数在减少过拟合上还是可以挖掘出更多用处的。</li><li><strong>alpha[默认1]</strong>,权重的L1正则化项。(和Lasso regression类似)。 可以应用在很高维度的情况下，使得算法的速度更快。</li><li><strong>scale_pos_weight[默认1]</strong>,在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。</li></ol><h2 id="学习目标参数"><a href="#学习目标参数" class="headerlink" title="学习目标参数"></a>学习目标参数</h2><ol><li><strong>objective[默认reg:linear]</strong>，这个参数定义需要被最小化的损失函数。最常用的值有：binary:logistic 二分类的逻辑回归，返回预测的概率(不是类别)。multi:softmax 使用softmax的多分类器，返回预测的类别(不是概率)。在这种情况下，你还需要多设一个参数：num_class(类别数目)。 multi:softprob 和multi:softmax参数一样，但是返回的是每个数据属于各个类别的概率。</li><li><strong>eval_metric[默认值取决于objective参数的取值]</strong>，对于有效数据的度量方法。 对于回归问题，默认值是rmse，对于分类问题，默认值是error。 典型值有：rmse 均方根误差，mae 平均绝对误差(∑Ni=1|?|N) logloss 负对数似然函数值 error 二分类错误率(阈值为0.5) merror 多分类错误率 mlogloss 多分类logloss损失函数 auc 曲线下面积。</li><li><strong>seed(默认0)</strong>，随机数的种子 设置它可以复现随机数据的结果，也可以用于调整参数。</li></ol><h1 id="参数调优的一般方法"><a href="#参数调优的一般方法" class="headerlink" title="参数调优的一般方法"></a>参数调优的一般方法</h1><p>我们会使用和GBM中相似的方法。需要进行如下步骤：</p><ol><li>选择较高的学习速率(learning rate)。一般情况下，学习速率的值为0.1。但是，对于不同的问题，理想的学习速率有时候会在0.05到0.3之间波动。选择对应于此学习速率的理想决策树数量。XGBoost有一个很有用的函数“cv”，这个函数可以在每一次迭代中使用交叉验证，并返回理想的决策树数量。</li><li>对于给定的学习速率和决策树数量，进行决策树特定参数调优(max_depth, min_child_weight, gamma, subsample, colsample_bytree)。在确定一棵树的过程中，可以选择不同的参数。</li><li>xgboost的正则化参数的调优。(lambda, alpha)。这些参数可以降低模型的复杂度，从而提高模型的表现。</li><li>降低学习速率，确定理想参数。<h1 id="用xgboost模型对特征重要性进行排序"><a href="#用xgboost模型对特征重要性进行排序" class="headerlink" title="用xgboost模型对特征重要性进行排序"></a>用xgboost模型对特征重要性进行排序</h1><h2 id="梯度提升算法是如何计算特征重要性的？"><a href="#梯度提升算法是如何计算特征重要性的？" class="headerlink" title="梯度提升算法是如何计算特征重要性的？"></a>梯度提升算法是如何计算特征重要性的？</h2>使用梯度提升算法的好处是在提升树被创建后，可以相对直接地得到每个属性的重要性得分。一般来说，重要性分数，衡量了特征在模型中的提升决策树构建中价值。一个属性越多的被用来在模型中构建决策树，它的重要性就相对越高。</li></ol><p>属性重要性是通过对数据集中的每个属性进行计算，并进行排序得到。在单个决策树中通过每个属性分裂点改进性能度量的量来计算属性重要性，由节点负责加权和记录次数。也就说一个属性对分裂点改进性能度量越大（越靠近根节点），权值越大；被越多提升树所选择，属性越重要。性能度量可以是选择分裂节点的Gini纯度，也可以是其他度量函数。</p><p>最终将一个属性在所有提升树中的结果进行加权求和后然后平均，得到重要性得分。</p><h2 id="根据xgboost特征重要性得分进行特征选择"><a href="#根据xgboost特征重要性得分进行特征选择" class="headerlink" title="根据xgboost特征重要性得分进行特征选择"></a>根据xgboost特征重要性得分进行特征选择</h2><p>特征重要性得分，可以用于在scikit-learn中进行特征选择。通过SelectFromModel类实现，该类采用模型并将数据集转换为具有选定特征的子集。这个类可以采取预先训练的模型，例如在整个数据集上训练的模型。然后，它可以阈值来决定选择哪些特征。当在SelectFromModel实例上调用transform()方法时，该阈值被用于在训练集和测试集上一致性选择相同特征。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>1、仅仅靠参数的调整和模型的小幅优化，想要让模型的表现有个大幅度提升是不可能的。GBM的最高得分是0.8487，XGBoost的最高得分是0.8494。确实是有一定的提升，但是没有达到质的飞跃。<br>2、要想让模型的表现有一个质的飞跃，需要依靠其他的手段，诸如，特征工程(feature egineering) ，模型组合(ensemble of model),以及堆叠(stacking)等。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;XGBoost调参&quot;&gt;&lt;a href=&quot;#XGBoost调参&quot; class=&quot;headerlink&quot; title=&quot;XGBoost调参&quot;&gt;&lt;/a&gt;XGBoost调参&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/mfryf/p/6
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>特征选择</title>
    <link href="https://github.com/zdkswd/2019/04/09/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    <id>https://github.com/zdkswd/2019/04/09/特征选择/</id>
    <published>2019-04-09T02:09:47.000Z</published>
    <updated>2019-04-09T02:10:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>特征选择是特征工程里的一个重要问题，其目标是寻找最优特征子集。特征选择的目的有如下三个：</p><ol><li>简化模型，使模型更易于研究人员和用户理解。</li><li>改善性能。节省存储和计算开销。</li><li>改善通用性，降低过拟合的风险。</li></ol><p>特征选择的一般流程<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/v2-a69a37aaa14a8040b4d867d7058aafe9_hd.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>主要分为产生过程，评估过程，停止条件和验证过程。</p><p><strong>当特征数量很大的时候， 这个搜索空间会很大，如何找最优特征还是需要一些经验结论。</strong></p><h1 id="具体特征选择方法"><a href="#具体特征选择方法" class="headerlink" title="具体特征选择方法"></a>具体特征选择方法</h1><p>分为三大类：</p><ol><li>Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。</li><li>Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。</li><li>Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小排序选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。</li></ol><h2 id="过滤特征选择"><a href="#过滤特征选择" class="headerlink" title="过滤特征选择"></a>过滤特征选择</h2><p>过滤特征选择法的想法是针对每个特征 x_i ，i 从 1 到 n ，计算 x_i 相对于类别标签 y 的信息量 S(i) ，得到 n 个结果，然后将 n 个 S(i) 按照从大到小排序，输出前 k  个特征。显然，这样复杂度大大降低。那么关键的问题就是使用什么样的方法来度量 S(i) ，我们的目标是选取与 y 关联最密切的一些 特征x_i 。</p><h3 id="Pearson相关系数"><a href="#Pearson相关系数" class="headerlink" title="Pearson相关系数"></a>Pearson相关系数</h3><p>皮尔森相关系数是一种最简单的，能帮助理解特征和响应变量之间关系的方法，该方法衡量的是变量之间的线性相关性，结果的取值区间为 [-1,1] ， -1 表示完全的负相关(这个变量下降，那个就会上升)， +1 表示完全的正相关， 0 表示没有线性相关。Pearson Correlation速度快、易于计算，经常在拿到数据(经过清洗和特征提取之后的)之后第一时间就执行。Scipy的pearsonr方法能够同时计算相关系数和p-value，<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8A%E5%8D%8810.03.30.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Pearson相关系数的一个<strong>明显缺陷</strong>是，作为特征排序机制，他只对<strong>线性关系敏感</strong>。如果关系是非线性的，即便两个变量具有一一对应的关系，Pearson相关性也可能会接近 0 。</p><h3 id="卡方验证"><a href="#卡方验证" class="headerlink" title="卡方验证"></a>卡方验证</h3><p>什么是卡方检验：<br>卡方检验就是检验两个变量之间有没有关系。<br>以运营为例:<br>卡方检验可以检验男性或者女性对线上买生鲜食品有没有区别；<br>不同城市级别的消费者对买SUV车有没有什么区别；<br>如果有显著区别的话，我们会考虑把这些变量放到模型或者分析里去。</p><p>注意：<strong>卡方检验针对分类变量。</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8A%E5%8D%8810.42.27.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8A%E5%8D%8810.42.41.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>置信度的话，我们按照我们自己意愿挑选，一般我们会挑90％或者95%。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8A%E5%8D%8810.47.39.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8A%E5%8D%8810.48.01.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8A%E5%8D%8811.00.32.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>卡方检验就是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时，卡方值就为0，表明理论值完全符合。</p><p>不难发现，这个统计量的含义简而言之就是自变量对因变量的相关性。用sklearn中feature_selection库的SelectKBest类结合卡方检验来选择特征的代码如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8A%E5%8D%8810.31.35.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>sklearn.feature_selection模块中的类可以用于样本集中的特征选择/维数降低，以提高估计器的准确度分数或提高其在非常高维数据集上的性能</p><h3 id="互信息和最大信息系数"><a href="#互信息和最大信息系数" class="headerlink" title="互信息和最大信息系数"></a>互信息和最大信息系数</h3><p>经典的互信息也是评价定性自变量对定性因变量的相关性的，互信息公式如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8B%E5%8D%8812.39.16.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>当 x_i 是0/1离散值的时候，这个公式如上。很容易推广到 x_i 是多个离散值的情况。这里的 p(x_i,y) , p(x_i) 和 p(y) 都是从训练集上得到的。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8B%E5%8D%8812.40.00.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>MI 衡量的是 x_i 和 y 的独立性。如果它俩独立 P(x_i,y)=p(x_i)p(y) ，那么 KL 距离值为0，也就是 x_i 和 y 不相关了，可以去除 x_i 。相反，<strong>如果两者密切相关，那么 MI 值会很大。</strong></p><p>在对 MI 进行排名后，最后剩余的问题就是如何选择 k 个值（前 k 个 x_i ）。我们继续使用交叉验证的方法，将 k 从 1 扫描到 n ，取最大的 F 。</p><p>想把互信息直接用于特征选择其实不是太方便：1、它不属于度量方式，也没有办法归一化，在不同数据及上的结果无法做比较；2、对于连续变量的计算不是很方便（ X 和 Y 都是集合, x_i, y 都是离散的取值），通常变量需要先离散化，而互信息的结果对离散化的方式很敏感。</p><p>最大信息系数克服了这两个问题。它首先寻找一种最优的离散化方式，然后把互信息取值转换成一种度量方式，取值区间在 [0,1] 。minepy提供了MIC功能。</p><p> 如y=x^2 这个例子，MIC算出来的互信息值为1(最大的取值)。代码如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-08%20%E4%B8%8B%E5%8D%8812.50.37.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h3 id="距离相关系数"><a href="#距离相关系数" class="headerlink" title="距离相关系数"></a>距离相关系数</h3><p>距离相关系数是为了克服Pearson相关系数的弱点而生的。在 x 和 x^2 这个例子中，即便Pearson相关系数是 0 ，我们也不能断定这两个变量是独立的（<strong>有可能是非线性相关</strong>）；但如果距离相关系数是 0 ，那么我们就可以说这两个变量是独立的。</p><p>尽管有MIC和距离相关系数在了，但当变量之间的关系接近线性相关的时候，Pearson相关系数仍然是不可替代的。第一、Pearson相关系数计算速度快，这在处理大规模数据的时候很重要。第二、Pearson相关系数的取值区间是[-1，1]，而MIC和距离相关系数都是[0，1]。这个特点使得Pearson相关系数能够表征更丰富的关系，符号表示关系的正负，绝对值能够表示强度。当然，Pearson相关性有效的前提是两个变量的变化关系是单调的。</p><h3 id="方差选择法"><a href="#方差选择法" class="headerlink" title="方差选择法"></a>方差选择法</h3><p>过滤特征选择法还有一种方法不需要度量特征 x_i 和类别标签 y 的信息量。这种方法先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。</p><p>例如，假设我们有一个具有布尔特征的数据集，并且我们要删所有01特征中出现0的概率超过80%的特征。布尔特征是伯努利随机变量，这些变量的方差由下式给出:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-09%20%E4%B8%8A%E5%8D%889.06.28.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>VarianceThreshold是特征选择的简单基线方法。它删除方差不符合某个阈值的所有特征。默认情况下，它会删除所有零差异特征，即所有样本中具有相同值的特征。代码如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-09%20%E4%B8%8A%E5%8D%889.08.42.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>输出结果：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-09%20%E4%B8%8A%E5%8D%889.09.21.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>如预期的那样，VarianceThreshold已经删除了第一列，其具有 p=5/6&gt;0.8 包含零的概率。</p><h2 id="包装-wrapper-特征选择"><a href="#包装-wrapper-特征选择" class="headerlink" title="包装(wrapper)特征选择"></a>包装(wrapper)特征选择</h2><p>Wrapper这里指不断地使用不同的特征组合来测试学习算法进行特征选择。先选定特定算法， 一般会选用普遍效果较好的算法， 例如Random Forest， SVM， kNN等等。</p><h3 id="前向搜索"><a href="#前向搜索" class="headerlink" title="前向搜索"></a>前向搜索</h3><p>前向搜索说白了就是每次增量地从剩余未选中的特征选出一个加入特征集中，待达到阈值或者 n 时，从所有的 F 中选出错误率最小的。过程如下：</p><ol><li>初始化特征集 F 为空。</li><li>扫描 i 从 1 到 n如果第 i 个特征不在 F 中，那么特征 i 和F 放在一起作为 F_i (即取并集，在只使用 F_i 中特征的情况下，利用交叉验证来得到 F_i 的错误率。</li><li>从上步中得到的 n 个 F_i 中选出错误率最小的 F_i ,更新 F 为 F_i 。</li><li>如果 F 中的特征数达到了 n 或者预定的阈值（如果有的话），那么输出整个搜索过程中最好的 ；若没达到，则转到 2，继续扫描。</li></ol><h3 id="后向搜索"><a href="#后向搜索" class="headerlink" title="后向搜索"></a>后向搜索</h3><p>既然有增量加，那么也会有增量减，后者称为后向搜索。先将 F 设置为 {1,2,…,n} ，然后每次删除一个特征，并评价，直到达到阈值或者为空，然后选择最佳的 F 。</p><p><strong>这两种算法都可以工作，但是计算复杂度比较大。</strong>时间复杂度为<br>O(n+(n-1)+(n-2)+…+1)=O(n^2)</p><h3 id="递归特征消除法"><a href="#递归特征消除法" class="headerlink" title="递归特征消除法"></a>递归特征消除法</h3><p>递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。使用feature_selection库的RFE类来选择特征的代码如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-09%20%E4%B8%8A%E5%8D%889.30.05.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="嵌入-Embedded-特征选择"><a href="#嵌入-Embedded-特征选择" class="headerlink" title="嵌入(Embedded)特征选择"></a>嵌入(Embedded)特征选择</h2><h3 id="基于惩罚项的特征选择法"><a href="#基于惩罚项的特征选择法" class="headerlink" title="基于惩罚项的特征选择法"></a>基于惩罚项的特征选择法</h3><p>通过L1正则项来选择特征：L1正则方法具有稀疏解的特性，因此天然具备特征选择的特性，但是要注意，L1没有选到的特征不代表不重要，原因是两个具有高相关性的特征可能只保留了一个，如果要确定哪个特征重要应再通过L2正则方法交叉检验。</p><h3 id="基于学习模型的特征排序"><a href="#基于学习模型的特征排序" class="headerlink" title="基于学习模型的特征排序"></a>基于学习模型的特征排序</h3><p>这种方法的思路是直接使用你要用的机器学习算法，针对每个单独的特征和响应变量建立预测模型。假如某个特征和响应变量之间的关系是非线性的，可以用基于树的方法（决策树、随机森林）、或者扩展的线性模型等。基于树的方法比较易于使用，因为他们对非线性关系的建模比较好，并且不需要太多的调试。但要注意过拟合问题，因此树的深度最好不要太大，再就是运用交叉验证。通过这种训练对特征进行打分获得相关性后再训练最终模型。</p><p>在波士顿房价数据集上使用sklearn的随机森林回归给出一个单变量选择的例子：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-09%20%E4%B8%8A%E5%8D%889.52.18.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;特征选择&quot;&gt;&lt;a href=&quot;#特征选择&quot; class=&quot;headerlink&quot; title=&quot;特征选择&quot;&gt;&lt;/a&gt;特征选择&lt;/h1&gt;&lt;p&gt;特征选择是特征工程里的一个重要问题，其目标是寻找最优特征子集。特征选择的目的有如下三个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;简化模型
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>百面  特征工程</title>
    <link href="https://github.com/zdkswd/2019/04/04/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    <id>https://github.com/zdkswd/2019/04/04/百面  特征工程/</id>
    <published>2019-04-04T12:00:47.000Z</published>
    <updated>2019-04-04T12:00:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="百面-特征工程"><a href="#百面-特征工程" class="headerlink" title="百面  特征工程"></a>百面  特征工程</h1><p>Garbage in, garbage out。对于一个机器学习问题，<strong>数据和特征</strong>往往<strong>决定</strong>结果的<strong>上限</strong>，而模型，<strong>算法</strong>的选择及优化是在逐步<strong>接近</strong>这个<strong>上限</strong>。</p><p>特征工程，顾名思义，是对原始数据进行一系列工程处理，将其提炼为特征，作为<strong>输入</strong>供算法和模型使用。从本质上来讲，特征工程是一个表示和展现数据的过程。在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关系。<strong>特征就是指input的x！</strong></p><p>有两种常用的数据类型：<br>(1) 结构化数据。结构化数据类型可以看作关系型数据库的一张表，每列都有清晰的定义，包含了数值型、类别型两种基本类型，每一行数据表示一个样本的信息。</p><p>（2）非结构化数据。非结构化数据主要包括文本，图像，音频，视频数据，其包含的信息无法用一个简单的数值表示，也没有清晰的类别定义，并且每条数据的大小各不相同。</p><h1 id="特征归一化"><a href="#特征归一化" class="headerlink" title="特征归一化"></a>特征归一化</h1><p>为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，使得不同指标之间具有可比性。例如，分析一个人的身高和体重对健康的影响，如果<br>使用米(m)和千克(kg)作为单位，那么身高特征会在1.6~1.8m的数值范围内，体重特征会在50~100kg的范围内，分析出来的结果显然会倾向于数值差别比较大的体重特征。想要得到更为准确的结果，就需要进行特征归一化(Normalization)处理，使各指标处于同一数值量级，以便进行分析。</p><h2 id="为什么需要对数值类型的特征做归一化？"><a href="#为什么需要对数值类型的特征做归一化？" class="headerlink" title="为什么需要对数值类型的特征做归一化？"></a>为什么需要对数值类型的特征做归一化？</h2><p>对数值类型的特征做归—化可以将所有的特征都统一到一个大致相同的数值区间内。最常用的方法主要有以下两种。</p><p>(1)线性函数归一化(Min-Max Scaling) 。它对原始数据进行线性变换，使结果映射到[0, 1]的范围，实现对原始数据的等比缩放。归一化公式如下<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-03%20%E4%B8%8B%E5%8D%881.35.54.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>（2）零均值归一化(Z-Score Normalization)。它会将原始数据映射到均值为0、标准差为1的分布上。具体来说，假设原始特征的均值为μ、标准差为δ，那么归一化公式定义为<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-03%20%E4%B8%8B%E5%8D%881.49.37.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>对数值型特征做归一化的原因在于，<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/WechatIMG70.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>数据归一化不是万能的，在实际应用中，通过<strong>梯度下降法</strong>求解的模型通常是需要归一化的，包括线性回归，逻辑回归，支持向量机，神经网络等模型。但对于决策树模型则并不适用，以C4.5为例，决策树在进行节点分裂时主要依据数据集D关于特征x的信息增益比，而信息增益比跟特征是否经过归一化是无关的，因为归一化不会改变样本在特征x上的信息增益。</p><h1 id="类别型特征"><a href="#类别型特征" class="headerlink" title="类别型特征"></a>类别型特征</h1><p>类别型特征(Categorical Feature)主要是指性别(男、女)、血型(A、B、AB、O)等只在有限选项内取值的特征。类别型特征原始输入通常是字符串形式，除了决策树等少数模型能直接处理字符串形式的输入，<strong>对于逻辑回归、支持向量机等模型来说，类别型特征必须经过处理转换成数值型特征才能正确工作。</strong></p><h2 id="与处理时如何处理类别型特征？"><a href="#与处理时如何处理类别型特征？" class="headerlink" title="与处理时如何处理类别型特征？"></a>与处理时如何处理类别型特征？</h2><h3 id="序号编码"><a href="#序号编码" class="headerlink" title="序号编码"></a>序号编码</h3><p>序号编码通常用于处理类别间具有大小关系的数据。例如成绩，可以分为低、中、高三档，并且存在“高&gt;中&gt;低”的排序关系。序号编码会按照大小关系对类别型特征赋予一个数值ID,例如高表示为3、中表示为2、低表示为1,转换后依然保留了大小关系。</p><h3 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h3><p>独热编码通常用于处理类别间不具有大小关系的特征。例如血型，一共有4个取值(A型血、B型血、AB型血、O型血)，独热编码会把血型变成一个4维稀疏向量，A型血表示为(1,0,0,0) ，B型血表示为(0, 1,0,0)，AB型表示为(0, 0,1,0)，O型血表示为(0,0,0,1)。对于类别取值较多的情况下使用独热编码需要<br>注意以下问题。</p><p>(1)使用稀疏向量来节省空间。在独热编码下，特征向量只有某一维取值为1，其他位置取值均为0。因此可以利用向量的稀疏表示有效地节省空间，并且目<br>前大部分的算法均接受稀疏向量形式的输入。</p><p>(2)配合特征选择来降低维度。高维度特征会带来几方面的问题。一是在K近邻算法中，高维空间下两点之间的距离很难得到有效的衡量;二是在逻辑回归模型中，参数的数量会随着维度的增高而增加，容易引起过拟合问题;三是通常只有部分维度是对分类、预测有帮助，因此可以考虑配合特征选择来降低维度。</p><h3 id="二进制编码"><a href="#二进制编码" class="headerlink" title="二进制编码"></a>二进制编码</h3><p>二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID,然后将类别ID对应的二进制编码作为结果。以A、B、AB、O血型为例，A型血的ID为1，二进制表示为001; B型血的ID为2，二进制表示为010;以此类推可以得到AB型血和O型血的二进制表示。可以看出，二进制编码本质上是利用二进制对ID进行哈希映射，最终得到0/1特征向量，且维数少于独热编码，节省了存储空间。</p><h1 id="组合特征"><a href="#组合特征" class="headerlink" title="组合特征"></a>组合特征</h1><h2 id="什么是组合特征？如何处理高维组合特征？"><a href="#什么是组合特征？如何处理高维组合特征？" class="headerlink" title="什么是组合特征？如何处理高维组合特征？"></a>什么是组合特征？如何处理高维组合特征？</h2><p>为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。以广告点击预估问题为例，原始数据有语言和类型两种离散特征，表1.2是语言和类型对点击的影响。为了提高拟合能力，语言和类型可以组成二阶特征，表1.3是语言和类型的组合特征对点击的影响。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/WechatIMG71.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><strong>表1.3乃组合特征矩阵。</strong><br>以逻辑回归为例，假设数据的特征向量为X=(x1,x2,…,xk)，则有，<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-03%20%E4%B8%8B%E5%8D%889.42.46.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中&lt;xi,xj&gt;表示xi和xj的组合特征,wij的维度等于|xi| * |xj|，|xi|和|xj|分别代表第i个特征和第j个特征不同取值的个数。在上述表中，wij即为表1.3中的0或1。</p><p>若是关于用户和物品的矩阵，用户数量为m，物品数量为n，当m，n的数量巨大时，几乎无法学习m•n规模的参数。此时，有效的办法是将用户和物品分别用k维的低维向量表示，k远小于m和n。此时<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/page29image88376.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>分别表示xi和xj对应的低维向量。需要学习的参数规模变为了m•k+n•k。这也就是推荐系统中的矩阵分解。</p><p>上述内容即为利用<strong>降维方法来减少两个高维特征组合后需要学习的参数。</strong></p><h1 id="组合特征-1"><a href="#组合特征-1" class="headerlink" title="组合特征"></a>组合特征</h1><p>在实际应用中，常常需要面对多种高维特征，简单地两两组合依然容易存在参数过多，过拟合等问题，而且并不是所有的特征组合都是有意义的。可以采用GBDT来构建特征。</p><h1 id="文本表示模型"><a href="#文本表示模型" class="headerlink" title="文本表示模型"></a>文本表示模型</h1><p>文本是一类非常重要的非结构化数据,如何表示文本数据一直是机器学习领域的一个重要研究方向。</p><h2 id="有哪些文本表示模型？各有什么优缺点？"><a href="#有哪些文本表示模型？各有什么优缺点？" class="headerlink" title="有哪些文本表示模型？各有什么优缺点？"></a>有哪些文本表示模型？各有什么优缺点？</h2><h3 id="词袋模型和N-gram模型"><a href="#词袋模型和N-gram模型" class="headerlink" title="词袋模型和N-gram模型"></a>词袋模型和N-gram模型</h3><p>最基础的文本表示模型是<strong>词袋模型</strong>。顾名思义,就是将每篇文章看成一袋子词,并忽略每个词出现的顺序。具体地说,就是将整段文本以词为单位切分开然后每篇文章可以表示成一个<strong>长向量</strong>,向量中的每一维代表一个单词,而该维对应的权重则反映了这个词在原文章中的重要程度。<strong>常用TF-IDF来计算权重</strong>,公式为<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-04%20%E4%B8%8B%E5%8D%886.43.52.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中TF(t,d)为单词t在文档d中出现的频率,IDF(t)是<strong>逆文档频率</strong>,用来衡量单词t对表达语义所起的重要性,表示为<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-04%20%E4%B8%8B%E5%8D%886.46.07.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>直观的解释是,如果一个单词在非常多的文章里面都出现,那么它可能是一个比较通用的词汇,对于区分某篇文章特殊语义的贡献较小,因此对权重做一定惩罚。</p><p>将文章进行单词级别的划分有时候并不是一种好的做法,比如英文中的natural  language processing(自然语言处理)一词,如果将 natural, language, processing这3个词拆分开来,所表达的含义与三个词连续出现时大相径庭。通常,可以将连续出现的n个词(n≤N)组成的词组(<strong>N-gram</strong>)也作为一个单独的特征放到向量表示中去,构成<strong>N-gram模型</strong>。另外,同一个词可能有多种词性变化,却具有相似的含义。在实际应用中,一般会对单词进行词干抽取(Word Stemming)处理,即将不同词性的单词统一成为同一词干的形式。</p><h3 id="主题模型"><a href="#主题模型" class="headerlink" title="主题模型"></a>主题模型</h3><p>主题模型用于从文本库中发现有代表性的主题，并且能够计算出每篇文章的主题分布。</p><h3 id="词嵌入与深度学习模型"><a href="#词嵌入与深度学习模型" class="headerlink" title="词嵌入与深度学习模型"></a>词嵌入与深度学习模型</h3><p>词嵌入是一类将词向量化的模型的统称,核心思想是将每个词都映射成低维空间(通常K=50~300维)上的一个稠密向量(<strong>Dense vector</strong>)。K维空间的每一维也可以看作一个隐含的主题,只不过不像主题模型中的主题那样直观。</p><p>由于词嵌入将每个词映射成一个K维的向量,如果一篇文档有N个词,就可以用一个NxK维的矩阵来表示这篇文档,但是这样的表示过于底层。在实际应用中,如果仅仅把这个矩阵作为原文本的表示特征输入到机器学习模型中,通常很难得到令人满意的结果。</p><p>因此,还需要在此基础之上加工出更高层的特征。在传统的浅层机器学习模型中,一个好的特征工程往往可以带来算法效果的显著提升。而深度学习模型正好为我们提供了一种自动地进行特征工程的方式,模型中的每个隐层都可以认为对应着不同抽象层次的特征。从这个角度来讲,<strong>深度学习模型</strong>能够打败浅层模型也就顺理成章了。卷积神经网络和循环神经网络的结构在文本表示中取得了很好的效果,主要是由于它们能够更好地对文本进行建模,抽取出一些高层的语义特征。与全连接的网络结构相比,卷积神经网络和循环神经网络一方面很好地抓住了文本的特性,另一方面又减少了网络中待学习的参数,提高了训练速度,并且降低了过拟合的风险。</p><p>所以说嵌入加深度模型成为了标配。</p><h1 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h1><p>谷歌2013年提出的word2vec是目前最常用的词嵌入模型之一。Word2Vec实际是一种<strong>浅层的神经网络模型</strong>,它有两种网络结构,分别是CBOW(Continues Bag of words)和Skip-gram。</p><h2 id="word2vec是如何工作的-它和LDA有什么区别与联系"><a href="#word2vec是如何工作的-它和LDA有什么区别与联系" class="headerlink" title="word2vec是如何工作的?它和LDA有什么区别与联系?"></a>word2vec是如何工作的?它和LDA有什么区别与联系?</h2><p><strong>CBOW</strong>的目标是根据上下文出现的词语来预测当前词的生成概率;而Skip-gram是根据当前词来预测上下文中各词的生成概率。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-04%20%E4%B8%8B%E5%8D%887.15.32.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中w()是当前所关注的词,w(t-2)、w(t-1)、w(t+1)、w(t+2)是上下文中出现的词。这里前后滑动窗口大小均设为2。</p><p>CBOW和Skip-gram都可以表示成由输入层(Input)、映射层(Projection)和输出层(Output)组成的神经网络。</p><p><strong>输入层</strong>中的每个词由<strong>独热编码</strong>方式表示,即所有词均表示成一个N维向量,其中N为词汇表中单词的总数。</p><p><strong>映射层</strong>(又称<strong>隐含层</strong>)中,K个隐含单元(Hidden units)的取值可以由N维输入向量以及连接输入和隐含单元之间的NxK维权重矩阵计算得到。在CBOW中,还需要将各个输入词所计算出的隐含单元求和。</p><p>同理,输出层向量的值可以通过隐含层向量(K维),以及连接隐含层和输出层之间的KxN维权重矩阵计算得到。输出层也是一个N维向量,每维与词汇表中的个单词相对应。最后,对输出层向量应用 Softmax激活函数,可以计算出每个单词的生成概率。 Softmax激活函数的定义为<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-04%20%E4%B8%8B%E5%8D%887.34.02.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中x代表N维的原始输出向量,xn为在原始输出向量中,与单词wn所对应维度的取值。</p><p>接下来的任务就是训练神经网络的权重,使得语料库中所有单词的整体生成概率最大化。从输入层到隐含层需要一个维度为NxK的权重矩阵,从隐含层到输出层又需要一个维度为KxN的权重矩阵,学习权重可以用反向传播算法实现,每次迭代时将权重沿梯度更优的方向进行一小步更新。但是由于Softmax激活函数中存在归一化项的缘故,推导出来的迭代公式需要对词汇表中的所有单词进行遍历,使得每次迭代过程非常缓慢,由此产生了<strong>Hierarchical Softmax</strong>和<strong>Negative Sampling</strong>两种改进方法。</p><p>谈到word2Vec与LDA的区别和联系,首先,LDA是利用文档中单词的共现关系来对单词按主题聚类,也可以理解为对“文档-单词”矩阵进行分解,得到“文档主题”和“主题-单词”两个概率分布。而Word2vec其实是对“上下文单词矩阵进行 学习,其中上下文由周围的几个单词组成,由此得到的词向量表示更多地融入了上下文共现的特征。也就是说,如果两个单词所对应的Word2Vec向量相似度较      高,那么它们很可能经常在同样的上下文中出现。需要说明的是,上述分析的是 LDA与Word2veC的不同,不应该作为主题模型和词嵌入两类方法的主要差异。主题模型通过一定的结构调整可以基于“上下文-单词”矩阵进行主题推理。同样地,  词嵌入方法也可以根据“文档-单词”矩阵学习出词的隐含向量表示。主题模型和词嵌入两类方法最大的不同其实在于模型本身,主题模型是一种基于概率图模型的生成式模型,其似然函数可以写成若干条件概率连乘的形式,其中包括需要推测的隐含变量(即主题);而词嵌入模型一般表达为神经网络的形式,似然函数定义在网络的输出之上,需要通过学习网络的权重以得到单词的稠密向量表示。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;百面-特征工程&quot;&gt;&lt;a href=&quot;#百面-特征工程&quot; class=&quot;headerlink&quot; title=&quot;百面  特征工程&quot;&gt;&lt;/a&gt;百面  特征工程&lt;/h1&gt;&lt;p&gt;Garbage in, garbage out。对于一个机器学习问题，&lt;strong&gt;数据和特征
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Happy Birthday to ZDK’s Blog🎁🎁🎁</title>
    <link href="https://github.com/zdkswd/2019/04/04/Happy%20Birthday%20to%20ZDK%E2%80%99s%20Blog%F0%9F%8E%81%F0%9F%8E%81%F0%9F%8E%81/"/>
    <id>https://github.com/zdkswd/2019/04/04/Happy Birthday to ZDK’s Blog🎁🎁🎁/</id>
    <published>2019-04-04T06:23:32.000Z</published>
    <updated>2019-04-04T06:23:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>去年的今天，ZDK的blog诞生了。</p><p>建立这个博客的初衷在于当做一个自己的读书笔记，在线免费云笔记。刚开始时是完全把大部分的内容照搬下来，基本上是读到了什么东西就写下来什么东西。基本上这个阶段主要就是体力劳动。此时博客的用处在于，当我看到一个什么东西时，我会想起来，我好像以前在博客中记录过这个东西，然后打开我的博客查看相关的内容来加深印象。这个阶段我的知识储备还不够多，所以处于知识积累的阶段。所以说博客这个时候更像是一个备忘录，什么知识点记得不太清了，可以翻翻博客加深记忆。</p><p>后来，我在《认知天性》这本书中找到了科学的解释，最适合人类大脑习性的学习方法包括三个步骤：<strong>编码，巩固和检索</strong>。使用博客来进行知识的积累貌似正好符合这几个阶段。第一个阶段我将博客当做我大脑的外存，我的大脑只需记忆知识的索引，在需要使用时，迅速从外存中调入我的大脑。随着调入次数的增多以及知识体系的逐渐建立，我对特定知识的印象也更深，很多时候也会在不同时期有着新的理解。知识慢慢地开始可以串联起来。而这个时候，在看到很多知识点时，就会有新的疑问，即为检索问题阶段。随着对问题的解决以及总结，慢慢发现自己对于知识点的理解更加深入了。善用检索，即问题导向。而发现问题更好的途径是对比知识点，以及真实场景。</p><p>随着不断的学习，越来越发现参考一本书是远远不够的，所以第二个阶段，这个博客开始出现了针对某个问题的总结，在这个阶段，需要翻阅多样参考文献来针对特定的问题作出总结，慢慢地，我发现，这个阶段大量的东西总结发生在纸上，真正到博客中的可能是经过总结后的。纸上总结有一个好处，就是不用鼠标的滚轮，在一个页面中即可构建知识的网络结构。下一个阶段，要更多的思考问题，更多的输出总结。形成自己的知识表征。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Happy%20Birthday%20to%20ZDK%E2%80%99s%20Blog%F0%9F%8E%81%F0%9F%8E%81%F0%9F%8E%81/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-04%20%E4%B8%8B%E5%8D%8812.10.28.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>主题阅读</strong><br><strong>问题导向</strong><br><strong>真实场景</strong><br><strong>刻意练习</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;去年的今天，ZDK的blog诞生了。&lt;/p&gt;
&lt;p&gt;建立这个博客的初衷在于当做一个自己的读书笔记，在线免费云笔记。刚开始时是完全把大部分的内容照搬下来，基本上是读到了什么东西就写下来什么东西。基本上这个阶段主要就是体力劳动。此时博客的用处在于，当我看到一个什么东西时，我会想
      
    
    </summary>
    
      <category term="个人总结" scheme="https://github.com/zdkswd/categories/%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="https://github.com/zdkswd/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>广告竞价  综述</title>
    <link href="https://github.com/zdkswd/2019/04/02/%E5%B9%BF%E5%91%8A%E7%AB%9E%E4%BB%B7%20%20%E7%BB%BC%E8%BF%B0/"/>
    <id>https://github.com/zdkswd/2019/04/02/广告竞价  综述/</id>
    <published>2019-04-02T04:01:47.000Z</published>
    <updated>2019-04-02T04:02:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于第二价位的广告竞拍"><a href="#基于第二价位的广告竞拍" class="headerlink" title="基于第二价位的广告竞拍"></a>基于第二价位的广告竞拍</h1><p>点击率预测可以提供对广告优劣的一种预测，还需要机制来决定如何从众多的广告中进行选取,这就是<strong>广告的竞价排名</strong>。</p><p>广告位竞价排名的出现有两个原因。第一，发布商的广告位是有限的。不管是搜索广告还是展示广告，绝大多数的发布商都以一定的比例在原生的内容，例如新闻、社交媒体内容里插入一些广告位。但是这些广告位的数目是有限的，特别是在优质的发布商资源里，就会出现一些广告位有着很大的竞争。第二，既然有竞争，那么如果引入一种竞价机制的话，势必有可能抬高广告的单价，从而让广告中间平台例如DSP，或者是发布商从中获取更高的价值。</p><h2 id="基于第一价位的竞拍"><a href="#基于第一价位的竞拍" class="headerlink" title="基于第一价位的竞拍"></a>基于第一价位的竞拍</h2><p>所谓基于第一价位的竞拍，指的是所有的投标方都定好自己的出价，然后一次性统一出价。 在出价的过程中，所有的投标方都是看不见竞争对手的出价的，这保证了出价的诚实性。当竞拍平台接到所有投标方的出价以后，按照出价由高到低排序，出价最高的投标方获得投标的胜利。</p><p>在广告系统中，如果要采用这样的形式，那么，决定最后投标顺序的不再是单纯的价格，而往往是一个投标价格和点击率的函数，最简单的函数就是<strong>点击率乘以投标价格</strong>。这其实也可以被认为是一种“<strong>期望收入</strong>”。也就是说，如果发布商或者DSP是按照广告的每一次点击来收取费用的话，那么，点击率乘以投标价格就是这种收入的一个数学期望值。</p><p>所以，基于第一价位竞价的广告系统，按照<strong>广告收入的期望值</strong>进行竞价排名。排名第一的广告被选为显示的广告。</p><p>这种机制在早期的互联网广告平台中曾被大量使用。但是一段时间以后，大家发现，基于第一价位竞价的竞价结果往往是“虚高”的。这也很容易形象地解释，在大家都不知道对方出价的情况下，如果希望自己能在竞拍中胜出，势必就可能报出比较高的价格。另外一个方面，投标方并不清楚这个广告位的真实价值，大家只能在条件允许的情况下，尽量抬高价格来获取这个机会。从某种意义上来说，这样的竞价并不利于广告商的长远发展，也打击了广告商的积极性。</p><h2 id="基于第二价位的竞拍"><a href="#基于第二价位的竞拍" class="headerlink" title="基于第二价位的竞拍"></a>基于第二价位的竞拍</h2><p>就是在基于第一价位竞价的基础上， 互联网广告界逐渐衍生出了一种新的竞拍方法一基于第二价位的竞拍。首先，和基于第一价位的竞拍模式一样，基于第二价位的模式也是按照广告的期望收入，也就是根据点击率和出价的乘积来进行排序。但和基于第一价位模式不一 样的是，中间商或者发布商并不按照第一位的价格来收取费用，而是按照竞价排位第二位的广告商的出价来收取费用。也就是说，<strong>虽然第一名利用自己的出价赢得了排名，但是只需要付第二名所出的价格。时至今日，基于第二价位的竞拍方式已经成为了互联网广告的主流竞拍模式。</strong></p><p>基于第二价位的竞拍方式好处在于，在这种形式下，广告商按照自己对广告为价值的理解来竞拍是相对较优的策略。技术难点在于对于广告商来说，主要是希望知道在当前出价的情况下，究竟有多大的概率赢得当前的竞拍。这也就是所谓的“<strong>赢的概率</strong>”，这对于广告商调整自己的出价有非常重要的指导意义。对于整个出价的概率分布的一个估计，有时候又叫作<strong>竞价全景观</strong>(Bid Landscape)预测。这是一个非常形象的说法，因为广告商希望知道整个赢的概率随着出价变化的整个分布，从而调整自己的安排。</p><p>这样的预测工作会用到一些简单的模型。比如，有学者认为，赢的价格服从一个“<strong>对数正态分布</strong>”(Log-normal) 也就是说，广告商出的价格并且最终赢得竞拍的这些价格，在取了对数的情况下，服从一个正态分布。当然，这是一个假设。但是有了这么一个假设以后，我们就可以从数据中估计这个对数正态分布的参数，从而能够对整个“竞价全景观”进行估计。</p><p>对于“竞价全景观”或者是赢的价格分布的估计有一个比较困难的地方，那就是，作为广告商来说，往往并不知道所有其他竞争对手的出价，以及在没有赢得竞拍的情况下，那些赢得竞拍的出价是多少。简而言之，也就是我们<strong>只观测到了一部分数据</strong>，那就是我们赢得这些广告位的出价。在这种只有一部分信息的情况下，所做的估计就会不准确。</p><h1 id="广告竞价策略"><a href="#广告竞价策略" class="headerlink" title="广告竞价策略"></a>广告竞价策略</h1><h2 id="竞价策略"><a href="#竞价策略" class="headerlink" title="竞价策略"></a>竞价策略</h2><p>其实这个问题主要是在“<strong>实时竞价</strong>”，或简称<strong>RTB</strong>的背景下来探讨的。RTB是DSP目前流行的竞价模式，也就是广告商等利用计算机程序来自动对广告竞拍进行出价。从实际的运作中来看，这样的自动竞价模式要比人工竞价更加方便快捷，也更加高效。然而，在自动竞价的模式下，我们势必需要一种指导思想，来让我们的计算机程序能够随着形式的变化来进行出价。</p><p>在RTB中，竞价策略的环境。竞价的一个重要特征，作为一个竞价方，并不知道其他竞标方的点击率和出价，因此<strong>处在一个信息不完整的竞价环境中</strong>。只能根据自己的点击率估计和自己的出价，以及过去出价的成功与否来对整个市场形势进行判断。这就是RTB竞价策略的一大挑战和难点。</p><p>在这样的背景下， RTB竞价策略的研究和开发集中在以下两种思路上。</p><p>一种思路是<strong>把整个竞价策略当做一种“博弈”</strong>(Game) ，从而根据博弈论中的方法来对竞价环境中各个竞标方的行为和收益进行研究。 用博弈论的方法来对竞价进行研究有一个最大的特点，那就是博弈论主要是对各个竞标方行为之间的<strong>关联性</strong>进行建模，这种关联性包括他们之间的<strong>收益</strong>和他们的<strong>动机</strong>。</p><p>另外一种思路是<strong>把整个竟价策略当做是纯粹的统计决策</strong>,也就是直接对广告商的行为进行建模,而把整个竟价环境中的种种联系都当做是当前决策下的不确定因素。在这样的思路下,各个竞标方之间的行为关联变得不那么重要,而对于整个不确定性的建模则变得至关重要。</p><p>第一种思路,也就是利用博弈论的方法来对竟价策略进行硏究主要存在于学术界。虽然从理论上来说,博弈论可能提供一种比较有说服力的解释,但是这种思路需要对整个竟价环境有非常多的假设(例如竞标方是不是理性,市场是不是充分竞争等等)。而<strong>第二种思路</strong>,仅仅需要从广告商自身的角度出发,因此在现实中,这种思路的操作性更强,从而<strong>受到工业界的青睐</strong>。</p><p>总的来说,第二种思路其实就是根据当前的输入信息,例如页面信息、广告信息、用户信息以及上下文信息等,学到一个<strong>输出价格的函数</strong>,也就是说,这个函数的输出就是在现在情况下当前广告的出价。当然,这个函数势必需要考虑各种不确定的因素。</p><h2 id="搜索广告和展示广告的竞价"><a href="#搜索广告和展示广告的竞价" class="headerlink" title="搜索广告和展示广告的竞价"></a>搜索广告和展示广告的竞价</h2><p>搜索广告和展示广告的竞标存在着不小的区别，因此，从技术上来讲，就发展出了一系列不同的方法。</p><p>对于搜索广告来讲，在大多数情况下，每-一个出价都是针对某-个搜索关键词的。利用机器学习方法对搜索广告的出价进行建模的工作。在这个工作里，每一个关键词的出价来自于一一个线性函数的输出，而这个线性函数是把用户信息、关键词以及其他的页面信息当做特性，学习了一个<strong>从特性到出价的线性关系</strong>。这可以算是最早的利用线性函数来进行出价的例子了。</p><p>展示广告的竞价则面临着不同的挑战。首先，在展示广告中，场景中并不存在搜索关键词这种概念。因此，很多广告商无法针对场景事先产生出价。这也就要求RTB的提供商要能够在不同的场景中帮助广告商进行出价。</p><p>同时，相比于搜索广告针对<strong>每一个关键词</strong>的出价方式来说，针对<strong>每一个页面显示机会</strong>出价的挑战则更大。理论上讲，每一个页面显示机会的价格都可能有很大的不同。很多RTB都利用一种叫作<strong>CPM的收费模式</strong>，也就是说，一旦某一个广告位被赢得之后，对于广告商来说，这往往就意味着需要被收取费用。所以，在展示广告的情况下，如何针对当前的页面显示机会以及目前的预<br>算剩余等等因素进行统一建模，就成为一个必不可少的步骤。</p><h2 id="竞价策略的其他问题"><a href="#竞价策略的其他问题" class="headerlink" title="竞价策略的其他问题"></a>竞价策略的其他问题</h2><p>因此，在广告竞价策略中，还存在着一个叫“<strong>预算步调</strong>”(Budget Pacing)的技术，也就是希望能够让广告的展示相对平缓而不至于在短时间内使用完全部的预算。这势必对于广告如何出价有着直接的影响。</p><p>另外，对于平台而言，虽然竞价保证了一定的竞争，但是也并不是所有的展示机会都有非常充分的竞争。因此，从平台的角度来说，如何能够保证一定的收益就变得十分重要。在这样的情况下，有的平台有一种叫作“<strong>保留价格</strong>”(Reserved Price)的做法，用来设置一个 最低的竞价价格。保留价格虽然能够来保证收益，但是也可能会让广告商觉得不划算，因此如何来设置这个保留价格，也就成为了出价策略中的一个重要组成部分。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基于第二价位的广告竞拍&quot;&gt;&lt;a href=&quot;#基于第二价位的广告竞拍&quot; class=&quot;headerlink&quot; title=&quot;基于第二价位的广告竞拍&quot;&gt;&lt;/a&gt;基于第二价位的广告竞拍&lt;/h1&gt;&lt;p&gt;点击率预测可以提供对广告优劣的一种预测，还需要机制来决定如何从众多的
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>RS矩阵分解  概述</title>
    <link href="https://github.com/zdkswd/2019/03/29/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/"/>
    <id>https://github.com/zdkswd/2019/03/29/RS矩阵分解  概述/</id>
    <published>2019-03-29T13:36:47.000Z</published>
    <updated>2019-04-01T08:35:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RS矩阵分解-概述"><a href="#RS矩阵分解-概述" class="headerlink" title="RS矩阵分解  概述"></a>RS矩阵分解  概述</h1><p>源自于评分预测问题。评分预测问题很典型但是并不大众，与之相对的另一类问题行为预测，才是平民级推荐问题，处处可见。</p><h1 id="为什么要矩阵分解"><a href="#为什么要矩阵分解" class="headerlink" title="为什么要矩阵分解"></a>为什么要矩阵分解</h1><p>矩阵分解确实可以解决一些近邻模型无法解决的问题。</p><p>近邻模型存在的问题：</p><ol><li>物品建存在相关性，信息量并不随着向量维度增加而线性增加。</li><li>矩阵元素稀疏，计算结果不稳定，增减一个向量维度，导致近邻结果差异很大的情况存在。</li></ol><p>上述两个问题，在矩阵分解中可以得到解决。矩阵分解，直观上说来简单，就是把原来的大矩阵，近似分解成两个小矩阵的乘积，在实际推荐计算时不再使用大矩阵，而是使用分解得到的两个小矩阵。</p><p>具体说来就是，假设用户物品的评分矩阵A是m乘以n维，即共有m个用户，n个物品。我们选一个很小的数k，这个k比m和n都小很多，比如小两个数量级这样，通过一套算法得到两个矩阵U和V,矩阵U的维度是m乘以k,代表用户偏好的用户隐因子向量。矩阵V的维度是n乘以k，代表物品语义主题的隐因子向量。</p><p>矩阵UV需要能够通过公式复原矩阵A：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%882.02.13.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>得到的这两个矩阵有这么几个特点:<br>1.每个用户对应一个k维向量，每个物品也对应一个k维向量，就是所谓的隐因子向量，因为是无中生有变出来的，所以叫做“隐因子”;<br>2.两个矩阵相乘后，就得到了任何一个用户对任何一个物品的预测评分，具体这个评分靠不靠谱，那就是看功夫了。就需要定义损失函数去优化。</p><p>所以说矩阵分解，所做的事就是矩阵填充。</p><h1 id="基础的SVD算法"><a href="#基础的SVD算法" class="headerlink" title="基础的SVD算法"></a>基础的SVD算法</h1><p>SVD全称奇异值分解，属于线性代数的知识，在推荐算法中实际使用的并不是正统的奇异值分解，而是一个伪奇异值分解。传统SVD在实际应用场景中面临着稀疏性问题和效率问题。所以，提出了一个新的方法Funk-SVD算法，其主要思路是将原始评分矩阵M（m*n）分解成两个矩阵P（m*k）和Q(k*n),同时仅考察原始评分矩阵中有评分的项分解结果是否准确，而判别标准是均方差。这种方法被称为隐语义模型（Latent factor）<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/add/28.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>用户评分矩阵通常是稀疏的，如果只有少数项有值，极易造成过拟合，此时就要通过矩阵分解将矩阵分解为稠密的矩阵。矩阵分解，就是把用户和物品都映射到一个k维空间中，这个k维空间不是我们能直接看到的，也不一定具有非常好的可解释性，每一个维度也没有名字，所以常常叫做<strong>隐因子</strong>，代表藏在直观的矩阵数据下。</p><p>每一个物品都获得一个向量q，每一个用户也得到一个向量p。</p><p>对于物品，与它对应的向量q中的元素有正有负，代表这个物品背后隐藏的一些用户关注的因素。</p><p>对于用户，与它对应的向量p的元素，也有正有负，代表这个用户在若干因素上的偏好。物品被关注的因素，和用户偏好的因素，它们的数量和意义是一致的，就是矩阵分解之初人为指定的k。</p><p>例如，用户u的向量是pu，物品i的向量是qi，要计算物品i推荐给用户u的推荐分数，直接计算点积即可：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%882.16.24.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>难点在于，如何得到每一个用户，每一个物品的k维向量。这是一个机器学习问题。两个要素，损失函数和优化算法。</p><p>SVD的损失函数定义如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%882.22.50.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>加号前一部分控制着模型的偏差，加号后一部分控制着模型的方差。<br>前一部分就是用分解后的矩阵预测分数，要和实际的用户评分之间误差越小越好。后一部分就是，得到的隐因子向量要越简单越好，以控制这个模型的方差，也就是让它在真正执行推荐任务时要发挥稳定，以免产生“过拟合”。</p><p>整个SVD的学习过程就是：</p><ol><li>准备好用户物品的评分矩阵，每一条评分数据看做一条训练样本。</li><li>给分解后的U矩阵和V矩阵随机初始化元素值。</li><li>用U和V计算预测后的分数。</li><li>计算预测的分数和实际的分数误差。</li><li>按照梯度下降的方向更新U和V中的元素值。</li><li>重复步骤3到5，直到到达停止条件。</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/add/29.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>得到分解后的矩阵之后，实质上就是得到了每个用户和每个物品的隐因子向量，拿着这个向量再做推荐计算就简单了。</p><h1 id="增加偏置信息"><a href="#增加偏置信息" class="headerlink" title="增加偏置信息"></a>增加偏置信息</h1><p>实际情况下，一些用户会给出偏高的分数，比如标准宽松的用户，有些物品也会受到偏高的评分，比如一些目标观众为铁粉的电影，甚至有可能整个平台的全局评分就偏高。</p><p>原装的SVD就有了第一个变种:把偏置信息抽出来的SVD。</p><p>一个用户给一个物品的评分会由四部分相加:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%883.34.44.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>从左至右分别代表:全局平均分、物品的评分偏置、用户评分的偏置、用户和物品之间的兴趣偏好。</p><p>针对前面三项偏置分数，我在这里举个例子，假如一个电影评分网站全局平均分是3分,《肖申克的救赎》的平均分比全局平均分要高1分。</p><p>你是一个对电影非常严格的人，你一般打分比平均分都要低0.5,所以前三项从左到右分别就是3, 1, -0.5。 如果简单的就靠这三项，也可以给计算出一个你会给《肖申克的救赎》打的分数，就是3.5。</p><p>增加了偏置信息的SVD模型目标函数稍有改变:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%883.37.24.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>和基本的SVD相比，要想学习两个参数:用户偏置和物品偏置。学习的算法还是一样的。</p><h1 id="增加历史行为"><a href="#增加历史行为" class="headerlink" title="增加历史行为"></a>增加历史行为</h1><p>相比沉默的大多数，主动点评电影或者美食的用户是少数。也就是显示反馈比隐式反馈少，但是可以利用隐式反馈来弥补这一点，对于用户的个人属性，比如性别，也可以加入到模型中来弥补冷启动的不足。</p><p>在SVD中结合用户的隐式反馈行为和属性，这套模型叫做SVD++。</p><p>加入隐式反馈的方法是除了假设评分矩阵中的物品有一个隐因子向量外，用户有过行为的物品集合也都有一个隐因子向量，维度是一样的。把用户操作过的物品隐因子向量加起来，用来表达用户的兴趣偏好。</p><p>综合两者，SVD++的目标函数中，只需要把推荐分数预测部分稍作修改，原来的用户向量部分增加了隐式反馈向量和用户属性向量。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%884.36.29.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>学习算法依然不变，只是要学习的参数多了两个向量: x和y。其中N(U)表示为用户U提供了隐式反馈的物品的集合。xi所在的项是隐式反馈的物品向量，ya所在的项是用户属性的向量。这样一来，在用户没有评分时，也可以用他的隐式反馈和属性做出一定的预测。</p><h1 id="考虑时间因素"><a href="#考虑时间因素" class="headerlink" title="考虑时间因素"></a>考虑时间因素</h1><p>人是善变的，今天的我们和十年前的我们很可能不一样了，在SVD中考虑时间因素也变得顺理成章。</p><p>在SVD中考虑时间因素，有几种做法:<br>1.对评分按照时间加权，让久远的评分更趋近平均值;<br>2.对评分时间划分区间，不同的时间区间内分别学习出隐因子向量，使用时按照区间使用对应的隐因子向量来计算;<br>3.对特殊的期间，如节日、周末等训练对应的隐因子向量。</p><h1 id="交替最小二乘原理（ALS）"><a href="#交替最小二乘原理（ALS）" class="headerlink" title="交替最小二乘原理（ALS）"></a>交替最小二乘原理（ALS）</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%885.39.58.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>有了目标函数，就要用到优化算法找到使它最小的参数，优化算法常用的有两个，一个是<strong>随机梯度下降（SGD）</strong>，是针对qi或者pu整条向量进行更新而不是单个元素。<br>损失函数求偏导：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/add/30.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>根据随机梯度下降法得到的递推公式:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/add/31.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>另一个是<strong>交替最小二乘(ALS)</strong>。</p><p>在实际应用中，交替最小二乘更常用一些，这也是社交巨头Facebook在他们的推荐系统中选择的主要矩阵分解方法。</p><p>交替最小二乘的核心是交替,任务是找到两个矩阵P和Q,让它们相乘后约等于原矩阵R：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%887.56.11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>如果知道其中一个，那另一Q也就已知了，交替最小二乘法通过迭代解决了这个鸡生蛋蛋生鸡的问题。<br>1.初始化随机矩阵Q里面的元素值;<br>2.把Q矩阵当做已知的，直接用线性代数的方法求得矩阵P;<br>3.得到了矩阵P后，把P当做已知的，故技重施，回去求解矩阵Q;<br>4.上面两个过程交替进行，直到目标函数可以接受为止。</p><p>交替最小二乘的好处:<br>1.在交替的其中一步，也就是假设已知其中一个矩阵求解另一个时，要优化的参数是很容易并行化的;<br>2.在不那么稀疏的数据集合上，交替最小二乘通常比随机梯度下降要更快地得到结果。</p><h1 id="隐式反馈"><a href="#隐式反馈" class="headerlink" title="隐式反馈"></a>隐式反馈</h1><p>矩阵分解算法，是为解决评分预测问题而生的，然而事实上却是，用户首先必须先去浏览商品，然后是购买，最后才可能打分。相比“预测用户会打多少分”，“预测用户会不会去浏览”更加有意义，而且，用户浏览数据远远多于打分评价数据。也就是说，实际上推荐系统关注的是预测行为，行为也就是一再强调的隐式反馈。</p><p>最方便的数据时高质量的显式反馈，其中包括用户对产品感兴趣的显式输入。通常，显式反馈包含一个稀疏矩阵，因为任何一个用户可能只对可能的项目进行了一小部分的评分。隐式反馈通常指示一个事件存在或不存在，因此它通常由一个密集的矩阵表示。</p><p>如果把预测用户行为看成一个二分类问题， 猜用户会不会做某件事，但实际上收集到的数据只有明确的一类:用户干了某件事，而用户明确“不干”某件事的数据却没有明确表达。所以这就是One-Class的由来，One-Class数据也是隐式反馈的通常特点。</p><p>对隐式反馈的矩阵分解，需要将交替最小二乘做一些改进，改进后的算法叫做<strong>加权交替最小二乘</strong>: <strong>Weighted-ALS</strong>。</p><p>用户对物品的反馈，通常是多次的，行为的次数是对行为的置信度反应，也就是所谓的加权。</p><p>加权交替最小二乘法对待隐式反馈：<br>1.如果用户对物品无隐式反馈则认为评分是0;<br>2.如果用户对物品有至少一次隐式反馈则认为评分是1,次数作为该评分的置信度。</p><p>现在的目标函数变为：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%888.30.19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>多出来的Cui就是置信度，在计算误差时考虑反馈次数,次数越多，就越可信。置信度一般也不是直接等于反馈次数，根据一些经验，置信度Cui这样计算:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%20%20%E6%A6%82%E8%BF%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-29%20%E4%B8%8B%E5%8D%888.43.16.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中阿尔法是一个超参数，需要调教，默认值取40可以得到差不多的效果，C就是次数了。</p><p>此时那些没有反馈的缺失值，就是在我们的设定下，取值为0的评分就非常多，有两个原因导致在实际使用时要注意这个问题:<br>1.本身隐式反馈就只有正类别是确定的，负类别是我们假设的。<br>2.这会导致正负类别样本非常不平衡，严重倾斜到0评分这边。</p><p>应对这个问题的做法就是负样本采样：挑一部分缺失值作为负类别样本即可。有两种挑的方法。<br>1.随机均匀采样和正类别一样多。<br>2.按照物品的热门程度采样。</p><p>在实践中，第一种不是很靠谱，第二种经受住了检验，其思想是一个越热门的物品，用户越可能知道它的存在。那这种情况下，用户还没对它有反馈就表明:这很可能就是真正的负样本。</p><h1 id="推荐计算"><a href="#推荐计算" class="headerlink" title="推荐计算"></a>推荐计算</h1><p>在得到了分解后的矩阵后，相当于每个用户得到了隐因子向量，这是一个稠密向量，用于代表他的兴趣。同时每个物品也得到了-个稠密向量，代表它的语义或主题。而且可以认为这两者是一一对应的，用户的兴趣就是表现在物品的语义维度上的。</p><p>看上去，让用户和物品的隐因子向量两两相乘,计算点积就可以得到所有的推荐结果了。但是实际上复杂度还是很高，尤其对于用户数量和物品数量都巨大的应用，如Facebook,就更不现实。于是Facebook提出了两个办法得到真正的推荐结果。</p><p><strong>第一种</strong>， 利用一些专门设计的数据结构存储所有物品的隐因子向量，从而实现通过一个用户向量可以返回最相似的K个物品。Facebook给出了自己的开源实现Faiss,类似的开源实现还有Annoy, KGraph, NMSL IB。其中Facebook开源的Faiss 和NMSLIB (Non-Metric Space Library)都用到了ball tree来存储物品向量。</p><p>如果需要动态增加新的物品向量到索引中，推荐使用Faiss,如果不是，推荐使用NMSLIB或者KGraph。用户向量则可以存在内存数据中，这样可以在用户访问时，实时产生推荐结果。</p><p><strong>第二种</strong>，就是拿着物品的隐因子向量先做聚类，海量的物品会减少为少量的聚类。然后再逐一计算用户和每个聚类中心的推荐分数，给用户推荐物品就变成了给用户推荐物品聚类。</p><p>得到给用户推荐的聚类后，再从每个聚类中挑选少许几个物品作为最终推荐结果。这样做的好处除了大大减小推荐计算量之外，还可以控制推荐结果的多样性，因为可以控制在每个类别中选择的物品数量。</p><h1 id="矩阵分解的优缺点"><a href="#矩阵分解的优缺点" class="headerlink" title="矩阵分解的优缺点"></a>矩阵分解的优缺点</h1><p>矩阵分解有如下的优点：</p><ol><li>能将高维的矩阵映射成两个低维矩阵的乘积，很好地解决了数据稀疏的问题；</li><li>具体实现和求解都很简洁，预测的精度也比较好；</li><li>模型的可扩展性也非常优秀，其基本思想也能广泛运用于各种场景中。</li></ol><p>矩阵分解的缺点有：</p><ol><li>可解释性很差，其隐空间中的维度无法与现实中的概念对应起来；</li><li>训练速度慢，很难实现实时推荐，不过可以通过离线训练来弥补这个缺点；</li><li>实际推荐场景中往往只关心topn结果的准确性，此时考察全局的均方差显然是不准确的。</li></ol><p>矩阵分解作为推荐系统中的经典模型，已经经过了十几年的发展，时至今日依然被广泛应用于推荐系统当中，其基本思想更是在各式各样的模型中发挥出重要作用。但是对于推荐系统来说，仅仅有一个好的模型是远远不够的。影响推荐系统效果的因素非常之多。想要打造一个一流的推荐系统，除了一个强大的算法模型之外，更需要想方设法结合起具体业务，不断进行各种尝试、升级，方能取得最终的胜利。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;RS矩阵分解-概述&quot;&gt;&lt;a href=&quot;#RS矩阵分解-概述&quot; class=&quot;headerlink&quot; title=&quot;RS矩阵分解  概述&quot;&gt;&lt;/a&gt;RS矩阵分解  概述&lt;/h1&gt;&lt;p&gt;源自于评分预测问题。评分预测问题很典型但是并不大众，与之相对的另一类问题行为预测
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="矩阵分解" scheme="https://github.com/zdkswd/tags/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>熵</title>
    <link href="https://github.com/zdkswd/2019/03/27/%E7%86%B5/"/>
    <id>https://github.com/zdkswd/2019/03/27/熵/</id>
    <published>2019-03-27T11:46:47.000Z</published>
    <updated>2019-03-27T11:47:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h1><p><a href="https://www.jianshu.com/p/09b70253c840" target="_blank" rel="noopener">https://www.jianshu.com/p/09b70253c840</a><br><a href="https://baijiahao.baidu.com/s?id=1618702220267847958&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">完美解释交叉熵</a></p><h1 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h1><p>包含不确定性的变量称为随机变量，统计学就是研究这类不确定性变量的工具。刻画随机变量最有力的一个工具就是它的概率分布。有了概率分布，我们可以说对一个随机变量有了完全的掌握，因为我们可以知道它可能取哪些值，某个值的概率是多少。</p><h1 id="什么是熵"><a href="#什么是熵" class="headerlink" title="什么是熵"></a>什么是熵</h1><p>概率分布是对随机变量的刻画，不同的随机变量有着相同或不同的概率分布，熵，就是对不同概率分布的刻画！本质上，是为了描述不确定的程度，并以此对不同的概率分布进行比较。</p><p>如果我们知道一枚硬币抛出后正面朝上概率为0.8，要比知道概率为0.5，更容易猜对硬币抛出后哪面朝上。即0.8的概率分布比0.5的概率分布对我们来说，具有更大的信息量。</p><p>需要的是一个定量的指标，来衡量概率分布的不确定性。这个指标就是熵。</p><h1 id="熵的数学表达"><a href="#熵的数学表达" class="headerlink" title="熵的数学表达"></a>熵的数学表达</h1><p>以抛硬币为例，我们看正面这个取值。可以看到，取正面的概率越大，则不确定性就越小。即概率越大，不确定性越小。能够表达出概率越大，不确定性越小的表达式就是：<br>-logP，图像如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-26%20%E4%B8%8B%E5%8D%889.14.29.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>图中的纵轴为-logP，横轴为P。</p><p>-logP只是衡量了某个概率的不确定性，对于抛硬币，是正面的不确定性小了，那是反面的不确定性就大了。所以衡量一个概率的分布的不确定性，就要综合衡量所有概率表达的不确定性，也就是求一个概率分部综合的不确定性。<strong>熵</strong>的表达式即为：<strong>-∑PlogP</strong></p><p>这个指标可以理解成概率分布的不确定性的期望值。这个值越大，表示该概率分布不确定性越大。它为我们人类提供的“信息”就越小，我们越难利用这个概率分布做出一个正确的判断。从这个角度，我们可以看到，熵是对概率分布信息含量的衡量，这与它是不确定性的衡量，其实是两种解读方式而已。</p><h1 id="从另一个角度理解熵"><a href="#从另一个角度理解熵" class="headerlink" title="从另一个角度理解熵"></a>从另一个角度理解熵</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/u=2536703424,2008652302&fm=173&app=49&f=JPEG.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>上图例中，每种颜色的概率都是1/4。此时的最优策略。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/u=766989654,2959505221&fm=173&app=49&f=JPEG.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>上图为1/8绿色, 1/8 橘色, 1/4 红色, 1/2 蓝色时的最优策略。</p><p>对于同一问题，目标是问最少次数的问题，就能得到正确的答案。在这个问题中, 问题个数的期望是<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/u=1914240327,2567469862&fm=173&app=49&f=JPEG.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>即为<strong>熵</strong>。<br>第一幅图的熵为 1/4(机率) <em> 2道题目 </em> 4颗球 = 2，平均需要问两道题目才能找出不同颜色的球，也就是说期望值为2，就是熵。<br>第二幅图为1/2×1+1/4×2+1/8×3+1/8×3=1.75。<br>极端情况下全是一种颜色，就不用问问题，熵为0。</p><p>熵的意义就是在<strong>最优化</strong>策略下, <strong>猜到颜色所需要的问题的个数</strong>。也就是一种情况下，只对应一个熵。在不同的情况中，熵越大，需要问的东西越多，说明其不确定性大，熵越小，<strong>需要判断的次数就越少</strong>。</p><h1 id="伯努利分布的熵"><a href="#伯努利分布的熵" class="headerlink" title="伯努利分布的熵"></a>伯努利分布的熵</h1><p>抛硬币即为伯努利分布，它的熵为：H(p) = -plogp -(1-p)log(1-p)</p><p>画出来即为下图：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-27%20%E4%B8%8A%E5%8D%889.09.49.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><strong>当p=0.5时，熵最大</strong>，因为此时硬币朝上朝下完全是随机的，<strong>不确定性最大</strong>。在两侧当其中一面向上的概率为1时，则完全没有不确定性。所以熵就是0。<strong>熵越大，不确定性越大，熵越小，信息越多。</strong>所以熵越小越好，可以把熵看做是优化的目标。</p><p>事实上方差可以用来描述变量变化程度，和熵有一致性，方差越大，不确定性就越大，熵就越大。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-27%20%E4%B8%8A%E5%8D%889.18.40.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h1><p>联合熵与联合概率分布有关，对于随机变量X和Y，二者的联合概率分布为p(x,y),则这个联合概率分布的熵就叫做<strong>联合熵</strong>：<br><strong>H(x,y) = -Σp(x,y)log(p(x,y))</strong></p><p>H(x,y)肯定是大于等于H(x)或H(y)的。仅当X没有不确定性时，比如永远是正面朝上，此时，在Y的基础上联合X，并没有引入新的不确定性，所以，H(x,y)=H(y)。</p><h1 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h1><p>x,y的联合熵大于等于x和y单独的熵，对于y来说，引入的x增大了熵，那么，衡量x的引入增加了多大的熵呢，这就是<strong>条件熵</strong>。<br><strong>H(x|y) = H(x,y) - H(y)</strong></p><p>注意H(x|y)叫做条件熵，它可不是条件概率p(x|y)的熵。因为p(x|y)不是一个概率分布。</p><p>条件熵的计算，和条件概率还是有点关系的。<br>H(x|y) = - Σp(x,y)log(p(x|y))</p><p><strong>条件熵是在Y上引入X后增加的不确定性</strong>，从感觉上，增加的不确定性无论如何不可能大于X本身自有的不确定性，也就是：<br><strong>H(x|y) &lt;= H(x)</strong>  仅当x，y相互独立时，等号才成立。</p><h1 id="李航-信息增益"><a href="#李航-信息增益" class="headerlink" title="李航 信息增益"></a>李航 信息增益</h1><p>当熵和条件熵中的概率有数据统计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为<strong>经验熵</strong>和<strong>经验条件熵</strong>。此时如果有0概率，令0log0=0</p><p><strong>信息增益</strong>表示得知<strong>特征X</strong>的信息而使得<strong>类Y</strong>的信息的不确定性减少的程度。</p><p>特征A对训练数据集D的信息增益g(D,A)，定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差，即<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-27%20%E4%B8%8B%E5%8D%8812.29.58.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>一般地，熵H(Y)与条件熵H(Y|X)之差称为<strong>互信息</strong>。决策树学习中的信息增益等价于训练数据集中<strong>类与特征的互信息</strong>。详见决策树个人总结。</p><h1 id="相对熵（又叫互熵，KL散度）"><a href="#相对熵（又叫互熵，KL散度）" class="headerlink" title="相对熵（又叫互熵，KL散度）"></a>相对熵（又叫互熵，KL散度）</h1><p>相对熵和前面的几个概念联系不大。互熵D(q||p)实际上就是在衡量我们通过计算得出的真实分布的表达式q，究竟与由样本统计得来的分布p有多接近，在衡量多接近这个概念时，我们运用到了熵的形式。PQ完全相同，互熵就等于0了。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-27%20%E4%B8%8B%E5%8D%881.44.20.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中P代表真实分布，Q代表模型分布。也可写为：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/9922720e0cf3d7ca31c6e0d3ff1fbe096b63a967.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>KL散度大于等于0</strong>.</p><p>其值等于<strong>真实分布</strong>与<strong>拟合分布</strong>的<strong>交叉熵</strong>与真实分布的<strong>信息熵</strong>之差。<br>此时是两个分布间的运算，与前面同个分布两个变量的运算不是一个概念。</p><h1 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h1><p>P的熵是-Σp(x)log(p(x))，Q的熵是-ΣQ(x)log(Q(x))<br>交叉熵即为<strong>-ΣP(x)log(Q(x))</strong><br>交叉熵是不满足交换律的。<br>如果说对于第二个例子，仍然使用第一个例子中的策略，如下<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%86%B5/u=3840435294,1181281422&fm=173&app=49&f=JPEG.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>即认为小球分布是(1/4，1/4，1/4，1/4），这个分布就是非真实分布。平均来说, 需要的问题数是 1/8×2+1/8×2+1/4×2+1/2×2=2。 因此, 在例子二中使用例子一的策略是一个比较差的策略. 其中2是这个方案中的<strong>交叉熵</strong>。而最优方案的交叉熵是1.75。那样预测模型与真实最佳模型是一样的。</p><p>即为给定一个策略（分布）, 交叉熵就是在该策略（分布）下猜中颜色所需要的问题的期望值。更普遍的说，<strong>交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略产生的熵。</strong></p><h2 id="为什么使用交叉熵损失函数"><a href="#为什么使用交叉熵损失函数" class="headerlink" title="为什么使用交叉熵损失函数"></a>为什么使用交叉熵损失函数</h2><p>由于KL散度是衡量真实与模型分布的准则，后一项为常数值，KL值大于等于0，所以损失函数为交叉熵即可，使交叉熵越小越好。交叉熵的最小值即为真实分布的熵。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;熵&quot;&gt;&lt;a href=&quot;#熵&quot; class=&quot;headerlink&quot; title=&quot;熵&quot;&gt;&lt;/a&gt;熵&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/09b70253c840&quot; target=&quot;_blank&quot; rel=&quot;noop
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>统计学习方法  k近邻法</title>
    <link href="https://github.com/zdkswd/2019/03/24/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%20%20k%E8%BF%91%E9%82%BB%E6%B3%95/"/>
    <id>https://github.com/zdkswd/2019/03/24/统计学习方法  k近邻法/</id>
    <published>2019-03-24T11:16:47.000Z</published>
    <updated>2019-03-24T11:16:18.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="统计学习方法-k近邻法"><a href="#统计学习方法-k近邻法" class="headerlink" title="统计学习方法  k近邻法"></a>统计学习方法  k近邻法</h1><p>k近邻法(k-nearest neighbor, k-NN)是一种基本<strong>分类</strong>与<strong>回归</strong>方法，下面只讨论分类问题中的k近邻法，k近邻法的输入为实例的特征向量，对应于特征空间的点;输出为实例的类别，可以取多类. k近邻法假设给定一个训练数据集，其中的实例类别已定.分类时，对新的实例,根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测.因此，k近邻法不具有显式的学习过程，k近邻法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。<strong>k值的选择、距离度量及分类决策规则</strong>是k近邻法的三个基本要素. </p><h1 id="k近邻算法"><a href="#k近邻算法" class="headerlink" title="k近邻算法"></a>k近邻算法</h1><p>k近邻算法简单、直观:给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的k个实例，这k个实例的多数属于某个类，就把该输入实例分为这个类.</p><p><strong>k近邻法没有显式的学习过程.</strong></p><h1 id="k近邻模型"><a href="#k近邻模型" class="headerlink" title="k近邻模型"></a>k近邻模型</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>特征空间中，对每个训练实例点，距离该点比其他点更近的所有点组成一个区域，叫作单元(cell). 每个训练实例点拥有一个单元，所有训练实例点的单元构成对特征空间的一个划分.最近邻法将实例xi的类yi作为其单元中所有点的类标记(class label). 这样，每个单元的实例点的类别是确定的。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%20%20k%E8%BF%91%E9%82%BB%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-24%20%E4%B8%8B%E5%8D%886.30.48.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h2><p>欧式距离，曼哈顿距离等。</p><h2 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h2><p>如果选择较小的k值，就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差(approximation error)会减小，只有与输入实例较近的(相似的)训练实例才会对预测结果起作用.但缺点是“学习”的估计误差(estimation error)会增大，预测结果会对近邻的实例点非常敏感.如果邻近的实例点恰巧是噪声,预测就会出错.换句话说，<strong>k值的减小就意味着整体模型变得复杂，容易发生过拟合.</strong></p><p>如果选择较大的k值，就相当于用较大邻域中的训练实例进行预测.其优点是可以减少学习的估计误差.但缺点是学习的近似误差会增大.这时与输入实例较远的(不相似的)训练实例也会对预测起作用，使预测发生错误. <strong>k值的增大就意味着整体的模型变得简单.</strong></p><p>在应用中，k值一般取一个比较小的数值.通常采用交叉验证法来选取最优的k值.</p><h2 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h2><p>k近邻法中的分类决策规则往往是多数表决，即由输入实例的k个邻近的训练实例中的多数类决定输入实例的类.</p><h1 id="k近邻法的实现：kd树"><a href="#k近邻法的实现：kd树" class="headerlink" title="k近邻法的实现：kd树"></a>k近邻法的实现：kd树</h1><p>实现k近邻法时,主要考虑的问题是如何对训练数据进行快速k近邻搜索.这点在特征空间的维数大及训练数据容量大时尤其必要.</p><p>k近邻法最简单的实现方法是线性扫描(linear scan).这时要计算输入实例与每一个训练实例的距离.当训练集很大时，计算非常耗时,这种方法是不可行的.</p><p>为了提高k近邻搜索的效率，可以考虑<strong>使用特殊的结构存储训练数据</strong>,以<strong>减少计算距离的次数</strong>.比如kd tree方法。</p><h2 id="构造kd树"><a href="#构造kd树" class="headerlink" title="构造kd树"></a>构造kd树</h2><p>kd树是一种对k维空间中的实例点进行存储以便对其进行快速检索的<strong>树形数据结构</strong>. kd 树是<strong>二叉树</strong>，表示对k维空间的一个<strong>划分</strong>(patition). 构造kd树相当于不断地用垂直于坐标轴的超平面将k维空间切分,构成一系列的k维超矩形区域、kd树的每个结点对应于一个k维超矩形区域.</p><p>通常,依次选择坐标轴对空间切分，选择训练实例点在选定坐标轴上的中位数(median)为切分点，这样得到的kd树是平衡的.注意，平衡的kd树搜索时的效率未必是最优的.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%20%20k%E8%BF%91%E9%82%BB%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-24%20%E4%B8%8B%E5%8D%887.03.29.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%20%20k%E8%BF%91%E9%82%BB%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-24%20%E4%B8%8B%E5%8D%887.03.48.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%20%20k%E8%BF%91%E9%82%BB%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-24%20%E4%B8%8B%E5%8D%887.04.07.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="搜索kd树"><a href="#搜索kd树" class="headerlink" title="搜索kd树"></a>搜索kd树</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%20%20k%E8%BF%91%E9%82%BB%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-24%20%E4%B8%8B%E5%8D%887.05.52.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>利用kd树可以省去对大部分数据点的搜索，从而减少搜索的计算量。以最近邻为例，给定一个目标点，搜索其最近邻.首先找到包含目标点的叶结点;然后从该叶结点出发,依次回退到父结点;不断查找与目标点最邻近的结点，当确定不可能存在更近的结点时终止.这样搜索就被限制在空间的局部区域上，效率大为提高.</p><p>如果实例点是随机分布的, kd树搜索的平均计算复杂度是O(logN),这里N是训练实例数. kd树更适用于训练实例数远大于空间维数时的k近邻搜索.当空间维数接近训练实例数时，它的效率会迅速下降，几乎接近线性扫描.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;统计学习方法-k近邻法&quot;&gt;&lt;a href=&quot;#统计学习方法-k近邻法&quot; class=&quot;headerlink&quot; title=&quot;统计学习方法  k近邻法&quot;&gt;&lt;/a&gt;统计学习方法  k近邻法&lt;/h1&gt;&lt;p&gt;k近邻法(k-nearest neighbor, k-NN)是一
      
    
    </summary>
    
      <category term="读书笔记" scheme="https://github.com/zdkswd/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>莫凡 sklearn</title>
    <link href="https://github.com/zdkswd/2019/03/22/%E8%8E%AB%E5%87%A1%20sklearn/"/>
    <id>https://github.com/zdkswd/2019/03/22/莫凡 sklearn/</id>
    <published>2019-03-22T12:12:56.000Z</published>
    <updated>2019-03-22T12:12:54.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="莫凡-sklearn"><a href="#莫凡-sklearn" class="headerlink" title="莫凡 sklearn"></a>莫凡 sklearn</h1><p>Sklearn 包含了很多种机器学习的方式:</p><p>Classification 分类<br>Regression 回归<br>Clustering 非监督分类<br>Dimensionality reduction 数据降维<br>Model Selection 模型选择<br>Preprocessing 数据预处理<br>我们总能够从这些方法中挑选出一个适合于自己问题的, 然后解决自己的问题.</p><p>看图选方法<br>由图中，可以看到算法有四类，分类，回归，聚类，降维。<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20sklearn/2_1_1.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h1><h2 id="Model基础验证法"><a href="#Model基础验证法" class="headerlink" title="Model基础验证法"></a>Model基础验证法</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20sklearn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8B%E5%8D%885.05.50.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="Model交叉验证法"><a href="#Model交叉验证法" class="headerlink" title="Model交叉验证法"></a>Model交叉验证法</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20sklearn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8B%E5%8D%885.08.19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>其中scoring还可以取neg_mean_squared_error,则返回的就是平均方差的数组。</p><p>sklearn.learning_curve 中的 learning curve 可以很直观的看出我们的 model 学习的进度, 对比发现有没有 overfitting 的问题. 然后我们可以对我们的 model 进行调整, 克服 overfitting 的问题.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20sklearn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8B%E5%8D%885.20.33.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20sklearn/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8B%E5%8D%885.20.44.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>连续三节的交叉验证(cross validation)让我们知道在机器学习中验证是有多么的重要, 这一次的 sklearn 中我们用到了sklearn.learning_curve当中的另外一种, 叫做validation_curve,用这一种曲线我们就能更加直观看出改变模型中的参数的时候有没有过拟合(overfitting)的问题了. 这也是可以让我们更好的选择参数的方法.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;莫凡-sklearn&quot;&gt;&lt;a href=&quot;#莫凡-sklearn&quot; class=&quot;headerlink&quot; title=&quot;莫凡 sklearn&quot;&gt;&lt;/a&gt;莫凡 sklearn&lt;/h1&gt;&lt;p&gt;Sklearn 包含了很多种机器学习的方式:&lt;/p&gt;
&lt;p&gt;Classifi
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>译 Numpy Vs Pandas 表现比较</title>
    <link href="https://github.com/zdkswd/2019/03/22/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/"/>
    <id>https://github.com/zdkswd/2019/03/22/译 Numpy Vs Pandas 表现比较/</id>
    <published>2019-03-22T02:50:56.000Z</published>
    <updated>2019-03-22T02:51:08.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="译-Numpy-Vs-Pandas-表现比较"><a href="#译-Numpy-Vs-Pandas-表现比较" class="headerlink" title="译 Numpy Vs Pandas 表现比较"></a>译 Numpy Vs Pandas 表现比较</h1><p>原文链接：<a href="http://gouthamanbalaraman.com/blog/numpy-vs-pandas-comparison.html" target="_blank" rel="noopener">http://gouthamanbalaraman.com/blog/numpy-vs-pandas-comparison.html</a></p><ol><li>Numpy比起Pandas消耗更少的内存</li><li>对于5w行或更少的数据，Numpy的表现普遍要好。</li><li>对于50w行或更多的数据，pandas的表现普遍要好。</li><li>对于5w到50w行的数据，就要取决于使用哪种操作。</li></ol><p>对于15MM行的数据，pandas要使用内存1506m，Numpy要使用内存686m，pandas的内存要求是Numpy的两倍多。</p><h1 id="对列进行操作"><a href="#对列进行操作" class="headerlink" title="对列进行操作"></a>对列进行操作</h1><p>聚合操作mean，Numpy与pandas速度的比较。分界点在于10w行。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/download.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>对于向量化操作符log，10w行以下Numpy更快，对于10w行以上两者差不多，但是pandas占用的内存要更大。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/download%202.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>对于去重函数，pandas使用unique，numpy使用species。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/download%203.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="对于有过滤条件的操作"><a href="#对于有过滤条件的操作" class="headerlink" title="对于有过滤条件的操作"></a>对于有过滤条件的操作</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%8810.17.54.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/download%204.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%8810.20.34.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/download%205.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="对于列的向量化操作"><a href="#对于列的向量化操作" class="headerlink" title="对于列的向量化操作"></a>对于列的向量化操作</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%8810.23.26.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/download%206.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%8810.24.00.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%AF%91%20Numpy%20Vs%20Pandas%20%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83/download%207.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="留下一个疑问"><a href="#留下一个疑问" class="headerlink" title="留下一个疑问"></a>留下一个疑问</h1><p>pandas对于大量行的数据做了哪些优化，为什么性能得到了提升？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;译-Numpy-Vs-Pandas-表现比较&quot;&gt;&lt;a href=&quot;#译-Numpy-Vs-Pandas-表现比较&quot; class=&quot;headerlink&quot; title=&quot;译 Numpy Vs Pandas 表现比较&quot;&gt;&lt;/a&gt;译 Numpy Vs Pandas 表现
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="Python" scheme="https://github.com/zdkswd/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>莫凡 使用Numpy的技巧</title>
    <link href="https://github.com/zdkswd/2019/03/22/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/"/>
    <id>https://github.com/zdkswd/2019/03/22/莫凡 使用Numpy的技巧/</id>
    <published>2019-03-22T01:30:12.000Z</published>
    <updated>2019-03-22T11:01:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="莫凡-使用Numpy的技巧"><a href="#莫凡-使用Numpy的技巧" class="headerlink" title="莫凡 使用Numpy的技巧"></a>莫凡 使用Numpy的技巧</h1><p>pandas要比Numpy慢，所以尽量避免使用Pandas。</p><h1 id="为什么用Numpy？"><a href="#为什么用Numpy？" class="headerlink" title="为什么用Numpy？"></a>为什么用Numpy？</h1><p>Python 是慢的, 简单来说, 因为 Python 执行代码的时候会执行很多复杂的“check” 功能, 比如赋值<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-20%20%E4%B8%8B%E5%8D%889.42.23.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>在计算机内部, b 首先要从一个整数 integer 转换成浮点数 float, 才能进行后面的 b/0.5, 因为得到的要是一个小数.提到 Numpy, 它就是一个 Python 的救星. 能把简单好用的 Python 和高性能的 C 语言合并在一起. 当你调用 Numpy 功能的时候, 他其实调用了很多 C 语言而不是纯 Python. 这就是为什么大家都爱用 Numpy 的原因.</p><h1 id="创建Numpy-Array的结构"><a href="#创建Numpy-Array的结构" class="headerlink" title="创建Numpy Array的结构"></a>创建Numpy Array的结构</h1><p>其实 Numpy 就是 C 的逻辑, 创建存储容器 “Array” 的时候是寻找内存上的一连串区域来存放, 而 Python 存放的时候则是不连续的区域, 这使得 Python 在索引这个容器里的数据时不是那么有效率. Numpy 只需要再这块固定的连续区域前后走走就能不费吹灰之力拿到数据.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/4-1-2.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>在运用 Numpy 的时候, 我们通常不是用一个一维 Array 来存放数据, 而是用二维或者三维的块来存放<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/4-1-3.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>因为 Numpy 快速的<strong>矩阵相乘</strong>运算, 能将乘法运算分配到计算机中的多个核, 让运算并行. 这种并行运算大大加速了运算速度.</p><p>不管是1D，2D，3D 的 Array, 从根本上, 它都是一个 1D array。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/4-1-4.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>2D Array, 如果追溯到计算机内存里, 它其实是储存在一个连续空间上的. 而对于这个连续空间, 我们如果创建 Array 的方式不同, 在这个连续空间上的排列顺序也有不同. 这将影响之后所有的事情!</p><p>在 Numpy 中, 创建 2D Array 的默认方式是 “C-type” 以 row 为主在内存中排列, 而如果是 “Fortran” 的方式创建的, 就是以 column 为主在内存中排列.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-21%20%E4%B8%8B%E5%8D%886.52.43.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="在-Axis-上的动作"><a href="#在-Axis-上的动作" class="headerlink" title="在 Axis 上的动作"></a>在 Axis 上的动作</h1><p>当你的计算中涉及合并矩阵, 不同形式的矩阵创建方式会有不同的时间效果. 因为在 Numpy 中的矩阵合并等, 都是发生在一维空间里 ! 不是二维空间中!</p><p>从上面的那张图, 可以想到, row 为主的存储方式, 如果在 row 的方向上合并矩阵, 将会更快. 因为只要我们将思维放在 1D array 那, 直接再加一个 row 放在1D array 后面就好了。</p><p>但是在以 column 为主的系统中, 往 1D array 后面加 row 的规则变复杂了, 消耗的时间也变长. 如果以 axis=1 的方式合并, “F” 方式将会比 “C” 方式更好.</p><p>在数组的拼接中，对比<strong>np.stack</strong>和<strong>np.concatenate</strong>,通过测试发现，为了速度，尽量使用<strong>np.concatenate</strong>。</p><h1 id="copy慢，view快"><a href="#copy慢，view快" class="headerlink" title="copy慢，view快"></a>copy慢，view快</h1><p>在 Numpy 中, 有两个很重要的概念, copy 和 view. copy 顾名思义, 会将数据 copy 出来存放在内存中另一个地方, 而 view 则是不 copy 数据, 直接取源数据的索引部分.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/4-1-5.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>简单说, a_view 的东西全部都是 a 的东西, 动 a_view 的任何地方, a 都会被动到, 因为他们在内存中的位置是一模一样的, 本质上就是自己. 而 a_copy 则是将 a copy 了一份, 然后把 a_copy 放在内存中的另外的地方, 这样改变 a_copy, a 是不会被改变的.</p><p>因为 view 不会复制东西, 速度快。</p><p>对于 view 还有一点要提,<strong>把一个矩阵展平</strong>, 用到 <strong>np.flatten()</strong> 或者<strong>np.ravel()</strong>. 他俩是不同的!ravel 返回的是一个 view (官方说如果用 ravel, 需要 copy 的时候才会被 copy , 我想这个时候可能是把 ravel 里面 order 转换的时候, 如 ‘C-type’ -&gt; ‘Fortran’), 而 flatten 返回的总是一个 copy. 相比于 flatten, <strong>ravel</strong> 是神速.</p><h1 id="选择数据"><a href="#选择数据" class="headerlink" title="选择数据"></a>选择数据</h1><p>选择数据的时候, 我们常会用到 view 或者 copy 的形式. 我们知道了, 如果能用到 view 的, 我们就尽量用 view, 避免 copy 数据.下面举例的都是 view 的方式:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%889.10.18.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>使用copy的方式：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%889.10.48.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>对于fancy indexing的形式，我们也是可以对它加速。<br>1.使用<strong>np.take()</strong>, 替代用 index 选数据的方法.<br>像 a_copy1 = a[ [1,4,6] ,  [2,4,6] ], 用 take 在大部分情况中会比这样的 a_copy1 要快.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%889.15.16.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>2 使用 np.compress(), 替代用 mask 选数据的方法.<br>a_copy2 = a[ [ True, True] ,  [ False, True]] 这种就是用 TRUE, FALSE 来选择数据的.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%889.17.11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="非常有用的out参数"><a href="#非常有用的out参数" class="headerlink" title="非常有用的out参数"></a>非常有用的out参数</h1><p>下面两个其实在功能上是没差的, 不过运算时间上有差, 我觉得可能是 a=a+1 要先转换成 np.add() 这种形式再运算, 所以前者要用更久一点的时间.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%889.19.23.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>这两个被赋值的 a, 都是原来 a 的一个 copy, 并不是 a 的 view. 但是在功能里面有一个 out 参数, 让我们不必要重新创建一个 a. 所以下面两个是一样的功能, 都不会创建另一个 copy. 可能是上面提到的那个原因, 这里的运算时间也有差.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E8%8E%AB%E5%87%A1%20%E4%BD%BF%E7%94%A8Numpy%E7%9A%84%E6%8A%80%E5%B7%A7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-22%20%E4%B8%8A%E5%8D%889.22.03.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>所以只要是已经存在了一个 placeholder (比如 a), 我们就没有必要去再创建一个, 用 out 方便又有效.</p><h1 id="给数据一个名字"><a href="#给数据一个名字" class="headerlink" title="给数据一个名字"></a>给数据一个名字</h1><p>使用Numpy的structured array.</p><p>pandas 为什么比 numpy 慢, 因为 pandas data 里面还有很多七七八八的数据, 记录着这个 data 的种种其他的特征. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;莫凡-使用Numpy的技巧&quot;&gt;&lt;a href=&quot;#莫凡-使用Numpy的技巧&quot; class=&quot;headerlink&quot; title=&quot;莫凡 使用Numpy的技巧&quot;&gt;&lt;/a&gt;莫凡 使用Numpy的技巧&lt;/h1&gt;&lt;p&gt;pandas要比Numpy慢，所以尽量避免使用Pan
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="Python" scheme="https://github.com/zdkswd/tags/Python/"/>
    
  </entry>
  
</feed>
