<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ZDK&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://github.com/zdkswd/"/>
  <updated>2019-05-27T07:05:48.829Z</updated>
  <id>https://github.com/zdkswd/</id>
  
  <author>
    <name>ZDK</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spring Boot实战 入门</title>
    <link href="https://github.com/zdkswd/2019/05/27/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/"/>
    <id>https://github.com/zdkswd/2019/05/27/Spring Boot实战 入门/</id>
    <published>2019-05-27T07:00:47.000Z</published>
    <updated>2019-05-27T07:05:48.829Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自动配置"><a href="#自动配置" class="headerlink" title="自动配置"></a>自动配置</h1><p><strong>初始化后的项目</strong><br>Application.java不仅是启动引导类，还是配置类。<br><strong>@SpringBootApplication</strong>开启组件扫描和自动配置。将三个有用的注解组合在了一起。<br>1.Spring的<strong>@Configuration</strong>:标明该类使用Spring基于Java的配置。<br>2.Spring的<strong>@ComponentScan</strong>:启用组件扫描，这样所写的Web控制器类和其他组件才能被自动发现并注册为Spring应用程序上下文中里的Bean。<br>3.Spring Boot的<strong>@EnableAutoConfiguration</strong>:这一行配置开启了Spring Boot自动配置的魔力，可以不再写成篇的配置了。</p><p><strong>application.properties</strong>可以很方便地细粒度调整Spring Boot的自动配置。完全不用告诉Spring Boot加载application.properties,只要存在就会被加载。</p><p> <strong>Spring Boot项目构建插件</strong><br>Spring Boot的构建插件对构建过程有所帮助，如Maven钟spring-boot-maven-plugin。构建插件的主要功能是把项目打包成一个可执行的超级JAR，包括把应用程序的所有依赖打入JAR文件中，并为JAR添加一个描述文件，其中的内容能用java -jar来运行应用程序。</p><p><strong>指定基于功能的依赖</strong><br>并不需要指定版本号，起步依赖本身的版本是由正在使用的Spring Boot的版本来决定的，而起步依赖则会决定它们引入的传递依赖版本。<br>Maven和gradle中使用构建工具来显示包含项目汇总每一个库以及它们的版本。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.13.47.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>![]<br>(Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.13.40.png)</p><p><strong>覆盖起步依赖引入的传递依赖</strong><br>gradle</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.15.40.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>Maven<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.16.59.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>需要指定版本的依赖，则可以在pom.xml中覆盖传递依赖引入的另一个依赖。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.18.46.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>gradle则是倾向于使用更新的依赖，若要指定老版本的生效，则要先将较新版本的exclude。</p><p><strong>使用自动配置</strong><br>Spring Boot的自动配置是一个运行时的过程，考虑了众多的因素，才决定Spring配置应该用哪一个不该用哪一个。例如。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.22.59.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>专注于应用程序功能：1.定义领域模型如一个实体。2.定义仓库接口。3.创建Web界面。</p><p>1.<strong>@Entity</strong>注解表明对象是一个JPA实体。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.25.57.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>id属性加了<strong>@Id</strong>和<strong>@GeneratedValue</strong>注解，说明这个字段是实体的唯一标识，并且这个字段的值是自动生成的。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.26.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>2.通过扩展JpaRepository,ReadingListRespository直接继承了18个执行常用持久化操作的方法。JpaRepository是个泛型接口，有两个参数：仓库操作的领域对象类型，及ID属性的类型。以及自己增加的方法findByReader()。只需定义仓库接口，在应用程序启动后，该接口在运行时会自动实现。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.31.11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>3.使用SpringMVC为应用程序处理HTTP请求。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8A%E5%8D%888.37.12.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><strong>@Controller</strong>注解，组件扫描会自动将其注册为Spring应用程序上下文的一个Bean。<br><strong>@RequestMapping</strong>注解，将其中所有的处理器方法都映射到了”/”这个URL路径上。</p><p>在向应用程序加入 Spring boot时,有个名为<strong>spring-boot-autoconfigurel.JAR</strong>文件,其中包含了很多配置类。每个配置类都在应用程序的Classpath里,都有机会为应用程序的配置添砖加瓦。这些配置类里有用于 Thymeleaf的配置,有用于 Spring data JPa的配置,有用于 Spiring mvc的配置<br>还有很多其他东西的配置,你可以自己选择是否在 Spring应用程序里使用它们。其中利用了Spring的条件化配置，条件化配置运行配置存在于应用程序中，但在满足某些特定条件之前都忽略这个配置。在Spring里可以很方便地编写自己的条件，要做的就是实现Condition接口，覆盖它的matches方法。</p><p>下面的简单条件类只有在Classpath里存在JdbcTemplate时才会生效。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8B%E5%8D%8812.39.06.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>当用Java来声明Bean时，可以用自定义条件类。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8B%E5%8D%8812.42.03.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>在这个例子中，只有当JdbcTemplateCondition类的条件成立时才会创建MyService这个Bean。也就是说，MyService Bean创建条件是Classpath里有JdbcTemplate。否则，这个Bean的声明就会被忽略。</p><p><strong>Classpath</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/191992114-5b5c838544f7c_articlex.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>自动配置会做出以下配置决策，它们和之前的例子息息相关。<br>1.因为Classpath里有H2，所以会创建一个嵌入式H2数据库Bean，它的类型是javax.sql.DataSource,JPA实现( Hibernate )需要它来访问数据库。<br>2.因为Classpath里有Hibernate ( Spring Data JPA传递引入的)的实体管理器，所以自动配置会配置与Hibernate相关的Bean，包括Spring的LocalContainerEntityManagerFactory Bean和JpaVendorAdapter。<br>3.因为Classpath里有Spring Data JIPA，所以它会自动配置为根据仓库的接口创建仓库实现。<br>4.因为Classpath里有Thymeleaf,所以Thymeleaf会配置为Spring MVC的视图，包括一个Thymeleaf的模板解析器、模板引擎及视图解析器。视图解析器会解析相对于Classpath根目录的 / templates目录里的模板。<br>5.因为Classpath里有SpringMVC(归功于Web起步依赖)，所以会配置Spring的DispatcherServlet并启用Spring MVC。<br>6.因为这是一个Spring MVC Web应用程序,所以会注册一个资源处理器,把相对于Classpath根目录的 / static目录里的静态内容提供出来。(这个资源处理器还能处理 / public、/ resources和_META-INF_resources的静态内容。)<br>7.因为Classpath里有Tomcat(通过Web起步依赖传递引用),所以会启动一个嵌入式的Tomcat容器，监听8080端口。</p><h1 id="自定义配置"><a href="#自定义配置" class="headerlink" title="自定义配置"></a>自定义配置</h1><p><strong>覆盖Spring Boot自动配置</strong><br>正如上面所讲。</p><p><strong>@Configuration</strong>用于定义配置类，可替换xml配置文件，被注解的类内部包含有一个或多个被@Bean注解的方法，这些方法将会被AnnotationConfigApplicationContext或AnnotationConfigWebApplicationContext类进行扫描，并用于构建bean定义，初始化Spring容器。</p><p><strong>通过属性文件外置配置。</strong><br>另一种方式是通过applocation.properties,yml也可以。</p><p>Spring Boot能从多种属性源获得属性，优先级从高到低是：<br>(1)命令行参数<br>(2) java: comp / env里的JNDI属性<br>(3)JVM系统属性<br>(4)操作系统环境变量<br>(5)随机生成的带random. * 前缀的属性<br>(6)应用程序以外的application. properties或者appliaction.yml文件<br>(7)打包在应用程序内的application.properties或者appliaction.yml文件<br>(8)通过@PropertySource标注的属性源<br>(9)默认属性</p><p>application. properties和application.yml文件能放在以下四个位置。优先级有高到低<br>(1)外置，在相对于应用程序运行目录的 / config子目录里。<br>(2)外置，在应用程序运行的目录里。<br>(3)内置，在config包内 。<br>(4)内置，在Classpath根目录。</p><p>同一优先级位置上，application.yml会覆盖application.properties的属性。</p><p>在application.yml / prop通常你都无需指定JDBC驱动，Spring Boot会根据数据库URL识别出需要的驱动，但如果识别出问题了，你还可以设置spring datasource.driver-class-name属性。在自动配置DataSourceBean的时候，SpringBoot会使用这里的连接数据。</p><p>DataSourceBean是一个连接池，如果Classpath里有Tomcat的连接池DataSource,那么就会使用这个连接池;否则，Spring Boot会在Classpath里查找以下连接池:HikariCP，Commons DBCP 2。还可以自己配置DataSource Bean,使用自己喜欢的各种连接池。</p><p><strong>应用程序Bean的配置外置</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8B%E5%8D%882.44.19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><strong>@ConfigurationProperties</strong>注解说明该Bean的属性应该是（通过setter）从配置属性值注入的，更具体就是说明应该注入带amazon前缀的属性。</p><p>本例中ReadingListController只有一个setter方法，就是设置associateId属性用的setter方法。因此，设置Amazon Associate ID唯一要做的就是添加amazon.associateId属性，把它加入支持的任一属性源位置里即可。<br>例如在application.properties中设置：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8B%E5%8D%882.51.39.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>开启配置属性</strong>从技 术上来说，<strong>@ConfigurationProperties</strong>注解不会生效，除非先向Spring配置类添加<strong>@EnableConfigurationProperties</strong>注解。但通常无需这么做，因为Spring Boot自动配置后面的全部配置类都已经加上了<strong>@EnableConfigurationProperties</strong>注解。因此，除非你完全不使用自动配置，否则就无需显式地添加<strong>@EnableConfigurationProperties</strong>。</p><p>需要注意，Spring Boot的属性解析器非常智能，它会自动把驼峰规则的属性和使用连字符或下划线的同名属性关联起来。换句话说，amazon. associateId这个属性和amazon. associate_ id以及amazon.associate-id都是等价的。</p><p><strong>在一个类里收集属性</strong>，创建一个单独的Bean,为它加上<strong>@ConfigurationProperties</strong>注解，让这个Bean收集所有配置属性。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8B%E5%8D%883.08.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>有了加载amazon.associateld配置属性的AmazonProperties后，我们可以调整ReadingListController ,让它从注入的AmazonProperties中获取Amazon Associate ID。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8B%E5%8D%883.13.23.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>使用Profile进行配置</strong><br>Profile是一种条件化配置，基于运行时激活Profile，会使用或者忽略不同的Bean或配置类。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8B%E5%8D%883.51.20.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><strong>@Profile</strong>注解要求运行时激活production Profile,这样才能应用该配置。如果production Profile没有激活，就会忽略该配置。设置spring.profiles.active属性就能激活Profile，任意设置配置属性的方式都能用于设置这个值。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-23%20%E4%B8%8B%E5%8D%883.57.59.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>如果正在使用application.properties，可以创建额外的属性文件，遵循application-{profile}.properties命名格式，就能提供特定于Profile的属性了。<br>比如说生产环境，就是application-production.properties。</p><p>使用YAML就可以把所有的Profile的配置属性都放在一个application.yml文件里，例如：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Spring%20Boot%E5%AE%9E%E6%88%98%20%E5%85%A5%E9%97%A8/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-27%20%E4%B8%8B%E5%8D%882.48.39.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;自动配置&quot;&gt;&lt;a href=&quot;#自动配置&quot; class=&quot;headerlink&quot; title=&quot;自动配置&quot;&gt;&lt;/a&gt;自动配置&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;初始化后的项目&lt;/strong&gt;&lt;br&gt;Application.java不仅是启动引导类，还是配置类。&lt;br
      
    
    </summary>
    
      <category term="读书笔记" scheme="https://github.com/zdkswd/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Spring" scheme="https://github.com/zdkswd/tags/Spring/"/>
    
      <category term="Java" scheme="https://github.com/zdkswd/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>百面 优化算法</title>
    <link href="https://github.com/zdkswd/2019/05/14/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    <id>https://github.com/zdkswd/2019/05/14/百面 优化算法/</id>
    <published>2019-05-14T01:45:47.000Z</published>
    <updated>2019-05-14T01:47:09.114Z</updated>
    
    <content type="html"><![CDATA[<h1 id="百面-优化算法"><a href="#百面-优化算法" class="headerlink" title="百面 优化算法"></a>百面 优化算法</h1><p>机器学习算法=模型表征+模型评估+优化算法<br>优化算法所做的事情就是在模型表征空间中找到模型评估指标最好的模型。<br>经典的支持向量机对应的模型表征和评估指标分别为线性分类模型和最大间隔，逻辑回归对应的模型表征和评估指标则分别为线性分类模型和交叉熵。</p><h1 id="有监督学习的损失函数"><a href="#有监督学习的损失函数" class="headerlink" title="有监督学习的损失函数"></a>有监督学习的损失函数</h1><p><strong>问：有监督学习涉及的损失函数有哪些？请列举并简述它们的特点。</strong></p><p>答：在有监督学习中，损失函数刻画了模型和训练样本的匹配程度。<br>对于二分类问题，最自然地损失函数是0-1损失。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%888.33.40.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中1p是指示函数，当且仅当p为真时取值为1，否则取值为0。该损失函数能够直观地刻画分类的错误率，但是由于其非凸非光滑的特点，使得算法很难直接对其进行优化。<br>0-1损失的一个代理损失函数是hinge损失函数。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%888.35.50.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>hinge损失函数是0-1损失函数相对紧的凸上界，且当fy&gt;=1时，该函数不对其做任何惩罚。hinge损失在fy=1处不可导，因此不能用梯度下降法进行优化，而是用<strong>次梯度下降法</strong>。<br>0-1损失的另一个代理损失函数是logistic损失函数：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%888.38.32.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>logistic损失函数也是0-1损失函数的凸上界，且该函数处处光滑，因此可以用梯度下降法进行优化。但是，该损失函数对所有样本点都有所惩罚，因此对异常值相对更敏感一些。<br>当预测值f属于[-1,1]时，另一个代理损失函数就是交叉熵损失函数。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%888.56.54.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>交叉熵损失函数也是0-1损失函数的光滑凸上界。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%888.57.28.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>对于回归问题，最常用的损失函数是平方损失函数。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%888.58.48.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>平方损失函数是光滑函数，能够用梯度下降法进行优化。当预测值距离真实值越远时，平方损失函数的惩罚力度越大，因为它对异常点比较敏感。可以采用绝对损失函数来解决这个问题。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.02.05.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>绝对损失对异常点更鲁棒一些，但是绝对损失函数在f=y处无法求导数。综合考虑可导性和对异常点的鲁棒性，可以采用huber损失函数。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.18.43.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br> huber损失函数在|f-y|较小时为平方损失，在|f-y|较大时为线性损失，处处可导，且对异常点鲁棒。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.21.47.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="机器学习中的优化问题"><a href="#机器学习中的优化问题" class="headerlink" title="机器学习中的优化问题"></a>机器学习中的优化问题</h1><p><strong>问： 机器学习中优化问题，哪些是凸优化问题，哪些是非凸优化问题？</strong></p><p>答：凸函数，函数L是凸函数当且仅当对定义域中的任意两点x，y和任意实数λ∈[0,1]总有<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.25.15.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.25.42.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>逻辑回归对应的就是凸优化问题，对于二分类问题，Y={1,-1},假设模型参数为θ，则逻辑回归的优化问题为。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.27.51.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>可以通过计算目标函数的二阶Hessian矩阵来验证凸性。令<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.37.57.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>对该函数求一阶导，得到：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.38.29.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>继续求导，得到函数的Hessian矩阵<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.39.18.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>该矩阵满足半正定的性质。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.40.51.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>因此<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.41.05.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>函数L为凸函数。对于凸优化问题，所有的局部极小值都是全局极小值，因此这类问题一般认为是比较容易求解的问题。</p><p>主成分分析的优化问题为非凸优化问题。一般来说，非凸优化问题被认为是比较南求解的问题，但主成分分析是一个特例，我们可以借助SVD直接得到主成分分析的全局极小值。</p><p><strong>总结与扩展：</strong>其他凸优化的例子包括支持向量机，线性回归等线性模型，非凸优化问题的例子包括低秩模型(如矩阵分解),深度神经网络模型。</p><h1 id="经典优化算法"><a href="#经典优化算法" class="headerlink" title="经典优化算法"></a>经典优化算法</h1><p><strong>问题：无约束优化问题的优化方法有哪些？</strong>对于无约束优化问题：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%889.54.49.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中目标函数L是光滑的，求解该问题的优化算法有哪些，适用场景是什么。</p><p>答：优化算法分为<strong>直接法</strong>和<strong>迭代法</strong>。<br>直接法，就是能够直接给出优化问题的最优解。直接法不是万能的。直接法要求目标函数需要满足两个条件，第一个是，L是凸函数。二，若L是凸函数，那么θ是最优解的充分必要条件是L在θ处的梯度为0。<br>即<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%8810.00.16.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>经典的例子是岭回归，其最优解为：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%8810.04.11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>直接法要满足的这两个条件限制了它的应用范围。因此，在很多实际问题中，会采用迭代法。迭代法就是迭代地修正对最优解得估计。迭代法又分为一阶法和二阶法两类。<br>一阶法的迭代公式为：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%8810.20.55.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中α称为学习率，一阶法也称为梯度下降法，梯度就是目标函数的一阶信息。<br>二阶法的迭代公式<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%8810.22.05.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>二阶法也称为牛顿法，Hessian矩阵就是目标函数的二阶信息，二阶法的收敛速度一般要远快于一阶法，但是在高维情况下，Hessian矩阵求逆的计算复杂度很大，而且当目标函数非凸时，二阶法有可能会收敛到鞍点。</p><h1 id="梯度验证"><a href="#梯度验证" class="headerlink" title="梯度验证"></a>梯度验证</h1><p>在实际应用中，写出计算梯度的代码后，通常需要验证自己写的代码是否正确。<br><strong>问：如何验证求目标函数梯度功能的正确性？</strong></p><p>答：ei是单位向量，维度与θ相同，仅在第i个位置取值为1，其余位置取值为0。可以取h为一个比较小的数(例如10的-7次方)，则有<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%8811.00.14.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%8811.03.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>在实际应用中，随机初始化θ，取h为较小的数(例如10的-7次方)，并对i=1,2,…,n,依次验证<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-08%20%E4%B8%8A%E5%8D%8811.01.00.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>是否成立。如果对于某个下标i，该不等式不成立，则有以下两种可能。<br>1 该下标对应的M过大<br>2 该梯度分量计算不正确</p><p>此时可以固定θ，减小h为原来的十分之一，并再次计算下标i对应的近似误差，若近似误差越减小为原来的百分之一，则对应第一种可能，我们应该采用更小的h重新做一次梯度验证，否则对应第二种可能，应检查梯度的代码是否有错误。</p><h1 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h1><p><strong>问：当训练数据量特别大时，经典的梯度下降法存在什么问题，需要做如何改进？</strong></p><p>答：经典的梯度下降法在每次对模型参数进行更新时，需要遍历所有的训练数据。当M很大时，这需要很大的计算量，耗费很长的计算时间，在实际应用中基本不可行。为了解决该问题，随机梯度下降法(SGD)用单个训练样本的损失来近似平均损失，即随机梯度下降法用单个训练数据即可对模型参数进行一次更新，大大加快了收敛速率。该方法也非常适用于数据源源不断到来的在线更新场景。</p><p>为了降低随机梯度的方差，从而使得迭代算法更加稳定，也为了充分利用高度优化的矩阵运算操作，在实际应用中我们会同时处理若干训练数据，该方法被称为小批量梯度下降法(Mini-Batch Gradient Descent)<br>有三个需要注意的地方：<br>1.选取参数m，在不同的应用中，最优的m通常会不一样，需要通过调参选取。一般m取2的幂次能充分利用矩阵运算操作，所以可以在2的幂次中挑选出最优的取值，例如32，64，128，256等。<br>2.挑选m个训练数据，为了避免数据的特定顺序给算法收敛带来的影响，一般会在每次遍历训练数据之前，先对所有的数据进行随机排序，然后在每次迭代时按顺序挑选m个训练数据直至遍历完所有的数据。<br>3.选取学习速率α，为了加快收敛速率，同时提高求解精度，通常会采用衰减学习速率的方案:一开始算法采用较大的学习速率，当误差曲线进入平台期后，减小学习速率做更精细的调整。最优的学习速率方案也通常需要调参才能得到。</p><p>综上，通常采用小批量梯度下降法解决训练数据量过大的问题。每次更新模型参数时，只需要处理m个训练数据即可，其中m是一个远小于总数据量M的常数，这样能够大大加快训练过程。</p><h1 id="随机梯度下降法的加速"><a href="#随机梯度下降法的加速" class="headerlink" title="随机梯度下降法的加速"></a>随机梯度下降法的加速</h1><p>提到深度学习中的优化方法，人们通常会想到随机梯度下降法。但是，随机梯度下降法并不是万金油，有时候反而会成为一个坑。当设计出一个深度神经网络时，如果只知道用随机梯度下降法来训练模型，那么当得到一个比较差的训练结果时，可能会放弃在这个模型上继续投入精力。然而，造成训练效果差的真正原因，可能并不是模型的问题，而是随机梯度下降法在优化过程中失效了，这可能会导致你丧失一次新发现的机会。</p><p><strong>问：随机梯度下降法偶尔也会失效，无法给出满意的训练结果，这是为什么？</strong></p><p>答：随机梯度下降法放弃了对梯度准确性的追求，每步仅仅随机采样一个或少量样本来估计当前梯度，计算速度快，内存开销小。但由于每步接受的信息量有限，随机梯度下降法对梯度的估计常常出现偏差，造成目标函数曲线收敛得很不稳定，伴有剧烈波动，有时甚至出现不收敛的情况。</p><p>深度学习中的优化问题本身就很难，有太多局部最优点的陷阱。这些陷阱对随机梯度下降法和批量梯度下降法都是普遍存在的。但对随机梯度下降法来说，可怕的不是局部最优点，而是<strong>山谷</strong>和<strong>鞍点</strong>两类地形。</p><p>山谷顾名思义就是狭长的山间小道，左右两边是峭璧;鞍点的形状像是一个马鞍，一个方向上两头翘，另一个方向上两头垂，而中心区域是一片近乎水平的平地。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/f08834008016f4c23a67e931d2f5a281_b.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>山谷地形</p><p>在山谷中，准确的梯度方向是沿山道向下，稍有偏离就会撞向山壁，而粗糙的梯度估计使得它在两山壁间来回反弹震荡，不能沿山道方向迅速下降，导致收敛不稳定和收敛速度慢。在鞍点处，随机梯度下降法会走入一片平坦之地，结果就停滞下来。</p><p><strong>问：解决之道—惯性保持和环境感知。</strong></p><p>答：1.动量(<strong>Momentum</strong>)方法。<br>随机梯度下降法更新公式为：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%887.56.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>动量方法模型参数迭代公式为：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%887.56.40.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>具体来说，前进步伐-v,由两部分组成。一是学习速率乘以当前估计的梯度g;二是带衰减的前一次步伐v。这里，惯性就体现在对前一次步伐信息的重利用上。类比中学物理知识，当前梯度就好比当前时刻受力产生的加速度，前一次步伐好比前一时刻的速度，当前步伐好比当前时刻的速度。为了计算当前时刻的速度，应当考虑前一时刻速度和当前加速度共同作用的结果，因此vt直接依赖于vt-1 和gt, 而不仅仅是gt。另外，衰减系数y扮演了阻力的作用。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/3e0e36c25cfc4dccb28e651aa7a47b01_b.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/a1a5fe431b8ab803d778337c8be2f275_b.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/20180515233015431.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>AdaGrad方法</strong><br>随机梯度下降法对环境的感知是指在参数空间中，根据不同参数的一些经验性判断，自适应地确定参数的学习速率，不同参数的更新步幅是不同的。例如，在文本处理中训练词嵌入模型的参数时，有的词或词组频繁出现，有的词或词组则极少出现。数据的稀疏性导致相应参数的梯度的稀疏性，不频繁出现的词或词组的参数的梯度在大多数情况下为零，从而这些参数被更新的频率很低。在应用中，我们希望更新频率低的参数可以拥有较大的更新步幅，而更新频率高的参数的步幅可以减小。<strong>AdaGrad方法采用“历史梯度平方和”来衡量不同参数的梯度的稀疏性，取值越小表明越稀疏</strong>，具体的更新公式表示为<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%889.09.19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>分母求和的形式实现了退火过程，这是很多优化技术中常见的策略，意味着随着时间推移，学习速率越来越小，从而保证了算法的最终收敛。</p><p><strong>Adam方法</strong><br>Adam方法将惯性保持和环境感知这两个优点集于一身。一方面，Adam记录梯度的一阶矩(first moment) ，即过往梯度与当前梯度的平均，这体现了惯性保持;另一方面，Adam还记录梯度的二阶矩(second moment)，即过往梯度平方与当前梯度平方的平均，这类似AdaGrad方法，体现了环境感知能力，为不同参数产生自适应的学习速率。</p><p>一阶矩和二阶矩采用类似于滑动窗口内求平均的思想进行融合，即当前梯度和近一段时间内梯度的平均值，时间久远的梯度对当前平均值的贡献呈指数衰减。具体来说，一阶矩和二阶矩采用指数衰退平均(exponentialdecay average)技术，计算公式<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%889.16.48.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中β，β2为衰减系数，m是一阶矩，v是二阶矩。</p><p> 一阶矩相当于估计E[g]:由于当下梯度g,是随机采样得到的估计结果，因此更关注它在统计意义上的期望;二阶矩相当于估计E[g2]，这点与AdaGrad方法不同，不是g2从开始到现在的加和，而是它的期望。它们的物理意义是，当|m|大且v大时， 梯度大且稳定，这表明遇到一个明显的大坡，前进方向明确;当|m|趋于零 且v,大时，梯度不稳定，表明可能遇到一个峡谷，容易引起反弹震荡;当lm|大 且v,趋于零时，这种情况不可能出现;当|m|趋于零且v趋于零时，梯度趋于零，可能到达局部最低点，也可能走到一片坡度极缓的平地，此时要避免陷入平原(plateau) 。另外，Adam方法还考虑了m， v,在零初始值情况下的偏置矫正。具体来说，Adam的更新公式为<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%889.23.22.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%889.24.33.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="L1正则化与稀疏性"><a href="#L1正则化与稀疏性" class="headerlink" title="L1正则化与稀疏性"></a>L1正则化与稀疏性</h1><p><strong>问：L1正则化使得模型参数具有稀疏性的原理是什么？</strong></p><p>角度1：解空间形状。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%889.27.24.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>在二维的情况下，黄色的部分是L2和L1正则项约束后的解空间，绿色的等高线是凸优化问题中目标函数的等高线。由图可知，L2正则项约束后的解空间是圆形，而L1正则项约束的解空间是多边形。显然，多边形的解空间更容易在尖角处与等高线碰撞出稀疏解。</p><p>事实上，带正则项和带约束条件是等价的。为了约束w的可能取值空间从而防止过拟合，我们为该最优化问题加上一个约束，就是w的L2范数的平方不能大于m:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%889.54.41.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>为了求解带约束条件的凸优化问题，写出拉格朗日函数。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-13%20%E4%B8%8B%E5%8D%889.56.48.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>若w <em>  和λ </em> 分别是原问题和对偶问题的最优解，根据KKT条件，它们应满足<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-14%20%E4%B8%8A%E5%8D%888.48.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>L2正则化相当于为参数定义了一个圆形的解空间(因为必须保证L2范数不能大于m),而L1正则化相当于为参数定义了个棱形的解空间。如果原问题目标函数的最优解不是恰好落在解空间内,那么约束条件下的最优解一定是在解空间的边界上,而L1“棱角分明”的解空间显然更容易与目标函数等高线在角点碰撞,从而产生稀疏解。</p><p>L2的切点只有一个点，L1的话，一个尖尖可以和无数个圆连着。</p><p><strong>角度2：函数叠加</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%99%BE%E9%9D%A2%20%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-14%20%E4%B8%8A%E5%8D%888.55.34.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>棕线是原始目标函数L(w)的曲线图，最小值点在蓝点处，且对应w * 值非0。</p><p>考虑加上L2正则化项，目标函数变成L(w)+Cw2,其函数曲线为黄色。此时，最小值点在黄点处，对应w * 的绝对值减小了，但仍然非0.</p><p>考虑加上L1正则化项，目标函数变成L(w)+C|w|,其函数曲线为绿色，最小值点在红色处，对应的w是0，产生了稀疏性。</p><p>原因很直观，加入L1正则化后，对带正则项的目标函数求导，正则项部分产生的导数在原点左边部分是-C，在原点右边部分是C，因此，只要原目标函数的导数绝对值小于C，那么带正则项的目标函数在原点左边部分始终是递减的，在原点右边部分始终是递增的，最小值点自然在原点处。相反，L2正则项在原点处的导数是0，只要原目标函数在原点处的导数不为0，那么最小值点就不会在原点，所以L2只有减小w绝对值的作用，对解空间的稀疏性没有贡献。</p><p>在一些在线梯度下降算法中，往往会采用截断梯度法来产生稀疏性，这同L1正则项产生稀疏性的原理是类似的。<br><strong>由上可以看出，L1产生稀疏性的概率比L2大很多，L2只有原目标函数导数为0这一种情况，L1则是原目标函数的导数绝对值小于C即可。</strong></p><p><strong>角度3：贝叶斯先验</strong><br>从贝叶斯的角度来理解L1正则化和L2正则化，简单的解释是，L1正则化相当于对模型参数w引入了拉普拉斯先验，L2正 则化相当于引入了高斯先验，而拉普拉斯先验使参数为0的可能性更大。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;百面-优化算法&quot;&gt;&lt;a href=&quot;#百面-优化算法&quot; class=&quot;headerlink&quot; title=&quot;百面 优化算法&quot;&gt;&lt;/a&gt;百面 优化算法&lt;/h1&gt;&lt;p&gt;机器学习算法=模型表征+模型评估+优化算法&lt;br&gt;优化算法所做的事情就是在模型表征空间中找到模型评估
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>leetcode分类练习</title>
    <link href="https://github.com/zdkswd/2019/05/07/leetcode%E5%88%86%E7%B1%BB%E7%BB%83%E4%B9%A0/"/>
    <id>https://github.com/zdkswd/2019/05/07/leetcode分类练习/</id>
    <published>2019-05-07T11:56:47.000Z</published>
    <updated>2019-05-07T11:56:40.783Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h1><p>15.3sum<br>169.majority element<br>41.first missing positive</p><h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><p>141.linked list cycle<br>23.merge k sorted list</p><h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h1><p>20.valid parenthess<br>32.longest valid parentheses<br>150.evaluate reverse polish notation</p><h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h1><p>641.design circular deque<br>239.sliding window maxumum</p><h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h1><p>70.climbing stairs</p><h1 id="排序与二分查找"><a href="#排序与二分查找" class="headerlink" title="排序与二分查找"></a>排序与二分查找</h1><p>69.sqrt(x)</p><h1 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h1><p>344.reverse string<br>151.reverse words in a string<br>8.string to integer(atoi)</p><h1 id="二叉树和堆"><a href="#二叉树和堆" class="headerlink" title="二叉树和堆"></a>二叉树和堆</h1><p>226.invert binary tree<br>104.maximum depth of binary tree<br>98.validate binary search tree<br>112.path sum</p><h1 id="图"><a href="#图" class="headerlink" title="图"></a>图</h1><p>200.number of islands<br>36.vaild sudoku</p><h1 id="回溯分治动态规划"><a href="#回溯分治动态规划" class="headerlink" title="回溯分治动态规划"></a>回溯分治动态规划</h1><p>10.regular expression matching<br>64.minimum path sum<br>322.coin change<br>121.best time to buy and sell stock<br>152.maximum product subarray<br>120.triangle</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数组&quot;&gt;&lt;a href=&quot;#数组&quot; class=&quot;headerlink&quot; title=&quot;数组&quot;&gt;&lt;/a&gt;数组&lt;/h1&gt;&lt;p&gt;15.3sum&lt;br&gt;169.majority element&lt;br&gt;41.first missing positive&lt;/p&gt;
&lt;h1 i
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="算法" scheme="https://github.com/zdkswd/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>二分查找</title>
    <link href="https://github.com/zdkswd/2019/05/07/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
    <id>https://github.com/zdkswd/2019/05/07/二分查找/</id>
    <published>2019-05-07T08:53:47.000Z</published>
    <updated>2019-05-07T08:54:04.241Z</updated>
    
    <content type="html"><![CDATA[<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/9dadf04cdfa7b3724e0df91da7cacd9b.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/8bce81259abf0e9a06f115e22586b829.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>二分查找针对的是一个有序的数据集合,查找思想有点类似分治思想。每次都通过跟区间的中间元素对比,将待查找的区间缩小为之前的一半,直到找到要查找的元素,或者区间被缩小为0。</p><p><strong>惊人的查找速度O(logn)。</strong>比如n等于2的32次方，大约是32亿，但是在42亿个数据中用二分查找一个数据，最多需要比较32次。常量级时间复杂度的算法有时候可能还没有O(logn)的算法执行效率高。</p><h1 id="二分查找的递归与非递归实现"><a href="#二分查找的递归与非递归实现" class="headerlink" title="二分查找的递归与非递归实现"></a>二分查找的递归与非递归实现</h1><p>对于最简单的情况，即不存在重复数据的情况。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-07%20%E4%B8%8B%E5%8D%883.33.19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>三个容易出错的地方：<br>1.循环退出条件<br>是low&lt;=high,而不是low&lt;high。<br>2.mid的取值<br>实际上,mid=(ow+high)/2这种写法是有问题的。因为如果low和high比较大的话,两者之和就有可能会溢出。改进的方法是将md的计算方式写成low+(high-low)/2。更进一步,如果要将性能优化到极致的话,我们可以将这里的除以2操作转化成位运算low+(high-low)&gt;&gt;1)。因为相比除法运算来说,计算机处理位运算要快得多。<br>3.low和hign的更新<br>low=md+1,high=mid-1。注意这里的+1和-1,如果直接写成low=mid或者high=mid,就可能会发生死循环。比如,当high=3,low=3时,如果a3]不等于value,就会导致一直循环不退出。</p><p>二分查找除了用循环来实现，还可以用递归来实现。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-07%20%E4%B8%8B%E5%8D%883.45.20.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="二分查找应用场景的局限性"><a href="#二分查找应用场景的局限性" class="headerlink" title="二分查找应用场景的局限性"></a>二分查找应用场景的局限性</h1><p><strong>首先，二分查找依赖的是顺序表结构，简单说就是数组。</strong><br><strong>其次，二分查找针对的是有序数据。</strong>如果数据没有序，我们需要先排序。二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。针对动态变化的数据集合，二分查找将不再适用。<br><strong>再次，数据量太小不适合二分查找。</strong>如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。只有数据量比较大时，二分查找的优势才会比较明显。如果数据之间的比较操作非常耗时，不管数据量大小，都推荐使用二分查找。<br><strong>最后，数据量太大也不适合二分查找。</strong>二分查找的底层需要依赖数组，需要有大量的连续的内存空间，对于1gb的数据，需要有1gb<strong>连续</strong>内存空间。</p><p>虽然大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决，但是不论是散列表还是二叉树都会需要比较多的额外的内存空间。二分查找底层依赖的是数组，除了数据本身之外，不需要额外存储其他信息，是最省内存空间的存储方式。</p><h1 id="二分查找简单情况的变形"><a href="#二分查找简单情况的变形" class="headerlink" title="二分查找简单情况的变形"></a>二分查找简单情况的变形</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/4221d02a2e88e9053085920f13f9ce36.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="查找第一个值等于给定值的元素"><a href="#查找第一个值等于给定值的元素" class="headerlink" title="查找第一个值等于给定值的元素"></a>查找第一个值等于给定值的元素</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/503c572dd0f9d734b55f1bd12765c4f8.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>对于之前简单情况的代码进行一些变形。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-07%20%E4%B8%8B%E5%8D%884.30.51.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>查找的是任意一个值等于给定值的元素，当a[mid]等于要查找的值时，a[mid]就是我们要找的元素，此时需要确认是否是第一个值等于给定值的元素。经检查发现a[mid]前面一个元素a[mid-1]也等于value，那么说明此时的a[mid]肯定不是第一个值等于给定值的元素，就更新high=mid-1。</p><h2 id="变体二-查找最后一个值等于给定值的元素"><a href="#变体二-查找最后一个值等于给定值的元素" class="headerlink" title="变体二 查找最后一个值等于给定值的元素"></a>变体二 查找最后一个值等于给定值的元素</h2><p>同理可得</p><h2 id="变体三-查找第一个大于等于给定值的元素"><a href="#变体三-查找第一个大于等于给定值的元素" class="headerlink" title="变体三 查找第一个大于等于给定值的元素"></a>变体三 查找第一个大于等于给定值的元素</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-05-07%20%E4%B8%8B%E5%8D%884.40.19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>思路类似</p><h2 id="变体四-查找最后一个小于等于给定值的元素"><a href="#变体四-查找最后一个小于等于给定值的元素" class="headerlink" title="变体四 查找最后一个小于等于给定值的元素"></a>变体四 查找最后一个小于等于给定值的元素</h2><p>类似</p><h1 id="快速定位出一个ip地址归属地"><a href="#快速定位出一个ip地址归属地" class="headerlink" title="快速定位出一个ip地址归属地"></a>快速定位出一个ip地址归属地</h1><p>首先将ip地址排序，将问题转化为在有序数组中，查找最后一个小于等于某个给定值的元素。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;二分查找&quot;&gt;&lt;a href=&quot;#二分查找&quot; class=&quot;headerlink&quot; title=&quot;二分查找&quot;&gt;&lt;/a&gt;二分查找&lt;/h1&gt;&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lig
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="算法" scheme="https://github.com/zdkswd/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>线性排序 O(n)  排序优化</title>
    <link href="https://github.com/zdkswd/2019/05/07/%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F%20O(n)%20%20%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/"/>
    <id>https://github.com/zdkswd/2019/05/07/线性排序 O(n)  排序优化/</id>
    <published>2019-05-07T06:32:32.000Z</published>
    <updated>2019-05-07T06:33:45.069Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性排序-O-n-排序优化"><a href="#线性排序-O-n-排序优化" class="headerlink" title="线性排序 O(n)  排序优化"></a>线性排序 O(n)  排序优化</h1><p>桶排序，计数排序，基数排序的时间复杂度是线性的，之所以能做到线性的时间复杂度主要是因为这些算法是非基于比较的排序算法，都不涉及元素之间的比较操作。</p><h1 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h1><p>核心思想是将要排序的数据分到几个有序的桶中，每个桶里的数据再单独进行排序。桶内排完序后，再将每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F%20O(n)%20%20%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/987564607b864255f81686829503abae.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><strong>时间复杂度分析：</strong>如果要排序的数据有n个，把它们均匀地划分到m个桶内，每个桶里就有k=n / m个元素。每个桶内部使用快速排序，时间复杂度为O(k <em> logk)。m个桶排序的时间复杂度就是O(m </em> k <em> logk),因为k=n / m,所以整个桶排序的时间复杂度就是O(n </em> log(n / m))。当桶的个数m接近数据个数n时，log(n / m)就是一个非常小的常量，这个时候桶排序的时间复杂度接近O(n)。</p><p>桶排序对要排序数据的要求是非常苛刻的：<strong>首先</strong>要排序的数据需要很容易能划分成m个桶，并且桶与桶之间有着天然的大小顺序。这样每个桶内数据都排序完之后，桶与桶之间的数据不需要进行排序。<strong>其次</strong>，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为O(nlogn)的排序算法了。</p><p><strong>桶排序比较适合用在外部排序中。</strong></p><h1 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h1><p><strong>计数排序其实是桶排序的一种特殊情况。</strong>当要排序的n个数据，所处的范围并不大时，比如最大值为k，就可以将数据划分为k个桶，每个桶内的数据值都是相同的，省掉了桶内排序的时间。</p><p>比如高考成绩排序，考生的满分是750，最小是0，就可以分为751个桶，根据考生成绩，将50万考生划分到751个桶中，桶内的数据都是分数相同的学生，所以并不需要再进行排序，只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了50万考生的排序，因为只涉及扫描遍历操作，所以时间复杂度是O(n)。</p><p>计数排序的名字计数有何而来呢？比如8个考生分数在0-5之间。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F%20O(n)%20%20%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/adc75672ef33fa54b023a040834fcbc9.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>C[6]内存储的不是考生，而是对应的考生的个数。将C[6]数组顺序求和。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F%20O(n)%20%20%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/dd6c62b12b0dc1b3a294af0fa1ce371f.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>C[k]里存储小于等于分数k的考生个数。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F%20O(n)%20%20%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/1d730cb17249f8e92ef5cab53ae65784.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>这种利用另外一个数组来计数的实现方式非常巧妙，这也是为什么这种排序算法叫计数排序的原因。</p><p><strong>计数排序只能用在数据范围不大的场景中，</strong>如果数据范围k比要排序的数据n大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要在其不改变相对大小的情况下，转化为非负整数。</p><h1 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F%20O(n)%20%20%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/df0cdbb73bd19a2d69a52c54d8b9fc0c.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>对于每一位的排序的算法需要是稳定的。可以使用桶排序或者计数排序，其中桶排序中每个桶不能用快排而要用归并排序。</p><p><strong>基数排序对要排序的数据是有要求的，需要可以分割出独立的‘位’来比较，而且位之间有递进的关系，如果a数据的高位比b数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到O(n)了。</strong></p><h1 id="选择合适的排序算法"><a href="#选择合适的排序算法" class="headerlink" title="选择合适的排序算法"></a>选择合适的排序算法</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BA%BF%E6%80%A7%E6%8E%92%E5%BA%8F%20O(n)%20%20%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/1f6ef7e0a5365d6e9d68f0ccc71755fd.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>其中默认桶排序是不稳定的。</p><h1 id="排序优化，实现高性能的排序函数"><a href="#排序优化，实现高性能的排序函数" class="headerlink" title="排序优化，实现高性能的排序函数"></a>排序优化，实现高性能的排序函数</h1><p>线性排序算法的时间复杂度较低，但是适用场景比较特殊。所以如果要写一个通用的排序函数,不能选择线性排序算法。</p><p>如果对小规模数据进行排序,可以选择时间复杂度是o(n2)的算法;如果对大规模数据进行排序,时间复杂度是 o(nlogn)的算法更加高效。所以,为了兼顾任意规模数据的排序,一般都会首选时间复杂度是o( nlogn)的排序算法来实现排序函数。</p><p>然而归并排序使用的并不多，虽然其稳定O(nlogn)，但是由于其不是原地排序算法，空间复杂度是O(n)，所以并没有得到很多的使用。</p><h1 id="优化快速排序"><a href="#优化快速排序" class="headerlink" title="优化快速排序"></a>优化快速排序</h1><p>最坏的情况下快排的时间复杂度是O(n2),如果数据原来就是有序或者接近有序的，每次分区点都选择最后一个数据，那么快速排序算法就会变得非常糟糕，时间复杂度就会退化为O(n2)，出现的主要原因是我们分区点选的不够合理。理想的分区点是，<strong>被分区点分开的两个分区中，数据的数量差不多。</strong>为了提高排序算法的性能，要尽可能地让每次分区都比较平均。</p><h2 id="三数取中法"><a href="#三数取中法" class="headerlink" title="三数取中法"></a>三数取中法</h2><p>我们从区间的首、尾、中间,分别取出一个数,然后对比大小,取这3个数的中间值作为分区点。这样每间隔某个固定的长度,取数据岀来比较,将中间值作为分区点的分区算法,肯定要比单纯取某一个数据更好。但是,如果要排序的数组比较大,那“三数取中”可能就不够了,可能要“五数取中”或者“十数取中”。</p><h2 id="随机法"><a href="#随机法" class="headerlink" title="随机法"></a>随机法</h2><p>随机法就是每次从要排序的区间中,随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好,但是从概率的角度来看,也不大可能会出现每次分区点都选的很差的情况,所以平均情况下,这样选的分区点是比较好的。时间复杂度退化为最糟糕的O(n2)的情况,出现的可能性不大。</p><p>快速排序是用递归来实现的。我们在递归那一节讲过,递归要警惕堆栈溢出。为了避免快速排序里,递归过深而堆栈过小,导致堆栈溢岀,我们有两种解决办法:第一种是限制递归深度。一旦递归过深,超过了我们事先设定的阈值,就停止递归。第二种是通过在堆上模拟实现一个函数调用栈,手动模拟递归压栈、岀栈的过程,这样就没有了系统栈大小的限制。</p><h1 id="举例分析排序函数"><a href="#举例分析排序函数" class="headerlink" title="举例分析排序函数"></a>举例分析排序函数</h1><p>比如<strong>qsort()函数</strong>，会优先使用归并排序来处理小数据量的排序。使用空间来换时间，当数据量太大，就会改用快速排序算法来排序。选取分区点的方法便是三数取中法。对于递归太深导致堆栈溢出的问题，是通过自己实现一个堆上的栈，手动模拟递归来解决的。qsort()并不仅仅用到了归并排序和快速排序，还用到了插入排序。在快速排序的过程中，当要排序的区间中，元素的个数小于等于4时，qsort()就退化为插入排序，在小规模数据前，O(n2)时间复杂度的算法并不一定比O(nlogn)的算法执行时间长。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性排序-O-n-排序优化&quot;&gt;&lt;a href=&quot;#线性排序-O-n-排序优化&quot; class=&quot;headerlink&quot; title=&quot;线性排序 O(n)  排序优化&quot;&gt;&lt;/a&gt;线性排序 O(n)  排序优化&lt;/h1&gt;&lt;p&gt;桶排序，计数排序，基数排序的时间复杂度是线性
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="算法" scheme="https://github.com/zdkswd/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>极客时间 排序算法O(n^2) O(nlogn)</title>
    <link href="https://github.com/zdkswd/2019/04/30/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/"/>
    <id>https://github.com/zdkswd/2019/04/30/极客时间 排序算法O(n^2) O(nlogn)/</id>
    <published>2019-04-30T12:05:47.000Z</published>
    <updated>2019-05-07T12:10:22.450Z</updated>
    
    <content type="html"><![CDATA[<h1 id="极客时间-排序算法O-n-2-O-nlogn"><a href="#极客时间-排序算法O-n-2-O-nlogn" class="headerlink" title="极客时间 排序算法O(n^2) O(nlogn)"></a>极客时间 排序算法O(n^2) O(nlogn)</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/WechatIMG92.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>所谓的算法稳定性就是<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/1381c1f3f7819ae61ab17455ed7f0b59.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h1><p>比如对于4，5，6，3，2，1<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/4038f64f47975ab9f519e4f739e464e9.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/9246f12cca22e5d872cbfce302ef4d09.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>冒泡的过程可以优化，当某次操作没有数据交换时，说明已经到达完全有序。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/a9783a3b13c11a5e064c5306c261e8e6.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>一，冒泡排序的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以空间复杂度为O(1)，是一个<strong>原地排序</strong>算法。<br>二，为保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，不做交换。所以冒泡排序是<strong>稳定</strong>的。<br>三，最好情况，要排序的数据已经是有序的，只需进行一次冒泡操作即可结束，<strong>最好</strong>时间复杂度是<strong>O(n)</strong>。最坏要排序的数据是倒序的，需要进行n次冒泡，<strong>最坏</strong>为<strong>O(n^2)</strong><br>在最坏情况下，进行n <em> (n-1) / 2次交换，最好情况下不需要进行交换，取中间值为n </em> (n-1) / 4来表示平均，所以<strong>平均</strong>复杂度为<strong>O(n^2)</strong></p><h1 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/7b257e179787c633d2bd171a764171a6.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/b60f61ec487358ac037bf2b6974d2de1.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>插入排序包括元素的比较与元素的移动两种操作。<br>一，插入排序不需要额外的存储空间，所以空间复杂度是O(1)，所以是一个<strong>原地排序</strong>算法。<br>二，对于值相同的元素，通过选择后面出现的元素，就可以保持原有的前后顺序不变，所以插入排序是<strong>稳定</strong>的排序算法。<br>三，<strong>最好</strong>情况是有序，即为从头到尾遍历一遍为<strong>O(n)</strong>。最坏为倒序，每次要插到第一个位置，并且需要大量的移动数据，<strong>最坏</strong>情况时间复杂度为<strong>O(n^2)</strong>。<br>在数组中插入一个数据的平均时间复杂度是O(n)，对于插入排序来说，每次插入操作都相当于在数组中插入一个数据，循环n次，所以平均时间复杂度为O(n^2)。</p><h1 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/32371475a0b08f0db9861d102474181d.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>选择排序算法的实现思路有点类似插入排序，但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。</p><p>选择排序空间复杂度为O(1)，是一种原地排序算法，最好最坏和平均时间复杂度都是O(n^2)。选择排序每次都要找到剩余未排序元素中的最小值，并和前面的元素交换位置，破坏了稳定性，所以选择排序是一种不稳定的排序算法。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/348604caaf0a1b1d7fee0512822f0e50.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/db7f892d3355ef74da9cd64aa926dc2b.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>归并排序使用的就是<strong>分治思想</strong>。<strong>分治是一种解决问题的处理思想，递归是一种编程技巧。</strong>分治算法一般都是用递归来实现的。<br>归并排序的递推公式：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-30%20%E4%B8%8B%E5%8D%885.00.35.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-30%20%E4%B8%8B%E5%8D%885.01.35.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>merge函数的具体操作。需要借助一个临时数组tmp<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/95897ade4f7ad5d10af057b1d144a22f.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>一，对于A[p…q]和A[q+1…r]之间值相同的元素，可以将A[p…q]中的元素放入tmp数组中，就保证了值相同的元素合并前后顺序不变，所以归并排序是个<strong>稳定</strong>的排序。<br>二，由图中可以看出过程不论是最好最坏还是平均情况，<strong>时间复杂度</strong>都是<strong>O(nlogn)</strong><br>三，显而易见，归并排序不是原地排序，递归代码的空间复杂度并不能像时间复杂度那样累加，所以<strong>空间复杂度</strong>是<strong>O(n)</strong>。</p><h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h1><p>快排主要思想：如果要排序数组中下标为p到r之间的一组数据，选择p到r之间任意一个数据作为pivot(分区点)。遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间，至此，p到r就被分为了三部分。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/4d892c3a2e08a17f16097d07ea088a81.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>根据分治、递归的处理思想，可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-30%20%E4%B8%8B%E5%8D%885.58.03.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-30%20%E4%B8%8B%E5%8D%886.00.40.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>partition()分区函数就是随机选择一个元素作为pivot(一般情况下，可以选择p到r区间的最后一个元素)，然后对A[p…r]分区，函数返回pivot的下标。我们希望快排是个<strong>原地排序</strong>算法。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/640.gif" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/aa03ae570dace416127c9ccf9db8ac05.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>可以发现归并排序的处理是<strong>由下向上</strong>的，快排是<strong>由上到下</strong>的。</p><p>性能分析：快排是一种<strong>原地</strong>、<strong>不稳定</strong>的排序算法。由图中可见，有交换的过程，所以是不稳定的，一般来说快排的时间复杂度是O(nlogn)，最差情况是数组中的数据原来已经是有序的，选择最后一个元素作为pivot，分区就是极度不均衡的，那么复杂度就从O(nlogn)退化到O(n^2)，最佳情况就是分区极度均衡，为O(nlogn)，平均来看在大部分时间里，时间复杂度可以做到O(nlohn)，只有在极端情况下，会退化到O(n^2)，但是也有很多方法将这个概率降到很低。</p><p>问题:O(n)时间复杂度内求无序数组的第K大元素。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95O(n%5E2)%20O(nlogn)/898d94fc32e0a795fd65897293b98791.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>选择A[0…n-1]的最后一个元素A[n-1]作为pivot,对数组原地分区，这样数组就分为了三部分,A[0…p-1],A[p],A[p+1…n-1]。</p><p>如果p+1=K，那么A[p]就是要求解的元素；如果K&gt;p+1,说明在右侧，然后同样思路在右边区间去找。</p><h1 id="O-n-时间找到一组数据第K大元素"><a href="#O-n-时间找到一组数据第K大元素" class="headerlink" title="O(n)时间找到一组数据第K大元素"></a>O(n)时间找到一组数据第K大元素</h1><p>解题思路:利用快排中分区的思想,选择数组区间A[0…n-1]的左右一个元素A[n-1]作为pivot,对数组A[0…n-1]原地分区,这样数组就分成了三部分,A[0…p-1],A[p],A[p+1…n-1],如果p+1=k那么A[p]就是要求解的元素,如果K&gt;p+1,则说明第K大的元素在A[p+1…n-1]这个区间,否则在A[0…p-1]这个区间,递归的查找第K大的元素。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;极客时间-排序算法O-n-2-O-nlogn&quot;&gt;&lt;a href=&quot;#极客时间-排序算法O-n-2-O-nlogn&quot; class=&quot;headerlink&quot; title=&quot;极客时间 排序算法O(n^2) O(nlogn)&quot;&gt;&lt;/a&gt;极客时间 排序算法O(n^2) O(
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="算法" scheme="https://github.com/zdkswd/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM: A Highly Efficient Gradient Boosting Decision Tree </title>
    <link href="https://github.com/zdkswd/2019/04/29/LightGBM:%20A%20Highly%20Efficient%20Gradient%20Boosting%20Decision%20Tree/"/>
    <id>https://github.com/zdkswd/2019/04/29/LightGBM: A Highly Efficient Gradient Boosting Decision Tree/</id>
    <published>2019-04-29T04:31:32.000Z</published>
    <updated>2019-04-29T04:32:05.871Z</updated>
    
    <content type="html"><![CDATA[<h1 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h1><p>介绍了两种能让gbdt加速训练的方法。</p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p> Conventional implementations of GBDT need to, for every feature, scan all the data instances to estimate the information gain of all the possible split points.<br>The efficiency and scalability of XGBoost are still unsatisfactory when the feature dimension is high and data size is large.<br>A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. </p><p>LightGBM use <strong>Gradient-based One-Side Sampling(GOSS)</strong> and <strong>Exclusive Feature Bundling(EFB)</strong>  to solve this problem.</p><p><strong>GOSS:</strong>exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. </p><p><strong>EFB:</strong>bundle mutually exclusive features .This is NP-hard,but a greedy algorithm can achieve quite good approximation ratio.</p><p>They call new GBDT implementation with GOSS and EFB <strong>LightGBM</strong>. </p><h1 id="About-GBDT"><a href="#About-GBDT" class="headerlink" title="About GBDT"></a>About GBDT</h1><p>In each iteration, GBDT learns the decision trees by fitting the negative gradients (also known as <strong>residual errors</strong>). </p><p>The main cost in GBDT lies in learning the decision trees, and the most time-consuming part in learning a decision tree is to find the best split points. </p><p>Another popular algorithm is the histogram-based algorithm.Instead of finding the split points on the sorted feature values, histogram-based algorithm buckets continuous feature values into discrete bins and uses these bins to construct feature histograms during training. </p><p>Since the histogram-based algorithm is more efficient in both memory consumption and training speed, they develop work on its basis.</p><h1 id="Gradient-based-One-Side-Sampling-GOSS"><a href="#Gradient-based-One-Side-Sampling-GOSS" class="headerlink" title="Gradient-based One-Side Sampling(GOSS)"></a>Gradient-based One-Side Sampling(GOSS)</h1><p>notice that data instances with different gradients play different roles in the computation of information gain. In particular, according to the definition of information gain, those instances with larger gradients(<strong>i.e., under-trained instances</strong>) will contribute more to the information gain. </p><p>Therefore, when down sampling the data instances, in order to retain the accuracy of information gain estimation, should better keep those instances with large gradients (e.g., larger than a pre-defined threshold, or among the top percentiles), and only randomly drop those instances with small gradients. </p><p>They prove that such a treatment can lead to a more accurate gain estimation than uniformly random sampling, with the same target sampling rate, especially when the value of information gain has a large range. </p><h2 id="Algorithm-Description"><a href="#Algorithm-Description" class="headerlink" title="Algorithm Description"></a>Algorithm Description</h2><p>In AdaBoost, the sample weight serves as a good indicator for the importance of data instances. gradient for each data instance in GBDT provides us with useful information for data sampling. That is, if an instance is associated with a small gradient, the training error for this instance is small and it is already well-trained. </p><p>A straightforward idea is to discard those data instances with small gradients. However, the data distribution will be changed by doing so, which will hurt the accuracy of the learned model. To avoid this problem, they propose a new method called Gradient-based One-Side Sampling (GOSS). </p><p>GOSS keeps all the instances with large gradients(large <strong>residual errors</strong>) and performs random sampling on the instances with small gradients. </p><p>GOSS firstly sorts the data instances according to the absolute value of their gradients and selects the (top a) × 100% instances. Then it randomly samples b × 100% instances from the rest of the data. After that, GOSS amplifies the sampled data with small gradients by a constant<br>(1−a / b) when calculating the information gain.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM:%20A%20Highly%20Efficient%20Gradient%20Boosting%20Decision%20Tree/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-29%20%E4%B8%8B%E5%8D%8812.25.17.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Exclusive-Feature-Bundling-EFB"><a href="#Exclusive-Feature-Bundling-EFB" class="headerlink" title="Exclusive Feature Bundling(EFB)"></a>Exclusive Feature Bundling(EFB)</h1><p>in a sparse feature space, many features are (almost) exclusive, i.e., they rarely take nonzero values simultaneously. Examples include the one-hot features.They can safely bundle such exclusive features.</p><p>To this end, They design an efficient algorithm by reducing the optimal bundling problem to a graph coloring problem (by taking features as vertices and adding edges for every two features if they are not mutually exclusive), and solving it by a greedy algorithm with a constant approximation ratio. </p><p>There are two issues to be addressed. The <strong>first</strong> one is to determine which features should be bundled together. The <strong>second</strong> is how to construct the bundle. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;要点&quot;&gt;&lt;a href=&quot;#要点&quot; class=&quot;headerlink&quot; title=&quot;要点&quot;&gt;&lt;/a&gt;要点&lt;/h1&gt;&lt;p&gt;介绍了两种能让gbdt加速训练的方法。&lt;/p&gt;
&lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;h
      
    
    </summary>
    
      <category term="论文" scheme="https://github.com/zdkswd/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>极客时间 数据结构</title>
    <link href="https://github.com/zdkswd/2019/04/25/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%20%E4%B8%80/"/>
    <id>https://github.com/zdkswd/2019/04/25/极客时间 算法与数据结构 一/</id>
    <published>2019-04-25T12:56:47.000Z</published>
    <updated>2019-05-07T12:05:18.732Z</updated>
    
    <content type="html"><![CDATA[<h1 id="极客时间-算法与数据结构-一"><a href="#极客时间-算法与数据结构-一" class="headerlink" title="极客时间 算法与数据结构 一"></a>极客时间 算法与数据结构 一</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%20%E4%B8%80/861556196039_.pic.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%20%E4%B8%80/901556196041_.pic.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%20%E4%B8%80/911556196043_.pic.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%20%E4%B8%80/871556196040_.pic.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%20%E4%B8%80/881556196041_.pic.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%20%E4%B8%80/891556196042_.pic.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;极客时间-算法与数据结构-一&quot;&gt;&lt;a href=&quot;#极客时间-算法与数据结构-一&quot; class=&quot;headerlink&quot; title=&quot;极客时间 算法与数据结构 一&quot;&gt;&lt;/a&gt;极客时间 算法与数据结构 一&lt;/h1&gt;&lt;figure class=&quot;image-bubb
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="算法" scheme="https://github.com/zdkswd/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Keras.Embedding</title>
    <link href="https://github.com/zdkswd/2019/04/25/Keras.Embedding/"/>
    <id>https://github.com/zdkswd/2019/04/25/Keras.Embedding/</id>
    <published>2019-04-25T12:51:47.000Z</published>
    <updated>2019-04-25T12:51:41.039Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Keras-Embedding"><a href="#Keras-Embedding" class="headerlink" title="Keras.Embedding"></a>Keras.Embedding</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras.Embedding/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-25%20%E4%B8%8B%E5%8D%886.13.17.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras.Embedding/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-25%20%E4%B8%8B%E5%8D%886.13.33.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras.Embedding/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-25%20%E4%B8%8B%E5%8D%886.14.32.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras.Embedding/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-25%20%E4%B8%8B%E5%8D%886.14.51.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>对于一个类别变量的embedding层，input_length=1.input_dim为labelEncoder后的最大值。将label的一个值转化为out_dim的向量的多个值表示。实验如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras.Embedding/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-25%20%E4%B8%8B%E5%8D%888.14.15.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras.Embedding/WechatIMG85.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Keras-Embedding&quot;&gt;&lt;a href=&quot;#Keras-Embedding&quot; class=&quot;headerlink&quot; title=&quot;Keras.Embedding&quot;&gt;&lt;/a&gt;Keras.Embedding&lt;/h1&gt;&lt;figure class=&quot;image-
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>RS Embedding Papers</title>
    <link href="https://github.com/zdkswd/2019/04/18/RS%20Embedding%20Papers/"/>
    <id>https://github.com/zdkswd/2019/04/18/RS Embedding Papers/</id>
    <published>2019-04-18T05:56:47.000Z</published>
    <updated>2019-04-18T07:55:06.501Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Item2Vec-Microsoft"><a href="#Item2Vec-Microsoft" class="headerlink" title="Item2Vec  Microsoft"></a>Item2Vec  Microsoft</h1><p><strong>ITEM2VEC: NEURAL ITEM EMBEDDING FOR COLLABORATIVE FILTERING</strong></p><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>The method is capable of inferring item-item relations even when user information is not available. </p><h2 id="INTRODUCTION-AND-RELATED-WORK"><a href="#INTRODUCTION-AND-RELATED-WORK" class="headerlink" title="INTRODUCTION AND RELATED WORK"></a>INTRODUCTION AND RELATED WORK</h2><p>many recommendation algorithms are focused on learning a low dimensional embedding of users and items simultaneously ,computing item similarities is an end in itself .</p><p>The single item recommendations are different than the more “traditional” user-to-item recommendations because they are usually shown in the context of an explicit user interest in a specific item and in the context of an explicit user intent to purchase. Therefore, single item recommendations based on item similarities often have higher Click-Through Rates (CTR) than user-to-item recommendations and consequently responsible for a larger share of sales or revenue. </p><p>item similarities are used in online stores for better exploration and discovery and improve the overall user experience. </p><h2 id="ITEM2VEC-–-SGNS-FOR-ITEM-SIMILARITY"><a href="#ITEM2VEC-–-SGNS-FOR-ITEM-SIMILARITY" class="headerlink" title="ITEM2VEC – SGNS FOR ITEM SIMILARITY"></a>ITEM2VEC – SGNS FOR ITEM SIMILARITY</h2><p>Since some scenarios could not provide information about multiple sets of items might belong to the same user .user-item CF may not work well.</p><p>By moving from sequences to sets, the spatial / time information is lost. We choose to discard this information, since in this paper, we assume a static environment where items that share the same set are considered similar, no matter in what order / time they were generated by the user. </p><p>Since we ignore the spatial information, we treat each pair of items that share the same set as a positive example. <strong>This implies a window size that is determined from the set size.</strong> 这里意思是在训练时，窗口不像w2v中是定长的，而是一个变长的窗口，根据一个订单中物品的大小来动态确定。Specifically, for a given set of items, the objective from Eq. (1) is modified as follows:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-18%20%E4%B8%8A%E5%8D%8810.09.42.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Another option is to keep the objective in w2v as is, and shuffle each set of items during runtime. In our experiments we observed that both options perform the same.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-18%20%E4%B8%8A%E5%8D%8810.10.49.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>In this work, we used u_i_ as the final representation for the i-th item and the affinity between a pair of items is computed by the cosine similarity. </p><h2 id="EXPERIMENTAL"><a href="#EXPERIMENTAL" class="headerlink" title="EXPERIMENTAL"></a>EXPERIMENTAL</h2><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>The first dataset is user-artist data that is retrieved from the Microsoft Xbox Music service. This dataset consist of 9M events. Each event consists of a <strong>user-artist</strong> relation, which means the user played a song by the specific artist. The dataset contains 732K users and 49K distinct artists. </p><p>The second dataset contains orders of products from Microsoft Store. An order is given by a basket of items without any information about the user that made it. Therefore, the information in this dataset is weaker in the sense that we <strong>cannot bind between users and items</strong>. The dataset consist of 379K orders (that contains more than a single item) and 1706 distinct items. </p><h3 id="Systems-and-parameters"><a href="#Systems-and-parameters" class="headerlink" title="Systems and parameters"></a>Systems and parameters</h3><p>We applied item2vec to both datasets. The optimization is done by stochastic gradient decent. We ran the algorithm for 20 epochs. We set the negative sampling value to N=15 for both datasets. The dimension parameter m was set to 100 and 40 for the Music and Store datasets, respectively. We further applied subsampling with ρ values of 10−5 and 10−3 to the Music and Store datasets, respectively. The reason we set different parameter values is due to different sizes of the datasets. </p><h2 id="论文解读"><a href="#论文解读" class="headerlink" title="论文解读"></a>论文解读</h2><p>一个物品集合被视作自然语言中的一个段落，物品集合的基本元素－物品等价于段落中的单词。因此在论文中，一个音乐物品集合是用户对某歌手歌曲的播放行为，一个商品集合是一个订单中包含的所有商品。</p><p>从自然语言序列迁移到物品集合，丢失了空间／时间信息，还无法对用户行为程度建模（喜欢和购买是不同程度的强行为）。好处是可以忽略用户－物品关系，即便获得的订单不包含用户信息，也可以生成物品集合。而论文的结论证明，在一些场景下序列信息的丢失是可忍受的。</p><h2 id="知乎上的实践思路"><a href="#知乎上的实践思路" class="headerlink" title="知乎上的实践思路"></a>知乎上的实践思路</h2><p><a href="https://zhuanlan.zhihu.com/p/28491088" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/28491088</a><br>爬取的训练数据是豆瓣网友的电影收藏夹（类比于网易云的歌单）。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/v2-4a91dea97a4b64bc2a72a28765188754_b.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>从结果中可以观察出一些有意思的结论。战狼2是最近刚出的电影(此文作于2017/08)，包含战狼2的大多是“暑期国产电影合集”，“2017年不得不看的国产电影“这类豆列；美国往事属于经典老片，训练语料足够多，skipgram和cbow的推荐结果各有千秋；小时代在豆瓣中属于不受待见的一类电影，包含小时代的豆列较少，skipgram的推荐结果优于cbow。</p><h1 id="Youtube"><a href="#Youtube" class="headerlink" title="Youtube"></a>Youtube</h1><p><strong>Deep Neural Networks for YouTube Recommendations</strong></p><h2 id="ABSTRACT-1"><a href="#ABSTRACT-1" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>Three major changllenging :(1)Scale,(2)Freshness,(3)Noise.</p><h2 id="SYSTEM-OVERVIEW"><a href="#SYSTEM-OVERVIEW" class="headerlink" title="SYSTEM OVERVIEW"></a>SYSTEM OVERVIEW</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-18%20%E4%B8%8B%E5%8D%881.48.07.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="CANDIDATE-GENERATION"><a href="#CANDIDATE-GENERATION" class="headerlink" title="CANDIDATE GENERATION"></a>CANDIDATE GENERATION</h2><p>During candidate generation, the enormous YouTube corpus is winnowed down to hundreds of videos that may be relevant to the user .</p><h3 id="Recommendation-as-Classification"><a href="#Recommendation-as-Classification" class="headerlink" title="Recommendation as Classification"></a>Recommendation as Classification</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-18%20%E4%B8%8B%E5%8D%882.03.50.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>compared to w2v<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/v2-4557472f61cfec30352942afea2b829b_hd.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>you can see Youtube have two embeddings.</p><p>Although explicit feedback mechanisms exist on YouTube (thumbs up/down, in-product surveys, etc.) <strong>They use the implicit feedback</strong>  of watches to train the model, where a user completing a video is a positive example. This choice is based on the orders of magnitude more implicit user history available, allowing They to produce recommendations deep in the tail where explicit feedback is extremely sparse. </p><h3 id="Efficient-Extreme-Multiclass"><a href="#Efficient-Extreme-Multiclass" class="headerlink" title="Efficient Extreme Multiclass"></a>Efficient Extreme Multiclass</h3><p>To efficiently train such a model with millions of classes, they rely on a technique to sample negative classes from the background distribution (“candidate sampling”) and then correct for this sampling via importance weighting ,For each example the cross-entropy loss is minimized for the true label and the sampled negative classes. </p><blockquote><p>negative sample?  </p></blockquote><p>In <strong>practice</strong> several thou- sand negatives are sampled, corresponding to more than <strong>100 times speedup</strong> over traditional softmax. </p><p>At serving time they need to compute the most likely N classes (videos) in order to choose the top N to present to the user. Scoring millions of items under a strict serving latency of tens of milliseconds requires an approximate scoring scheme sublinear in the number of classes. </p><p>The classifier described here uses a similar approach. the scoring problem reduces to <strong>a nearest neighbor search</strong> in the dot product space for which general purpose libraries can be used .</p><h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><p><strong>A user’s watch history</strong> is represented by a variable-length sequence of sparse <strong>video IDs</strong> which is mapped to a dense vector representation via the <strong>embeddings</strong>.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-18%20%E4%B8%8B%E5%8D%882.24.03.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h3 id="Heterogeneous-Signals"><a href="#Heterogeneous-Signals" class="headerlink" title="Heterogeneous Signals"></a>Heterogeneous Signals</h3><p>Search history is treated similarly to watch history - each query is tokenized into unigrams and bigrams and each token is embedded. Once averaged, the user’s tokenized, em- bedded queries represent a summarized dense search history. </p><p>Demographic features are important for providing priors so that the recommendations behave reasonably for new users. </p><p>The user’s geographic region and device are embedded and concatenated. Simple binary and continuous features such as the user’s gender, logged-in state and age are input directly into the network as real values normalized to [0, 1]. </p><p><strong>“Example Age” Feature</strong><br>Many hours worth of videos are uploaded each second to YouTube. Recommending this recently uploaded (“fresh”) content is extremely important for YouTube as a product. We consistently observe that users prefer fresh content, though not at the expense of relevance. </p><p>Machine learning systems often exhibit an implicit bias towards the past because they are trained to predict future behavior from historical examples. To correct for this, we feed the age of the training example as a feature during training.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-18%20%E4%B8%8B%E5%8D%882.39.10.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h3 id="Label-and-Context-Selection"><a href="#Label-and-Context-Selection" class="headerlink" title="Label and Context Selection"></a>Label and Context Selection</h3><h2 id="王喆知乎"><a href="#王喆知乎" class="headerlink" title="王喆知乎"></a>王喆知乎</h2><ul><li style="list-style: none"><input type="checkbox"> 除了文中的单独对embedding层进行训练，还可以加上一个embedding层后跟DNN一起训练。优劣？</li></ul><p>本文字字珠玑适合之后细读。</p><h1 id="Airbnb"><a href="#Airbnb" class="headerlink" title="Airbnb"></a>Airbnb</h1><p><strong>Real-time Personalization using Embeddings for Search Ranking at Airbnb</strong> </p><h2 id="ABSTRACT-2"><a href="#ABSTRACT-2" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>capture guest’s short-term and long-term interests, delivering effective home listing recommendations. </p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>Since guests typically conduct multiple searches before booking, i.e. click on more than one listing and contact more than one host during their search session, we can use these in-session signals, i.e. clicks, host contacts, etc. for Real-time Personalization where the aim is to show to the guest more of the listings similar to the ones we think they liked since staring the search session. </p><p>At the same time we can use the negative signal, e.g. skips of high ranked listings, to show to the guest less of the listings similar to the ones we think<br>they did not like .</p><p>use <strong>listing embeddings</strong>, low-dimensional vector representations learned from search sessions. </p><p>In addition to Real-time Personalization using immediate user actions, such as clicks, that can be used as proxy signal for <strong>short- term user interest,</strong> we introduce another type of embeddings trained on bookings to be able to capture user’s <strong>long-term interest</strong>. </p><p>Due to the nature of travel business, where users travel 1-2 times per year on average, bookings are a sparse signal, with a long tail of users with a single booking. To tackle this we propose to train embeddings at a level of user type, instead of a particular user id, where type is determined using many-to-one rule-based mapping that leverages known user attributes. </p><p>At the same time we learn listing type embeddings in the same vector space as user type embeddings. This enables us to calculate similarities between user type embedding of the user who is conducting a search and listing type embeddings of candidate listings that need to be ranked. </p><p>For short-term interest personalization they trained listing embeddings using more than 800 million search clicks sessions, resulting in high quality listing representations. </p><p>For long-term interest personalization we trained user type and listing type embeddings using sequences of booked listings by 50 million users. Both user and listing type embeddings were learned in the same vector space, such that we can calculate similarities between user type and listing types of listings that need to be ranked. </p><h2 id="王喆知乎-1"><a href="#王喆知乎-1" class="headerlink" title="王喆知乎"></a>王喆知乎</h2><p>具体到embedding上，文章通过两种方式生成了两种不同的embedding分别capture用户的short term和long term的兴趣。</p><ol><li>一是通过click session数据生成listing的embedding，生成这个embedding的目的是为了进行listing的相似推荐，以及对用户进行session内的实时个性化推荐。</li><li>二是通过booking session生成user-type和listing-type的embedding，目的是捕捉不同user-type的long term喜好。由于booking signal过于稀疏，Airbnb对同属性的user和listing进行了聚合，形成了user-type和listing-type这两个embedding的对象。</li></ol><p>第一个对listing进行embedding的方法：<br>Airbnb采用了click session数据对listing进行embedding，其中click session指的是一个用户在一次搜索过程中，点击的listing的序列，这个序列需要满足两个条件，一个是只有停留时间超过30s的listing page才被算作序列中的一个数据点，二是如果用户超过30分钟没有动作，那么这个序列会断掉，不再是一个序列。这么做的目的无可厚非，一是清洗噪声点和负反馈信号，二是避免非相关序列的产生。</p><p>有了由clicked listings组成的sequence，我们可以把这个sequence当作一个“句子”样本，开始embedding的过程。Airbnb不出意外的选择了word2vec的skip-gram model作为embedding方法的框架。通过修改word2vec的objective使其靠近Airbnb的业务目标。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/v2-98bd1b08041a3f247c184b1a2207c044_hd.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>正样本很自然的取自click session sliding window里的两个listing，负样本则是在确定central listing后随机从语料库（这里就是listing的集合）中选取一个listing作为负样本。</p><p>因此，Airbnb初始的objective function几乎与word2vec的objective一模一样。</p><p>在原始word2vec embedding的基础上，针对其业务特点，Airbnb的工程师希望能够把booking的信息引入embedding。这样直观上可以使Airbnb的搜索列表和similar item列表中更倾向于推荐之前booking成功session中的listing。从这个motivation出发，Airbnb把click session分成两类，最终产生booking行为的叫booked session，没有的称做exploratory session。</p><p>文章多介绍了一下cold start的问题。简言之，如果有new listing缺失embedding vector，就找附近的3个同样类型、相似价格的listing embedding进行平均得到，不失为一个实用的工程经验。</p><p>embedding不仅encode了price，listing-type等信息，甚至连listing的风格信息都能抓住，说明即使我们不利用图片信息，也能从用户的click session中挖掘出相似风格的listing。</p><p>为了捕捉用户的长期偏好，airbnb在这里使用了booking session序列。比如用户j在过去1年依次book过5个listing。既然有了booking session的集合，我们是否可以像之前对待click session一样拿直接应用w2v的方法得到embedding呢？答案是否定的，因为我们会遇到非常棘手的数据稀疏问题。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/RS%20Embedding%20Papers/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-18%20%E4%B8%8B%E5%8D%883.32.53.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>具体来讲booking session的数据稀疏问题表现在下面三点上：</p><ol><li>book行为的总体数量本身就远远小于click的行为，所以booking session集合的大小是远远小于click session的</li><li>单一用户的book行为很少，大量用户在过去一年甚至只book过一个房源，这导致很多booking session sequence的长度为1</li><li>大部分listing被book的次数也少的可怜，大家知道w2v要训练出较稳定有意义的embedding，item最少需要出现5-10次，但大量listing的book次数少于5次，根本无法得到有效的embedding。</li></ol><p>Airbnb如何解决如此严重的数据稀疏问题，训练出有意义的user embedding和listing embedding呢？他们给出的答案是基于某些属性规则做相似user和相似listing的聚合。</p><p>可以之后再细读。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Item2Vec-Microsoft&quot;&gt;&lt;a href=&quot;#Item2Vec-Microsoft&quot; class=&quot;headerlink&quot; title=&quot;Item2Vec  Microsoft&quot;&gt;&lt;/a&gt;Item2Vec  Microsoft&lt;/h1&gt;&lt;p&gt;&lt;str
      
    
    </summary>
    
      <category term="论文" scheme="https://github.com/zdkswd/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch get started</title>
    <link href="https://github.com/zdkswd/2019/04/17/PyTorch%20get%20started/"/>
    <id>https://github.com/zdkswd/2019/04/17/PyTorch get started/</id>
    <published>2019-04-17T12:04:47.000Z</published>
    <updated>2019-04-17T12:05:51.964Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h1><p>Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.04.33.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Construct a 5x3 matrix, uninitialized:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.04.46.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Construct a randomly initialized matrix:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.05.13.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Construct a matrix filled zeros and of dtype long:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.05.25.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Construct a tensor directly from data:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.06.00.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>or create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.07.08.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Get its size:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.15.15.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><strong>Note:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.32.30.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h1><p>Addition: syntax 1<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.33.06.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Addition: syntax 2<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.33.26.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Addition: providing an output tensor as argument<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.34.20.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Addition: in-place<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.35.28.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><strong>Note:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.36.19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>You can use standard NumPy-like indexing<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.36.52.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Resizing: If you want to resize/reshape tensor, you can use torch.view:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.39.51.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Out:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.40.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>If you have a one element tensor, use .item() to get the value as a Python number<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.40.24.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Numpy-Bridge"><a href="#Numpy-Bridge" class="headerlink" title="Numpy Bridge"></a>Numpy Bridge</h1><p>The Torch Tensor and NumPy array will share their underlying memory locations, and changing one will change the other.</p><h2 id="Converting-a-Torch-Tensor-to-a-NumPy-Array"><a href="#Converting-a-Torch-Tensor-to-a-NumPy-Array" class="headerlink" title="Converting a Torch Tensor to a NumPy Array"></a>Converting a Torch Tensor to a NumPy Array</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.42.30.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.42.42.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.42.37.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.43.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.43.18.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>Out:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.43.41.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="Converting-NumPy-Array-to-Torch-Tensor"><a href="#Converting-NumPy-Array-to-Torch-Tensor" class="headerlink" title="Converting NumPy Array to Torch Tensor"></a>Converting NumPy Array to Torch Tensor</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.44.25.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>out:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%886.44.38.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>All the Tensors on the CPU except a CharTensor support converting to NumPy and back.</p><h1 id="CUDA-Tensors"><a href="#CUDA-Tensors" class="headerlink" title="CUDA Tensors"></a>CUDA Tensors</h1><p>Tensors can be moved onto any device using the .to method.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%887.43.19.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>out:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%887.46.16.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="examples"><a href="#examples" class="headerlink" title="examples"></a>examples</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%887.58.55.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%887.59.10.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="PyTorch-Custom-nn-Modules"><a href="#PyTorch-Custom-nn-Modules" class="headerlink" title="PyTorch: Custom nn Modules"></a>PyTorch: Custom nn Modules</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%888.01.01.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/PyTorch%20get%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%888.01.17.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Tensors&quot;&gt;&lt;a href=&quot;#Tensors&quot; class=&quot;headerlink&quot; title=&quot;Tensors&quot;&gt;&lt;/a&gt;Tensors&lt;/h1&gt;&lt;p&gt;Tensors are similar to NumPy’s ndarrays, with the 
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>tx往届心得</title>
    <link href="https://github.com/zdkswd/2019/04/17/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/"/>
    <id>https://github.com/zdkswd/2019/04/17/tx往届心得/</id>
    <published>2019-04-17T08:49:47.000Z</published>
    <updated>2019-04-17T02:57:36.841Z</updated>
    
    <content type="html"><![CDATA[<h1 id="stacking技术分享"><a href="#stacking技术分享" class="headerlink" title="stacking技术分享"></a>stacking技术分享</h1><p>stacking不能称为一种算法，而是一种对模型的集成策略。在给定数据集的情况下，数据内部的空间结构和数据之间的关系是非常复杂得。不同的模型，其实很重要的一点就是在不同的角度去观测数据集。stacking框架就是用来取长补短进行结合的。</p><p>假设是五折的stacking，我们有一个train数据集和一个test数据集，那么一个基本的stacking框架会进行如下几个操作：</p><ol><li>选择基模型。我们可以有xgboost，lightGBM，RandomForest，SVM，ANN，KNN，LR等等你能想到的各种基本算法模型。</li><li>把训练集分为不交叉的五份。我们标记为train1到train5。</li><li>从train1开始作为预测集，使用train2到train5建模，然后预测train1，并保留结果；然后，以train2作为预测集，使用train1，train3到train5建模，预测train2，并保留结果；如此进行下去，直到把train1到train5各预测一遍；</li><li>把预测的结果按照train1到trian5的位置对应填补上，得到对train整个数据集在第一个基模型的一个stacking转换。</li><li>在上述建立的五个模型过程中，每个模型分别对test数据集进行预测，并最终保留这五列结果，然后对这五列取平均，作为第一个基模型对test数据的一个stacking转换。</li><li>选择第二个基模型，重复以上2-5操作，再次得到train整个数据集在第二个基模型的一个stacking转换。</li><li>以此类推。有几个基模型，就会对整个train数据集生成几列新的特征表达。同样，也会对test有几列新的特征表达。</li><li>一般使用LR作为第二层的模型进行建模预测。</li></ol><p><img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.32.08.png" alt=""><br>上面这个框架说明的是：对训练数据进行无重复的五次划分之后，分别对其中每一部分进行一次预测，而预测的模型就是由其余四部分训练的；并且在预测了预测集之后，还需要对我们的test数据集也进行一次预测，这这样就会得到5个N/5行、1列的对train数据集的特征转换，和5个M行、1列的对test数据集的特征转换，由此进入下一个图。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-02%20%E4%B8%8B%E5%8D%881.33.39.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>1.stacking的框架设计比较复杂，对于一个基模型要训练5次，如果你的一个xgb模型要训练2个小时，即使在进行stacking的时候每折减少了五分之一的数据量，你的计算时间仍然是很可观的，加起来应该还是8-9小时，所以耗费时间很长（想像一下一个stacking框架跑一个基模型要大半天，简直太可怕）。所以建议大家在使用的时候要计算时间的耗费，或者可以改为3折，4折等等；</p><p>2、我们前面讲过了，stacking框架是集成了不同的算法，充分利用不同算法从不同的数据空间角度和数据结构角度的对数据的不同观测，来取长补短，优化结果。所以，我们的基模型除了是不同参数的相同模型之外，比如不同参数的xgboost，或者不同K值的KNN等等；更重要的是要尽可能的多加一些不同种类的基模型进去，也就是说所谓的模型要“跨越空间”的概念。这样的话我们的集成结果会更加稳健，更加精确。（曾经有一个比赛集成了上百个基模型的stacking框架获奖）</p><h2 id="基本变种改进"><a href="#基本变种改进" class="headerlink" title="基本变种改进"></a>基本变种改进</h2><p>在变种改进方面，我们可以不仅对模型进行融合，还可以对特征级进行一些变化，比如选部分特征做stacking；或者对stacking的结果进行再次的stacking，上面介绍的是两层的stacking，可以有3层，或者更多。但是时间复杂度很高，效果并不一定明显。</p><h1 id="Kaggle数据挖掘比赛经验分享"><a href="#Kaggle数据挖掘比赛经验分享" class="headerlink" title="Kaggle数据挖掘比赛经验分享"></a>Kaggle数据挖掘比赛经验分享</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzIzMzgzOTUxNA==&amp;mid=2247483678&amp;idx=1&amp;sn=5f044dabfaa726e292686287a1dd5ca4&amp;chksm=e8fecfebdf8946fdabf71fd5c4c0e019144f105da993c12fa257c64f281ecfb3a7557f16b79e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">【干货】Kaggle 数据挖掘比赛经验分享</a><br>一个完整的数据挖掘比赛基本流程如下：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/640.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><p>通过对数据进行探索性分析（甚至有些情况下需要肉眼观察样本），还可以有助于启发数据清洗和特征抽取，譬如缺失值和异常值的处理，文本数据是否需要进行拼写纠正等。</p><h3 id="分析特征变量的分布"><a href="#分析特征变量的分布" class="headerlink" title="分析特征变量的分布"></a>分析特征变量的分布</h3><ol><li><strong>特征变量</strong>为连续值：如果为长尾分布并且考虑使用线性模型，可以对变量进行幂变换或者对数变换。</li><li><strong>特征变量</strong>为离散值：观察每个离散值的频率分布，对于频次较低的特征，可以考虑统一编码为“其他”类别。</li></ol><h3 id="分析目标变量的分布"><a href="#分析目标变量的分布" class="headerlink" title="分析目标变量的分布"></a>分析目标变量的分布</h3><ol><li><strong>目标变量</strong>为连续值：查看其值域范围是否较大，如果较大，可以考虑对其进行对数变换，并以变换后的值作为新的目标变量进行建模（<strong>在这种情况下，需要对预测结果进行逆变换</strong>）。一般情况下，可以对连续变量进行<strong>Box-Cox</strong>变换。通过变换可以使得模型更好的优化，通常也会带来效果上的提升。</li><li><strong>目标变量</strong>为离散值：如果数据分布不平衡，考虑是否需要上采样/下采样；如果目标变量在某个ID上面分布不平衡，在划分本地训练集和验证集的时候，需要考虑<strong>分层采样（Stratified Sampling）</strong>。</li></ol><h3 id="分析变量之间两两的分布和相关度"><a href="#分析变量之间两两的分布和相关度" class="headerlink" title="分析变量之间两两的分布和相关度"></a>分析变量之间两两的分布和相关度</h3><ol><li>可以用于发现高相关和共线性的特征。</li></ol><h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><p>数据清洗是指对提供的原始数据进行一定的加工，使得其方便后续的特征抽取。其与特征抽取的界限有时也没有那么明确。常用的数据清洗一般包括：</p><h3 id="数据的拼接"><a href="#数据的拼接" class="headerlink" title="数据的拼接"></a>数据的拼接</h3><ol><li>提供的数据散落在多个文件，需要根据相应的键值进行数据的拼接。</li></ol><h3 id="特征缺失值的处理"><a href="#特征缺失值的处理" class="headerlink" title="特征缺失值的处理"></a>特征缺失值的处理</h3><ol><li>特征值为连续值：按不同的分布类型对缺失值进行补全：<strong>偏正态分布</strong>，使用均值代替，可以保持数据的均值；<strong>偏长尾分布</strong>，使用中值代替，避免受 outlier 的影响；</li><li>特征值为离散值：使用众数代替。</li></ol><h3 id="文本数据的清洗"><a href="#文本数据的清洗" class="headerlink" title="文本数据的清洗"></a>文本数据的清洗</h3><ol><li>在比赛当中，如果数据包含文本，往往需要进行大量的数据清洗工作。如去除HTML 标签，分词，拼写纠正, 同义词替换，去除停词，抽词干，数字和单位格式统一等。</li></ol><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>有一种说法是，特征决定了效果的上限，而不同模型只是以不同的方式或不同的程度来逼近这个上限。这样来看，好的特征输入对于模型的效果至关重要，正所谓”Garbage in, garbage out”。要做好特征工程，往往跟领域知识和对问题的理解程度有很大的关系，也跟一个人的经验相关。特征工程的做法也是Case by Case，以下就一些点，谈谈自己的一些看法。</p><h3 id="特征变换"><a href="#特征变换" class="headerlink" title="特征变换"></a>特征变换</h3><p>主要针对一些长尾分布的特征，<strong>需要进行幂变换或者对数变换，使得模型（LR或者DNN）能更好的优化</strong>。需要注意的是，Random Forest 和 GBDT 等模型对单调的函数变换不敏感。其原因在于树模型在求解分裂点的时候，只考虑排序分位点。</p><h3 id="特征编码"><a href="#特征编码" class="headerlink" title="特征编码"></a>特征编码</h3><p>对于离散的类别特征，往往需要进行必要的特征转换/编码才能将其作为特征输入到模型中。常用的编码方式有 LabelEncoder，OneHotEncoder（sklearn里面的接口）。譬如对于”性别”这个特征（取值为男性和女性），使用这两种方式可以分别编码为{0,1}和{[1,0], [0,1]}。</p><p>对于取值较多（如几十万）的类别特征（ID特征），直接进行OneHotEncoder编码会导致特征矩阵非常巨大，影响模型效果。可以使用如下的方式进行处理：<br>◆ 统计每个取值在样本中出现的频率，取 Top N 的取值进行 One-hot 编码，剩下的类别分到“其他“类目下，其中 N 需要根据模型效果进行调优；<br>◆ 统计每个 ID 特征的一些统计量（譬如历史平均点击率，历史平均浏览率）等代替该 ID 取值作为特征，具体可以参考 Avazu 点击率预估比赛第二名的获奖方案；<br>◆ 参考 word2vec 的方式，将每个类别特征的取值映射到一个连续的向量，对这个向量进行初始化，跟模型一起训练。训练结束后，可以同时得到每个ID的Embedding。具体的使用方式，可以参考 Rossmann 销量预估竞赛第三名的获奖方案，<a href="https://github.com/entron/entity-embedding-rossmann。">https://github.com/entron/entity-embedding-rossmann。</a></p><p>对于 Random Forest 和 GBDT 等模型，如果类别特征存在较多的取值，可以直接使用 LabelEncoder 后的结果作为特征（这里应该只是将数字来代替类别，数字并不具有实际含义）。注意labelEncoder将文字变换为数字，是虚拟数据，不一定有意义，建模时要注意去除。</p><h2 id="模型训练和验证"><a href="#模型训练和验证" class="headerlink" title="模型训练和验证"></a>模型训练和验证</h2><h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><p>在处理好特征后，我们可以进行模型的训练和验证。<br>◆ 对于稀疏型特征（如文本特征，One-hot的ID类特征），我们一般使用线性模型，譬如 Linear Regression 或者 Logistic Regression。Random Forest 和 GBDT 等树模型不太适用于稀疏的特征，但可以先对特征进行降维（如PCA，SVD/LSA等），再使用这些特征。稀疏特征直接输入 DNN 会导致网络 weight 较多，不利于优化，也可以考虑先降维，或者对 ID 类特征使用 Embedding 的方式；<br>◆ 对于稠密型特征，推荐使用 XGBoost 进行建模，简单易用效果好；<br>◆ 数据中既有稀疏特征，又有稠密特征，可以考虑使用线性模型对稀疏特征进行建模，将其输出与稠密特征一起再输入 XGBoost/DNN 建模，具体可以参考Stacking 部分。</p><h3 id="调参和模型验证"><a href="#调参和模型验证" class="headerlink" title="调参和模型验证"></a>调参和模型验证</h3><p>对于选定的特征和模型，我们往往还需要对模型进行超参数的调优，才能获得比较理想的效果。调参一般可以概括为以下三个步骤：</p><p>1.<strong>训练集和验证集的划分。</strong>根据比赛提供的训练集和测试集，模拟其划分方式对训练集进行划分为本地训练集和本地验证集。划分的方式视具体比赛和数据而定，常用的方式有：<br>a) 随机划分：譬如随机采样 70% 作为训练集，剩余的 30% 作为测试集。在这种情况下，本地可以采用 KFold 或者 Stratified KFold 的方法来构造训练集和验证集。<br>b) 按时间划分：一般对应于时序序列数据，譬如取前 7 天数据作为训练集，后 1 天数据作为测试集。这种情况下，划分本地训练集和验证集也需要按时间先后划分。常见的错误方式是随机划分，这种划分方式可能会导致模型效果被高估。<br>c) 按某些规则划分：在 HomeDepot 搜索相关性比赛中，训练集和测试集中的 Query 集合并非完全重合，两者只有部分交集。而在另外一个相似的比赛中（CrowdFlower 搜索相关性比赛），训练集和测试集具有完全一致的 Query 集合。对于 HomeDepot 这个比赛中，训练集和验证集数据的划分，需要考虑 Query 集合并非完全重合这个情况，其中的一种方法可以参考第三名的获奖方案，<a href="https://github.com/ChenglongChen/Kaggle_HomeDepot。">https://github.com/ChenglongChen/Kaggle_HomeDepot。</a></p><p>2.<strong>指定参数空间</strong>。在指定参数空间的时候，需要对模型参数以及其如何影响模型的效果有一定的了解，才能指定出合理的参数空间。譬如DNN或者XGBoost中学习率这个参数，一般就选 0.01 左右就 OK 了（太大可能会导致优化算法错过最优化点，太小导致优化收敛过慢）。再如 Random Forest，一般设定树的棵数范围为 100~200 就能有不错的效果，当然也有人固定数棵数为 500，然后只调整其他的超参数。</p><p>3.<strong>按照一定的方法进行参数搜索</strong>。常用的参数搜索方法有，Grid Search，Random Search以及一些自动化的方法（如 Hyperopt）。其中，Hyperopt 的方法，根据历史已经评估过的参数组合的效果，来推测本次评估使用哪个参数组合更有可能获得更好的效果。</p><h3 id="适当利用-Public-LB-的反馈"><a href="#适当利用-Public-LB-的反馈" class="headerlink" title="适当利用 Public LB 的反馈"></a>适当利用 Public LB 的反馈</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%8810.30.48.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="模型集成"><a href="#模型集成" class="headerlink" title="模型集成"></a>模型集成</h2><h3 id="Averaging-和-Voting"><a href="#Averaging-和-Voting" class="headerlink" title="Averaging 和 Voting"></a>Averaging 和 Voting</h3><p>直接对多个模型的预测结果求平均或者投票。对于目标变量为连续值的任务，使用平均；对于目标变量为离散值的任务，使用投票的方式。</p><h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/tx%E5%BE%80%E5%B1%8A%E5%BF%83%E5%BE%97/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%8810.32.33.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><ol><li><strong>数据集划分</strong>。将训练数据按照5-Fold进行划分（如果数据跟时间有关，需要按时间划分）</li><li><strong>基础模型训练 I</strong>。按照交叉验证（Cross Validation）的方法，在训练集（Training Fold）上面训练模型（如图灰色部分所示），并在验证集（Validation Fold）上面做预测，得到预测结果（如图黄色部分所示）。最后综合得到整个训练集上面的预测结果（如图第一个黄色部分的CV Prediction所示）。</li><li><strong>基础模型训练 II</strong>（如图5第二和三行左半部分所示）。在全量的训练集上训练模型（如图第二行灰色部分所示），并在测试集上面做预测，得到预测结果（如图第三行虚线后绿色部分所示）。</li><li><strong>Stage 1 模型集成训练 I</strong>（如图5第一行右半部分所示）。将步骤 2 中得到的 CV Prediction 当作新的训练集，按照步骤 2 可以得到 Stage 1模型集成的 CV Prediction。</li><li>Stage 1 模型集成训练 II（如图5第二和三行右半部分所示）。将步骤 2 中得到的 CV Prediction 当作新的训练集和步骤 3 中得到的 Prediction 当作新的测试集，按照步骤 3 可以得到 Stage 1 模型集成的测试集 Prediction。此为 Stage 1 的输出，可以提交至 Kaggle 验证其效果。</li></ol><p>在图5中，基础模型只展示了一个，而实际应用中，基础模型可以多种多样，如SVM，DNN，XGBoost 等。也可以相同的模型，不同的参数，或者不同的样本权重。重复4和5两个步骤，可以相继叠加 Stage 2, Stage 3 等模型。</p><h3 id="Blending"><a href="#Blending" class="headerlink" title="Blending"></a>Blending</h3><p>Blending 与 Stacking 类似，但单独留出一部分数据（如 20%）用于训练 Stage X 模型。</p><h3 id="Bagging-Ensemble-Selection"><a href="#Bagging-Ensemble-Selection" class="headerlink" title="Bagging Ensemble Selection"></a>Bagging Ensemble Selection</h3><p>Bagging Ensemble Selection [5] 是我在 CrowdFlower 搜索相关性比赛中使用的方法，其主要的优点在于可以以优化任意的指标来进行模型集成。这些指标可以是可导的（如 LogLoss 等）和不可导的（如正确率，AUC，Quadratic Weighted Kappa等）。它是一个前向贪婪算法，存在过拟合的可能性，作者在文献 [5] 中提出了一系列的方法（如 Bagging）来降低这种风险，稳定集成模型的性能。使用这个方法，需要有成百上千的基础模型。为此，在 CrowdFlower 的比赛中，我把在调参过程中所有的中间模型以及相应的预测结果保留下来，作为基础模型。这样做的好处是，不仅仅能够找到最优的单模型（Best Single Model），而且所有的中间模型还可以参与模型集成，进一步提升效果。</p><h2 id="自动化框架"><a href="#自动化框架" class="headerlink" title="自动化框架"></a>自动化框架</h2><p>这份代码开源在 Github 上面，目前是 Github 有关 Kaggle 竞赛解决方案的 Most Stars，地址：<a href="https://github.com/ChenglongChen/Kaggle_CrowdFlower。">https://github.com/ChenglongChen/Kaggle_CrowdFlower。</a></p><p>其主要包含以下部分：</p><p>1.模块化特征工程<br>a) 接口统一，只需写少量的代码就能够生成新的特征；<br>b) 自动将单独的特征拼接成特征矩阵。</p><p>2.自动化模型调参和验证<br>a) 自定义训练集和验证集的划分方法；<br>b) 使用 Grid Search / Hyperopt 等方法，对特定的模型在指定的参数空间进行调优，并记录最佳的模型参数以及相应的性能。</p><p>3.自动化模型集成<br>a) 对于指定的基础模型，按照一定的方法（如Averaging_Stacking_Blending 等）生成集成模型。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;stacking技术分享&quot;&gt;&lt;a href=&quot;#stacking技术分享&quot; class=&quot;headerlink&quot; title=&quot;stacking技术分享&quot;&gt;&lt;/a&gt;stacking技术分享&lt;/h1&gt;&lt;p&gt;stacking不能称为一种算法，而是一种对模型的集成策略。
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM Python quick start</title>
    <link href="https://github.com/zdkswd/2019/04/17/LightGBM%20Python%20quick%20start/"/>
    <id>https://github.com/zdkswd/2019/04/17/LightGBM Python quick start/</id>
    <published>2019-04-17T06:00:32.000Z</published>
    <updated>2019-04-17T06:00:16.594Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LightGBM-Python-quick-start"><a href="#LightGBM-Python-quick-start" class="headerlink" title="LightGBM Python quick start"></a>LightGBM Python quick start</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.00.51.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="Data-Interface"><a href="#Data-Interface" class="headerlink" title="Data Interface"></a>Data Interface</h1><p>The LightGBM Python module can load data from:</p><p>1.libsvm/ tsv / csv / txt format file<br>2.NumPy 2D array(s), pandas DataFrame, H2O DataTable’s Frame, SciPy sparse matrix<br>3.LightGBM binary file</p><p>The data is stored in a <strong>Dataset</strong> object.</p><p><strong>To load a libsvm text file or a LightGBM binary file into Dataset:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.02.58.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>To load a numpy array into Dataset:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.02.47.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>Saving Dataset into a LightGBM binary file will make loading faster:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.03.46.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>Create validation data:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.05.34.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>or<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.06.14.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>In LightGBM, the validation data should be aligned with training data.</p><p><strong>Specific feature names and categorical features:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.22.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>LightGBM can use categorical features as input directly. It doesn’t need to convert to one-hot coding, and is much faster than one-hot coding (about 8x speed-up).</p><p><strong>Note</strong>: You should convert your categorical features to <strong>int</strong> type before you construct <strong>Dataset</strong>.</p><p><strong>Weights can be set when needed:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.22.53.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>or<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.23.06.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>And you can use <strong>Dataset.set_init_score()</strong> to set initial score, and <strong>Dataset.set_group()</strong> to set group/query data for ranking tasks.</p><p><strong>Memory efficient usage:</strong><br>The <strong>Dataset</strong> object in LightGBM is very memory-efficient, it only needs to save discrete bins. However, Numpy / Array / Pandas object is memory expensive. If you are concerned about your memory consumption, you can save memory by:</p><ol><li>Set <strong>free_raw_data=True</strong> (default is <strong>True</strong>) when constructing the <strong>Dataset</strong></li><li>Explicitly set <strong>raw_data=None</strong> after the <strong>Dataset</strong> has been constructed</li><li>Call <strong>gc</strong></li></ol><h1 id="Setting-Parameters"><a href="#Setting-Parameters" class="headerlink" title="Setting Parameters"></a>Setting Parameters</h1><p>LightGBM can use either a list of pairs or a dictionary to set <strong>Parameters</strong>. For instance:<br><strong>Booster parameters</strong>:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.56.05.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.27.59.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p><strong>You can also specify multiple eval metrics:</strong><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.28.16.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><p>Training a model requires a parameter list and data set:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.29.43.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>After training, the model can be saved:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.30.14.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>The trained model can also be dumped to JSON format:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.31.17.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>A saved model can be loaded:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.31.36.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h1><p>Training with 5-fold CV:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.33.58.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h1><p>If you have a validation set, you can use early stopping to find the optimal number of boosting rounds. Early stopping requires at least one set in <strong>valid_sets</strong>. If there is more than one, it will use all of them except the training data:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.35.00.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>The model will train until the validation score stops improving. Validation score needs to improve at least every <strong>early_stopping_rounds</strong> to continue training.</p><p>The index of iteration that has the best performance will be saved in the <strong>best_iteration</strong> field if early stopping logic is enabled by setting <strong>early_stopping_rounds</strong>. Note that <strong>train()</strong> will return a model from the best iteration.</p><p>This works with both metrics to minimize (L2, log loss, etc.) and to maximize (NDCG, AUC, etc.). Note that if you specify more than one evaluation metric, all of them will be used for early stopping. However, you can change this behavior and make LightGBM check only the first metric for early stopping by creating <strong>early_stopping</strong> callback with <strong>first_metric_only=True</strong>.</p><h1 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h1><p>A model that has been trained or loaded can perform predictions on datasets:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.51.55.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>If early stopping is enabled during training, you can get predictions from the best iteration with <strong>bst.best_iteration</strong>:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/LightGBM%20Python%20quick%20start/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8B%E5%8D%881.52.37.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;LightGBM-Python-quick-start&quot;&gt;&lt;a href=&quot;#LightGBM-Python-quick-start&quot; class=&quot;headerlink&quot; title=&quot;LightGBM Python quick start&quot;&gt;&lt;/a&gt;Light
      
    
    </summary>
    
      <category term="教程" scheme="https://github.com/zdkswd/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>word2vec</title>
    <link href="https://github.com/zdkswd/2019/04/17/word2vec/"/>
    <id>https://github.com/zdkswd/2019/04/17/word2vec/</id>
    <published>2019-04-17T01:55:47.000Z</published>
    <updated>2019-04-17T01:56:26.837Z</updated>
    
    <content type="html"><![CDATA[<h1 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h1><p>谷歌2013年提出的word2vec是目前最常用的词嵌入模型之一。Word2ec实际是一种<strong>浅层的神经网络模型</strong>,它有两种网络结构,分别是CBOW( Continues Bag      of words)和 Skip-gram。</p><h1 id="百面-Word2Vec"><a href="#百面-Word2Vec" class="headerlink" title="百面  Word2Vec"></a>百面  Word2Vec</h1><h2 id="问-Word2Vec是如何工作的？"><a href="#问-Word2Vec是如何工作的？" class="headerlink" title="问  Word2Vec是如何工作的？"></a>问  Word2Vec是如何工作的？</h2><p>答：CBOW的目标是根据上下文出现的词语来预测当前词的生成概率，如图1.3 (a) 所示;而Skip-gram是根据当前词来预测上下文中各词的生成概率，如图1.3 (b)所示。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-26%20%E4%B8%8B%E5%8D%884.54.01.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中w(t)是当前所关注的词，w(t-2)、 w(t-1)、 w(t+1)、 w(t+2)是 上下文中出现的词。这里前后滑动窗口大小均设为2。</p><p>CBOW和Skip-gram都可以表示成由输入层(Input)、映射层(Projection)和输出层(Output)组成的神经网络。</p><p>输入层中的每个词由独热编码方式表示,即所有词均表示成一个N维向量,其中N为词汇表中单词的总数。在向量中,每个词都将与之对应的维度置为1,其余维度的值均设为0。</p><p>在映射层(又称隐含层)中,K个隐含单元( Hidden units)的取值可以由N维输入向量以及连接输入和隐含单元之间的N乘K维权重矩阵计算得到。在CBOV中,还需要将各个输入词所计算出的隐含单元求和。补一个其他博客的图。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/20180113213325970.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/20180113212531373.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>同理，输出层向量的值可以通过隐含层向量(K维)，以及连接隐含层和输出层之间的KxN维权重矩阵计算得到。输出层也是一个N维向量，每维与词汇表中的一个单词相对应。最后，对输出层向量应用Softmax激活函数，可以计算出每个单词的生成概率。Softmax激活函数的定义为：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-26%20%E4%B8%8B%E5%8D%886.21.23.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>其中x代表N维的原始输出向量,xn为在原始输出向量中，与单词wn所对应维度的取值。</p><p>接下来的任务就是训练神经网络的权重,使得语料库中所有单词的整体生成概率最大化。从输入层到隐含层需要一个维度为NxK的权重矩阵，从隐含层到输出层又需要一个维度为KxN的权重矩阵，学习权重可以用反向传播算法实现，每次迭代时将权重沿梯度更优的方向进行一小步更新。但是由于Softmax激活函数中存在归一化项的缘故，推导出来的迭代公式需要对词汇表中的所有单词进行遍历，使得每次迭代过程非常缓慢，由此产生了Hierarchical Softmax和Negative Sampling两种改进方法。训练得到维度为NxK和KxN的两个权重矩阵之后，可以选择其中一个作为N个词的K维向量表示。</p><h1 id="王喆-知乎"><a href="#王喆-知乎" class="headerlink" title="王喆 知乎"></a>王喆 知乎</h1><p><a href="https://zhuanlan.zhihu.com/p/53194407" target="_blank" rel="noopener">万物皆Embedding，从经典的word2vec到深度学习基本操作item2vec - 知乎</a><br><strong>万物皆Embedding，从经典的word2vec到深度学习基本操作item2vec</strong></p><h2 id="什么是embedding？"><a href="#什么是embedding？" class="headerlink" title="什么是embedding？"></a>什么是embedding？</h2><p>简单来说，embedding就是用一个低维的向量表示一个物体，可以是一个词，或是一个商品，或是一个电影等等。这个<strong>embedding向量的性质是能使距离相近的向量对应的物体有相近的含义</strong>，比如 Embedding(复仇者联盟)和Embedding(钢铁侠)之间的距离就会很接近，但 Embedding(复仇者联盟)和Embedding(乱世佳人)的距离就会远一些。</p><p>除此之外Embedding<strong>甚至还具有数学运算</strong>的关系，比如Embedding（马德里）-Embedding（西班牙）+Embedding(法国)≈Embedding(巴黎)</p><p>从另外一个空间表达物体，甚至揭示了物体间的潜在关系，从某种意义上来说，Embedding方法甚至具备了一些本体论的哲学意义。</p><h2 id="为什么说embedding是深度学习的基本操作？"><a href="#为什么说embedding是深度学习的基本操作？" class="headerlink" title="为什么说embedding是深度学习的基本操作？"></a>为什么说embedding是深度学习的基本操作？</h2><p>Embedding能够用低维向量对物体进行编码还能保留其含义的特点非常适合深度学习。在传统机器学习模型构建过程中，经常使用one hot encoding对离散特征，特别是id类特征进行编码，但由于one hot encoding的维度等于物体的总数，比如阿里的商品one hot encoding的维度就至少是千万量级的。这样的编码方式对于商品来说是极端稀疏的，甚至用multi hot encoding对用户浏览历史的编码也会是一个非常稀疏的向量。</p><p>而深度学习的特点以及工程方面的原因使其不利于稀疏特征向量的处理。因此如果能把物体编码为一个低维稠密向量再喂给DNN，自然是一个高效的基本操作。因为从梯度下降的过程来说，如果特征过于稀疏会导致整个网络收敛过慢，因为每次更新只有极少数的权重会得到更新。这样在样本有限的情况下会导致模型不收敛。而且还会导致全连接层有过多的参数。</p><p>尽管有采用relu函数等各种手段减少梯度消失现象的发生，但nn还是会存在梯度消失问题，所以到输入层的时候梯度受输出层diff的影响已经很小了因此收敛慢再加上大量稀疏特征导致一次只有个别权重更新这个现象就更严重了。对于lr来说，梯度能够直接传导到权重，因为其只有一层。倒不是说lr更适合处理大规模离散特征 而是相比nn 需要更少的数据收敛 如果数据量和时间都无限的话nn也适合处理稀疏特征。</p><h1 id="McCormick-W2V"><a href="#McCormick-W2V" class="headerlink" title="McCormick W2V"></a>McCormick W2V</h1><p><a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/" target="_blank" rel="noopener">http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/</a></p><h2 id="The-Model"><a href="#The-Model" class="headerlink" title="The Model"></a>The Model</h2><p>Word2Vec uses a trick you may have seen elsewhere in machine learning. We’re going to train a simple neural network with a single hidden layer to perform a certain task, but then we’re not actually going to use that neural network for the task we trained it on! Instead, the goal is actually just to learn the weights of the <strong>hidden layer</strong>。</p><p>We’ll train the neural network to do this by feeding it word pairs found in our training documents.The word highlighted in blue is the input word.</p><p>this is skip-gram.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/training_data.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="Model-Details"><a href="#Model-Details" class="headerlink" title="Model Details"></a>Model Details</h2><p>let’s say we have a vocabulary of 10,000 unique words.We’re going to represent an input word  as a one-hot vector. This vector will have 10,000 components.The output of the network is a single vector (also with 10,000 components) Here’s the architecture of our neural network.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/skip_gram_net_arch.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>There is <strong>no activation function</strong> on the hidden layer neurons, but the output neurons use <strong>softmax</strong>.</p><p>When training this network on word pairs, the input is a one-hot vector representing the input word and the training output is also a one-hot vector representing the output word.But when you evaluate the trained network on an input word, the output vector will actually be a probability distribution (i.e., a bunch of floating point values, not a one-hot vector).</p><h2 id="The-Hidden-Layer"><a href="#The-Hidden-Layer" class="headerlink" title="The Hidden Layer"></a>The Hidden Layer</h2><p>For our example, we’re going to say that we’re learning word vectors with 300 features. So the hidden layer is going to be represented by a weight matrix with 10,000 rows (one for every word in our vocabulary) and 300 columns (one for every hidden neuron).The number of features is a “hyper parameter” that you would just have to tune to your application .</p><p>显然，每个单词对应一个300维的隐向量，也可以理解为300维的语义。</p><p>that is why we use one-hot .<strong>右边矩阵中绿色的值即为左边矩阵中1对应的词的隐向量。</strong> 对应的，竖着的第一列即为隐藏层第一个神经元连接的上一层的神经元权重。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/matrix_mult_w_one_hot.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>just as this image.根据反向传播公式，当梯度传递到这一层时，只有非0的值才会对梯度进行更新。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%889.42.26.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>This means that the hidden layer of this model is really just operating as a <strong>lookup</strong> table. The output of the hidden layer is just the “word vector” for the input word.</p><h2 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h2><p> The skip-gram neural network contains a huge number of weights… For our example with 300 features and a vocab of 10,000 words, that’s 3M weights in the hidden layer and output layer each! Training this on a large dataset would be prohibitive, And to make matters worse, you need a huge amount of training data in order to tune that many weights and avoid over-fitting. so the word2vec authors introduced a number of tweaks to make training feasible.The first one is Negative Sampling</p><p>the innovations:</p><ol><li><strong>Subsampling</strong> frequent words to decrease the number of training examples.</li><li>Modifying the optimization objective with a technique they called “<strong>Negative Sampling</strong>”, which causes each training sample to update only a small percentage of the model’s weights.</li></ol><p>It’s worth noting that subsampling frequent words and applying Negative Sampling not only reduced the compute burden of the training process, but also improved the quality of their resulting word vectors as well.</p><h2 id="Subsampling-Frequent-Words"><a href="#Subsampling-Frequent-Words" class="headerlink" title="Subsampling Frequent Words"></a>Subsampling Frequent Words</h2><p>The word highlighted in blue is the input word.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/training_data%202.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>There are two “problems” with common words like “the”:</p><ol><li>When looking at word pairs, (“fox”, “the”) doesn’t tell us much about the meaning of “fox”. “the” appears in the context of pretty much every word.</li><li>We will have many more samples of (“the”, …) than we need to learn a good vector for “the”.</li></ol><p>Word2Vec implements a “subsampling” scheme to address this. For each word we encounter in our training text, there is a chance that we will effectively delete it from the text. The probability that we cut the word is related to the word’s frequency.</p><p>If we have a window size of 10, and we remove a specific instance of “the” from our text:</p><ol><li>As we train on the remaining words, “the” will not appear in any of their context windows.</li><li>We’ll have 10 fewer training samples where “the” is the input word.</li></ol><h3 id="Sample-rate"><a href="#Sample-rate" class="headerlink" title="Sample rate"></a>Sample rate</h3><p>wi is the word, z(wi) is the fraction of the total words in the corpus that are that word. For example, if the word “peanut” occurs 1,000 times in a 1 billion word corpus, then z(‘peanut’) = 1E-6.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%889.13.31.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%889.13.53.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>1.P(wi)=1.0 (100% chance of being kept) when z(wi)&lt;=0.0026.<br>This means that only words which represent more than 0.26% of the total words will be subsampled.<br>2.P(wi)=0.5 (50% chance of being kept) when z(wi)=0.00746.<br>3.P(wi)=0.033 (3.3% chance of being kept) when z(wi)=1.0.<br>That is, if the corpus consisted entirely of word wi, which of course is ridiculous.</p><h2 id="Negative-Sampling-1"><a href="#Negative-Sampling-1" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h2><p>Negative sampling addresses this by having each training sample only modify a small percentage of the weights, rather than all of them. Here’s how it works.</p><p>When training the network on the word pair (“fox”, “quick”), recall that the “label” or “correct output” of the network is a one-hot vector. That is, for the output neuron corresponding to “quick” to output a 1, and for all of the other thousands of output neurons to output a 0.</p><p>With negative sampling, we are instead going to randomly select just a small number of “negative” words (let’s say 5) to update the weights for. (In this context, a “negative” word is one for which we want the network to output a 0 for). We will also still update the weights for our “positive” word (which is the word “quick” in our current example).</p><p>Recall that the output layer of our model has a weight matrix that’s 300 x 10,000. So we will just be updating the weights for our positive word (“quick”), plus the weights for 5 other words that we want to output 0. That’s a total of 6 output neurons, and 1,800 weight values total. That’s only 0.06% of the 3M weights in the output layer!</p><p>In the hidden layer, only the weights for the input word are updated (this is true whether you’re using Negative Sampling or not).</p><h3 id="Selecting-Negative-Samples"><a href="#Selecting-Negative-Samples" class="headerlink" title="Selecting Negative Samples"></a>Selecting Negative Samples</h3><p>The “negative samples” (that is, the 5 output words that we’ll train to output 0) are selected using a “unigram distribution”, where more frequent words are more likely to be selected as negative samples.</p><p>For instance, suppose you had your entire training corpus as a list of words, and you chose your 5 negative samples by picking randomly from the list. In this case, the probability for picking the word “couch” would be equal to the number of times “couch” appears in the corpus, divided the total number of word occus in the corpus. This is expressed by the following equation:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%889.27.08.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>The authors state in their paper that they tried a number of variations on this equation, and the one which performed best was to raise the word counts to the 3/4 power:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-17%20%E4%B8%8A%E5%8D%889.27.29.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h2 id="Applying-word2vec-to-Recommenders-and-Advertising"><a href="#Applying-word2vec-to-Recommenders-and-Advertising" class="headerlink" title="Applying word2vec to Recommenders and Advertising"></a>Applying word2vec to Recommenders and Advertising</h2><p>The key principle behind word2vec is the notion that the meaning of a word can be inferred from it’s context–what words tend to be around it. To abstract that a bit, text is really just a sequence of words, and the meaning of a word can be extracted from what words tend to be just before and just after it in the sequence.</p><p>What researchers and companies are finding is that the time series of online user activity offers the same opportunity for inferring meaning from context. That is, as a user browses around and interacts with different content, the abstract qualities of a piece of content can be inferred from what content the user interacts with before and after. This allows ML teams to apply word vector models to learn good vector representations for products, content, and ads.</p><p>The word2vec approach has proven successful in extracting these hidden insights, and being able to compare, search, and categorize items on these abstract dimensions opens up a lot of opportunities for smarter, better recommendations. </p><h2 id="Four-Production-Examples"><a href="#Four-Production-Examples" class="headerlink" title="Four Production Examples"></a>Four Production Examples</h2><h3 id="Music-Recommendations"><a href="#Music-Recommendations" class="headerlink" title="Music Recommendations"></a>Music Recommendations</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/word2vec/Spotify_user_activity.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>One use is to create a kind of “music taste” vector for a user by averaging together the vectors for songs that a user likes to listen to. This taste vector can then become the query for a similarity search to find songs which are similar to the user’s taste vector.<br>and Listing Recommendations at Airbnb,Product Recommendations in Yahoo Mail,Matching Ads to Search Queries</p><h1 id="几篇论文"><a href="#几篇论文" class="headerlink" title="几篇论文"></a>几篇论文</h1><p> <strong>Distributed Representations of Words and Phrases and their Compositionality</strong><br>Google的Tomas Mikolov提出word2vec的两篇文章之一，这篇文章更具有综述性质，列举了NNLM、RNNLM等诸多词向量模型，但最重要的还是提出了CBOW和Skip-gram两种word2vec的模型结构。虽然词向量的研究早已有之，但不得不说还是Google的word2vec的提出让词向量重归主流，拉开了整个embedding技术发展的序幕。</p><p><strong>Efficient Estimation of Word Representations in Vector Space</strong><br>Tomas Mikolov的另一篇word2vec奠基性的文章。相比上一篇的综述，本文更详细的阐述了Skip-gram模型的细节，包括模型的具体形式和 Hierarchical Softmax和 Negative Sampling两种可行的训练方法。</p><p> <strong>Word2vec Parameter Learning Explained</strong><br>虽然Mikolov的两篇代表作标志的word2vec的诞生，但其中忽略了大量技术细节，如果希望完全读懂word2vec的原理和实现方法，比如词向量具体如何抽取，具体的训练过程等，强烈建议大家阅读UMich Xin Rong博士的这篇针对word2vec的解释性文章。惋惜的是Xin Rong博士在完成这篇文章后的第二年就由于飞机事故逝世，在此也致敬并缅怀一下Xin Rong博士。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;word2vec&quot;&gt;&lt;a href=&quot;#word2vec&quot; class=&quot;headerlink&quot; title=&quot;word2vec&quot;&gt;&lt;/a&gt;word2vec&lt;/h1&gt;&lt;p&gt;谷歌2013年提出的word2vec是目前最常用的词嵌入模型之一。Word2ec实际是一种&lt;
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>About id </title>
    <link href="https://github.com/zdkswd/2019/04/16/About%20id/"/>
    <id>https://github.com/zdkswd/2019/04/16/About id/</id>
    <published>2019-04-16T12:42:47.000Z</published>
    <updated>2019-04-17T04:35:42.947Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何利用id类特征"><a href="#如何利用id类特征" class="headerlink" title="如何利用id类特征"></a>如何利用id类特征</h1><p><a href="https://www.zhihu.com/question/34819617" target="_blank" rel="noopener">机器学习中如何利用id类特征？ - 知乎</a></p><h2 id="为什么用"><a href="#为什么用" class="headerlink" title="为什么用"></a>为什么用</h2><p>会极大提高模型的个性化能力和实际效果。而且可以对抗热度穿透现象。</p><p>直接加入id类特征，尽管并不能实现完全的个性化，但是可以把每个用户的行为模式区分开，从而提高了其他特征的泛化能力。</p><p>例如有两个id和一项特征来进行一个回归预测。一个id是正常用户，一个id是刷子用户。式子可以表示为w1x1+w2x2+w3x3=rate<br>对于正常用户rate值低，刷子用户rate值高。即w1x1+w3x3值较小，w2x2+w3x3值较大。可得是w2x2项较大即模型学习到了提高w2，对于不同的id就进行了区别对待。</p><p>加入id类特征的价值：</p><ol><li>可以使得在学习过程中每个人的信号更合理地影响整体模型，使得模型泛化能力更好。</li><li>可以使得模型能够对每个id有更细粒度的排序能力，使得模型的个性化效果更好。</li></ol><h2 id="怎么用"><a href="#怎么用" class="headerlink" title="怎么用"></a>怎么用</h2><ol><li>id类特征上的信号是及其稀疏的，所以意味着我们需要更大量的数据，但是其实这并不困难，在计算广告，推荐系统的场景下，单个id上收集的数据其实是非常多的，但是一定要通过正则化的方法来限制以使id类特征不过拟合。</li><li>id类特征在预测中的命中率可能并不高，但这其实也不是问题。因为一个特征就是一个体系，一个体系化的特征是通过层次化的特征设计来达到命中率和个性化的综合。比如说 用户id-&gt;用户GPS坐标+用户喜好Tag+用户最近行为-&gt;用户年龄，用户性别。通过分层，由最细粒度到最粗粒度的特征搭配来保证特征命中率。</li><li>组合。单独的id类特征时意义并没有那么高，有意义的是不同层次的交叉组合。userid和itemid交互后，也就是用户对物品的评分矩阵，这时候就可以使用itemcf或svd等等。</li><li>模型和算法。实际上，LR是适合使用ID类特征One-hot编码的，原因在于LR适合接受超高维度的特征输入。但是这么做的前提是训练样本足够多。对于XGBoost，DNN，就要先对id特征one-hot进行embedding。</li></ol><h1 id="Entity-Embeddings-of-Categorical-Variables"><a href="#Entity-Embeddings-of-Categorical-Variables" class="headerlink" title="Entity Embeddings of Categorical Variables"></a>Entity Embeddings of Categorical Variables</h1><p><a href="https://arxiv.org/pdf/1604.06737.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1604.06737.pdf</a></p><h2 id="Intorduction"><a href="#Intorduction" class="headerlink" title="Intorduction"></a>Intorduction</h2><p>神经网路不适合去拟合非连续的函数，因为其假定一般形式具有连续性。在训练阶段，数据的连续性保证了优化的收敛性，在预测阶段，输入值的微小变化保证了输出的稳定。另一方面，决策树不假定特征变量有任何的连续性。</p><p>有意思的是，如果我们使用了正确的表示数据的形式，在现实世界中，我们面对的问题总是连续的。每当我们找到了一个更好的方式来表示连续数据，就提升了神经网络学习数据的能力。比如NLP是由于使用了w2v去将one-hot转为了连续的向量。</p><p>不同于自然中存在的非结构化数据，机器学习中使用的结构化数据可能很难发现连续性质。神经网络连续函数的特性限制了对于类别变量的应用。embedding解决了one-hot的两个问题，一是太过稀疏，而是类与类之间没有关联。</p><p>记号：（h,r,t），h和t是两个实体，r是关系。<br>在w2v中发现隐向量具有如下的关系：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/About%20id/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%881.49.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>w2v除了使用常规的滑动窗口学习还可以使用标记进行监督学习。<br>以及说树是结构化数据中用的最多的模型。以及该方法针对的是表格数据中的离散目标值，也就是类别值。</p><h2 id="Entity-Embedding"><a href="#Entity-Embedding" class="headerlink" title="Entity Embedding"></a>Entity Embedding</h2><p>embedding层的维度D是个超参数。范围是[1,m-1]，m是类别数。在实际中，根据实验来确定最后的维度数。下面是一些经验之谈，一，大体的估计一下需要描述的维度，二如果不知道怎么下手，从m-1开始。</p><p>定义衡量两个隐向量相似度的方法。最简单的就是隐向量求距离。</p><p>a example for dimension<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/About%20id/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%882.52.30.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>原始的数据是两部分，第一部分是train.csv,包含了2.5年的每日销售数据，包括1115种不同的商店，共计有1017210条数据。第二部分是关于1115店的更详细的信息。除了主办方给出的数据，外部的数据同样重要，比如日期的天气信息，流行信息，甚至于重大比赛的日期信息。</p><h1 id="业务实践"><a href="#业务实践" class="headerlink" title="业务实践"></a>业务实践</h1><p>场景：网络购物场景中，运用W2V+BP进行个性化推荐。</p><ol><li><strong>对物品进行向量化</strong>，把每个用户看作一篇文章，用户购买物品按照时间序列排序，物品看作词，带入W2V模型得到物品的向量。</li><li><strong>样本收集</strong>，收集客户端中，对用户的物品曝光及购买记录，以用户历史购买的物品列表作为用户画像，以给用户曝光物品后用户是否购买为目标变量。</li><li><strong>构造W2V + BP的模型</strong>，模型的输入有两个，第一个为用户历史购买物品的向量均值，第二个为曝光物品的向量。模型的输出为用户是否购买曝光的物品，中间用BP网络进行连接。</li><li><strong>模型训练与使用</strong>，模型训练：目前业界一般使用TF进行实现，BP网络的节点数及层数需要根据训练情况确定。模型使用：给定一个用户u及一个物品i，把用户u购买物品向量均值及物品i的向量作为模型输入，计算物品i的模型得分。重复该操作，计算出用户u所有候选物品的模型得分，根据物品的模型得分降序推荐给用户。</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/About%20id/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%884.23.44.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;如何利用id类特征&quot;&gt;&lt;a href=&quot;#如何利用id类特征&quot; class=&quot;headerlink&quot; title=&quot;如何利用id类特征&quot;&gt;&lt;/a&gt;如何利用id类特征&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/34
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Keras:getting started</title>
    <link href="https://github.com/zdkswd/2019/04/16/Keras:getting%20started/"/>
    <id>https://github.com/zdkswd/2019/04/16/Keras:getting started/</id>
    <published>2019-04-16T12:31:32.000Z</published>
    <updated>2019-04-16T12:32:08.098Z</updated>
    
    <content type="html"><![CDATA[<h1 id="30s-to-Keras"><a href="#30s-to-Keras" class="headerlink" title="30s to Keras"></a>30s to Keras</h1><p>The core data structure of Keras is a <strong>model</strong>,The simplest type of model is the Sequential model, a linear stack of layers.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.07.41.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Stacking layers is as easy as .add():<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.10.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>the first layer should specify input_dim.</p><p>Once your model looks good, configure its learning process with .compile():<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.11.58.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.13.57.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>通过引入Momentum可以让那些因学习率太大而来回摆动的参数，梯度能前后抵消，从而阻止发散。</p><p>You can now iterate on your training data in batches:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.15.15.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Alternatively, you can feed batches to your model manually:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.15.36.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Evaluate your performance in one line:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.16.01.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Or generate predictions on new data:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.23.03.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="a-densely-connected-network"><a href="#a-densely-connected-network" class="headerlink" title="a densely-connected network"></a>a densely-connected network</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.53.43.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p><strong>notice that a layer instance is callable on a tensor,and returns a tensor.</strong></p><h1 id="All-models-are-callable-just-like-layers"><a href="#All-models-are-callable-just-like-layers" class="headerlink" title="All models are callable, just like layers"></a>All models are callable, just like layers</h1><p>With the functional API, it is easy to reuse trained models: you can treat any model as if it were a layer, by calling it on a tensor. Note that by calling a model you aren’t just reusing the architecture of the model, you are also reusing its weights.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.00.22.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>This can allow, for instance, to quickly create models that can process sequences of inputs. You could turn an image classification model into a video classification model, in just one line.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.01.10.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Multi-input-and-multi-output-models"><a href="#Multi-input-and-multi-output-models" class="headerlink" title="Multi-input and multi-output models"></a>Multi-input and multi-output models</h1><p>Here’s a good use case for the functional API: models with multiple inputs and outputs. The functional API makes it easy to manipulate a large number of intertwined datastreams.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/multi-input-multi-output-graph.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>The main input will receive the headline, as a sequence of integers (each integer encodes a word). The integers will be between 1 and 10,000 (a vocabulary of 10,000 words) and the sequences will be 100 words long.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.13.45.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Here we insert the auxiliary loss, allowing the LSTM and Embedding layer to be trained smoothly even though the main loss will be much higher in the model.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.14.57.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>At this point, we feed into the model our auxiliary input data by concatenating it with the LSTM output:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.16.01.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>This defines a model with two inputs and two outputs:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.28.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>We compile the model and assign a weight of 0.2 to the auxiliary loss. To specify different loss_weights or loss for each different output, you can use a list or a dictionary. Here we pass a single loss as the loss argument, so the same loss will be used on all outputs.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.28.39.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>We can train the model by passing it lists of input arrays and target arrays:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.28.59.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>Since our inputs and outputs are named (we passed them a “name” argument), we could also have compiled the model via:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%888.29.23.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h1><p>keras.layers.Embedding(input_dim, output_dim, embeddings_initializer=‘uniform’, embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)</p><p>This layer can only be used as the first layer in a model.<br>Example<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Keras:getting%20started/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-16%20%E4%B8%8B%E5%8D%887.27.54.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;30s-to-Keras&quot;&gt;&lt;a href=&quot;#30s-to-Keras&quot; class=&quot;headerlink&quot; title=&quot;30s to Keras&quot;&gt;&lt;/a&gt;30s to Keras&lt;/h1&gt;&lt;p&gt;The core data structure of Ker
      
    
    </summary>
    
      <category term="教程" scheme="https://github.com/zdkswd/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>转 逻辑回归LR的特征为什么要先离散化</title>
    <link href="https://github.com/zdkswd/2019/04/16/%E8%BD%AC%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92LR%E7%9A%84%E7%89%B9%E5%BE%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%85%88%E7%A6%BB%E6%95%A3%E5%8C%96/"/>
    <id>https://github.com/zdkswd/2019/04/16/转 逻辑回归LR的特征为什么要先离散化/</id>
    <published>2019-04-16T02:42:56.000Z</published>
    <updated>2019-04-16T02:43:13.399Z</updated>
    
    <content type="html"><![CDATA[<h1 id="转-逻辑回归LR的特征为什么要先离散化"><a href="#转-逻辑回归LR的特征为什么要先离散化" class="headerlink" title="转 逻辑回归LR的特征为什么要先离散化"></a>转 逻辑回归LR的特征为什么要先离散化</h1><p><a href="https://blog.csdn.net/yang090510118/article/details/39478033" target="_blank" rel="noopener">逻辑回归LR的特征为什么要先离散化 - yang090510118的专栏 - CSDN博客</a></p><p>在工业界，很少直接将连续值作为特征喂给逻辑回归模型，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：</p><ol><li>稀疏向量内积乘法运算速度快，计算结果方便存储，容易scalable（扩展）。</li><li>离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰。</li><li>逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。</li><li>离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力。</li><li>特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问。</li></ol><p>模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型” 同 “少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习。就看是喜欢折腾特征还是折腾模型了。通常来说，前者容易，而且可以n个人一起并行做，有成功经验；后者目前看很赞，能走多远还须拭目以待。</p><p>大概的理解：</p><p>1）计算简单<br>2）简化模型<br>3）增强模型的泛化能力，不易受噪声的影响</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;转-逻辑回归LR的特征为什么要先离散化&quot;&gt;&lt;a href=&quot;#转-逻辑回归LR的特征为什么要先离散化&quot; class=&quot;headerlink&quot; title=&quot;转 逻辑回归LR的特征为什么要先离散化&quot;&gt;&lt;/a&gt;转 逻辑回归LR的特征为什么要先离散化&lt;/h1&gt;&lt;p&gt;&lt;a
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>featexp</title>
    <link href="https://github.com/zdkswd/2019/04/14/featexp/"/>
    <id>https://github.com/zdkswd/2019/04/14/featexp/</id>
    <published>2019-04-14T12:15:32.000Z</published>
    <updated>2019-04-14T12:15:42.157Z</updated>
    
    <content type="html"><![CDATA[<h1 id="featexp"><a href="#featexp" class="headerlink" title="featexp"></a>featexp</h1><p><a href="https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c" target="_blank" rel="noopener">https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c</a></p><h1 id="feature-understanding"><a href="#feature-understanding" class="headerlink" title="feature understanding"></a>feature understanding</h1><p>if target is binary, scatter is not very useful.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%885.41.15.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>And for continuous target, too many data points make it difficult to understand the target vs. feature trend.</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%885.52.05.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>use above code,Featexp creates <strong>equal population bins (X-axis)</strong> of a numeric feature.It then calculates target’s <strong>mean</strong> in each bin and plots it in the left-hand side plot above. As you can see the plot on the right shows they are the same number.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%885.54.45.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Identifying-noisy-features"><a href="#Identifying-noisy-features" class="headerlink" title="Identifying noisy features"></a>Identifying noisy features</h1><p>Noisy features lead to overfitting and identifying them isn’t easy. In featexp, you can pass a test set and compare feature trends in train|test to identify noisy ones. This test set is not the actual test set. Its your local test set|validation set for which you know target.</p><blockquote><p>get_univariate_plots(data=data_train, target_col=’target’, data_test=data_test, features_list=[‘DAYS_EMPLOYED’])  </p></blockquote><p><img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%886.10.12.png" alt=""><br>Featexp calculates two metrics to display on these plots which help with gauging(计量；测量) noisiness:</p><p>1.<strong>Trend correlation</strong> (seen in test plot): If a feature doesn’t hold same trend w.r.t. target across train and evaluation sets, it can lead to overfitting. This happens because the model is learning something which is not applicable in test data. Trend correlation helps understand how similar train/test trends are and mean target values for bins in train &amp; test are used to calculate it. Feature above has 99% correlation. Doesn’t seem noisy!<br>2.<strong>Trend changes</strong>: Sudden and repeated changes in trend direction could imply noisiness. But, such trend change can also happen because that bin has a very different value in terms of <strong>other features</strong> and hence, its value can’t really be compared with other bins.</p><p>for example the nosiy feature.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%886.37.26.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>Dropping low trend-correlation features works well when <strong>there are a lot of features and they are correlated with each other</strong>. It leads to less overfitting and other correlated features avoid information loss. It’s also important to <strong>not drop too many important features</strong> as it might lead to a drop in performance. Also, <strong>you can’t identify these noisy features using feature importance</strong> because they could be fairly important and still be very noisy!</p><p><strong>Using test data from a different time period works better because then you would be making sure if feature trend holds over time.</strong></p><p><strong>get_trend_stats()</strong> function in featexp returns a dataframe with trend correlation and changes for each feature.</p><blockquote><p>from featexp import get_trend_stats  stats=get_trend_stats(data=data_train,target_col=’target’,data_test=data_test)  </p></blockquote><p><img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%886.54.44.png" alt=""><br> try dropping features with low trend-correlation in our data and see how results improve.<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%886.56.50.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>We can see that higher the trend-correlation threshold to drop features, higher is the leaderboard (LB) AUC.</p><h1 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h1><p>The insights that you get by looking at these plots help with creating better features. Just having a better understanding of data can lead to better feature engineering. But, in addition to this, it can also help you in improving the existing features. Let’s look at another feature EXT_SOURCE_1:<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/featexp/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-14%20%E4%B8%8B%E5%8D%887.10.11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h1 id="Feature-importance"><a href="#Feature-importance" class="headerlink" title="Feature importance"></a>Feature importance</h1><p>i choose xgboost this part.</p><h1 id="Feature-debugging"><a href="#Feature-debugging" class="headerlink" title="Feature debugging"></a>Feature debugging</h1><p>check the trend is or not as you wish.</p><h1 id="Leakage-Detection"><a href="#Leakage-Detection" class="headerlink" title="Leakage Detection"></a>Leakage Detection</h1><h1 id="Model-Monitoring"><a href="#Model-Monitoring" class="headerlink" title="Model Monitoring"></a>Model Monitoring</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;featexp&quot;&gt;&lt;a href=&quot;#featexp&quot; class=&quot;headerlink&quot; title=&quot;featexp&quot;&gt;&lt;/a&gt;featexp&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/my-secret-
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>美团  特征提取</title>
    <link href="https://github.com/zdkswd/2019/04/14/%E7%BE%8E%E5%9B%A2%20%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    <id>https://github.com/zdkswd/2019/04/14/美团  特征提取/</id>
    <published>2019-04-14T08:33:47.000Z</published>
    <updated>2019-04-14T08:33:37.891Z</updated>
    
    <content type="html"><![CDATA[<h1 id="美团-特征提取"><a href="#美团-特征提取" class="headerlink" title="美团  特征提取"></a>美团  特征提取</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BE%8E%E5%9B%A2%20%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/WechatIMG77.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/%E7%BE%8E%E5%9B%A2%20%20%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/WechatIMG76.jpeg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;美团-特征提取&quot;&gt;&lt;a href=&quot;#美团-特征提取&quot; class=&quot;headerlink&quot; title=&quot;美团  特征提取&quot;&gt;&lt;/a&gt;美团  特征提取&lt;/h1&gt;&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div 
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle竞赛案例一</title>
    <link href="https://github.com/zdkswd/2019/04/14/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/"/>
    <id>https://github.com/zdkswd/2019/04/14/Kaggle竞赛案例一/</id>
    <published>2019-04-14T07:37:47.000Z</published>
    <updated>2019-04-14T07:44:25.371Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kaggle-CrowdFlower"><a href="#Kaggle-CrowdFlower" class="headerlink" title="Kaggle_CrowdFlower"></a>Kaggle_CrowdFlower</h1><p><a href="https://github.com/ChenglongChen/Kaggle_CrowdFlower">GitHub - ChenglongChen/Kaggle_CrowdFlower: 1st Place Solution for Search Results Relevance Competition on Kaggle (https://www.kaggle.com/c/crowdflower-search-relevance)</a><br>1st Place Solution for Search Results Relevance Competition on Kaggle<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/FlowChart.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>问题描述：搜索结果相关挑战，给定搜索结果，搜索出的产品名称，产品描述，建立模型去预测搜索结果的相关得分。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>解决方案分为两部分：特征工程和模型集成。</p><p>特征包括三部分的特征：<br>1.计数特征<br>2.距离特征<br>3.TF-IDF特征</p><p>在生产特征前，对数据进行拼写检查，同义词替换，词干提取是非常有用的。模型集成包括两个主要的步骤，首先，使用不同种，不同参数设置，不同特征子集去训练模型。然后使用训练的模型进行bagged集成选择。在训练集上使用交叉验证来评估表现。</p><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>进行了几步去清洗文本。</p><h2 id="去除HTML标签"><a href="#去除HTML标签" class="headerlink" title="去除HTML标签"></a>去除HTML标签</h2><p>在商品描述中存在html标签的干扰，使用bs4去除之。</p><h2 id="单词替换"><a href="#单词替换" class="headerlink" title="单词替换"></a>单词替换</h2><p>在搜索中会出现词义相关的搜索，要考虑到。<br>1.拼写纠正<br>2.同义词替换<br>3.词干提取</p><h2 id="特征提取-选择"><a href="#特征提取-选择" class="headerlink" title="特征提取/选择"></a>特征提取/选择</h2><p>$$\left(q_{i}, t_{i}, d_{i}\right)$$是train.csv以及test.csv中的第i个样本，qi是查询，ti是产品名，di是产品描述。使用ri和vi来表示<strong>median_relevance</strong>和<strong>relevance_variance</strong>。使用函数ngram(s,n)去提取句子中的n个词。例如<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.09.02.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h3 id="计数特征"><a href="#计数特征" class="headerlink" title="计数特征"></a>计数特征</h3><p>为$$\left{q_{i}, t_{i}, d_{i}\right}$$生成计数特征。</p><h4 id="基础计数特征"><a href="#基础计数特征" class="headerlink" title="基础计数特征"></a>基础计数特征</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.17.52.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h4 id="交叉计数特征"><a href="#交叉计数特征" class="headerlink" title="交叉计数特征"></a>交叉计数特征</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.20.07.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h4 id="交叉位置特征"><a href="#交叉位置特征" class="headerlink" title="交叉位置特征"></a>交叉位置特征</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.23.08.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="距离特征"><a href="#距离特征" class="headerlink" title="距离特征"></a>距离特征</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%883.24.35.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="TF-IDF特征"><a href="#TF-IDF特征" class="headerlink" title="TF-IDF特征"></a>TF-IDF特征</h3><h3 id="其他特征"><a href="#其他特征" class="headerlink" title="其他特征"></a>其他特征</h3><h4 id="查询ID"><a href="#查询ID" class="headerlink" title="查询ID"></a>查询ID</h4><p>将查询id进行独热编码。</p><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>相同的模型经常被用来在特征集上进行交叉验证来测试与之前的特征集合相比是否得分有所提升。对于高维特征，使用XGBoost with linear booster(MSE为目标函数)，对于低维特征使用sklearn中的ExtraTreesRegressor。</p><p>值得注意的是，有了集成选择(<strong>ensemble selection</strong>)，我们可以利用不同的特征集合来训练特征库，并且利用集成选择去挑选出最佳的集成。但是特征选择依旧有用。使用上述的特征选择，可以首先明确一些表现好的特征集合，然后使用其去训练模型，这会在一定程度上减少计算负担。</p><h2 id="模型技术和训练"><a href="#模型技术和训练" class="headerlink" title="模型技术和训练"></a>模型技术和训练</h2><h3 id="交叉验证方法学"><a href="#交叉验证方法学" class="headerlink" title="交叉验证方法学"></a>交叉验证方法学</h3><h4 id="划分"><a href="#划分" class="headerlink" title="划分"></a>划分</h4><p>StratifiedKFold</p><h1 id="Kaggle-HomeDepot"><a href="#Kaggle-HomeDepot" class="headerlink" title="Kaggle_HomeDepot"></a>Kaggle_HomeDepot</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/FlowChart%202.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="Kaggle——销售量预测"><a href="#Kaggle——销售量预测" class="headerlink" title="Kaggle——销售量预测"></a>Kaggle——销售量预测</h1><p>比赛地址<a href="https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data" target="_blank" rel="noopener">Predict Future Sales | Kaggle</a><br>这个比赛作为经典的时间序列问题之一，目标是为了预测下个月每种产品和商店的总销售额。</p><p>以下为<strong>1st solution</strong>。</p><h2 id="part1-hands-on-data"><a href="#part1-hands-on-data" class="headerlink" title="part1 hands on data"></a>part1 hands on data</h2><p><a href="https://www.kaggle.com/kyakovlev/1st-place-solution-part-1-hands-on-data/notebook" target="_blank" rel="noopener">https://www.kaggle.com/kyakovlev/1st-place-solution-part-1-hands-on-data/notebook</a></p><h3 id="数据域含义"><a href="#数据域含义" class="headerlink" title="数据域含义"></a>数据域含义</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%888.55.03.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>数据集情况：<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%889.04.04.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%889.04.46.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h3 id="trick1"><a href="#trick1" class="headerlink" title="trick1"></a>trick1</h3><p><strong>downcasting DataFrame.</strong> It will save some memory, everyone will need all memory possible.</p><p>In this case from 134.4MB to 61.6 MB</p><h3 id="trick2"><a href="#trick2" class="headerlink" title="trick2"></a>trick2</h3><p>pd.pivot_table()透视表功能<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-12%20%E4%B8%8B%E5%8D%888.52.35.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><h3 id="trick3"><a href="#trick3" class="headerlink" title="trick3"></a>trick3</h3><p>利用图像去除极端值<br>使用<strong>seaborn</strong>。boxplot</p><h3 id="item-id"><a href="#item-id" class="headerlink" title="item_id"></a>item_id</h3><p>以item_id为索引，月份为列名生成表格来观察数据。<br>分析每个月销售的总和的趋势。<br>分析每个平均一个商品销售的趋势（和👆趋势一致）<br>查看有多少6个月来没有销售记录的商品<br>查看测试数据中有多少这样过期的商品<br>查看价格和销售额的离群点</p><p>可能的特征：</p><ol><li>时间间隔</li><li>商品放出的日期</li><li>上月的销售</li><li>销售的日期</li><li>临近的商品（id1000与1001的商品可能有所相似）</li></ol><h3 id="shop-id"><a href="#shop-id" class="headerlink" title="shop_id"></a>shop_id</h3><p>以shop_id为索引，月份为列名生成表格来观察数据。<br>查看最近开张的商店数<br>查看最近倒闭的商店数</p><p>可能的特征：</p><ol><li>时间间隔（shop_id/shp_cnt_mth）</li><li>开业月份（可能的开业促销活动）</li><li>倒闭月份（可能的清仓大甩卖）<h3 id="price"><a href="#price" class="headerlink" title="price"></a>price</h3>可能的特征：</li><li>价格分档（1/10/20/等等），显然，更低价的物品拥有着更大的销量。</li><li>打折和打折期间</li><li>价格的时间间隔（显示打折）</li><li>价格修正</li><li>店铺的收入<h3 id="dates"><a href="#dates" class="headerlink" title="dates"></a>dates</h3>可能的日期特征：</li><li>周末和假期的销售额（去修正月度的销售）</li><li>该月有几天（去修正月度的销售）</li><li>是第几个月（与季节性的物品有关）</li></ol><h3 id="shop-info"><a href="#shop-info" class="headerlink" title="shop info"></a>shop info</h3><p>shop city | shop type | shop name</p><p>可能的商店特征：</p><ol><li>shop city</li><li>shop type</li></ol><h3 id="items-csv"><a href="#items-csv" class="headerlink" title="items.csv"></a>items.csv</h3><p>从items.csv中挖掘特征<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%883.18.54.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>可能的特征，1.item name 2.Encoded aditional feature</p><h3 id="category-csv"><a href="#category-csv" class="headerlink" title="category.csv"></a>category.csv</h3><p>category.csv中满足的格式<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%883.25.09.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><br>可能的种类特征：</p><ol><li>部分</li><li>主要种类的名字</li><li>主要子种类的名字</li><li>第二子种类的名字</li></ol><h3 id="test-set"><a href="#test-set" class="headerlink" title="test set"></a>test set</h3><p>对测试数据集进行分析<br>将测试条目分为三组：</p><ol><li>Item/shop pairs that are in train</li><li>Items without any data</li><li>Items that are in train</li></ol><h1 id="Kaggle——销售量预测-1"><a href="#Kaggle——销售量预测-1" class="headerlink" title="Kaggle——销售量预测"></a>Kaggle——销售量预测</h1><p>没有看错，接下来是另一个solution<br>主要是Feature Engineering，XGBoost<br><a href="https://www.kaggle.com/dlarionov/feature-engineering-xgboost" target="_blank" rel="noopener">https://www.kaggle.com/dlarionov/feature-engineering-xgboost</a></p><h2 id="part1-，perfect-features"><a href="#part1-，perfect-features" class="headerlink" title="part1 ，perfect features"></a>part1 ，perfect features</h2><p>同样使用sns 显示后，去除离群点<br>其中有一个物品的价格是负，使用价格中位数来替换之。<br>根据名字来看有些商店id重复出现了，fix it。<br>对于商店，种类，物品进行预处理</p><h3 id="Monthly-sales"><a href="#Monthly-sales" class="headerlink" title="Monthly sales"></a>Monthly sales</h3><p>新增特征revenue：<br>train[‘revenue’] = train[‘item_price’] *  train[‘item_cnt_day’]</p><p>测试集是34个月中一些商店和一些物品的组合，共有5100 items * 42 shops = 2142400对组合。363个物品在训练集中是没有的。因此，对于大多数测试集中的物品目标值应该是0.另一个方面，训练集只包含过去售出或者退回的对。主要的思路是计算月度的销售将其在当月的对中用0值进行扩展。这样训练数据将会与测试数据相似。</p><p>将训练集中的 shop/item对去聚合去计算目标聚合，然后将目标值截取为（0，20），这样训练目标值将会与测试预测相似。</p><h3 id="测试集"><a href="#测试集" class="headerlink" title="测试集"></a>测试集</h3><p>将测试集的月份设置为34，并与训练集进行合并</p><h3 id="Shops-Items-Cats-features"><a href="#Shops-Items-Cats-features" class="headerlink" title="Shops/Items/Cats features"></a>Shops/Items/Cats features</h3><p>将shop，item，item_category表进行合并</p><h3 id="Traget-lags"><a href="#Traget-lags" class="headerlink" title="Traget lags"></a>Traget lags</h3><p>相当于将窗口移动，[0,33]，lags为1则为[1,33]</p><h3 id="均值编码特征"><a href="#均值编码特征" class="headerlink" title="均值编码特征"></a>均值编码特征</h3><p>表格的特征的命名形式为  feature1_feature2_avg_feature_cnt<br>意思为选定feature1,feature2,来聚合feature_cnt求均值。<br>求每个月中物品售出的均值数 0.3左右<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%888.09.49.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>求每个月中每个物品所对应的均值（可以理解为平均每家商店售出的值）<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%888.11.42.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>选定date_block_num，shop_id，在item_cnt_month聚合求均值<br>可以理解为一个月一家店销售物品数量的均值数<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/media/Kaggle%E7%AB%9E%E8%B5%9B%E6%A1%88%E4%BE%8B%E4%B8%80/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-04-13%20%E4%B8%8B%E5%8D%888.27.11.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure></p><p>同理还有：<br>选定date_block_num，item_category_id，在item_cnt_month聚合求均值<br>选定date_block_num，item_category_id，shop_id，在item_cnt_month聚合求均值<br>选定date_block_num，type_code，shop_id，在item_cnt_month聚合求均值<br>选定date_block_num，subtype_code，shop_id，在item_cnt_month聚合求均值<br>选定date_block_num，city_code，在item_cnt_month聚合求均值<br>选定date_block_num，city_code，item_id 在item_cnt_month聚合求均值<br>选定date_block_num，type_code 在item_cnt_month聚合求均值<br>选定date_block_num，subtype_code 在item_cnt_month聚合求均值</p><h3 id="trend-features"><a href="#trend-features" class="headerlink" title="trend features"></a>trend features</h3><p>上六个月的价格趋势。<br>上个月的商店的营收趋势。</p><h3 id="Special-features"><a href="#Special-features" class="headerlink" title="Special features"></a>Special features</h3><p>将月份中添加上天数</p><p>对于每个shop/item对上一笔销售的月，使用编程方法实现：<br>创建HashTable键值等于{shop_id,item_id},值等于date_block_num。对于数据表从上往下迭代。如果{row.shop_id,row.item_id}不在表中，则添加进表中，并将值设为row.date_block_num。如果HashTable中包含值，则计算cached value与row.date_block_num。</p><p>Months since the first sale for each shop/item pair and for item only.</p><h3 id="最终准备"><a href="#最终准备" class="headerlink" title="最终准备"></a>最终准备</h3><p>Because of the using 12 as lag value drop first 12 months. Also drop all the columns with this month calculated values (other words which can not be calcucated for the test set).</p><p>Producing lags brings a lot of nulls.</p><h2 id="part2-xgboost"><a href="#part2-xgboost" class="headerlink" title="part2 ,xgboost"></a>part2 ,xgboost</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Kaggle-CrowdFlower&quot;&gt;&lt;a href=&quot;#Kaggle-CrowdFlower&quot; class=&quot;headerlink&quot; title=&quot;Kaggle_CrowdFlower&quot;&gt;&lt;/a&gt;Kaggle_CrowdFlower&lt;/h1&gt;&lt;p&gt;&lt;a hre
      
    
    </summary>
    
      <category term="知识总结" scheme="https://github.com/zdkswd/categories/%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="机器学习" scheme="https://github.com/zdkswd/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
